pub mod prelude_category_pipeline_impls { pub mod ast_reconstruction_functor { use anyhow :: Result ; use std :: pin :: Pin ; use std :: future :: Future ; use std :: boxed :: Box ; use crate :: measurement ; use pipeline_traits :: { PipelineFunctor , ValidatedFile } ; pub struct AstReconstructionFunctor ; impl PipelineFunctor < ValidatedFile , String > for AstReconstructionFunctor { fn map < 'writer > (& 'writer self , writer : & 'writer mut (impl tokio :: io :: AsyncWriteExt + Unpin + Send) , input : ValidatedFile ,) -> Pin < Box < dyn Future < Output = Result < String > > + Send + 'writer > > { Box :: pin (async move { measurement :: record_function_entry ("AstReconstructionFunctor::map" ,) ; let ValidatedFile (source_code , dataset_path) = input ; writer . write_all (:: alloc :: __export :: must_use ({ :: alloc :: fmt :: format (format_args ! ("--- Stage 5: AST Reconstruction from Hugging Face Dataset (Mock) ---\n" ,) ,) }) . as_bytes () ,) . await ? ; writer . write_all (:: alloc :: __export :: must_use ({ :: alloc :: fmt :: format (format_args ! ("  -> Dataset path: {0:#?}\n" , dataset_path) ,) }) . as_bytes () ,) . await ? ; writer . write_all (:: alloc :: __export :: must_use ({ :: alloc :: fmt :: format (format_args ! ("  -> Returning original source code as mock reconstruction.\n" ,) ,) }) . as_bytes () ,) . await ? ; let __result = Ok (source_code) ; measurement :: record_function_exit ("AstReconstructionFunctor::map" ,) ; __result }) } } } pub mod inspect_functor { use anyhow :: Result ; use std :: fmt :: Debug ; use std :: pin :: Pin ; use std :: future :: Future ; use std :: boxed :: Box ; use pipeline_traits :: PipelineFunctor ; pub struct InspectFunctor < 'a , T : Debug > { label : & 'a str , _phantom : std :: marker :: PhantomData < T > , } impl < 'a , T : Debug > InspectFunctor < 'a , T > { pub fn new (label : & 'a str) -> Self { InspectFunctor { label , _phantom : std :: marker :: PhantomData , } } } impl < 'a , T : Debug + Clone + Send + Sync + 'static > PipelineFunctor < T , T > for InspectFunctor < 'a , T > { fn map < 'writer > (& 'writer self , writer : & 'writer mut (impl tokio :: io :: AsyncWriteExt + Unpin + Send) , input : T ,) -> Pin < Box < dyn Future < Output = Result < T > > + Send + 'writer > > { Box :: pin (async move { writer . write_all (:: alloc :: __export :: must_use ({ :: alloc :: fmt :: format (format_args ! ("--- Inspecting: {0} ---\n" , self . label) ,) }) . as_bytes () ,) . await ? ; writer . write_all (:: alloc :: __export :: must_use ({ :: alloc :: fmt :: format (format_args ! ("{0:#?}\n" , input)) }) . as_bytes () ,) . await ? ; Ok (input) }) } } } pub mod extract_uses_functor { use anyhow :: { Context , Result } ; use std :: pin :: Pin ; use std :: future :: Future ; use std :: boxed :: Box ; use crate :: measurement ; use crate :: code_generator ; use pipeline_traits :: { PipelineFunctor , ParsedFile , UseStatements } ; use syn ; pub struct ExtractUsesFunctor ; impl PipelineFunctor < ParsedFile , UseStatements > for ExtractUsesFunctor { fn map < 'writer > (& 'writer self , _writer : & 'writer mut (impl tokio :: io :: AsyncWriteExt + Unpin + Send) , input : ParsedFile ,) -> Pin < Box < dyn Future < Output = Result < UseStatements > > + Send + 'writer > , > { Box :: pin (async move { measurement :: record_function_entry ("ExtractUsesFunctor::map") ; let ParsedFile (source_code , _) = input ; let use_statements = tokio :: task :: spawn_blocking (move | | -> anyhow :: Result < _ , > { let ast = syn :: parse_file (& source_code) . context ("Failed to parse source code for use statement extraction" ,) ? ; let mut use_statements = Vec :: new () ; for item in ast . items { if let syn :: Item :: Use (use_item) = item { use_statements . push (code_generator :: use_item_to_string (& use_item)) ; } } Ok (UseStatements (use_statements)) }) . await . context ("Blocking task for extracting use statements failed" ,) ? ? ; measurement :: record_function_exit ("ExtractUsesFunctor::map") ; Ok (use_statements) }) } } } pub mod classify_uses_functor { use anyhow :: Result ; use std :: pin :: Pin ; use std :: future :: Future ; use std :: boxed :: Box ; use std :: collections :: HashMap ; use crate :: measurement ; use pipeline_traits :: { PipelineFunctor , UseStatements , ClassifiedUseStatements , UseStatement , } ; use syn ; pub struct ClassifyUsesFunctor ; impl PipelineFunctor < UseStatements , ClassifiedUseStatements > for ClassifyUsesFunctor { fn map < 'writer > (& 'writer self , _writer : & 'writer mut (impl tokio :: io :: AsyncWriteExt + Unpin + Send) , input : UseStatements ,) -> Pin < Box < dyn Future < Output = Result < ClassifiedUseStatements > , > + Send + 'writer , > , > { Box :: pin (async move { measurement :: record_function_entry ("ClassifyUsesFunctor::map") ; let UseStatements (use_statements) = input ; let mut classified_uses = Vec :: new () ; for use_statement in use_statements { let mut current_use_statement = UseStatement { statement : use_statement . clone () , error : None , git_details : None , nix_details : None , rust_details : None , cargo_details : None , syn_details : None , llvm_details : None , linux_details : None , } ; if use_statement . contains ("git") { current_use_statement . git_details = Some (pipeline_traits :: GitDetails :: Info (pipeline_traits :: GitInfo { repo_url : "inferred_from_use" . to_string () , branch : "inferred_from_use" . to_string () , commit_hash : "inferred_from_use" . to_string () , }) ,) ; } if use_statement . contains ("nix") { current_use_statement . nix_details = Some (pipeline_traits :: NixDetails :: Info (pipeline_traits :: NixInfo { flake_path : "inferred_from_use" . to_string () , output_type : "inferred_from_use" . to_string () , }) ,) ; } if use_statement . contains ("rust") || use_statement . contains ("std") || use_statement . contains ("core") { current_use_statement . rust_details = Some (pipeline_traits :: RustDetails :: Info (pipeline_traits :: RustDetailsInfo { version : "inferred_from_use" . to_string () , crate_name : "inferred_from_use" . to_string () , item_path : "inferred_from_use" . to_string () , }) ,) ; } if use_statement . contains ("cargo") { current_use_statement . cargo_details = Some (pipeline_traits :: CargoDetails :: Info (pipeline_traits :: CargoInfo { package_name : "inferred_from_use" . to_string () , version : "inferred_from_use" . to_string () , }) ,) ; } if use_statement . contains ("syn") { current_use_statement . syn_details = Some (pipeline_traits :: SynDetails :: Info (pipeline_traits :: SynInfo { parsed_type : "ItemUse" . to_string () , version : "inferred_from_use" . to_string () , }) ,) ; } if use_statement . contains ("llvm") { current_use_statement . llvm_details = Some (pipeline_traits :: LlvmDetails :: Info (pipeline_traits :: LlvmInfo { ir_version : "inferred_from_use" . to_string () , target_triple : "inferred_from_use" . to_string () , }) ,) ; } if use_statement . contains ("linux") { current_use_statement . linux_details = Some (pipeline_traits :: LinuxDetails :: Info (pipeline_traits :: LinuxInfo { kernel_version : "inferred_from_use" . to_string () , architecture : "inferred_from_use" . to_string () , }) ,) ; } match syn :: parse_str :: < syn :: ItemUse > (& use_statement) { Ok (_) => { } Err (e) => { current_use_statement . error = Some (e . to_string ()) ; } } classified_uses . push (current_use_statement) ; } let __result = Ok (ClassifiedUseStatements (classified_uses , HashMap :: new ()) ,) ; measurement :: record_function_exit ("ClassifyUsesFunctor::map") ; __result }) } } } pub mod preprocess_functor { use anyhow :: Result ; use std :: pin :: Pin ; use std :: future :: Future ; use std :: boxed :: Box ; use std :: collections :: HashMap ; use crate :: measurement ; use pipeline_traits :: { PipelineFunctor , ClassifiedUseStatements , UseStatement , } ; pub struct PreprocessFunctor ; impl PipelineFunctor < ClassifiedUseStatements , ClassifiedUseStatements > for PreprocessFunctor { fn map < 'writer > (& 'writer self , _writer : & 'writer mut (impl tokio :: io :: AsyncWriteExt + Unpin + Send) , input : ClassifiedUseStatements ,) -> Pin < Box < dyn Future < Output = Result < ClassifiedUseStatements > , > + Send + 'writer , > , > { Box :: pin (async move { measurement :: record_function_entry ("PreprocessFunctor::map") ; let ClassifiedUseStatements (classified_uses , _) = input ; let mut new_classified_uses = Vec :: new () ; for use_statement in classified_uses { if use_statement . error . is_some () { let temp_dir = tempfile :: tempdir () ? ; let temp_file_path = temp_dir . path () . join ("main.rs") ; let content = :: alloc :: __export :: must_use ({ :: alloc :: fmt :: format (format_args ! ("{0}\nfn main() {{}}" , use_statement . statement) ,) }) ; tokio :: fs :: write (& temp_file_path , content) . await ? ; let output = tokio :: process :: Command :: new ("rustc") . arg (& temp_file_path) . output () . await ? ; if output . status . success () { new_classified_uses . push (UseStatement { statement : use_statement . statement , error : None , git_details : None , nix_details : None , rust_details : None , cargo_details : None , syn_details : None , llvm_details : None , linux_details : None , }) ; } else { new_classified_uses . push (UseStatement { statement : use_statement . statement , error : Some (String :: from_utf8_lossy (& output . stderr) . to_string () ,) , git_details : None , nix_details : None , rust_details : None , cargo_details : None , syn_details : None , llvm_details : None , linux_details : None , }) ; } } else { new_classified_uses . push (UseStatement { statement : use_statement . statement , error : use_statement . error , git_details : use_statement . git_details , nix_details : use_statement . nix_details , rust_details : use_statement . rust_details , cargo_details : use_statement . cargo_details , syn_details : use_statement . syn_details , llvm_details : use_statement . llvm_details , linux_details : use_statement . linux_details , }) ; } } let __result = Ok (ClassifiedUseStatements (new_classified_uses , HashMap :: new ()) ,) ; measurement :: record_function_exit ("PreprocessFunctor::map") ; __result }) } } } pub mod hugging_face_validator_functor { use anyhow :: { Context , Result } ; use std :: path :: PathBuf ; use std :: pin :: Pin ; use std :: future :: Future ; use std :: boxed :: Box ; use crate :: measurement ; use pipeline_traits :: { PipelineFunctor , ParsedFile , ValidatedFile } ; use indoc :: indoc ; use tempfile :: tempdir ; use super :: utils :: copy_dir_all ; pub struct HuggingFaceValidatorFunctor { pub args : crate :: Args , pub hf_validator_path : Option < PathBuf > , } impl PipelineFunctor < ParsedFile , ValidatedFile > for HuggingFaceValidatorFunctor { fn map < 'writer > (& 'writer self , writer : & 'writer mut (impl tokio :: io :: AsyncWriteExt + Unpin + Send) , input : ParsedFile ,) -> Pin < Box < dyn Future < Output = Result < ValidatedFile > > + Send + 'writer > , > { Box :: pin (async move { measurement :: record_function_entry ("HuggingFaceValidatorFunctor::map" ,) ; let ParsedFile (source_code , original_file_path) = input ; use std :: hash :: { Hash , Hasher } ; use std :: collections :: hash_map :: DefaultHasher ; let mut hasher = DefaultHasher :: new () ; original_file_path . hash (& mut hasher) ; let short_id = :: alloc :: __export :: must_use ({ :: alloc :: fmt :: format (format_args ! ("{0:x}" , hasher . finish ())) }) ; writer . write_all (:: alloc :: __export :: must_use ({ :: alloc :: fmt :: format (format_args ! ("  -> Short ID for hf-validator project: {0}\n" , short_id ,) ,) }) . as_bytes () ,) . await ? ; let hf_validator_project_dir = PathBuf :: from (:: alloc :: __export :: must_use ({ :: alloc :: fmt :: format (format_args ! ("generated/hf_validator_projects/{0}" , short_id ,) ,) }) ,) ; tokio :: fs :: create_dir_all (& hf_validator_project_dir) . await ? ; let source_file_path = hf_validator_project_dir . join ("main.rs") ; tokio :: fs :: write (& source_file_path , source_code . as_bytes ()) . await . context ("Failed to write source code to persistent file") ? ; let cargo_toml_content = r#"[package]
name = "temp_hf_project"
version = "0.1.0"
edition = "2021"

[[bin]]
name = "temp_hf_project"
path = "main.rs"

[dependencies]
anyhow = "1.0"
tokio = { version = "1", features = ["full"] }

[workspace]
"# ; tokio :: fs :: write (hf_validator_project_dir . join ("Cargo.toml") , cargo_toml_content ,) . await ? ; let output = tokio :: process :: Command :: new ("git") . arg ("init") . current_dir (& hf_validator_project_dir) . output () . await . context ("Failed to initialize git repository") ? ; if ! output . status . success () { return Err (:: anyhow :: Error :: msg (:: alloc :: __export :: must_use ({ :: alloc :: fmt :: format (format_args ! ("git init failed: {0}" , String :: from_utf8_lossy (& output . stderr) ,) ,) }) ,) ,) ; } let output = tokio :: process :: Command :: new ("git") . arg ("config") . arg ("user.email") . arg ("test@example.com") . current_dir (& hf_validator_project_dir) . output () . await . context ("Failed to configure git user email") ? ; if ! output . status . success () { return Err (:: anyhow :: Error :: msg (:: alloc :: __export :: must_use ({ :: alloc :: fmt :: format (format_args ! ("git config user.email failed: {0}\nStderr: {1}" , String :: from_utf8_lossy (& output . status . code () . unwrap_or (- 1) . to_string () . as_bytes () ,) , String :: from_utf8_lossy (& output . stderr) ,) ,) }) ,) ,) ; } let output = tokio :: process :: Command :: new ("git") . arg ("config") . arg ("user.name") . arg ("Test User") . current_dir (& hf_validator_project_dir) . output () . await . context ("Failed to configure git user name") ? ; if ! output . status . success () { return Err (:: anyhow :: Error :: msg (:: alloc :: __export :: must_use ({ :: alloc :: fmt :: format (format_args ! ("git config user.name failed: {0}\nStderr: {1}" , String :: from_utf8_lossy (& output . status . code () . unwrap_or (- 1) . to_string () . as_bytes () ,) , String :: from_utf8_lossy (& output . stderr) ,) ,) }) ,) ,) ; } let output = tokio :: process :: Command :: new ("git") . arg ("commit") . arg ("--allow-empty") . arg ("-m") . arg ("Initial empty commit") . current_dir (& hf_validator_project_dir) . output () . await . context ("Failed to make initial empty git commit") ? ; if ! output . status . success () { return Err (:: anyhow :: Error :: msg (:: alloc :: __export :: must_use ({ :: alloc :: fmt :: format (format_args ! ("git commit --allow-empty failed: {0}\nStderr: {1}" , String :: from_utf8_lossy (& output . status . code () . unwrap_or (- 1) . to_string () . as_bytes () ,) , String :: from_utf8_lossy (& output . stderr) ,) ,) }) ,) ,) ; } let temp_output_dir = tempdir () . context ("Failed to create temporary output directory") ? ; let output_path = temp_output_dir . path () . to_path_buf () ; let hf_validator_executable = self . hf_validator_path . clone () . unwrap_or_else (| | { self . args . path . join ("target/release/hf-validator") }) ; writer . write_all (:: alloc :: __export :: must_use ({ :: alloc :: fmt :: format (format_args ! ("  -> Executing hf-validator: {0:#?}\n" , hf_validator_executable ,) ,) }) . as_bytes () ,) . await ? ; if let Some (path_env) = std :: env :: var_os ("PATH") { writer . write_all (:: alloc :: __export :: must_use ({ :: alloc :: fmt :: format (format_args ! ("  -> PATH: {0:#?}\n" , path_env) ,) }) . as_bytes () ,) . await ? ; } if let Some (ld_library_path_env) = std :: env :: var_os ("LD_LIBRARY_PATH" ,) { writer . write_all (:: alloc :: __export :: must_use ({ :: alloc :: fmt :: format (format_args ! ("  -> LD_LIBRARY_PATH: {0:#?}\n" , ld_library_path_env ,) ,) }) . as_bytes () ,) . await ? ; } let status = tokio :: process :: Command :: new (hf_validator_executable . to_str () . unwrap () ,) . current_dir (& self . args . path) . envs (std :: env :: vars_os ()) . arg ("analyze-rust-to-ir") . arg (hf_validator_project_dir . as_os_str ()) . arg (output_path . as_os_str ()) . status () . await . context ("Failed to execute hf-validator command") ? ; if ! status . success () { return Err (:: anyhow :: Error :: msg (:: alloc :: __export :: must_use ({ :: alloc :: fmt :: format (format_args ! ("hf-validator command failed with status: {0}" , status ,) ,) }) ,) ,) ; } writer . write_all (:: alloc :: __export :: must_use ({ :: alloc :: fmt :: format (format_args ! ("  -> Hugging Face Validation Result: Dataset generated at {0:#?}\n" , output_path ,) ,) }) . as_bytes () ,) . await ? ; let permanent_output_dir = PathBuf :: from (:: alloc :: __export :: must_use ({ :: alloc :: fmt :: format (format_args ! ("generated/hf_dataset_output/{0}" , short_id) ,) }) ,) ; tokio :: fs :: create_dir_all (& permanent_output_dir) . await ? ; use serde :: { Deserialize , Serialize } ; use std :: collections :: HashMap ; use tokio :: fs :: File ; use tokio :: io :: { AsyncReadExt , AsyncWriteExt } ; struct Mapping { # [serde (flatten)] files : HashMap < String , String > , } # [automatically_derived] impl :: core :: fmt :: Debug for Mapping { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter ,) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field1_finish (f , "Mapping" , "files" , & & self . files ,) } } # [automatically_derived] impl :: core :: default :: Default for Mapping { # [inline] fn default () -> Mapping { Mapping { files : :: core :: default :: Default :: default () , } } } # [doc (hidden)] # [allow (non_upper_case_globals , unused_attributes , unused_qualifications , clippy :: absolute_paths ,)] const _ : () = { # [allow (unused_extern_crates , clippy :: useless_attribute)] extern crate serde as _serde ; # [automatically_derived] impl < 'de > _serde :: Deserialize < 'de > for Mapping { fn deserialize < __D > (__deserializer : __D ,) -> _serde :: __private228 :: Result < Self , __D :: Error > where __D : _serde :: Deserializer < 'de > , { # [allow (non_camel_case_types)] # [doc (hidden)] enum __Field < 'de > { __other (_serde :: __private228 :: de :: Content < 'de >) , } # [doc (hidden)] struct __FieldVisitor ; # [automatically_derived] impl < 'de > _serde :: de :: Visitor < 'de > for __FieldVisitor { type Value = __Field < 'de > ; fn expecting (& self , __formatter : & mut _serde :: __private228 :: Formatter ,) -> _serde :: __private228 :: fmt :: Result { _serde :: __private228 :: Formatter :: write_str (__formatter , "field identifier" ,) } fn visit_bool < __E > (self , __value : bool ,) -> _serde :: __private228 :: Result < Self :: Value , __E > where __E : _serde :: de :: Error , { _serde :: __private228 :: Ok (__Field :: __other (_serde :: __private228 :: de :: Content :: Bool (__value) ,) ,) } fn visit_i8 < __E > (self , __value : i8 ,) -> _serde :: __private228 :: Result < Self :: Value , __E > where __E : _serde :: de :: Error , { _serde :: __private228 :: Ok (__Field :: __other (_serde :: __private228 :: de :: Content :: I8 (__value) ,) ,) } fn visit_i16 < __E > (self , __value : i16 ,) -> _serde :: __private228 :: Result < Self :: Value , __E > where __E : _serde :: de :: Error , { _serde :: __private228 :: Ok (__Field :: __other (_serde :: __private228 :: de :: Content :: I16 (__value) ,) ,) } fn visit_i32 < __E > (self , __value : i32 ,) -> _serde :: __private228 :: Result < Self :: Value , __E > where __E : _serde :: de :: Error , { _serde :: __private228 :: Ok (__Field :: __other (_serde :: __private228 :: de :: Content :: I32 (__value) ,) ,) } fn visit_i64 < __E > (self , __value : i64 ,) -> _serde :: __private228 :: Result < Self :: Value , __E > where __E : _serde :: de :: Error , { _serde :: __private228 :: Ok (__Field :: __other (_serde :: __private228 :: de :: Content :: I64 (__value) ,) ,) } fn visit_u8 < __E > (self , __value : u8 ,) -> _serde :: __private228 :: Result < Self :: Value , __E > where __E : _serde :: de :: Error , { _serde :: __private228 :: Ok (__Field :: __other (_serde :: __private228 :: de :: Content :: U8 (__value) ,) ,) } fn visit_u16 < __E > (self , __value : u16 ,) -> _serde :: __private228 :: Result < Self :: Value , __E > where __E : _serde :: de :: Error , { _serde :: __private228 :: Ok (__Field :: __other (_serde :: __private228 :: de :: Content :: U16 (__value) ,) ,) } fn visit_u32 < __E > (self , __value : u32 ,) -> _serde :: __private228 :: Result < Self :: Value , __E > where __E : _serde :: de :: Error , { _serde :: __private228 :: Ok (__Field :: __other (_serde :: __private228 :: de :: Content :: U32 (__value) ,) ,) } fn visit_u64 < __E > (self , __value : u64 ,) -> _serde :: __private228 :: Result < Self :: Value , __E > where __E : _serde :: de :: Error , { _serde :: __private228 :: Ok (__Field :: __other (_serde :: __private228 :: de :: Content :: U64 (__value) ,) ,) } fn visit_f32 < __E > (self , __value : f32 ,) -> _serde :: __private228 :: Result < Self :: Value , __E > where __E : _serde :: de :: Error , { _serde :: __private228 :: Ok (__Field :: __other (_serde :: __private228 :: de :: Content :: F32 (__value) ,) ,) } fn visit_f64 < __E > (self , __value : f64 ,) -> _serde :: __private228 :: Result < Self :: Value , __E > where __E : _serde :: de :: Error , { _serde :: __private228 :: Ok (__Field :: __other (_serde :: __private228 :: de :: Content :: F64 (__value) ,) ,) } fn visit_char < __E > (self , __value : char ,) -> _serde :: __private228 :: Result < Self :: Value , __E > where __E : _serde :: de :: Error , { _serde :: __private228 :: Ok (__Field :: __other (_serde :: __private228 :: de :: Content :: Char (__value) ,) ,) } fn visit_unit < __E > (self ,) -> _serde :: __private228 :: Result < Self :: Value , __E > where __E : _serde :: de :: Error , { _serde :: __private228 :: Ok (__Field :: __other (_serde :: __private228 :: de :: Content :: Unit) ,) } fn visit_str < __E > (self , __value : & str ,) -> _serde :: __private228 :: Result < Self :: Value , __E > where __E : _serde :: de :: Error , { match __value { _ => { let __value = _serde :: __private228 :: de :: Content :: String (_serde :: __private228 :: ToString :: to_string (__value) ,) ; _serde :: __private228 :: Ok (__Field :: __other (__value)) } } } fn visit_bytes < __E > (self , __value : & [u8] ,) -> _serde :: __private228 :: Result < Self :: Value , __E > where __E : _serde :: de :: Error , { match __value { _ => { let __value = _serde :: __private228 :: de :: Content :: ByteBuf (__value . to_vec () ,) ; _serde :: __private228 :: Ok (__Field :: __other (__value)) } } } fn visit_borrowed_str < __E > (self , __value : & 'de str ,) -> _serde :: __private228 :: Result < Self :: Value , __E > where __E : _serde :: de :: Error , { match __value { _ => { let __value = _serde :: __private228 :: de :: Content :: Str (__value ,) ; _serde :: __private228 :: Ok (__Field :: __other (__value)) } } } fn visit_borrowed_bytes < __E > (self , __value : & 'de [u8] ,) -> _serde :: __private228 :: Result < Self :: Value , __E > where __E : _serde :: de :: Error , { match __value { _ => { let __value = _serde :: __private228 :: de :: Content :: Bytes (__value ,) ; _serde :: __private228 :: Ok (__Field :: __other (__value)) } } } } # [automatically_derived] impl < 'de > _serde :: Deserialize < 'de > for __Field < 'de > { # [inline] fn deserialize < __D > (__deserializer : __D ,) -> _serde :: __private228 :: Result < Self , __D :: Error > where __D : _serde :: Deserializer < 'de > , { _serde :: Deserializer :: deserialize_identifier (__deserializer , __FieldVisitor ,) } } # [doc (hidden)] struct __Visitor < 'de > { marker : _serde :: __private228 :: PhantomData < Mapping > , lifetime : _serde :: __private228 :: PhantomData < & 'de () > , } # [automatically_derived] impl < 'de > _serde :: de :: Visitor < 'de > for __Visitor < 'de > { type Value = Mapping ; fn expecting (& self , __formatter : & mut _serde :: __private228 :: Formatter ,) -> _serde :: __private228 :: fmt :: Result { _serde :: __private228 :: Formatter :: write_str (__formatter , "struct Mapping" ,) } # [inline] fn visit_map < __A > (self , mut __map : __A ,) -> _serde :: __private228 :: Result < Self :: Value , __A :: Error > where __A : _serde :: de :: MapAccess < 'de > , { let mut __collect = _serde :: __private228 :: Vec :: < _serde :: __private228 :: Option < (_serde :: __private228 :: de :: Content , _serde :: __private228 :: de :: Content ,) , > , > :: new () ; while let _serde :: __private228 :: Some (__key) = _serde :: de :: MapAccess :: next_key :: < __Field , > (& mut __map) ? { match __key { __Field :: __other (__name) => { __collect . push (_serde :: __private228 :: Some ((__name , _serde :: de :: MapAccess :: next_value_seed (& mut __map , _serde :: __private228 :: de :: ContentVisitor :: new () ,) ? ,)) ,) ; } } } let __field0 : HashMap < String , String > = _serde :: de :: Deserialize :: deserialize (_serde :: __private228 :: de :: FlatMapDeserializer (& mut __collect , _serde :: __private228 :: PhantomData ,) ,) ? ; _serde :: __private228 :: Ok (Mapping { files : __field0 }) } } _serde :: Deserializer :: deserialize_map (__deserializer , __Visitor { marker : _serde :: __private228 :: PhantomData :: < Mapping > , lifetime : _serde :: __private228 :: PhantomData , } ,) } } } ; # [doc (hidden)] # [allow (non_upper_case_globals , unused_attributes , unused_qualifications , clippy :: absolute_paths ,)] const _ : () = { # [allow (unused_extern_crates , clippy :: useless_attribute)] extern crate serde as _serde ; # [automatically_derived] impl _serde :: Serialize for Mapping { fn serialize < __S > (& self , __serializer : __S ,) -> _serde :: __private228 :: Result < __S :: Ok , __S :: Error > where __S : _serde :: Serializer , { let mut __serde_state = _serde :: Serializer :: serialize_map (__serializer , _serde :: __private228 :: None ,) ? ; _serde :: Serialize :: serialize (& & self . files , _serde :: __private228 :: ser :: FlatMapSerializer (& mut __serde_state ,) ,) ? ; _serde :: ser :: SerializeMap :: end (__serde_state) } } } ; let mapping_file_path = PathBuf :: from ("generated/hf_dataset_output/mapping.toml" ,) ; let mut mapping = if mapping_file_path . exists () { let mut file = File :: open (& mapping_file_path) . await . context ("Failed to open mapping.toml") ? ; let mut contents = String :: new () ; file . read_to_string (& mut contents) . await . context ("Failed to read mapping.toml") ? ; toml :: from_str (& contents) . context ("Failed to parse mapping.toml") ? } else { Mapping :: default () } ; mapping . files . insert (original_file_path . to_string_lossy () . to_string () , short_id . clone () ,) ; let toml_string = toml :: to_string_pretty (& mapping) . context ("Failed to serialize mapping to TOML") ? ; let mut file = File :: create (& mapping_file_path) . await . context ("Failed to create mapping.toml") ? ; file . write_all (toml_string . as_bytes ()) . await . context ("Failed to write mapping.toml") ? ; let mut entries = tokio :: fs :: read_dir (& output_path) . await ? ; while let Some (entry) = entries . next_entry () . await ? { let entry_path = entry . path () ; let destination_path = permanent_output_dir . join (entry_path . file_name () . unwrap ()) ; if entry_path . is_dir () { copy_dir_all (& entry_path , & destination_path) . await ? ; } else { tokio :: fs :: copy (& entry_path , & destination_path) . await ? ; } } let __result = Ok (ValidatedFile (source_code , permanent_output_dir) ,) ; measurement :: record_function_exit ("HuggingFaceValidatorFunctor::map" ,) ; __result }) } } } pub mod utils { use anyhow :: Result ; use std :: path :: Path ; use tokio :: fs ; pub async fn copy_dir_all (src : impl AsRef < Path > , dst : impl AsRef < Path > ,) -> Result < () > { fs :: create_dir_all (& dst) . await ? ; let mut stack = < [_] > :: into_vec (:: alloc :: boxed :: box_new ([src . as_ref () . to_path_buf ()]) ,) ; while let Some (current_src) = stack . pop () { let current_dst = dst . as_ref () . join (current_src . strip_prefix (src . as_ref ()) . unwrap ()) ; let mut entries = fs :: read_dir (& current_src) . await ? ; while let Some (entry) = entries . next_entry () . await ? { let entry_path = entry . path () ; let relative_path = entry_path . strip_prefix (& current_src) . unwrap () ; let destination_path = current_dst . join (relative_path) ; if entry_path . is_dir () { fs :: create_dir_all (& destination_path) . await ? ; stack . push (entry_path) ; } else { fs :: copy (& entry_path , & destination_path) . await ? ; } } } Ok (()) } } }