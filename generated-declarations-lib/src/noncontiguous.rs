pub mod noncontiguous { # ! [doc = "\nProvides a noncontiguous NFA implementation of Aho-Corasick.\n\nThis is a low-level API that generally only needs to be used in niche\ncircumstances. When possible, prefer using [`AhoCorasick`](crate::AhoCorasick)\ninstead of a noncontiguous NFA directly. Using an `NFA` directly is typically\nonly necessary when one needs access to the [`Automaton`] trait implementation.\n"] use alloc :: { collections :: { BTreeSet , VecDeque } , vec , vec :: Vec , } ; use crate :: { automaton :: Automaton , util :: { alphabet :: { ByteClassSet , ByteClasses } , error :: { BuildError , MatchError } , prefilter :: { self , opposite_ascii_case , Prefilter } , primitives :: { IteratorIndexExt , PatternID , SmallIndex , StateID } , remapper :: Remapper , search :: { Anchored , MatchKind } , special :: Special , } , } ; # [doc = " A noncontiguous NFA implementation of Aho-Corasick."] # [doc = ""] # [doc = " When possible, prefer using [`AhoCorasick`](crate::AhoCorasick) instead of"] # [doc = " this type directly. Using an `NFA` directly is typically only necessary"] # [doc = " when one needs access to the [`Automaton`] trait implementation."] # [doc = ""] # [doc = " This NFA represents the \"core\" implementation of Aho-Corasick in this"] # [doc = " crate. Namely, constructing this NFA involving building a trie and then"] # [doc = " filling in the failure transitions between states, similar to what is"] # [doc = " described in any standard textbook description of Aho-Corasick."] # [doc = ""] # [doc = " In order to minimize heap usage and to avoid additional construction costs,"] # [doc = " this implementation represents the transitions of all states as distinct"] # [doc = " sparse memory allocations. This is where it gets its name from. That is,"] # [doc = " this NFA has no contiguous memory allocation for its transition table. Each"] # [doc = " state gets its own allocation."] # [doc = ""] # [doc = " While the sparse representation keeps memory usage to somewhat reasonable"] # [doc = " levels, it is still quite large and also results in somewhat mediocre"] # [doc = " search performance. For this reason, it is almost always a good idea to"] # [doc = " use a [`contiguous::NFA`](crate::nfa::contiguous::NFA) instead. It is"] # [doc = " marginally slower to build, but has higher throughput and can sometimes use"] # [doc = " an order of magnitude less memory. The main reason to use a noncontiguous"] # [doc = " NFA is when you need the fastest possible construction time, or when a"] # [doc = " contiguous NFA does not have the desired capacity. (The total number of NFA"] # [doc = " states it can have is fewer than a noncontiguous NFA.)"] # [doc = ""] # [doc = " # Example"] # [doc = ""] # [doc = " This example shows how to build an `NFA` directly and use it to execute"] # [doc = " [`Automaton::try_find`]:"] # [doc = ""] # [doc = " ```"] # [doc = " use aho_corasick::{"] # [doc = "     automaton::Automaton,"] # [doc = "     nfa::noncontiguous::NFA,"] # [doc = "     Input, Match,"] # [doc = " };"] # [doc = ""] # [doc = " let patterns = &[\"b\", \"abc\", \"abcd\"];"] # [doc = " let haystack = \"abcd\";"] # [doc = ""] # [doc = " let nfa = NFA::new(patterns).unwrap();"] # [doc = " assert_eq!("] # [doc = "     Some(Match::must(0, 1..2)),"] # [doc = "     nfa.try_find(&Input::new(haystack))?,"] # [doc = " );"] # [doc = " # Ok::<(), Box<dyn std::error::Error>>(())"] # [doc = " ```"] # [doc = ""] # [doc = " It is also possible to implement your own version of `try_find`. See the"] # [doc = " [`Automaton`] documentation for an example."] pub struct NFA { # [doc = " The match semantics built into this NFA."] match_kind : MatchKind , # [doc = " A set of states. Each state defines its own transitions, a fail"] # [doc = " transition and a set of indices corresponding to matches."] # [doc = ""] # [doc = " The first state is always the fail state, which is used only as a"] # [doc = " sentinel. Namely, in the final NFA, no transition into the fail state"] # [doc = " exists. (Well, they do, but they aren't followed. Instead, the state's"] # [doc = " failure transition is followed.)"] # [doc = ""] # [doc = " The second state (index 1) is always the dead state. Dead states are"] # [doc = " in every automaton, but only used when leftmost-{first,longest} match"] # [doc = " semantics are enabled. Specifically, they instruct search to stop"] # [doc = " at specific points in order to report the correct match location. In"] # [doc = " the standard Aho-Corasick construction, there are no transitions to"] # [doc = " the dead state."] # [doc = ""] # [doc = " The third state (index 2) is generally intended to be the starting or"] # [doc = " \"root\" state."] states : Vec < State > , # [doc = " Transitions stored in a sparse representation via a linked list."] # [doc = ""] # [doc = " Each transition contains three pieces of information: the byte it"] # [doc = " is defined for, the state it transitions to and a link to the next"] # [doc = " transition in the same state (or `StateID::ZERO` if it is the last"] # [doc = " transition)."] # [doc = ""] # [doc = " The first transition for each state is determined by `State::sparse`."] # [doc = ""] # [doc = " Note that this contains a complete set of all transitions in this NFA,"] # [doc = " including states that have a dense representation for transitions."] # [doc = " (Adding dense transitions for a state doesn't remove its sparse"] # [doc = " transitions, since deleting transitions from this particular sparse"] # [doc = " representation would be fairly expensive.)"] sparse : Vec < Transition > , # [doc = " Transitions stored in a dense representation."] # [doc = ""] # [doc = " A state has a row in this table if and only if `State::dense` is"] # [doc = " not equal to `StateID::ZERO`. When not zero, there are precisely"] # [doc = " `NFA::byte_classes::alphabet_len()` entries beginning at `State::dense`"] # [doc = " in this table."] # [doc = ""] # [doc = " Generally a very small minority of states have a dense representation"] # [doc = " since it uses so much memory."] dense : Vec < StateID > , # [doc = " Matches stored in linked list for each state."] # [doc = ""] # [doc = " Like sparse transitions, each match has a link to the next match in the"] # [doc = " state."] # [doc = ""] # [doc = " The first match for each state is determined by `State::matches`."] matches : Vec < Match > , # [doc = " The length, in bytes, of each pattern in this NFA. This slice is"] # [doc = " indexed by `PatternID`."] # [doc = ""] # [doc = " The number of entries in this vector corresponds to the total number of"] # [doc = " patterns in this automaton."] pattern_lens : Vec < SmallIndex > , # [doc = " A prefilter for quickly skipping to candidate matches, if pertinent."] prefilter : Option < Prefilter > , # [doc = " A set of equivalence classes in terms of bytes. We compute this while"] # [doc = " building the NFA, but don't use it in the NFA's states. Instead, we"] # [doc = " use this for building the DFA. We store it on the NFA since it's easy"] # [doc = " to compute while visiting the patterns."] byte_classes : ByteClasses , # [doc = " The length, in bytes, of the shortest pattern in this automaton. This"] # [doc = " information is useful for detecting whether an automaton matches the"] # [doc = " empty string or not."] min_pattern_len : usize , # [doc = " The length, in bytes, of the longest pattern in this automaton. This"] # [doc = " information is useful for keeping correct buffer sizes when searching"] # [doc = " on streams."] max_pattern_len : usize , # [doc = " The information required to deduce which states are \"special\" in this"] # [doc = " NFA."] # [doc = ""] # [doc = " Since the DEAD and FAIL states are always the first two states and"] # [doc = " there are only ever two start states (which follow all of the match"] # [doc = " states), it follows that we can determine whether a state is a fail,"] # [doc = " dead, match or start with just a few comparisons on the ID itself:"] # [doc = ""] # [doc = "    is_dead(sid): sid == NFA::DEAD"] # [doc = "    is_fail(sid): sid == NFA::FAIL"] # [doc = "   is_match(sid): NFA::FAIL < sid && sid <= max_match_id"] # [doc = "   is_start(sid): sid == start_unanchored_id || sid == start_anchored_id"] # [doc = ""] # [doc = " Note that this only applies to the NFA after it has been constructed."] # [doc = " During construction, the start states are the first ones added and the"] # [doc = " match states are inter-leaved with non-match states. Once all of the"] # [doc = " states have been added, the states are shuffled such that the above"] # [doc = " predicates hold."] special : Special , } # [automatically_derived] impl :: core :: clone :: Clone for NFA { # [inline] fn clone (& self) -> NFA { NFA { match_kind : :: core :: clone :: Clone :: clone (& self . match_kind) , states : :: core :: clone :: Clone :: clone (& self . states) , sparse : :: core :: clone :: Clone :: clone (& self . sparse) , dense : :: core :: clone :: Clone :: clone (& self . dense) , matches : :: core :: clone :: Clone :: clone (& self . matches) , pattern_lens : :: core :: clone :: Clone :: clone (& self . pattern_lens) , prefilter : :: core :: clone :: Clone :: clone (& self . prefilter) , byte_classes : :: core :: clone :: Clone :: clone (& self . byte_classes) , min_pattern_len : :: core :: clone :: Clone :: clone (& self . min_pattern_len) , max_pattern_len : :: core :: clone :: Clone :: clone (& self . max_pattern_len) , special : :: core :: clone :: Clone :: clone (& self . special) , } } } impl NFA { # [doc = " Create a new Aho-Corasick noncontiguous NFA using the default"] # [doc = " configuration."] # [doc = ""] # [doc = " Use a [`Builder`] if you want to change the configuration."] pub fn new < I , P > (patterns : I) -> Result < NFA , BuildError > where I : IntoIterator < Item = P > , P : AsRef < [u8] > , { NFA :: builder () . build (patterns) } # [doc = " A convenience method for returning a new Aho-Corasick noncontiguous NFA"] # [doc = " builder."] # [doc = ""] # [doc = " This usually permits one to just import the `NFA` type."] pub fn builder () -> Builder { Builder :: new () } } impl NFA { # [doc = " The DEAD state is a sentinel state like the FAIL state. The DEAD state"] # [doc = " instructs any search to stop and return any currently recorded match,"] # [doc = " or no match otherwise. Generally speaking, it is impossible for an"] # [doc = " unanchored standard search to enter a DEAD state. But an anchored"] # [doc = " search can, and so to can a leftmost search."] # [doc = ""] # [doc = " We put DEAD before FAIL so that DEAD is always 0. We repeat this"] # [doc = " decision across the other Aho-Corasicm automata, so that DEAD"] # [doc = " states there are always 0 too. It's not that we need all of the"] # [doc = " implementations to agree, but rather, the contiguous NFA and the DFA"] # [doc = " use a sort of \"premultiplied\" state identifier where the only state"] # [doc = " whose ID is always known and constant is the first state. Subsequent"] # [doc = " state IDs depend on how much space has already been used in the"] # [doc = " transition table."] pub (crate) const DEAD : StateID = StateID :: new_unchecked (0) ; # [doc = " The FAIL state mostly just corresponds to the ID of any transition on a"] # [doc = " state that isn't explicitly defined. When one transitions into the FAIL"] # [doc = " state, one must follow the previous state's failure transition before"] # [doc = " doing the next state lookup. In this way, FAIL is more of a sentinel"] # [doc = " than a state that one actually transitions into. In particular, it is"] # [doc = " never exposed in the `Automaton` interface."] pub (crate) const FAIL : StateID = StateID :: new_unchecked (1) ; # [doc = " Returns the equivalence classes of bytes found while constructing"] # [doc = " this NFA."] # [doc = ""] # [doc = " Note that the NFA doesn't actually make use of these equivalence"] # [doc = " classes. Instead, these are useful for building the DFA when desired."] pub (crate) fn byte_classes (& self) -> & ByteClasses { & self . byte_classes } # [doc = " Returns a slice containing the length of each pattern in this searcher."] # [doc = " It is indexed by `PatternID` and has length `NFA::patterns_len`."] # [doc = ""] # [doc = " This is exposed for convenience when building a contiguous NFA. But it"] # [doc = " can be reconstructed from the `Automaton` API if necessary."] pub (crate) fn pattern_lens_raw (& self) -> & [SmallIndex] { & self . pattern_lens } # [doc = " Returns a slice of all states in this non-contiguous NFA."] pub (crate) fn states (& self) -> & [State] { & self . states } # [doc = " Returns the underlying \"special\" state information for this NFA."] pub (crate) fn special (& self) -> & Special { & self . special } # [doc = " Swaps the states at `id1` and `id2`."] # [doc = ""] # [doc = " This does not update the transitions of any state to account for the"] # [doc = " state swap."] pub (crate) fn swap_states (& mut self , id1 : StateID , id2 : StateID) { self . states . swap (id1 . as_usize () , id2 . as_usize ()) ; } # [doc = " Re-maps all state IDs in this NFA according to the `map` function"] # [doc = " given."] pub (crate) fn remap (& mut self , map : impl Fn (StateID) -> StateID) { let alphabet_len = self . byte_classes . alphabet_len () ; for state in self . states . iter_mut () { state . fail = map (state . fail) ; let mut link = state . sparse ; while link != StateID :: ZERO { let t = & mut self . sparse [link] ; t . next = map (t . next) ; link = t . link ; } if state . dense != StateID :: ZERO { let start = state . dense . as_usize () ; for next in self . dense [start ..] [.. alphabet_len] . iter_mut () { * next = map (* next) ; } } } } # [doc = " Iterate over all of the transitions for the given state ID."] pub (crate) fn iter_trans (& self , sid : StateID ,) -> impl Iterator < Item = Transition > + '_ { let mut link = self . states [sid] . sparse ; core :: iter :: from_fn (move | | { if link == StateID :: ZERO { return None ; } let t = self . sparse [link] ; link = t . link ; Some (t) }) } # [doc = " Iterate over all of the matches for the given state ID."] pub (crate) fn iter_matches (& self , sid : StateID ,) -> impl Iterator < Item = PatternID > + '_ { let mut link = self . states [sid] . matches ; core :: iter :: from_fn (move | | { if link == StateID :: ZERO { return None ; } let m = self . matches [link] ; link = m . link ; Some (m . pid) }) } # [doc = " Return the link following the one given. If the one given is the last"] # [doc = " link for the given state, then return `None`."] # [doc = ""] # [doc = " If no previous link is given, then this returns the first link in the"] # [doc = " state, if one exists."] # [doc = ""] # [doc = " This is useful for manually iterating over the transitions in a single"] # [doc = " state without borrowing the NFA. This permits mutating other parts of"] # [doc = " the NFA during iteration. Namely, one can access the transition pointed"] # [doc = " to by the link via `self.sparse[link]`."] fn next_link (& self , sid : StateID , prev : Option < StateID >) -> Option < StateID > { let link = prev . map_or (self . states [sid] . sparse , | p | self . sparse [p] . link) ; if link == StateID :: ZERO { None } else { Some (link) } } # [doc = " Follow the transition for the given byte in the given state. If no such"] # [doc = " transition exists, then the FAIL state ID is returned."] # [inline (always)] fn follow_transition (& self , sid : StateID , byte : u8) -> StateID { let s = & self . states [sid] ; if s . dense == StateID :: ZERO { self . follow_transition_sparse (sid , byte) } else { let class = usize :: from (self . byte_classes . get (byte)) ; self . dense [s . dense . as_usize () + class] } } # [doc = " Like `follow_transition`, but always uses the sparse representation."] # [inline (always)] fn follow_transition_sparse (& self , sid : StateID , byte : u8) -> StateID { for t in self . iter_trans (sid) { if byte <= t . byte { if byte == t . byte { return t . next ; } break ; } } NFA :: FAIL } # [doc = " Set the transition for the given byte to the state ID given."] # [doc = ""] # [doc = " Note that one should not set transitions to the FAIL state. It is not"] # [doc = " technically incorrect, but it wastes space. If a transition is not"] # [doc = " defined, then it is automatically assumed to lead to the FAIL state."] fn add_transition (& mut self , prev : StateID , byte : u8 , next : StateID ,) -> Result < () , BuildError > { if self . states [prev] . dense != StateID :: ZERO { let dense = self . states [prev] . dense ; let class = usize :: from (self . byte_classes . get (byte)) ; self . dense [dense . as_usize () + class] = next ; } let head = self . states [prev] . sparse ; if head == StateID :: ZERO || byte < self . sparse [head] . byte { let new_link = self . alloc_transition () ? ; self . sparse [new_link] = Transition { byte , next , link : head , } ; self . states [prev] . sparse = new_link ; return Ok (()) ; } else if byte == self . sparse [head] . byte { self . sparse [head] . next = next ; return Ok (()) ; } let (mut link_prev , mut link_next) = (head , self . sparse [head] . link) ; while link_next != StateID :: ZERO && byte > self . sparse [link_next] . byte { link_prev = link_next ; link_next = self . sparse [link_next] . link ; } if link_next == StateID :: ZERO || byte < self . sparse [link_next] . byte { let link = self . alloc_transition () ? ; self . sparse [link] = Transition { byte , next , link : link_next , } ; self . sparse [link_prev] . link = link ; } else { match (& byte , & self . sparse [link_next] . byte) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: None ,) ; } } } ; self . sparse [link_next] . next = next ; } Ok (()) } # [doc = " This sets every possible transition (all 255 of them) for the given"] # [doc = " state to the name `next` value."] # [doc = ""] # [doc = " This is useful for efficiently initializing start/dead states."] # [doc = ""] # [doc = " # Panics"] # [doc = ""] # [doc = " This requires that the state has no transitions added to it already."] # [doc = " If it has any transitions, then this panics. It will also panic if"] # [doc = " the state has been densified prior to calling this."] fn init_full_state (& mut self , prev : StateID , next : StateID ,) -> Result < () , BuildError > { match (& StateID :: ZERO , & self . states [prev] . dense) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! ("state must not be dense yet") ,) ,) ; } } } ; match (& StateID :: ZERO , & self . states [prev] . sparse) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! ("state must have zero transitions") ,) ,) ; } } } ; let mut prev_link = StateID :: ZERO ; for byte in 0 ..= 255 { let new_link = self . alloc_transition () ? ; self . sparse [new_link] = Transition { byte , next , link : StateID :: ZERO , } ; if prev_link == StateID :: ZERO { self . states [prev] . sparse = new_link ; } else { self . sparse [prev_link] . link = new_link ; } prev_link = new_link ; } Ok (()) } # [doc = " Add a match for the given pattern ID to the state for the given ID."] fn add_match (& mut self , sid : StateID , pid : PatternID ,) -> Result < () , BuildError > { let head = self . states [sid] . matches ; let mut link = head ; while self . matches [link] . link != StateID :: ZERO { link = self . matches [link] . link ; } let new_match_link = self . alloc_match () ? ; self . matches [new_match_link] . pid = pid ; if link == StateID :: ZERO { self . states [sid] . matches = new_match_link ; } else { self . matches [link] . link = new_match_link ; } Ok (()) } # [doc = " Copy matches from the `src` state to the `dst` state. This is useful"] # [doc = " when a match state can be reached via a failure transition. In which"] # [doc = " case, you'll want to copy the matches (if any) from the state reached"] # [doc = " by the failure transition to the original state you were at."] fn copy_matches (& mut self , src : StateID , dst : StateID ,) -> Result < () , BuildError > { let head_dst = self . states [dst] . matches ; let mut link_dst = head_dst ; while self . matches [link_dst] . link != StateID :: ZERO { link_dst = self . matches [link_dst] . link ; } let mut link_src = self . states [src] . matches ; while link_src != StateID :: ZERO { let new_match_link = StateID :: new (self . matches . len ()) . map_err (| e | { BuildError :: state_id_overflow (StateID :: MAX . as_u64 () , e . attempted () ,) }) ? ; self . matches . push (Match { pid : self . matches [link_src] . pid , link : StateID :: ZERO , }) ; if link_dst == StateID :: ZERO { self . states [dst] . matches = new_match_link ; } else { self . matches [link_dst] . link = new_match_link ; } link_dst = new_match_link ; link_src = self . matches [link_src] . link ; } Ok (()) } # [doc = " Create a new entry in `NFA::trans`, if there's room, and return that"] # [doc = " entry's ID. If there's no room, then an error is returned."] fn alloc_transition (& mut self) -> Result < StateID , BuildError > { let id = StateID :: new (self . sparse . len ()) . map_err (| e | { BuildError :: state_id_overflow (StateID :: MAX . as_u64 () , e . attempted () ,) }) ? ; self . sparse . push (Transition :: default ()) ; Ok (id) } # [doc = " Create a new entry in `NFA::matches`, if there's room, and return that"] # [doc = " entry's ID. If there's no room, then an error is returned."] fn alloc_match (& mut self) -> Result < StateID , BuildError > { let id = StateID :: new (self . matches . len ()) . map_err (| e | { BuildError :: state_id_overflow (StateID :: MAX . as_u64 () , e . attempted () ,) }) ? ; self . matches . push (Match :: default ()) ; Ok (id) } # [doc = " Create a new set of `N` transitions in this NFA's dense transition"] # [doc = " table. The ID return corresponds to the index at which the `N`"] # [doc = " transitions begin. So `id+0` is the first transition and `id+(N-1)` is"] # [doc = " the last."] # [doc = ""] # [doc = " `N` is determined via `NFA::byte_classes::alphabet_len`."] fn alloc_dense_state (& mut self) -> Result < StateID , BuildError > { let id = StateID :: new (self . dense . len ()) . map_err (| e | { BuildError :: state_id_overflow (StateID :: MAX . as_u64 () , e . attempted () ,) }) ? ; self . dense . extend (core :: iter :: repeat (NFA :: FAIL) . take (self . byte_classes . alphabet_len ()) ,) ; Ok (id) } # [doc = " Allocate and add a fresh state to the underlying NFA and return its"] # [doc = " ID (guaranteed to be one more than the ID of the previously allocated"] # [doc = " state). If the ID would overflow `StateID`, then this returns an error."] fn alloc_state (& mut self , depth : usize) -> Result < StateID , BuildError > { let depth = SmallIndex :: new (depth) . expect ("patterns longer than SmallIndex::MAX are not allowed") ; let id = StateID :: new (self . states . len ()) . map_err (| e | { BuildError :: state_id_overflow (StateID :: MAX . as_u64 () , e . attempted () ,) }) ? ; self . states . push (State { sparse : StateID :: ZERO , dense : StateID :: ZERO , matches : StateID :: ZERO , fail : self . special . start_unanchored_id , depth , }) ; Ok (id) } } unsafe impl Automaton for NFA { # [inline (always)] fn start_state (& self , anchored : Anchored) -> Result < StateID , MatchError > { match anchored { Anchored :: No => Ok (self . special . start_unanchored_id) , Anchored :: Yes => Ok (self . special . start_anchored_id) , } } # [inline (always)] fn next_state (& self , anchored : Anchored , mut sid : StateID , byte : u8 ,) -> StateID { loop { let next = self . follow_transition (sid , byte) ; if next != NFA :: FAIL { return next ; } if anchored . is_anchored () { return NFA :: DEAD ; } sid = self . states [sid] . fail () ; } } # [inline (always)] fn is_special (& self , sid : StateID) -> bool { sid <= self . special . max_special_id } # [inline (always)] fn is_dead (& self , sid : StateID) -> bool { sid == NFA :: DEAD } # [inline (always)] fn is_match (& self , sid : StateID) -> bool { ! self . is_dead (sid) && sid <= self . special . max_match_id } # [inline (always)] fn is_start (& self , sid : StateID) -> bool { sid == self . special . start_unanchored_id || sid == self . special . start_anchored_id } # [inline (always)] fn match_kind (& self) -> MatchKind { self . match_kind } # [inline (always)] fn patterns_len (& self) -> usize { self . pattern_lens . len () } # [inline (always)] fn pattern_len (& self , pid : PatternID) -> usize { self . pattern_lens [pid] . as_usize () } # [inline (always)] fn min_pattern_len (& self) -> usize { self . min_pattern_len } # [inline (always)] fn max_pattern_len (& self) -> usize { self . max_pattern_len } # [inline (always)] fn match_len (& self , sid : StateID) -> usize { self . iter_matches (sid) . count () } # [inline (always)] fn match_pattern (& self , sid : StateID , index : usize) -> PatternID { self . iter_matches (sid) . nth (index) . unwrap () } # [inline (always)] fn memory_usage (& self) -> usize { self . states . len () * core :: mem :: size_of :: < State > () + self . sparse . len () * core :: mem :: size_of :: < Transition > () + self . matches . len () * core :: mem :: size_of :: < Match > () + self . dense . len () * StateID :: SIZE + self . pattern_lens . len () * SmallIndex :: SIZE + self . prefilter . as_ref () . map_or (0 , | p | p . memory_usage ()) } # [inline (always)] fn prefilter (& self) -> Option < & Prefilter > { self . prefilter . as_ref () } } # [doc = " A representation of a sparse NFA state for an Aho-Corasick automaton."] # [doc = ""] # [doc = " It contains the transitions to the next state, a failure transition for"] # [doc = " cases where there exists no other transition for the current input byte"] # [doc = " and the matches implied by visiting this state (if any)."] pub (crate) struct State { # [doc = " A pointer to `NFA::trans` corresponding to the head of a linked list"] # [doc = " containing all of the transitions for this state."] # [doc = ""] # [doc = " This is `StateID::ZERO` if and only if this state has zero transitions."] sparse : StateID , # [doc = " A pointer to a row of `N` transitions in `NFA::dense`. These"] # [doc = " transitions correspond precisely to what is obtained by traversing"] # [doc = " `sparse`, but permits constant time lookup."] # [doc = ""] # [doc = " When this is zero (which is true for most states in the default"] # [doc = " configuration), then this state has no dense representation."] # [doc = ""] # [doc = " Note that `N` is equal to `NFA::byte_classes::alphabet_len()`. This is"] # [doc = " typically much less than 256 (the maximum value)."] dense : StateID , # [doc = " A pointer to `NFA::matches` corresponding to the head of a linked list"] # [doc = " containing all of the matches for this state."] # [doc = ""] # [doc = " This is `StateID::ZERO` if and only if this state is not a match state."] matches : StateID , # [doc = " The state that should be transitioned to if the current byte in the"] # [doc = " haystack does not have a corresponding transition defined in this"] # [doc = " state."] fail : StateID , # [doc = " The depth of this state. Specifically, this is the distance from this"] # [doc = " state to the starting state. (For the special sentinel states DEAD and"] # [doc = " FAIL, their depth is always 0.) The depth of a starting state is 0."] # [doc = ""] # [doc = " Note that depth is currently not used in this non-contiguous NFA. It"] # [doc = " may in the future, but it is used in the contiguous NFA. Namely, it"] # [doc = " permits an optimization where states near the starting state have their"] # [doc = " transitions stored in a dense fashion, but all other states have their"] # [doc = " transitions stored in a sparse fashion. (This non-contiguous NFA uses"] # [doc = " a sparse representation for all states unconditionally.) In any case,"] # [doc = " this is really the only convenient place to compute and store this"] # [doc = " information, which we need when building the contiguous NFA."] depth : SmallIndex , } # [automatically_derived] impl :: core :: clone :: Clone for State { # [inline] fn clone (& self) -> State { State { sparse : :: core :: clone :: Clone :: clone (& self . sparse) , dense : :: core :: clone :: Clone :: clone (& self . dense) , matches : :: core :: clone :: Clone :: clone (& self . matches) , fail : :: core :: clone :: Clone :: clone (& self . fail) , depth : :: core :: clone :: Clone :: clone (& self . depth) , } } } # [automatically_derived] impl :: core :: fmt :: Debug for State { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field5_finish (f , "State" , "sparse" , & self . sparse , "dense" , & self . dense , "matches" , & self . matches , "fail" , & self . fail , "depth" , & & self . depth ,) } } impl State { # [doc = " Return true if and only if this state is a match state."] pub (crate) fn is_match (& self) -> bool { self . matches != StateID :: ZERO } # [doc = " Returns the failure transition for this state."] pub (crate) fn fail (& self) -> StateID { self . fail } # [doc = " Returns the depth of this state. That is, the number of transitions"] # [doc = " this state is from the start state of the NFA."] pub (crate) fn depth (& self) -> SmallIndex { self . depth } } # [doc = " A single transition in a non-contiguous NFA."] # [repr (packed)] pub (crate) struct Transition { byte : u8 , next : StateID , link : StateID , } # [automatically_derived] impl :: core :: clone :: Clone for Transition { # [inline] fn clone (& self) -> Transition { let _ : :: core :: clone :: AssertParamIsClone < u8 > ; let _ : :: core :: clone :: AssertParamIsClone < StateID > ; * self } } # [automatically_derived] impl :: core :: marker :: Copy for Transition { } # [automatically_derived] impl :: core :: default :: Default for Transition { # [inline] fn default () -> Transition { Transition { byte : :: core :: default :: Default :: default () , next : :: core :: default :: Default :: default () , link : :: core :: default :: Default :: default () , } } } impl Transition { # [doc = " Return the byte for which this transition is defined."] pub (crate) fn byte (& self) -> u8 { self . byte } # [doc = " Return the ID of the state that this transition points to."] pub (crate) fn next (& self) -> StateID { self . next } # [doc = " Return the ID of the next transition."] fn link (& self) -> StateID { self . link } } impl core :: fmt :: Debug for Transition { fn fmt (& self , f : & mut core :: fmt :: Formatter) -> core :: fmt :: Result { f . write_fmt (format_args ! ("Transition(byte: {0:X?}, next: {1:?}, link: {2:?})" , self . byte , self . next () . as_usize () , self . link () . as_usize () ,) ,) } } # [doc = " A single match in a non-contiguous NFA."] struct Match { pid : PatternID , link : StateID , } # [automatically_derived] impl :: core :: clone :: Clone for Match { # [inline] fn clone (& self) -> Match { let _ : :: core :: clone :: AssertParamIsClone < PatternID > ; let _ : :: core :: clone :: AssertParamIsClone < StateID > ; * self } } # [automatically_derived] impl :: core :: marker :: Copy for Match { } # [automatically_derived] impl :: core :: default :: Default for Match { # [inline] fn default () -> Match { Match { pid : :: core :: default :: Default :: default () , link : :: core :: default :: Default :: default () , } } } impl Match { # [doc = " Return the pattern ID for this match."] pub (crate) fn pattern (& self) -> PatternID { self . pid } # [doc = " Return the ID of the next match."] fn link (& self) -> StateID { self . link } } impl core :: fmt :: Debug for Match { fn fmt (& self , f : & mut core :: fmt :: Formatter) -> core :: fmt :: Result { f . write_fmt (format_args ! ("Match(pid: {0:?}, link: {1:?})" , self . pattern () . as_usize () , self . link () . as_usize () ,) ,) } } # [doc = " A builder for configuring an Aho-Corasick noncontiguous NFA."] # [doc = ""] # [doc = " This builder has a subset of the options available to a"] # [doc = " [`AhoCorasickBuilder`](crate::AhoCorasickBuilder). Of the shared options,"] # [doc = " their behavior is identical."] pub struct Builder { match_kind : MatchKind , prefilter : bool , ascii_case_insensitive : bool , dense_depth : usize , } # [automatically_derived] impl :: core :: clone :: Clone for Builder { # [inline] fn clone (& self) -> Builder { Builder { match_kind : :: core :: clone :: Clone :: clone (& self . match_kind) , prefilter : :: core :: clone :: Clone :: clone (& self . prefilter) , ascii_case_insensitive : :: core :: clone :: Clone :: clone (& self . ascii_case_insensitive ,) , dense_depth : :: core :: clone :: Clone :: clone (& self . dense_depth) , } } } # [automatically_derived] impl :: core :: fmt :: Debug for Builder { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field4_finish (f , "Builder" , "match_kind" , & self . match_kind , "prefilter" , & self . prefilter , "ascii_case_insensitive" , & self . ascii_case_insensitive , "dense_depth" , & & self . dense_depth ,) } } impl Default for Builder { fn default () -> Builder { Builder { match_kind : MatchKind :: default () , prefilter : true , ascii_case_insensitive : false , dense_depth : 3 , } } } impl Builder { # [doc = " Create a new builder for configuring an Aho-Corasick noncontiguous NFA."] pub fn new () -> Builder { Builder :: default () } # [doc = " Build an Aho-Corasick noncontiguous NFA from the given iterator of"] # [doc = " patterns."] # [doc = ""] # [doc = " A builder may be reused to create more NFAs."] pub fn build < I , P > (& self , patterns : I) -> Result < NFA , BuildError > where I : IntoIterator < Item = P > , P : AsRef < [u8] > , { let nfa = Compiler :: new (self) ? . compile (patterns) ? ; Ok (nfa) } # [doc = " Set the desired match semantics."] # [doc = ""] # [doc = " See"] # [doc = " [`AhoCorasickBuilder::match_kind`](crate::AhoCorasickBuilder::match_kind)"] # [doc = " for more documentation and examples."] pub fn match_kind (& mut self , kind : MatchKind) -> & mut Builder { self . match_kind = kind ; self } # [doc = " Enable ASCII-aware case insensitive matching."] # [doc = ""] # [doc = " See"] # [doc = " [`AhoCorasickBuilder::ascii_case_insensitive`](crate::AhoCorasickBuilder::ascii_case_insensitive)"] # [doc = " for more documentation and examples."] pub fn ascii_case_insensitive (& mut self , yes : bool) -> & mut Builder { self . ascii_case_insensitive = yes ; self } # [doc = " Set the limit on how many states use a dense representation for their"] # [doc = " transitions. Other states will generally use a sparse representation."] # [doc = ""] # [doc = " See"] # [doc = " [`AhoCorasickBuilder::dense_depth`](crate::AhoCorasickBuilder::dense_depth)"] # [doc = " for more documentation and examples."] pub fn dense_depth (& mut self , depth : usize) -> & mut Builder { self . dense_depth = depth ; self } # [doc = " Enable heuristic prefilter optimizations."] # [doc = ""] # [doc = " See"] # [doc = " [`AhoCorasickBuilder::prefilter`](crate::AhoCorasickBuilder::prefilter)"] # [doc = " for more documentation and examples."] pub fn prefilter (& mut self , yes : bool) -> & mut Builder { self . prefilter = yes ; self } } # [doc = " A compiler uses a builder configuration and builds up the NFA formulation"] # [doc = " of an Aho-Corasick automaton. This roughly corresponds to the standard"] # [doc = " formulation described in textbooks, with some tweaks to support leftmost"] # [doc = " searching."] struct Compiler < 'a > { builder : & 'a Builder , prefilter : prefilter :: Builder , nfa : NFA , byteset : ByteClassSet , } # [automatically_derived] impl < 'a > :: core :: fmt :: Debug for Compiler < 'a > { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field4_finish (f , "Compiler" , "builder" , & self . builder , "prefilter" , & self . prefilter , "nfa" , & self . nfa , "byteset" , & & self . byteset ,) } } impl < 'a > Compiler < 'a > { fn new (builder : & 'a Builder) -> Result < Compiler < 'a > , BuildError > { let prefilter = prefilter :: Builder :: new (builder . match_kind) . ascii_case_insensitive (builder . ascii_case_insensitive) ; Ok (Compiler { builder , prefilter , nfa : NFA { match_kind : builder . match_kind , states : :: alloc :: vec :: Vec :: new () , sparse : :: alloc :: vec :: Vec :: new () , dense : :: alloc :: vec :: Vec :: new () , matches : :: alloc :: vec :: Vec :: new () , pattern_lens : :: alloc :: vec :: Vec :: new () , prefilter : None , byte_classes : ByteClasses :: singletons () , min_pattern_len : usize :: MAX , max_pattern_len : 0 , special : Special :: zero () , } , byteset : ByteClassSet :: empty () , }) } fn compile < I , P > (mut self , patterns : I) -> Result < NFA , BuildError > where I : IntoIterator < Item = P > , P : AsRef < [u8] > , { self . nfa . sparse . push (Transition :: default ()) ; self . nfa . matches . push (Match :: default ()) ; self . nfa . dense . push (NFA :: DEAD) ; self . nfa . alloc_state (0) ? ; self . nfa . alloc_state (0) ? ; self . nfa . special . start_unanchored_id = self . nfa . alloc_state (0) ? ; self . nfa . special . start_anchored_id = self . nfa . alloc_state (0) ? ; self . init_unanchored_start_state () ? ; self . add_dead_state_loop () ? ; self . build_trie (patterns) ? ; self . nfa . states . shrink_to_fit () ; self . nfa . byte_classes = self . byteset . byte_classes () ; self . set_anchored_start_state () ? ; self . add_unanchored_start_state_loop () ; self . densify () ? ; self . fill_failure_transitions () ? ; self . close_start_state_loop_for_leftmost () ; self . shuffle () ; self . nfa . prefilter = self . prefilter . build () ; self . nfa . special . max_special_id = if self . nfa . prefilter . is_some () { self . nfa . special . start_anchored_id } else { self . nfa . special . max_match_id } ; self . nfa . sparse . shrink_to_fit () ; self . nfa . dense . shrink_to_fit () ; self . nfa . matches . shrink_to_fit () ; self . nfa . pattern_lens . shrink_to_fit () ; Ok (self . nfa) } # [doc = " This sets up the initial prefix trie that makes up the Aho-Corasick"] # [doc = " automaton. Effectively, it creates the basic structure of the"] # [doc = " automaton, where every pattern given has a path from the start state to"] # [doc = " the end of the pattern."] fn build_trie < I , P > (& mut self , patterns : I) -> Result < () , BuildError > where I : IntoIterator < Item = P > , P : AsRef < [u8] > , { 'PATTERNS : for (i , pat) in patterns . into_iter () . enumerate () { let pid = PatternID :: new (i) . map_err (| e | { BuildError :: pattern_id_overflow (PatternID :: MAX . as_u64 () , e . attempted () ,) }) ? ; let pat = pat . as_ref () ; let patlen = SmallIndex :: new (pat . len ()) . map_err (| _ | BuildError :: pattern_too_long (pid , pat . len ())) ? ; self . nfa . min_pattern_len = core :: cmp :: min (self . nfa . min_pattern_len , pat . len () ,) ; self . nfa . max_pattern_len = core :: cmp :: max (self . nfa . max_pattern_len , pat . len () ,) ; match (& i , & self . nfa . pattern_lens . len ()) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! ("expected number of patterns to match pattern ID" ,) ,) ,) ; } } } ; self . nfa . pattern_lens . push (patlen) ; if self . builder . prefilter { self . prefilter . add (pat) ; } let mut prev = self . nfa . special . start_unanchored_id ; let mut saw_match = false ; for (depth , & b) in pat . iter () . enumerate () { saw_match = saw_match || self . nfa . states [prev] . is_match () ; if self . builder . match_kind . is_leftmost_first () && saw_match { continue 'PATTERNS ; } self . byteset . set_range (b , b) ; if self . builder . ascii_case_insensitive { let b = opposite_ascii_case (b) ; self . byteset . set_range (b , b) ; } let next = self . nfa . follow_transition (prev , b) ; if next != NFA :: FAIL { prev = next ; } else { let next = self . nfa . alloc_state (depth) ? ; self . nfa . add_transition (prev , b , next) ? ; if self . builder . ascii_case_insensitive { let b = opposite_ascii_case (b) ; self . nfa . add_transition (prev , b , next) ? ; } prev = next ; } } self . nfa . add_match (prev , pid) ? ; } Ok (()) } # [doc = " This routine creates failure transitions according to the standard"] # [doc = " textbook formulation of the Aho-Corasick algorithm, with a couple small"] # [doc = " tweaks to support \"leftmost\" semantics."] # [doc = ""] # [doc = " Building failure transitions is the most interesting part of building"] # [doc = " the Aho-Corasick automaton, because they are what allow searches to"] # [doc = " be performed in linear time. Specifically, a failure transition is"] # [doc = " a single transition associated with each state that points back to"] # [doc = " the longest proper suffix of the pattern being searched. The failure"] # [doc = " transition is followed whenever there exists no transition on the"] # [doc = " current state for the current input byte. If there is no other proper"] # [doc = " suffix, then the failure transition points back to the starting state."] # [doc = ""] # [doc = " For example, let's say we built an Aho-Corasick automaton with the"] # [doc = " following patterns: 'abcd' and 'cef'. The trie looks like this:"] # [doc = ""] # [doc = " ```ignore"] # [doc = "          a - S1 - b - S2 - c - S3 - d - S4*"] # [doc = "         /"] # [doc = "     S0 - c - S5 - e - S6 - f - S7*"] # [doc = " ```"] # [doc = ""] # [doc = " At this point, it should be fairly straight-forward to see how this"] # [doc = " trie can be used in a simplistic way. At any given position in the"] # [doc = " text we're searching (called the \"subject\" string), all we need to do"] # [doc = " is follow the transitions in the trie by consuming one transition for"] # [doc = " each byte in the subject string. If we reach a match state, then we can"] # [doc = " report that location as a match."] # [doc = ""] # [doc = " The trick comes when searching a subject string like 'abcef'. We'll"] # [doc = " initially follow the transition from S0 to S1 and wind up in S3 after"] # [doc = " observng the 'c' byte. At this point, the next byte is 'e' but state"] # [doc = " S3 has no transition for 'e', so the search fails. We then would need"] # [doc = " to restart the search at the next position in 'abcef', which"] # [doc = " corresponds to 'b'. The match would fail, but the next search starting"] # [doc = " at 'c' would finally succeed. The problem with this approach is that"] # [doc = " we wind up searching the subject string potentially many times. In"] # [doc = " effect, this makes the algorithm have worst case `O(n * m)` complexity,"] # [doc = " where `n ~ len(subject)` and `m ~ len(all patterns)`. We would instead"] # [doc = " like to achieve a `O(n + m)` worst case complexity."] # [doc = ""] # [doc = " This is where failure transitions come in. Instead of dying at S3 in"] # [doc = " the first search, the automaton can instruct the search to move to"] # [doc = " another part of the automaton that corresponds to a suffix of what"] # [doc = " we've seen so far. Recall that we've seen 'abc' in the subject string,"] # [doc = " and the automaton does indeed have a non-empty suffix, 'c', that could"] # [doc = " potentially lead to another match. Thus, the actual Aho-Corasick"] # [doc = " automaton for our patterns in this case looks like this:"] # [doc = ""] # [doc = " ```ignore"] # [doc = "          a - S1 - b - S2 - c - S3 - d - S4*"] # [doc = "         /                      /"] # [doc = "        /       ----------------"] # [doc = "       /       /"] # [doc = "     S0 - c - S5 - e - S6 - f - S7*"] # [doc = " ```"] # [doc = ""] # [doc = " That is, we have a failure transition from S3 to S5, which is followed"] # [doc = " exactly in cases when we are in state S3 but see any byte other than"] # [doc = " 'd' (that is, we've \"failed\" to find a match in this portion of our"] # [doc = " trie). We know we can transition back to S5 because we've already seen"] # [doc = " a 'c' byte, so we don't need to re-scan it. We can then pick back up"] # [doc = " with the search starting at S5 and complete our match."] # [doc = ""] # [doc = " Adding failure transitions to a trie is fairly simple, but subtle. The"] # [doc = " key issue is that you might have multiple failure transition that you"] # [doc = " need to follow. For example, look at the trie for the patterns"] # [doc = " 'abcd', 'b', 'bcd' and 'cd':"] # [doc = ""] # [doc = " ```ignore"] # [doc = "          - a - S1 - b - S2* - c - S3 - d - S4*"] # [doc = "         /               /         /"] # [doc = "        /         -------   -------"] # [doc = "       /         /         /"] # [doc = "     S0 --- b - S5* - c - S6 - d - S7*"] # [doc = "       \\                  /"] # [doc = "        \\         --------"] # [doc = "         \\       /"] # [doc = "          - c - S8 - d - S9*"] # [doc = " ```"] # [doc = ""] # [doc = " The failure transitions for this trie are defined from S2 to S5,"] # [doc = " S3 to S6 and S6 to S8. Moreover, state S2 needs to track that it"] # [doc = " corresponds to a match, since its failure transition to S5 is itself"] # [doc = " a match state."] # [doc = ""] # [doc = " Perhaps simplest way to think about adding these failure transitions"] # [doc = " is recursively. That is, if you know the failure transitions for every"] # [doc = " possible previous state that could be visited (e.g., when computing the"] # [doc = " failure transition for S3, you already know the failure transitions"] # [doc = " for S0, S1 and S2), then you can simply follow the failure transition"] # [doc = " of the previous state and check whether the incoming transition is"] # [doc = " defined after following the failure transition."] # [doc = ""] # [doc = " For example, when determining the failure state for S3, by our"] # [doc = " assumptions, we already know that there is a failure transition from"] # [doc = " S2 (the previous state) to S5. So we follow that transition and check"] # [doc = " whether the transition connecting S2 to S3 is defined. Indeed, it is,"] # [doc = " as there is a transition from S5 to S6 for the byte 'c'. If no such"] # [doc = " transition existed, we could keep following the failure transitions"] # [doc = " until we reach the start state, which is the failure transition for"] # [doc = " every state that has no corresponding proper suffix."] # [doc = ""] # [doc = " We don't actually use recursion to implement this, but instead, use a"] # [doc = " breadth first search of the automaton. Our base case is the start"] # [doc = " state, whose failure transition is just a transition to itself."] # [doc = ""] # [doc = " When building a leftmost automaton, we proceed as above, but only"] # [doc = " include a subset of failure transitions. Namely, we omit any failure"] # [doc = " transitions that appear after a match state in the trie. This is"] # [doc = " because failure transitions always point back to a proper suffix of"] # [doc = " what has been seen so far. Thus, following a failure transition after"] # [doc = " a match implies looking for a match that starts after the one that has"] # [doc = " already been seen, which is of course therefore not the leftmost match."] # [doc = ""] # [doc = " N.B. I came up with this algorithm on my own, and after scouring all of"] # [doc = " the other AC implementations I know of (Perl, Snort, many on GitHub)."] # [doc = " I couldn't find any that implement leftmost semantics like this."] # [doc = " Perl of course needs leftmost-first semantics, but they implement it"] # [doc = " with a seeming hack at *search* time instead of encoding it into the"] # [doc = " automaton. There are also a couple Java libraries that support leftmost"] # [doc = " longest semantics, but they do it by building a queue of matches at"] # [doc = " search time, which is even worse than what Perl is doing. ---AG"] fn fill_failure_transitions (& mut self) -> Result < () , BuildError > { let is_leftmost = self . builder . match_kind . is_leftmost () ; let start_uid = self . nfa . special . start_unanchored_id ; let mut queue = VecDeque :: new () ; let mut seen = self . queued_set () ; let mut prev_link = None ; while let Some (link) = self . nfa . next_link (start_uid , prev_link) { prev_link = Some (link) ; let t = self . nfa . sparse [link] ; if start_uid == t . next () || seen . contains (t . next) { continue ; } queue . push_back (t . next) ; seen . insert (t . next) ; if is_leftmost && self . nfa . states [t . next] . is_match () { self . nfa . states [t . next] . fail = NFA :: DEAD ; } } while let Some (id) = queue . pop_front () { let mut prev_link = None ; while let Some (link) = self . nfa . next_link (id , prev_link) { prev_link = Some (link) ; let t = self . nfa . sparse [link] ; if seen . contains (t . next) { continue ; } queue . push_back (t . next) ; seen . insert (t . next) ; if is_leftmost && self . nfa . states [t . next] . is_match () { self . nfa . states [t . next] . fail = NFA :: DEAD ; continue ; } let mut fail = self . nfa . states [id] . fail ; while self . nfa . follow_transition (fail , t . byte) == NFA :: FAIL { fail = self . nfa . states [fail] . fail ; } fail = self . nfa . follow_transition (fail , t . byte) ; self . nfa . states [t . next] . fail = fail ; self . nfa . copy_matches (fail , t . next) ? ; } if ! is_leftmost { self . nfa . copy_matches (self . nfa . special . start_unanchored_id , id) ? ; } } Ok (()) } # [doc = " Shuffle the states so that they appear in this sequence:"] # [doc = ""] # [doc = "   DEAD, FAIL, MATCH..., START, START, NON-MATCH..."] # [doc = ""] # [doc = " The idea here is that if we know how special states are laid out in our"] # [doc = " transition table, then we can determine what \"kind\" of state we're in"] # [doc = " just by comparing our current state ID with a particular value. In this"] # [doc = " way, we avoid doing extra memory lookups."] # [doc = ""] # [doc = " Before shuffling begins, our states look something like this:"] # [doc = ""] # [doc = "   DEAD, FAIL, START, START, (MATCH | NON-MATCH)..."] # [doc = ""] # [doc = " So all we need to do is move all of the MATCH states so that they"] # [doc = " all appear before any NON-MATCH state, like so:"] # [doc = ""] # [doc = "   DEAD, FAIL, START, START, MATCH... NON-MATCH..."] # [doc = ""] # [doc = " Then it's just a simple matter of swapping the two START states with"] # [doc = " the last two MATCH states."] # [doc = ""] # [doc = " (This is the same technique used for fully compiled DFAs in"] # [doc = " regex-automata.)"] fn shuffle (& mut self) { let old_start_uid = self . nfa . special . start_unanchored_id ; let old_start_aid = self . nfa . special . start_anchored_id ; if ! (old_start_uid < old_start_aid) { :: core :: panicking :: panic ("assertion failed: old_start_uid < old_start_aid" ,) } match (& 3 , & old_start_aid . as_usize ()) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! ("anchored start state should be at index 3") ,) ,) ; } } } ; let mut remapper = Remapper :: new (& self . nfa , 0) ; let mut next_avail = StateID :: from (4u8) ; for i in next_avail . as_usize () .. self . nfa . states . len () { let sid = StateID :: new (i) . unwrap () ; if ! self . nfa . states [sid] . is_match () { continue ; } remapper . swap (& mut self . nfa , sid , next_avail) ; next_avail = StateID :: new (next_avail . one_more ()) . unwrap () ; } let new_start_aid = StateID :: new (next_avail . as_usize () . checked_sub (1) . unwrap () ,) . unwrap () ; remapper . swap (& mut self . nfa , old_start_aid , new_start_aid) ; let new_start_uid = StateID :: new (next_avail . as_usize () . checked_sub (2) . unwrap () ,) . unwrap () ; remapper . swap (& mut self . nfa , old_start_uid , new_start_uid) ; let new_max_match_id = StateID :: new (next_avail . as_usize () . checked_sub (3) . unwrap () ,) . unwrap () ; self . nfa . special . max_match_id = new_max_match_id ; self . nfa . special . start_unanchored_id = new_start_uid ; self . nfa . special . start_anchored_id = new_start_aid ; if self . nfa . states [self . nfa . special . start_anchored_id] . is_match () { self . nfa . special . max_match_id = self . nfa . special . start_anchored_id ; } remapper . remap (& mut self . nfa) ; } # [doc = " Attempts to convert the transition representation of a subset of states"] # [doc = " in this NFA from sparse to dense. This can greatly improve search"] # [doc = " performance since states with a higher number of transitions tend to"] # [doc = " correlate with very active states."] # [doc = ""] # [doc = " We generally only densify states that are close to the start state."] # [doc = " These tend to be the most active states and thus benefit from a dense"] # [doc = " representation more than other states."] # [doc = ""] # [doc = " This tends to best balance between memory usage and performance. In"] # [doc = " particular, the *vast majority* of all states in a typical Aho-Corasick"] # [doc = " automaton have only 1 transition and are usually farther from the start"] # [doc = " state and thus don't get densified."] # [doc = ""] # [doc = " Note that this doesn't remove the sparse representation of transitions"] # [doc = " for states that are densified. It could be done, but actually removing"] # [doc = " entries from `NFA::sparse` is likely more expensive than it's worth."] fn densify (& mut self) -> Result < () , BuildError > { for i in 0 .. self . nfa . states . len () { let sid = StateID :: new (i) . unwrap () ; if sid == NFA :: DEAD || sid == NFA :: FAIL { continue ; } if self . nfa . states [sid] . depth . as_usize () >= self . builder . dense_depth { continue ; } let dense = self . nfa . alloc_dense_state () ? ; let mut prev_link = None ; while let Some (link) = self . nfa . next_link (sid , prev_link) { prev_link = Some (link) ; let t = self . nfa . sparse [link] ; let class = usize :: from (self . nfa . byte_classes . get (t . byte)) ; let index = dense . as_usize () + class ; self . nfa . dense [index] = t . next ; } self . nfa . states [sid] . dense = dense ; } Ok (()) } # [doc = " Returns a set that tracked queued states."] # [doc = ""] # [doc = " This is only necessary when ASCII case insensitivity is enabled, since"] # [doc = " it is the only way to visit the same state twice. Otherwise, this"] # [doc = " returns an inert set that nevers adds anything and always reports"] # [doc = " `false` for every member test."] fn queued_set (& self) -> QueuedSet { if self . builder . ascii_case_insensitive { QueuedSet :: active () } else { QueuedSet :: inert () } } # [doc = " Initializes the unanchored start state by making it dense. This is"] # [doc = " achieved by explicitly setting every transition to the FAIL state."] # [doc = " This isn't necessary for correctness, since any missing transition is"] # [doc = " automatically assumed to be mapped to the FAIL state. We do this to"] # [doc = " make the unanchored starting state dense, and thus in turn make"] # [doc = " transition lookups on it faster. (Which is worth doing because it's"] # [doc = " the most active state.)"] fn init_unanchored_start_state (& mut self) -> Result < () , BuildError > { let start_uid = self . nfa . special . start_unanchored_id ; let start_aid = self . nfa . special . start_anchored_id ; self . nfa . init_full_state (start_uid , NFA :: FAIL) ? ; self . nfa . init_full_state (start_aid , NFA :: FAIL) ? ; Ok (()) } # [doc = " Setup the anchored start state by copying all of the transitions and"] # [doc = " matches from the unanchored starting state with one change: the failure"] # [doc = " transition is changed to the DEAD state, so that for any undefined"] # [doc = " transitions, the search will stop."] fn set_anchored_start_state (& mut self) -> Result < () , BuildError > { let start_uid = self . nfa . special . start_unanchored_id ; let start_aid = self . nfa . special . start_anchored_id ; let (mut uprev_link , mut aprev_link) = (None , None) ; loop { let unext = self . nfa . next_link (start_uid , uprev_link) ; let anext = self . nfa . next_link (start_aid , aprev_link) ; let (ulink , alink) = match (unext , anext) { (Some (ulink) , Some (alink)) => (ulink , alink) , (None , None) => break , _ => { :: core :: panicking :: panic ("internal error: entered unreachable code" ,) } } ; uprev_link = Some (ulink) ; aprev_link = Some (alink) ; self . nfa . sparse [alink] . next = self . nfa . sparse [ulink] . next ; } self . nfa . copy_matches (start_uid , start_aid) ? ; self . nfa . states [start_aid] . fail = NFA :: DEAD ; Ok (()) } # [doc = " Set the failure transitions on the start state to loop back to the"] # [doc = " start state. This effectively permits the Aho-Corasick automaton to"] # [doc = " match at any position. This is also required for finding the next"] # [doc = " state to terminate, namely, finding the next state should never return"] # [doc = " a fail_id."] # [doc = ""] # [doc = " This must be done after building the initial trie, since trie"] # [doc = " construction depends on transitions to `fail_id` to determine whether a"] # [doc = " state already exists or not."] fn add_unanchored_start_state_loop (& mut self) { let start_uid = self . nfa . special . start_unanchored_id ; let mut prev_link = None ; while let Some (link) = self . nfa . next_link (start_uid , prev_link) { prev_link = Some (link) ; if self . nfa . sparse [link] . next () == NFA :: FAIL { self . nfa . sparse [link] . next = start_uid ; } } } # [doc = " Remove the start state loop by rewriting any transitions on the start"] # [doc = " state back to the start state with transitions to the dead state."] # [doc = ""] # [doc = " The loop is only closed when two conditions are met: the start state"] # [doc = " is a match state and the match kind is leftmost-first or"] # [doc = " leftmost-longest."] # [doc = ""] # [doc = " The reason for this is that under leftmost semantics, a start state"] # [doc = " that is also a match implies that we should never restart the search"] # [doc = " process. We allow normal transitions out of the start state, but if"] # [doc = " none exist, we transition to the dead state, which signals that"] # [doc = " searching should stop."] fn close_start_state_loop_for_leftmost (& mut self) { let start_uid = self . nfa . special . start_unanchored_id ; let start = & mut self . nfa . states [start_uid] ; let dense = start . dense ; if self . builder . match_kind . is_leftmost () && start . is_match () { let mut prev_link = None ; while let Some (link) = self . nfa . next_link (start_uid , prev_link) { prev_link = Some (link) ; if self . nfa . sparse [link] . next () == start_uid { self . nfa . sparse [link] . next = NFA :: DEAD ; if dense != StateID :: ZERO { let b = self . nfa . sparse [link] . byte ; let class = usize :: from (self . nfa . byte_classes . get (b)) ; self . nfa . dense [dense . as_usize () + class] = NFA :: DEAD ; } } } } } # [doc = " Sets all transitions on the dead state to point back to the dead state."] # [doc = " Normally, missing transitions map back to the failure state, but the"] # [doc = " point of the dead state is to act as a sink that can never be escaped."] fn add_dead_state_loop (& mut self) -> Result < () , BuildError > { self . nfa . init_full_state (NFA :: DEAD , NFA :: DEAD) ? ; Ok (()) } } # [doc = " A set of state identifiers used to avoid revisiting the same state multiple"] # [doc = " times when filling in failure transitions."] # [doc = ""] # [doc = " This set has an \"inert\" and an \"active\" mode. When inert, the set never"] # [doc = " stores anything and always returns `false` for every member test. This is"] # [doc = " useful to avoid the performance and memory overhead of maintaining this"] # [doc = " set when it is not needed."] struct QueuedSet { set : Option < BTreeSet < StateID > > , } # [automatically_derived] impl :: core :: fmt :: Debug for QueuedSet { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field1_finish (f , "QueuedSet" , "set" , & & self . set ,) } } impl QueuedSet { # [doc = " Return an inert set that returns `false` for every state ID membership"] # [doc = " test."] fn inert () -> QueuedSet { QueuedSet { set : None } } # [doc = " Return an active set that tracks state ID membership."] fn active () -> QueuedSet { QueuedSet { set : Some (BTreeSet :: new ()) , } } # [doc = " Inserts the given state ID into this set. (If the set is inert, then"] # [doc = " this is a no-op.)"] fn insert (& mut self , state_id : StateID) { if let Some (ref mut set) = self . set { set . insert (state_id) ; } } # [doc = " Returns true if and only if the given state ID is in this set. If the"] # [doc = " set is inert, this always returns false."] fn contains (& self , state_id : StateID) -> bool { match self . set { None => false , Some (ref set) => set . contains (& state_id) , } } } impl core :: fmt :: Debug for NFA { fn fmt (& self , f : & mut core :: fmt :: Formatter < '_ >) -> core :: fmt :: Result { use crate :: { automaton :: { fmt_state_indicator , sparse_transitions } , util :: debug :: DebugByte , } ; f . write_fmt (format_args ! ("noncontiguous::NFA(\n")) ? ; for (sid , state) in self . states . iter () . with_state_ids () { if sid == NFA :: FAIL { f . write_fmt (format_args ! ("F {0:06}:\n" , sid . as_usize ())) ? ; continue ; } fmt_state_indicator (f , self , sid) ? ; f . write_fmt (format_args ! ("{0:06}({1:06}): " , sid . as_usize () , state . fail . as_usize () ,) ,) ? ; let it = sparse_transitions (self . iter_trans (sid) . map (| t | (t . byte , t . next)) ,) . enumerate () ; for (i , (start , end , sid)) in it { if i > 0 { f . write_fmt (format_args ! (", ")) ? ; } if start == end { f . write_fmt (format_args ! ("{0:?} => {1:?}" , DebugByte (start) , sid . as_usize () ,) ,) ? ; } else { f . write_fmt (format_args ! ("{0:?}-{1:?} => {2:?}" , DebugByte (start) , DebugByte (end) , sid . as_usize () ,) ,) ? ; } } f . write_fmt (format_args ! ("\n")) ? ; if self . is_match (sid) { f . write_fmt (format_args ! ("         matches: ")) ? ; for (i , pid) in self . iter_matches (sid) . enumerate () { if i > 0 { f . write_fmt (format_args ! (", ")) ? ; } f . write_fmt (format_args ! ("{0}" , pid . as_usize ())) ? ; } f . write_fmt (format_args ! ("\n")) ? ; } } f . write_fmt (format_args ! ("match kind: {0:?}\n" , self . match_kind)) ? ; f . write_fmt (format_args ! ("prefilter: {0:?}\n" , self . prefilter . is_some ()) ,) ? ; f . write_fmt (format_args ! ("state length: {0:?}\n" , self . states . len ())) ? ; f . write_fmt (format_args ! ("pattern length: {0:?}\n" , self . patterns_len ()) ,) ? ; f . write_fmt (format_args ! ("shortest pattern length: {0:?}\n" , self . min_pattern_len ,) ,) ? ; f . write_fmt (format_args ! ("longest pattern length: {0:?}\n" , self . max_pattern_len) ,) ? ; f . write_fmt (format_args ! ("memory usage: {0:?}\n" , self . memory_usage ())) ? ; f . write_fmt (format_args ! (")\n")) ? ; Ok (()) } } }