pub mod dfa { # ! [doc = "\nProvides direct access to a DFA implementation of Aho-Corasick.\n\nThis is a low-level API that generally only needs to be used in niche\ncircumstances. When possible, prefer using [`AhoCorasick`](crate::AhoCorasick)\ninstead of a DFA directly. Using an `DFA` directly is typically only necessary\nwhen one needs access to the [`Automaton`] trait implementation.\n"] use alloc :: { vec , vec :: Vec } ; use crate :: { automaton :: Automaton , nfa :: noncontiguous , util :: { alphabet :: ByteClasses , error :: { BuildError , MatchError } , int :: { Usize , U32 } , prefilter :: Prefilter , primitives :: { IteratorIndexExt , PatternID , SmallIndex , StateID } , search :: { Anchored , MatchKind , StartKind } , special :: Special , } , } ; # [doc = " A DFA implementation of Aho-Corasick."] # [doc = ""] # [doc = " When possible, prefer using [`AhoCorasick`](crate::AhoCorasick) instead of"] # [doc = " this type directly. Using a `DFA` directly is typically only necessary when"] # [doc = " one needs access to the [`Automaton`] trait implementation."] # [doc = ""] # [doc = " This DFA can only be built by first constructing a [`noncontiguous::NFA`]."] # [doc = " Both [`DFA::new`] and [`Builder::build`] do this for you automatically, but"] # [doc = " [`Builder::build_from_noncontiguous`] permits doing it explicitly."] # [doc = ""] # [doc = " A DFA provides the best possible search performance (in this crate) via two"] # [doc = " mechanisms:"] # [doc = ""] # [doc = " * All states use a dense representation for their transitions."] # [doc = " * All failure transitions are pre-computed such that they are never"] # [doc = " explicitly handled at search time."] # [doc = ""] # [doc = " These two facts combined mean that every state transition is performed"] # [doc = " using a constant number of instructions. However, this comes at"] # [doc = " great cost. The memory usage of a DFA can be quite exorbitant."] # [doc = " It is potentially multiple orders of magnitude greater than a"] # [doc = " [`contiguous::NFA`](crate::nfa::contiguous::NFA) for example. In exchange,"] # [doc = " a DFA will typically have better search speed than a `contiguous::NFA`, but"] # [doc = " not by orders of magnitude."] # [doc = ""] # [doc = " Unless you have a small number of patterns or memory usage is not a concern"] # [doc = " and search performance is critical, a DFA is usually not the best choice."] # [doc = ""] # [doc = " Moreover, unlike the NFAs in this crate, it is costly for a DFA to"] # [doc = " support for anchored and unanchored search configurations. Namely,"] # [doc = " since failure transitions are pre-computed, supporting both anchored"] # [doc = " and unanchored searches requires a duplication of the transition table,"] # [doc = " making the memory usage of such a DFA ever bigger. (The NFAs in this crate"] # [doc = " unconditionally support both anchored and unanchored searches because there"] # [doc = " is essentially no added cost for doing so.) It is for this reason that"] # [doc = " a DFA's support for anchored and unanchored searches can be configured"] # [doc = " via [`Builder::start_kind`]. By default, a DFA only supports unanchored"] # [doc = " searches."] # [doc = ""] # [doc = " # Example"] # [doc = ""] # [doc = " This example shows how to build an `DFA` directly and use it to execute"] # [doc = " [`Automaton::try_find`]:"] # [doc = ""] # [doc = " ```"] # [doc = " use aho_corasick::{"] # [doc = "     automaton::Automaton,"] # [doc = "     dfa::DFA,"] # [doc = "     Input, Match,"] # [doc = " };"] # [doc = ""] # [doc = " let patterns = &[\"b\", \"abc\", \"abcd\"];"] # [doc = " let haystack = \"abcd\";"] # [doc = ""] # [doc = " let nfa = DFA::new(patterns).unwrap();"] # [doc = " assert_eq!("] # [doc = "     Some(Match::must(0, 1..2)),"] # [doc = "     nfa.try_find(&Input::new(haystack))?,"] # [doc = " );"] # [doc = " # Ok::<(), Box<dyn std::error::Error>>(())"] # [doc = " ```"] # [doc = ""] # [doc = " It is also possible to implement your own version of `try_find`. See the"] # [doc = " [`Automaton`] documentation for an example."] pub struct DFA { # [doc = " The DFA transition table. IDs in this table are pre-multiplied. So"] # [doc = " instead of the IDs being 0, 1, 2, 3, ..., they are 0*stride, 1*stride,"] # [doc = " 2*stride, 3*stride, ..."] trans : Vec < StateID > , # [doc = " The matches for every match state in this DFA. This is first indexed by"] # [doc = " state index (so that's `sid >> stride2`) and then by order in which the"] # [doc = " matches are meant to occur."] matches : Vec < Vec < PatternID > > , # [doc = " The amount of heap memory used, in bytes, by the inner Vecs of"] # [doc = " 'matches'."] matches_memory_usage : usize , # [doc = " The length of each pattern. This is used to compute the start offset"] # [doc = " of a match."] pattern_lens : Vec < SmallIndex > , # [doc = " A prefilter for accelerating searches, if one exists."] prefilter : Option < Prefilter > , # [doc = " The match semantics built into this DFA."] match_kind : MatchKind , # [doc = " The total number of states in this DFA."] state_len : usize , # [doc = " The alphabet size, or total number of equivalence classes, for this"] # [doc = " DFA. Note that the actual number of transitions in each state is"] # [doc = " stride=2^stride2, where stride is the smallest power of 2 greater than"] # [doc = " or equal to alphabet_len. We do things this way so that we can use"] # [doc = " bitshifting to go from a state ID to an index into 'matches'."] alphabet_len : usize , # [doc = " The exponent with a base 2, such that stride=2^stride2. Given a state"] # [doc = " index 'i', its state identifier is 'i << stride2'. Given a state"] # [doc = " identifier 'sid', its state index is 'sid >> stride2'."] stride2 : usize , # [doc = " The equivalence classes for this DFA. All transitions are defined on"] # [doc = " equivalence classes and not on the 256 distinct byte values."] byte_classes : ByteClasses , # [doc = " The length of the shortest pattern in this automaton."] min_pattern_len : usize , # [doc = " The length of the longest pattern in this automaton."] max_pattern_len : usize , # [doc = " The information required to deduce which states are \"special\" in this"] # [doc = " DFA."] special : Special , } # [automatically_derived] impl :: core :: clone :: Clone for DFA { # [inline] fn clone (& self) -> DFA { DFA { trans : :: core :: clone :: Clone :: clone (& self . trans) , matches : :: core :: clone :: Clone :: clone (& self . matches) , matches_memory_usage : :: core :: clone :: Clone :: clone (& self . matches_memory_usage ,) , pattern_lens : :: core :: clone :: Clone :: clone (& self . pattern_lens) , prefilter : :: core :: clone :: Clone :: clone (& self . prefilter) , match_kind : :: core :: clone :: Clone :: clone (& self . match_kind) , state_len : :: core :: clone :: Clone :: clone (& self . state_len) , alphabet_len : :: core :: clone :: Clone :: clone (& self . alphabet_len) , stride2 : :: core :: clone :: Clone :: clone (& self . stride2) , byte_classes : :: core :: clone :: Clone :: clone (& self . byte_classes) , min_pattern_len : :: core :: clone :: Clone :: clone (& self . min_pattern_len) , max_pattern_len : :: core :: clone :: Clone :: clone (& self . max_pattern_len) , special : :: core :: clone :: Clone :: clone (& self . special) , } } } impl DFA { # [doc = " Create a new Aho-Corasick DFA using the default configuration."] # [doc = ""] # [doc = " Use a [`Builder`] if you want to change the configuration."] pub fn new < I , P > (patterns : I) -> Result < DFA , BuildError > where I : IntoIterator < Item = P > , P : AsRef < [u8] > , { DFA :: builder () . build (patterns) } # [doc = " A convenience method for returning a new Aho-Corasick DFA builder."] # [doc = ""] # [doc = " This usually permits one to just import the `DFA` type."] pub fn builder () -> Builder { Builder :: new () } } impl DFA { # [doc = " A sentinel state ID indicating that a search should stop once it has"] # [doc = " entered this state. When a search stops, it returns a match if one has"] # [doc = " been found, otherwise no match. A DFA always has an actual dead state"] # [doc = " at this ID."] # [doc = ""] # [doc = " N.B. DFAs, unlike NFAs, do not have any notion of a FAIL state."] # [doc = " Namely, the whole point of a DFA is that the FAIL state is completely"] # [doc = " compiled away. That is, DFA construction involves pre-computing the"] # [doc = " failure transitions everywhere, such that failure transitions are no"] # [doc = " longer used at search time. This, combined with its uniformly dense"] # [doc = " representation, are the two most important factors in why it's faster"] # [doc = " than the NFAs in this crate."] const DEAD : StateID = StateID :: new_unchecked (0) ; # [doc = " Adds the given pattern IDs as matches to the given state and also"] # [doc = " records the added memory usage."] fn set_matches (& mut self , sid : StateID , pids : impl Iterator < Item = PatternID >) { let index = (sid . as_usize () >> self . stride2) . checked_sub (2) . unwrap () ; let mut at_least_one = false ; for pid in pids { self . matches [index] . push (pid) ; self . matches_memory_usage += PatternID :: SIZE ; at_least_one = true ; } if ! at_least_one { { :: core :: panicking :: panic_fmt (format_args ! ("match state must have non-empty pids") ,) ; } } } } unsafe impl Automaton for DFA { # [inline (always)] fn start_state (& self , anchored : Anchored) -> Result < StateID , MatchError > { match anchored { Anchored :: No => { let start = self . special . start_unanchored_id ; if start == DFA :: DEAD { Err (MatchError :: invalid_input_unanchored ()) } else { Ok (start) } } Anchored :: Yes => { let start = self . special . start_anchored_id ; if start == DFA :: DEAD { Err (MatchError :: invalid_input_anchored ()) } else { Ok (start) } } } } # [inline (always)] fn next_state (& self , _anchored : Anchored , sid : StateID , byte : u8) -> StateID { let class = self . byte_classes . get (byte) ; self . trans [(sid . as_u32 () + u32 :: from (class)) . as_usize ()] } # [inline (always)] fn is_special (& self , sid : StateID) -> bool { sid <= self . special . max_special_id } # [inline (always)] fn is_dead (& self , sid : StateID) -> bool { sid == DFA :: DEAD } # [inline (always)] fn is_match (& self , sid : StateID) -> bool { ! self . is_dead (sid) && sid <= self . special . max_match_id } # [inline (always)] fn is_start (& self , sid : StateID) -> bool { sid == self . special . start_unanchored_id || sid == self . special . start_anchored_id } # [inline (always)] fn match_kind (& self) -> MatchKind { self . match_kind } # [inline (always)] fn patterns_len (& self) -> usize { self . pattern_lens . len () } # [inline (always)] fn pattern_len (& self , pid : PatternID) -> usize { self . pattern_lens [pid] . as_usize () } # [inline (always)] fn min_pattern_len (& self) -> usize { self . min_pattern_len } # [inline (always)] fn max_pattern_len (& self) -> usize { self . max_pattern_len } # [inline (always)] fn match_len (& self , sid : StateID) -> usize { if true { if ! self . is_match (sid) { :: core :: panicking :: panic ("assertion failed: self.is_match(sid)") } } let offset = (sid . as_usize () >> self . stride2) - 2 ; self . matches [offset] . len () } # [inline (always)] fn match_pattern (& self , sid : StateID , index : usize) -> PatternID { if true { if ! self . is_match (sid) { :: core :: panicking :: panic ("assertion failed: self.is_match(sid)") } } let offset = (sid . as_usize () >> self . stride2) - 2 ; self . matches [offset] [index] } # [inline (always)] fn memory_usage (& self) -> usize { use core :: mem :: size_of ; (self . trans . len () * size_of :: < u32 > ()) + (self . matches . len () * size_of :: < Vec < PatternID > > ()) + self . matches_memory_usage + (self . pattern_lens . len () * size_of :: < SmallIndex > ()) + self . prefilter . as_ref () . map_or (0 , | p | p . memory_usage ()) } # [inline (always)] fn prefilter (& self) -> Option < & Prefilter > { self . prefilter . as_ref () } } impl core :: fmt :: Debug for DFA { fn fmt (& self , f : & mut core :: fmt :: Formatter) -> core :: fmt :: Result { use crate :: { automaton :: { fmt_state_indicator , sparse_transitions } , util :: debug :: DebugByte , } ; f . write_fmt (format_args ! ("dfa::DFA(\n")) ? ; for index in 0 .. self . state_len { let sid = StateID :: new_unchecked (index << self . stride2) ; if index == 1 { f . write_fmt (format_args ! ("F {0:06}:\n" , sid . as_usize ())) ? ; continue ; } fmt_state_indicator (f , self , sid) ? ; f . write_fmt (format_args ! ("{0:06}: " , sid . as_usize ())) ? ; let it = (0 .. self . byte_classes . alphabet_len ()) . map (| class | { (class . as_u8 () , self . trans [sid . as_usize () + class]) }) ; for (i , (start , end , next)) in sparse_transitions (it) . enumerate () { if i > 0 { f . write_fmt (format_args ! (", ")) ? ; } if start == end { f . write_fmt (format_args ! ("{0:?} => {1:?}" , DebugByte (start) , next . as_usize () ,) ,) ? ; } else { f . write_fmt (format_args ! ("{0:?}-{1:?} => {2:?}" , DebugByte (start) , DebugByte (end) , next . as_usize () ,) ,) ? ; } } f . write_fmt (format_args ! ("\n")) ? ; if self . is_match (sid) { f . write_fmt (format_args ! (" matches: ")) ? ; for i in 0 .. self . match_len (sid) { if i > 0 { f . write_fmt (format_args ! (", ")) ? ; } let pid = self . match_pattern (sid , i) ; f . write_fmt (format_args ! ("{0}" , pid . as_usize ())) ? ; } f . write_fmt (format_args ! ("\n")) ? ; } } f . write_fmt (format_args ! ("match kind: {0:?}\n" , self . match_kind)) ? ; f . write_fmt (format_args ! ("prefilter: {0:?}\n" , self . prefilter . is_some ())) ? ; f . write_fmt (format_args ! ("state length: {0:?}\n" , self . state_len)) ? ; f . write_fmt (format_args ! ("pattern length: {0:?}\n" , self . patterns_len ())) ? ; f . write_fmt (format_args ! ("shortest pattern length: {0:?}\n" , self . min_pattern_len) ,) ? ; f . write_fmt (format_args ! ("longest pattern length: {0:?}\n" , self . max_pattern_len) ,) ? ; f . write_fmt (format_args ! ("alphabet length: {0:?}\n" , self . alphabet_len)) ? ; f . write_fmt (format_args ! ("stride: {0:?}\n" , 1 << self . stride2)) ? ; f . write_fmt (format_args ! ("byte classes: {0:?}\n" , self . byte_classes)) ? ; f . write_fmt (format_args ! ("memory usage: {0:?}\n" , self . memory_usage ())) ? ; f . write_fmt (format_args ! (")\n")) ? ; Ok (()) } } # [doc = " A builder for configuring an Aho-Corasick DFA."] # [doc = ""] # [doc = " This builder has a subset of the options available to a"] # [doc = " [`AhoCorasickBuilder`](crate::AhoCorasickBuilder). Of the shared options,"] # [doc = " their behavior is identical."] pub struct Builder { noncontiguous : noncontiguous :: Builder , start_kind : StartKind , byte_classes : bool , } # [automatically_derived] impl :: core :: clone :: Clone for Builder { # [inline] fn clone (& self) -> Builder { Builder { noncontiguous : :: core :: clone :: Clone :: clone (& self . noncontiguous) , start_kind : :: core :: clone :: Clone :: clone (& self . start_kind) , byte_classes : :: core :: clone :: Clone :: clone (& self . byte_classes) , } } } # [automatically_derived] impl :: core :: fmt :: Debug for Builder { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field3_finish (f , "Builder" , "noncontiguous" , & self . noncontiguous , "start_kind" , & self . start_kind , "byte_classes" , & & self . byte_classes ,) } } impl Default for Builder { fn default () -> Builder { Builder { noncontiguous : noncontiguous :: Builder :: new () , start_kind : StartKind :: Unanchored , byte_classes : true , } } } impl Builder { # [doc = " Create a new builder for configuring an Aho-Corasick DFA."] pub fn new () -> Builder { Builder :: default () } # [doc = " Build an Aho-Corasick DFA from the given iterator of patterns."] # [doc = ""] # [doc = " A builder may be reused to create more DFAs."] pub fn build < I , P > (& self , patterns : I) -> Result < DFA , BuildError > where I : IntoIterator < Item = P > , P : AsRef < [u8] > , { let nnfa = self . noncontiguous . build (patterns) ? ; self . build_from_noncontiguous (& nnfa) } # [doc = " Build an Aho-Corasick DFA from the given noncontiguous NFA."] # [doc = ""] # [doc = " Note that when this method is used, only the `start_kind` and"] # [doc = " `byte_classes` settings on this builder are respected. The other"] # [doc = " settings only apply to the initial construction of the Aho-Corasick"] # [doc = " automaton. Since using this method requires that initial construction"] # [doc = " has already completed, all settings impacting only initial construction"] # [doc = " are no longer relevant."] pub fn build_from_noncontiguous (& self , nnfa : & noncontiguous :: NFA ,) -> Result < DFA , BuildError > { let byte_classes = if self . byte_classes { nnfa . byte_classes () . clone () } else { ByteClasses :: singletons () } ; let state_len = match self . start_kind { StartKind :: Unanchored | StartKind :: Anchored => nnfa . states () . len () , StartKind :: Both => { nnfa . states () . len () . checked_mul (2) . unwrap () . checked_sub (4) . unwrap () } } ; let trans_len = match state_len . checked_shl (byte_classes . stride2 () . as_u32 ()) { Some (trans_len) => trans_len , None => { return Err (BuildError :: state_id_overflow (StateID :: MAX . as_u64 () , usize :: MAX . as_u64 () ,) ,) ; } } ; StateID :: new (trans_len . checked_sub (byte_classes . stride ()) . unwrap ()) . map_err (| e | { BuildError :: state_id_overflow (StateID :: MAX . as_u64 () , e . attempted ()) }) ? ; let num_match_states = match self . start_kind { StartKind :: Unanchored | StartKind :: Anchored => { nnfa . special () . max_match_id . as_usize () . checked_sub (1) . unwrap () } StartKind :: Both => { nnfa . special () . max_match_id . as_usize () . checked_sub (1) . unwrap () . checked_mul (2) . unwrap () } } ; let mut dfa = DFA { trans : :: alloc :: vec :: from_elem (DFA :: DEAD , trans_len) , matches : :: alloc :: vec :: from_elem (:: alloc :: vec :: Vec :: new () , num_match_states ,) , matches_memory_usage : 0 , pattern_lens : nnfa . pattern_lens_raw () . to_vec () , prefilter : nnfa . prefilter () . cloned () , match_kind : nnfa . match_kind () , state_len , alphabet_len : byte_classes . alphabet_len () , stride2 : byte_classes . stride2 () , byte_classes , min_pattern_len : nnfa . min_pattern_len () , max_pattern_len : nnfa . max_pattern_len () , special : Special :: zero () , } ; match self . start_kind { StartKind :: Both => { self . finish_build_both_starts (nnfa , & mut dfa) ; } StartKind :: Unanchored => { self . finish_build_one_start (Anchored :: No , nnfa , & mut dfa) ; } StartKind :: Anchored => { self . finish_build_one_start (Anchored :: Yes , nnfa , & mut dfa) } } ; dfa . trans . shrink_to_fit () ; dfa . pattern_lens . shrink_to_fit () ; dfa . matches . shrink_to_fit () ; Ok (dfa) } # [doc = " Finishes building a DFA for either unanchored or anchored searches,"] # [doc = " but NOT both."] fn finish_build_one_start (& self , anchored : Anchored , nnfa : & noncontiguous :: NFA , dfa : & mut DFA ,) { let stride2 = dfa . stride2 ; let old2new = | oldsid : StateID | { StateID :: new_unchecked (oldsid . as_usize () << stride2) } ; for (oldsid , state) in nnfa . states () . iter () . with_state_ids () { let newsid = old2new (oldsid) ; if state . is_match () { dfa . set_matches (newsid , nnfa . iter_matches (oldsid)) ; } sparse_iter (nnfa , oldsid , & dfa . byte_classes , | byte , class , mut oldnextsid | { if oldnextsid == noncontiguous :: NFA :: FAIL { if anchored . is_anchored () { oldnextsid = noncontiguous :: NFA :: DEAD ; } else if state . fail () == noncontiguous :: NFA :: DEAD { oldnextsid = noncontiguous :: NFA :: DEAD ; } else { oldnextsid = nnfa . next_state (Anchored :: No , state . fail () , byte) ; } } dfa . trans [newsid . as_usize () + usize :: from (class)] = old2new (oldnextsid ,) ; } ,) ; } let old = nnfa . special () ; let new = & mut dfa . special ; new . max_special_id = old2new (old . max_special_id) ; new . max_match_id = old2new (old . max_match_id) ; if anchored . is_anchored () { new . start_unanchored_id = DFA :: DEAD ; new . start_anchored_id = old2new (old . start_anchored_id) ; } else { new . start_unanchored_id = old2new (old . start_unanchored_id) ; new . start_anchored_id = DFA :: DEAD ; } } # [doc = " Finishes building a DFA that supports BOTH unanchored and anchored"] # [doc = " searches. It works by inter-leaving unanchored states with anchored"] # [doc = " states in the same transition table. This way, we avoid needing to"] # [doc = " re-shuffle states afterward to ensure that our states still look like"] # [doc = " DEAD, MATCH, ..., START-UNANCHORED, START-ANCHORED, NON-MATCH, ..."] # [doc = ""] # [doc = " Honestly this is pretty inscrutable... Simplifications are most"] # [doc = " welcome."] fn finish_build_both_starts (& self , nnfa : & noncontiguous :: NFA , dfa : & mut DFA) { let stride2 = dfa . stride2 ; let stride = 1 << stride2 ; let mut remap_unanchored = :: alloc :: vec :: from_elem (DFA :: DEAD , nnfa . states () . len () ,) ; let mut remap_anchored = :: alloc :: vec :: from_elem (DFA :: DEAD , nnfa . states () . len () ,) ; let mut is_anchored = :: alloc :: vec :: from_elem (false , dfa . state_len) ; let mut newsid = DFA :: DEAD ; let next_dfa_id = | sid : StateID | StateID :: new_unchecked (sid . as_usize () + stride ,) ; for (oldsid , state) in nnfa . states () . iter () . with_state_ids () { if oldsid == noncontiguous :: NFA :: DEAD || oldsid == noncontiguous :: NFA :: FAIL { remap_unanchored [oldsid] = newsid ; remap_anchored [oldsid] = newsid ; newsid = next_dfa_id (newsid) ; } else if oldsid == nnfa . special () . start_unanchored_id || oldsid == nnfa . special () . start_anchored_id { if oldsid == nnfa . special () . start_unanchored_id { remap_unanchored [oldsid] = newsid ; remap_anchored [oldsid] = DFA :: DEAD ; } else { remap_unanchored [oldsid] = DFA :: DEAD ; remap_anchored [oldsid] = newsid ; is_anchored [newsid . as_usize () >> stride2] = true ; } if state . is_match () { dfa . set_matches (newsid , nnfa . iter_matches (oldsid)) ; } sparse_iter (nnfa , oldsid , & dfa . byte_classes , | _ , class , oldnextsid | { let class = usize :: from (class) ; if oldnextsid == noncontiguous :: NFA :: FAIL { dfa . trans [newsid . as_usize () + class] = DFA :: DEAD ; } else { dfa . trans [newsid . as_usize () + class] = oldnextsid ; } } ,) ; newsid = next_dfa_id (newsid) ; } else { let unewsid = newsid ; newsid = next_dfa_id (newsid) ; let anewsid = newsid ; newsid = next_dfa_id (newsid) ; remap_unanchored [oldsid] = unewsid ; remap_anchored [oldsid] = anewsid ; is_anchored [anewsid . as_usize () >> stride2] = true ; if state . is_match () { dfa . set_matches (unewsid , nnfa . iter_matches (oldsid)) ; dfa . set_matches (anewsid , nnfa . iter_matches (oldsid)) ; } sparse_iter (nnfa , oldsid , & dfa . byte_classes , | byte , class , oldnextsid | { let class = usize :: from (class) ; if oldnextsid == noncontiguous :: NFA :: FAIL { let oldnextsid = if state . fail () == noncontiguous :: NFA :: DEAD { noncontiguous :: NFA :: DEAD } else { nnfa . next_state (Anchored :: No , state . fail () , byte) } ; dfa . trans [unewsid . as_usize () + class] = oldnextsid ; } else { dfa . trans [unewsid . as_usize () + class] = oldnextsid ; dfa . trans [anewsid . as_usize () + class] = oldnextsid ; } } ,) ; } } for i in 0 .. dfa . state_len { let sid = i << stride2 ; if is_anchored [i] { for next in dfa . trans [sid ..] [.. stride] . iter_mut () { * next = remap_anchored [* next] ; } } else { for next in dfa . trans [sid ..] [.. stride] . iter_mut () { * next = remap_unanchored [* next] ; } } } let old = nnfa . special () ; let new = & mut dfa . special ; new . max_special_id = remap_anchored [old . max_special_id] ; new . max_match_id = remap_anchored [old . max_match_id] ; new . start_unanchored_id = remap_unanchored [old . start_unanchored_id] ; new . start_anchored_id = remap_anchored [old . start_anchored_id] ; } # [doc = " Set the desired match semantics."] # [doc = ""] # [doc = " This only applies when using [`Builder::build`] and not"] # [doc = " [`Builder::build_from_noncontiguous`]."] # [doc = ""] # [doc = " See"] # [doc = " [`AhoCorasickBuilder::match_kind`](crate::AhoCorasickBuilder::match_kind)"] # [doc = " for more documentation and examples."] pub fn match_kind (& mut self , kind : MatchKind) -> & mut Builder { self . noncontiguous . match_kind (kind) ; self } # [doc = " Enable ASCII-aware case insensitive matching."] # [doc = ""] # [doc = " This only applies when using [`Builder::build`] and not"] # [doc = " [`Builder::build_from_noncontiguous`]."] # [doc = ""] # [doc = " See"] # [doc = " [`AhoCorasickBuilder::ascii_case_insensitive`](crate::AhoCorasickBuilder::ascii_case_insensitive)"] # [doc = " for more documentation and examples."] pub fn ascii_case_insensitive (& mut self , yes : bool) -> & mut Builder { self . noncontiguous . ascii_case_insensitive (yes) ; self } # [doc = " Enable heuristic prefilter optimizations."] # [doc = ""] # [doc = " This only applies when using [`Builder::build`] and not"] # [doc = " [`Builder::build_from_noncontiguous`]."] # [doc = ""] # [doc = " See"] # [doc = " [`AhoCorasickBuilder::prefilter`](crate::AhoCorasickBuilder::prefilter)"] # [doc = " for more documentation and examples."] pub fn prefilter (& mut self , yes : bool) -> & mut Builder { self . noncontiguous . prefilter (yes) ; self } # [doc = " Sets the starting state configuration for the automaton."] # [doc = ""] # [doc = " See"] # [doc = " [`AhoCorasickBuilder::start_kind`](crate::AhoCorasickBuilder::start_kind)"] # [doc = " for more documentation and examples."] pub fn start_kind (& mut self , kind : StartKind) -> & mut Builder { self . start_kind = kind ; self } # [doc = " A debug setting for whether to attempt to shrink the size of the"] # [doc = " automaton's alphabet or not."] # [doc = ""] # [doc = " This should never be enabled unless you're debugging an automaton."] # [doc = " Namely, disabling byte classes makes transitions easier to reason"] # [doc = " about, since they use the actual bytes instead of equivalence classes."] # [doc = " Disabling this confers no performance benefit at search time."] # [doc = ""] # [doc = " See"] # [doc = " [`AhoCorasickBuilder::byte_classes`](crate::AhoCorasickBuilder::byte_classes)"] # [doc = " for more documentation and examples."] pub fn byte_classes (& mut self , yes : bool) -> & mut Builder { self . byte_classes = yes ; self } } # [doc = " Iterate over all possible equivalence class transitions in this state."] # [doc = " The closure is called for all transitions with a distinct equivalence"] # [doc = " class, even those not explicitly represented in this sparse state. For"] # [doc = " any implicitly defined transitions, the given closure is called with"] # [doc = " the fail state ID."] # [doc = ""] # [doc = " The closure is guaranteed to be called precisely"] # [doc = " `byte_classes.alphabet_len()` times, once for every possible class in"] # [doc = " ascending order."] fn sparse_iter < F : FnMut (u8 , u8 , StateID) > (nnfa : & noncontiguous :: NFA , oldsid : StateID , classes : & ByteClasses , mut f : F ,) { let mut prev_class = None ; let mut byte = 0usize ; for t in nnfa . iter_trans (oldsid) { while byte < usize :: from (t . byte ()) { let rep = byte . as_u8 () ; let class = classes . get (rep) ; byte += 1 ; if prev_class != Some (class) { f (rep , class , noncontiguous :: NFA :: FAIL) ; prev_class = Some (class) ; } } let rep = t . byte () ; let class = classes . get (rep) ; byte += 1 ; if prev_class != Some (class) { f (rep , class , t . next ()) ; prev_class = Some (class) ; } } for b in byte ..= 255 { let rep = b . as_u8 () ; let class = classes . get (rep) ; if prev_class != Some (class) { f (rep , class , noncontiguous :: NFA :: FAIL) ; prev_class = Some (class) ; } } } }