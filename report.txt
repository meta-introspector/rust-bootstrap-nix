split-expanded-bin started.
Verbosity level: 8
Created project src directory already exists or was created: /data/data/com.termux.nix/files/home/pick-up-nix2/rust-bootstrap-core/src
Processing file: ../expanded/.expand_output_aho-corasick.rs
  Extracted file_stem: .expand_output_aho-corasick
  Derived crate_name: aho-corasick
Processing single file: ../expanded/.expand_output_aho-corasick.rs
  [split-expanded-lib] Global use statement found: # [prelude_import] use core :: prelude :: rust_2021 :: * ;
  [split-expanded-lib] Global use statement found: pub use crate :: ahocorasick :: StreamFindIter ;
  [split-expanded-lib] Global use statement found: pub use crate :: { ahocorasick :: { AhoCorasick , AhoCorasickBuilder , AhoCorasickKind , FindIter , FindOverlappingIter , } , util :: { error :: { BuildError , MatchError , MatchErrorKind } , primitives :: { PatternID , PatternIDError } , search :: { Anchored , Input , Match , MatchKind , Span , StartKind } , } , } ;
  [split-expanded-lib] DeclsVisitor: Visiting module 'macros'. Required imports for module: {}
  [split-expanded-lib] DeclsVisitor: Visiting module 'ahocorasick'. Required imports for module: {"\"     let mat = match state.get_match() {\"", "\" assert_eq!(b\\\"x the z to the xage\\\".to_vec(), result);\"", "\" let haystack = \\\"The quick brown fox.\\\";\"", "\" When enabled, searching will attempt to quickly skip to match\"", "\" let ac = AhoCorasick::new(&[\\\"foo\\\", \\\"bar\\\", \\\"baz\\\"]).unwrap();\"", ":: core :: fmt :: Formatter", "\" with a small (less than 100) number of patterns.\"", "\" use aho_corasick::{AhoCorasick, PatternID};\"", "\" assert_eq!(Some(Match::must(0, 0..6)), state.get_match());\"", "self . try_find_iter (input) . expect (\"AhoCorasick::try_find_iter is not expected to fail\")", "self . start_kind = kind", ":: core :: cmp :: Eq", "\" field docs for more details.\"", "\"DFA\"", "self . dfa . prefilter (yes)", "self . nfa_noncontiguous", "UnwindSafe", "Arc :: new (cnfa)", "\" ```\"", "\" Overlapping searches do not report matches in their return value.\"", "\" // given the configuration above regardless of which kind of\"", "\" as a stream or overlapping search) with an automaton that was built with\"", "\" first building a noncontiguous NFA. Once the contiguous NFA is built, the\"", "\" immediately returned once they are seen, so there is no way for this to\"", "\" are a fair number of configurable options that can be set by using\"", "\" This is the fallible version of [`AhoCorasick::find_overlapping_iter`].\"", "\" any other match semantics will result in this returning an error.\"", "\" additional cost. Other automatons, like the DFA, require two copies of\"", "\" assert_eq!(Some(Match::must(2, 22..25)), state.get_match());\"", "\" Fallible search routines. These APIs return an error in cases where the\"", "\" }\"", "\" slice given. Matches correspond to the same matches as reported by\"", "\" This shows how to run an \\\"earliest\\\" search even when the Aho-Corasick\"", "\" use aho_corasick::{AhoCorasick, Input, PatternID};\"", "\" This also panics when `replace_with.len()` does not equal\"", "\" the default `Input` configuration. More specifically, this occurs only\"", "\" assert_eq!(11_136, ac.memory_usage());\"", "\" let ac = AhoCorasick::new(patterns).unwrap();\"", ":: core :: clone :: Clone :: clone (& self . dfa)", ":: core :: fmt :: Formatter :: write_str", "\" # Errors\"", "\" (Note that the memory usage above reflects the size of each automaton and\"", "\" [`StartKind::Anchored`], then running an unanchored search will\"", "self . dfa . ascii_case_insensitive (yes)", "\" supports both unanchored and anchored searches if it's configured to\"", "\"start_kind\"", "\" A builder may be reused to create more automatons.\"", "aut", "\" iteration by repeatedly calling `try_find_overlapping` until either\"", ":: core :: default :: Default :: default ()", "enforce_anchored_consistency (self . start_kind , Anchored :: No) . map_err (| e | std :: io :: Error :: new (std :: io :: ErrorKind :: Other , e))", "nfa . patterns_len () <= 100", "\" that first.\"", "\" [`AhoCorasick::memory_usage`] method.\"", "\" searches), an error will still be reported for a search that isn't\"", "anchored", "\" Returns the match kind used by this automaton.\"", "\" construction can fail is somewhere around \\\"millions of patterns.\\\"\"", "\"\"", "\" Basically, it seems bad to return an error or not based on some\"", "\" use aho_corasick::{AhoCorasick, MatchKind, Input};\"", "\" nfa::noncontiguous::NFA, nfa::contiguous::NFA or dfa::DFA.\"", "& Prefilter", "\"     .find_iter(haystack)\"", "\"     .collect();\"", "\" Note that the error returned by this method occurs during construction\"", "\" noncontiguous NFA.\"", "\" This iterator is constructed via the [`AhoCorasick::stream_find_iter`] and\"", "\" #    .build(patterns)\"", "# [allow (non_exhaustive_omitted_patterns)] match self . start_kind { StartKind :: Both => true , _ => false , }", "\" This is enabled by default.\"", "(* * self) . start_state (anchored)", "self . aut . try_find (& input . into () . earliest (true)) . expect (\"AhoCorasick::try_find is not expected to fail\")", "\" This iterator yields matches according to the [`MatchKind`] used by this\"", "\" use aho_corasick::{AhoCorasick, Anchored, Input, StartKind};\"", "\"         Some(mat) => mat,\"", "self . try_find_iter (input)", "\" Note that the heuristics used for choosing which `AhoCorasickKind`\"", "\" The type of Aho-Corasick implementation to use in an [`AhoCorasick`]\"", "\" for mat in ac.find_iter(haystack) {\"", "\" assert_eq!(b\\\"0 the 2 to the 0age\\\".to_vec(), result);\"", "\" `b`, `abc`, `abcd`.\"", "\" This panics when [`AhoCorasick::try_stream_find_iter`] would return\"", "Input < '_ >", "\" for result in ac.try_stream_find_iter(haystack.as_bytes())? {\"", "\" inspect any `AhoCorasick` and know what kind of search strategy it\"", "\" let haystack = \\\"abcd\\\";\"", "\" let patterns = &[\\\"foo\\\", \\\"bar\\\", \\\"quux\\\"];\"", "RefUnwindSafe", "\" assert_eq!(b\\\"0 the 2 to the appendage\\\".to_vec(), result);\"", "\" ]);\"", "\" let mat = ac.try_find(haystack)?.expect(\\\"should have a match\\\");\"", "\" [`AhoCorasick::try_find_iter`].\"", "{ let dfa = self . dfa . build_from_noncontiguous (& nfa) ? ; (Arc :: new (dfa) , AhoCorasickKind :: DFA) }", "self . kind", "nfa", "automaton :: StreamFindIter < 'a , Arc < dyn AcAutomaton > , R >", "\" implementations and their resource usage, here's a sample of construction\"", "\" For example, the [`AhoCorasick::find_iter`] method is the infallible\"", "\"AhoCorasick::try_find is not expected to fail\"", "false", "\" caller would then be able to run anchored searches, even though the\"", "\" the corresponding `try` method in the section below.\"", "\"     PatternID::must(0),\"", "(* * self) . prefilter ()", "true", "\" This is the fallible version of [`AhoCorasick::find`].\"", "\" let haystack = \\\"foo abcd\\\";\"", "\" Basic usage:\"", "\"     (PatternID::must(2), 43, 50),\"", "\" [`AhoCorasick::patterns_len`].\"", "\" // we get a different match back.\"", "\"     \\\"foo\\\", \\\"bar\\\", \\\"quux\\\", \\\"baz\\\",\"", "\" [`MatchKind::LeftmostLongest`] will cause some search routines on\"", "(* * self) . match_pattern (sid , index)", "std :: io :: Read", "\" for result in ac.stream_find_iter(haystack.as_bytes()) {\"", "& Match", "inline", "self . aut . patterns_len ()", "Option < Result < Match , std :: io :: Error > >", "\" assert!(ac.try_find_overlapping_iter(input).is_err());\"", "(* * self) . min_pattern_len ()", "\"     &mut result,\"", "Ok (FindIter (self . aut . try_find_iter (input) ?))", "\" * Running an anchored search with an automaton that only supports\"", "\" assert_eq!(3, ac.patterns_len());\"", "Result < Vec < u8 > , MatchError >", "\" automaton's alphabet or not.\"", "& self . start_kind", "\" representation requires executing a variable number of instructions.\"", "\" Basic usage with leftmost-first semantics:\"", "\" It is generally possible for building an Aho-Corasick automaton to fail.\"", "\" Because this method accepts anything that can be turned into an\"", "Ok (FindOverlappingIter (self . aut . try_find_overlapping_iter (input) ?))", ":: core :: clone :: Clone :: clone (& self . nfa_noncontiguous)", "StartKind :: Unanchored", "\" let input = Input::new(\\\"foo abcd\\\").anchored(Anchored::No);\"", "\" user or untrusted data, then you should handle errors at build or search\"", ":: core :: clone :: Clone :: clone", "self . aut . try_replace_all (haystack , replace_with)", "\" This is the infallible version of\"", "\" # Example\"", "\" Basic usage, with standard semantics:\"", "\" Returns the location of the first overlapping match in the given\"", "\" This shows how to build a searcher that only supports anchored\"", "\" The start kind of this automaton as configured by the caller.\"", "Option < Match >", "\" an error occurs or no more matches are reported.\"", "\" This shows how we can repeatedly call an overlapping search without\"", "dst", "try_dfa", "\" [`AhoCorasick::try_find_overlapping`].\"", "\" supported.\"", "& & self . start_kind", "\" The default configuration optimizes for less space usage, but at the\"", "OverlappingState", "\" assert_eq!(Some(Match::must(1, 4..7)), ac.try_find(input)?);\"", "__arg1_discr", "self . try_replace_all_with (haystack , dst , replace_with)", "\" will help things much, since the most active states have a small depth.\"", "& self . 0", "\" [`MatchKind::Standard`] match kind.\"", "\" The specific Aho-Corasick kind chosen. This makes it possible to\"", "Iterator", "(Arc :: new (nfa) , AhoCorasickKind :: ContiguousNFA)", "\" at the starting location of the search. For an iterator, an anchored\"", "& input . into () . earliest (true)", ":: core :: default :: Default :: default", "__self_discr", "\" let result = ac.try_replace_all(haystack, &[\\\"x\\\", \\\"y\\\", \\\"z\\\"])?;\"", "\" assert_eq!(MatchKind::Standard, ac.match_kind());\"", "\" position.\"", "wtr", "\" This panics when `AhoCorasick::try_find_overlapping_iter` would return\"", "if try_dfa { match self . dfa . build_from_noncontiguous (& nfa) { Ok (dfa) => { return (Arc :: new (dfa) , AhoCorasickKind :: DFA) ; } Err (_err) => { } } }", "AhoCorasickBuilder { nfa_noncontiguous : :: core :: default :: Default :: default () , nfa_contiguous : :: core :: default :: Default :: default () , dfa : :: core :: default :: Default :: default () , kind : :: core :: default :: Default :: default () , start_kind : :: core :: default :: Default :: default () , }", "\" Choose the type of underlying automaton to use.\"", "\" For example, if the pattern with index `2` is found, then it is\"", "core :: fmt :: Result", "\" This iterator is constructed via the [`AhoCorasick::find_overlapping_iter`]\"", "& self . aut", "\" would otherwise fail. Infallible routines are useful because the errors are\"", "\" **NOTE:** It is unlikely that support for Unicode case folding will\"", "\" contains a match somewhere, a match won't be reported unless one can\"", "\" [`AhoCorasickKind::DFA`] does however reduce the time complexity of\"", "& 'a Self", "\" ac.replace_all_with(haystack, &mut result, |mat, _, dst| {\"", "\" replaced by `replace_with[2]`.\"", "\" Implements the automatic selection logic for the Aho-Corasick\"", "\" assert!(ac.is_match(\\\"xxx bar xxx\\\"));\"", "\" `MatchKind`](MatchKind).\"", "\" between a match and a non-match in the automaton.\"", "\"     .build(patterns)\"", "\" This panics when [`AhoCorasick::try_replace_all`] would return an\"", "self . dfa . byte_classes (yes)", "f . debug_tuple (\"AhoCorasick\") . field (& self . aut)", "\" come from whether the given reader returns an error or not during the\"", "\" Convenience constructors for an Aho-Corasick searcher. To configure the\"", "\" the match and the writer with which to write the replaced text (if any).\"", "\"     mat.pattern() != PatternID::must(2)\"", "\" The matches yielded by this iterator use absolute position offsets in\"", "\" fine, but what if the DFA was chosen instead? Oops, the caller would\"", "Ok (AhoCorasick { aut , kind , start_kind : self . start_kind , })", "\"         None => break,\"", "()", "\" assert_eq!(result, \\\"The slow grey sloth.\\\");\"", "\" Knowing the Aho-Corasick kind is principally useful for diagnostic\"", "\" assert_eq!(\"", "\" let ac = AhoCorasickBuilder::new().build(patterns).unwrap();\"", "\" for example, that an error is never dependent on which internal\"", "\" If you're constructing an Aho-Corasick automaton from static or trusted\"", "self . nfa_contiguous . dense_depth (depth)", "\" works this way because searches depend on state saved during the\"", "\" example, if the pattern with index `2` is found, then it is replaced by\"", "{ }", "self . aut . try_stream_find_iter (rdr) . map (StreamFindIter)", "self . dfa", "\" iteration over all anchored matches. In particular,\"", "self . aut . try_replace_all_with_bytes (haystack , dst , replace_with)", "FindIter (self . aut . try_find_iter (input) ?)", "\" # Construction failure\"", "\" transitions from the original NFA and one generated by not following\"", "\" Aho-Corasick automatons are always constructed in `O(p)` time, where\"", "\" assert_eq!(\\\"b\\\", &haystack[mat.start()..mat.end()]);\"", "(* * self) . match_kind ()", "self . aut . try_stream_replace_all_with (rdr , wtr , replace_with)", "rdr", "\" with [`MatchKind::LeftmostFirst`] if you want to match how backtracking\"", "\" let haystack = b\\\"append the app to the appendage\\\";\"", "\" set the [`StartKind::Anchored`] mode since [`StartKind::Unanchored`] is the\"", "& self . kind", "\"AhoCorasick::try_replace_all is not expected to fail\"", "\"     Match::must(2, 22..25),\"", "self . dfa . build_from_noncontiguous (& nfa) ?", "\" searches. Only searchers built with [`MatchKind::Standard`] semantics\"", "IntoIterator < Item = P >", "\" assert!(ac.try_find(input).is_err());\"", "self . nfa_contiguous . match_kind (kind)", "& [B]", "\" little slower than a DFA for a search.\"", "StartKind :: Anchored", "\" assert_eq!(\\\"abc\\\", &haystack[mat.span()]);\"", ":: core :: clone :: Clone :: clone (& self . start_kind)", "\" too big. Whether that's a pattern that is too long, too many patterns\"", "\" let mat = ac.try_find(input)?.expect(\\\"should have a match\\\");\"", "\" assert_eq!(StartKind::Unanchored, ac.start_kind());\"", "Arc :: new (dfa)", "match self . dfa . build_from_noncontiguous (& nfa) { Ok (dfa) => { return (Arc :: new (dfa) , AhoCorasickKind :: DFA) ; } Err (_err) => { } }", "\" times and heap memory used after building an automaton from 100,000\"", "\" `Input` that requests an anchored (or unanchored) search when it isn't\"", "(* * self) . match_len (sid)", "enforce_anchored_consistency", "\" let patterns = &[\\\"b\\\", \\\"abc\\\", \\\"abcd\\\"];\"", "\" to always use a [`AhoCorasickKind::DFA`] if search speed is critical and\"", "\"     AhoCorasick, Anchored, Input, MatchKind, PatternID, StartKind,\"", "\" to build the Aho-Corasick searcher. Both of these things are not usually\"", "Match", "MatchError :: invalid_input_anchored ()", "\" previous search.\"", "\" [`AhoCorasick`] to return an error (or panic if you're using the\"", "\" this routine will report which one.\"", "\" **WARNING:** This is only useful for debugging automatons. Disabling\"", "\"     .kind(None) // default\"", "\"     .try_find_iter(Input::new(haystack).anchored(Anchored::Yes))?\"", "\"     .start_kind(StartKind::Anchored)\"", "\" DFA or not and various knobs for controlling the space-vs-time trade offs\"", "\" but its memory usage is quite small. Its search speed (not listed) is\"", "\" use aho_corasick::{AhoCorasick, AhoCorasickKind, MatchKind};\"", "\"AhoCorasick\"", "\" assert_eq!(vec![\"", "\" # Quick advice\"", "\" Now with leftmost-first semantics:\"", "\" assert_eq!(Some(Match::must(2, 0..3)), state.get_match());\"", "\" of the iterator. The iterator itself yields `Match` values. That is,\"", "\" example, you might choose `AhoCorasickKind::DFA` if you don't care\"", "\" let ac = AhoCorasick::new(&[\\\"foo\\\", \\\"bar\\\", \\\"quux\\\", \\\"baz\\\"]).unwrap();\"", "automaton :: FindOverlappingIter < 'a , 'h , Arc < dyn AcAutomaton > >", "AhoCorasickKind :: DFA", "\" When enabled, some (but not all) Aho-Corasick automatons will use a map\"", "Anchored", "(* * self) . patterns_len ()", "\" purposes. In particular, if no specific kind was given to\"", "\" about memory usage and want the fastest possible search times.\"", "\" # let patterns = &[\\\"append\\\", \\\"appendage\\\", \\\"app\\\"];\"", "\" very slow due to the start state itself being forced to use a sparse\"", "\" use aho_corasick::{AhoCorasick, Input, MatchKind};\"", "\" returns an iterator of all possible matches at every position.\"", "coverage", "{ return (Arc :: new (nfa) , AhoCorasickKind :: ContiguousNFA) ; }", "\" unanchored searches. (By default, `AhoCorasick` only supports unanchored\"", "\" `earliest` option to force the search to return as soon as it knows\"", "\" searches or only supports unanchored searches, then providing an\"", "\" [`AhoCorasick::try_find_overlapping_iter`], with the only difference\"", "self . nfa_contiguous . byte_classes (yes)", "\" searcher, use an [`AhoCorasickBuilder`] instead.\"", "\"     // 'bar' match. It needs to be adjacent because our search is\"", "FindIter", "\" an error or not during the search.\"", "\" For that reason, if you're building an Aho-Corasick automaton from\"", "\" This uses the default [`MatchKind::Standard`] match semantics, which\"", "\" best balance in terms of resource usage. It takes a little longer to build,\"", "\" routine panics if _construction_ of the iterator failed. The `Result`\"", "\" let expected = vec![\"", "\" let haystack = \\\"Nobody likes maple in their apple flavored Snapple.\\\";\"", "\" // DFA to take an order of magnitude more heap space (or more!).\"", "dyn AcAutomaton", "\" search implies that all matches are adjacent.\"", "FnMut (& Match , & str , & mut String) -> bool", ":: core :: marker :: StructuralPartialEq", "\" be found that starts at the beginning of the search:\"", "\" return an error.\"", "StreamFindIter", "\" The type variable `R` refers to the `io::Read` stream that is being read\"", "\" Use a contiguous NFA.\"", "\" anchored searches.\"", "& mut OverlappingState", "\" loop {\"", "std :: io :: Write", "\" For example, if the Aho-Corasick searcher only supports anchored\"", "\" latter corresponds to finding the longest possible match among all\"", "\" [`AhoCorasickBuilder`] instead. Such options include, but are not limited\"", "\" searches. Some automatons, like the NFAs, support this with almost zero\"", "\" expense of longer search times. To change the configuration, use\"", "\"FindIter\"", "\" should avoiding providing a buffered reader, if possible.\"", "self . aut . try_find (& input . into () . earliest (true))", "\" This setting is only used when an Aho-Corasick implementation is used\"", ":: core :: clone :: Clone :: clone (& self . nfa_contiguous)", "\" classes (rounded up to the nearest power of 2). As a result, total\"", "Anchored :: No", "\" * If you need an anchored search, use [`AhoCorasickBuilder::start_kind`] to\"", "\" let patterns = &[\\\"foo\\\", \\\"bar\\\", \\\"baz\\\"];\"", "\" that you give to the automaton. That is, it returns the leftmost match\"", "Ok (())", "\" of the haystack, this type provides both infallible and fallible methods\"", "\" after a search call.\"", "\"     .kind(Some(AhoCorasickKind::NoncontiguousNFA))\"", "\" an error. For example, when the Aho-Corasick searcher doesn't support\"", "\" assert_eq!(b\\\"The 2 1 0.\\\".to_vec(), result);\"", "& mut core :: fmt :: Formatter", "\" using the [`regex` crate](https://docs.rs/regex) or the lower level\"", "\" In general, searching streams will use a constant amount of memory for\"", "\" Returns an iterator of non-overlapping matches, using the match\"", "& self . nfa_contiguous", "\" bytes instead of the equivalence classes.\"", "\" [`AhoCorasick::try_find_overlapping_iter`] does not support this\"", "\"     ac.try_find_overlapping(haystack, &mut state)?;\"", "\" assert_eq!(2_584, ac.memory_usage());\"", "\" reading from the reader given.\"", "\" match. If the closure returns `false`, then searching is stopped.\"", "\" because it isn't totally clear what the match semantics ought to be.\"", "\" of the iterator failed. The `Result` values yield by the iterator\"", "core :: fmt :: Formatter", "& Input < '_ >", "& mut W", "\" This panics when [`AhoCorasick::try_replace_all_with_bytes`] would\"", "& nfa", "\" This panics when [`AhoCorasick::try_find`] would return an error.\"", "\" Note that there is currently no infallible version of this routine.\"", "\" searches.\"", "\"     .build(&[\\\"b\\\", \\\"abc\\\", \\\"abcd\\\"])\"", ":: core :: marker :: Copy", "\" the patterns `Sam` and `Samwise` were used to build the automaton (in\"", ":: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , \"FindIter\" , & & self . 0)", ":: core :: cmp :: PartialEq", "\" The `AhoCorasick` type uses thread safe reference counting internally. It\"", "\" This experiment very strongly argues that a contiguous NFA is often the\"", "\" The common thread between the different types of errors is that they are\"", "\" simultaneously in a case insensitive fashion. Each match includes the\"", "\"     };\"", "self . build_auto (nfa)", "\" ever needing to explicitly re-slice the haystack. Overlapping search\"", "\" This is the fallible version of\"", "bool", ":: core :: fmt :: Debug", "\" Examples of errors that can occur:\"", "\" ASCII case insensitivity and what kind of match semantics are used.\"", "Result < Option < Match > , MatchError >", "(* * self) . max_pattern_len ()", ":: core :: default :: Default", "\" boundary are silently skipped.\"", "\" assert_eq!(\\\"b\\\", &haystack[mat.span()]);\"", "StreamFindIter < 'a , R >", "\" size), then it is strongly recommended to handle the possibility of an\"", "(Arc :: new (cnfa) , AhoCorasickKind :: ContiguousNFA)", "\" when no specific 'AhoCorasickKind' is selected by the caller and\"", "\" Aside from convenience, when `AhoCorasick` was built with\"", "\"     matches.push(mat.pattern());\"", "\" For more details on match semantics, see the [documentation for\"", "& mut String", "\" semantics support stream searches.)\"", "\" ], matches);\"", "\" [`AhoCorasickBuilder::kind`], then one is automatically chosen and\"", "\" may be changed in a semver compatible release.\"", "\" To re-iterate, if the patterns, build or search configuration come from\"", "\" candidates using specialized literal search routines. A prefilter\"", "\" the beginning of our search.\"", "& [u8]", "\" Note that an `AhoCorasick` automaton has a minimum length of `0` if\"", "noncontiguous :: Builder", "\"AhoCorasick::try_replace_all_bytes should not fail\"", "\" # Memory usage\"", "\" the underlying transition table to support both simultaneously.\"", "MatchError :: invalid_input_unanchored ()", "\" a match has occurred.\"", "\" Routines for querying information about the Aho-Corasick automaton.\"", "\" This is the infallible version of [`AhoCorasick::try_find_iter`].\"", "\" So why record the start kind here? Well, consider what happens\"", "\" [`AhoCorasick::replace_all_with_bytes`].\"", "std :: io :: Error :: new", "kind", "\" factors, particularly when enabling the [DFA](AhoCorasickKind::DFA) option\"", "\" not be able to meaningfully impl `Debug` or the marker traits without also\"", "\"     replace_with,\"", "\" When searching a stream, an internal buffer is used. Therefore, callers\"", "\" be reduced drastically from `#states * 256 * sizeof(u32)` to\"", "\"     .start_kind(StartKind::Both)\"", "\" calls are guaranteed to succeed.)\"", "\" a result of both search-time configuration and what configuration is used\"", "\"     .match_kind(MatchKind::Standard) // default, not necessary\"", "\" Returns the kind of the Aho-Corasick automaton used by this searcher.\"", "\" assert_eq!(AhoCorasickKind::DFA, ac.kind());\"", "\" memory usage isn't a concern. Otherwise, not setting a kind will probably\"", "[u8]", "\" should be no need to handle errors anywhere and it is generally encouraged\"", "Self", "\" # let haystack = \\\"append the app to the appendage\\\";\"", "\" untrusted input (or input that doesn't have any reasonable bounds on its\"", "\" # Panics\"", "\" sophistication. If you do need Unicode handling, you might consider\"", "(* * self) . is_special (sid)", "\" assert_eq!(5_632, ac.memory_usage());\"", "\"ContiguousNFA\"", "\" from.\"", "Result < FindIter < 'a , 'h > , MatchError >", "\" pattern that matched along with the byte offsets of the match.\"", "\" Leftmost-first semantics:\"", "\" includes, but is not limited to, `&str` and `&[u8]`.\"", "\" match each pattern at each position in the haystack in the same order\"", "yes", "\" use aho_corasick::{AhoCorasick, AhoCorasickKind};\"", "\" let ac = AhoCorasick::new(&[\\\"foo\\\", \\\"\\\", \\\"quux\\\", \\\"baz\\\"]).unwrap();\"", ":: core :: fmt :: Result", "\" where an error is reported if there was a problem reading from the\"", "\" let result = ac.replace_all(haystack, replace_with);\"", "\" # Examples\"", "\" Indeed, since anchored searches tend to be somewhat more rare,\"", "\" ac.try_stream_replace_all_with(\"", "\" // An unanchored search is not supported! An error here is guaranteed\"", "\" programmer error. In cases where callers want errors instead of panics, use\"", "self . try_replace_all (haystack , replace_with) . expect (\"AhoCorasick::try_replace_all is not expected to fail\")", "\" Set the limit on how many states use a dense representation for their\"", "\" the match and a string buffer with which to write the replaced text\"", "self . aut", "\" from a non-contiguous NFA, the caller is responsible for building\"", "haystack", "\" former corresponds to the match you would get if you were to try to\"", "str", "\" # Example: unanchored and anchored searches\"", "\" result in using a DFA or it might pick an NFA. If it picks an NFA, the\"", "\" It isn't clear what the match semantics for anchored overlapping\"", "\" This usually permits one to just import the `AhoCorasick` type.\"", "AcAutomaton", "\" This iterator will report all possible matches in a particular haystack,\"", "& AhoCorasickKind", "byte", "\" If you need a fallible version of this, then [`AhoCorasick::try_find`]\"", "\" #    .match_kind(MatchKind::LeftmostFirst)\"", "\" automaton.\"", "\"     true\"", "\" supported would result in an error.\"", "\" result in an error (or a panic if using the infallible APIs). When\"", "self . aut . try_find_overlapping_iter (input) ?", "\" using the given closure. The result is written to the given\"", "\" default), a contiguous NFA is used in most cases.\"", "match self . kind { None => { self . build_auto (nfa) } Some (AhoCorasickKind :: NoncontiguousNFA) => { (Arc :: new (nfa) , AhoCorasickKind :: NoncontiguousNFA) } Some (AhoCorasickKind :: ContiguousNFA) => { let cnfa = self . nfa_contiguous . build_from_noncontiguous (& nfa) ? ; (Arc :: new (cnfa) , AhoCorasickKind :: ContiguousNFA) } Some (AhoCorasickKind :: DFA) => { let dfa = self . dfa . build_from_noncontiguous (& nfa) ? ; (Arc :: new (dfa) , AhoCorasickKind :: DFA) } }", "\" A dense representation uses more memory but is generally faster, since\"", "\" if using the infallible APIs). Similarly, when this is set to\"", "StartKind", "self . try_replace_all_with_bytes (haystack , dst , replace_with)", "\" assert_eq!(Some(Match::must(0, 22..28)), state.get_match());\"", "PatternID", "\" The other kinds of match semantics that are supported are\"", "\" for building a contiguous NFA is almost certainly worth it.\"", "\" [`AhoCorasickBuilder`].\"", "\" let result = ac.replace_all(haystack, &[\\\"x\\\", \\\"y\\\", \\\"z\\\"]);\"", "Arc < dyn AcAutomaton >", "\" use aho_corasick::{AhoCorasick, MatchKind};\"", "\" can be used with [`Input::earliest`] enabled.\"", "patterns", "\" A convenience method for returning a new Aho-Corasick builder.\"", "\" the result of user input, and thus, an error is typically indicative of a\"", "\" This is the fallible version of [`AhoCorasick::find_iter`].\"", "\" reaches `EOF`.\"", "\" # Cloning\"", "\" `expect()`) if construction fails.\"", "\" # Example: anchored search\"", "\" NFA and have it fail. In which case, it will fall back to using a\"", "\"AhoCorasick::try_replace_all_with_bytes should not fail\"", "(* * self) . next_state (anchored , sid , byte)", "(* * self) . pattern_len (pid)", "(* * self) . memory_usage ()", "\" are always supported.\"", "\" two copies of the transition table: one generated by following failure\"", "Sync", "\" must be at least the size of the longest possible match. In most use\"", "\" assert_eq!(matches, vec![\"", "\" cases, the default buffer size will be much larger than any individual\"", ":: core :: fmt :: Formatter :: write_str (f , match self { AhoCorasickKind :: NoncontiguousNFA => \"NoncontiguousNFA\" , AhoCorasickKind :: ContiguousNFA => \"ContiguousNFA\" , AhoCorasickKind :: DFA => \"DFA\" , } ,)", "\" anchored searches:\"", "\"StreamFindIter\"", "(Arc :: new (nfa) , AhoCorasickKind :: NoncontiguousNFA)", "\"     .kind(Some(AhoCorasickKind::DFA))\"", "\" _only_ unanchored searches are supported by default. Thus,\"", "\" Enable heuristic prefilter optimizations.\"", "\" since this replacement routine always does an unanchored search.\"", "\" that is used for unanchored searches and one that is used for anchored\"", "\" is possible to configure which starting state configuration is needed.\"", "\" The previous example can also be adapted to implement\"", "\" This iterator is constructed via the [`AhoCorasick::find_iter`] and\"", "\" to an [`Input`]. This includes `&[u8]`, `&str` and `Input` itself.\"", "input . into ()", "\" constant number of instructions. A sparse representation uses less\"", "\" # let ac = AhoCorasick::builder()\"", "\" This is the fallible version of [`AhoCorasick::replace_all_bytes`].\"", "\" assert_eq!(10_879, ac.memory_usage());\"", "\" Infallible search routines. These APIs panic when the underlying search\"", "\" let haystack = \\\"appendappendage app\\\";\"", "\" // Aho-Corasick implementation ends up being used internally.\"", "\" return an error. Since an error is _never_ dependent on the actual contents\"", "self . nfa_contiguous . prefilter (yes)", "\" reported by [`AhoCorasick::try_find_iter`].\"", "\" Leftmost-longest semantics:\"", "\" ac.try_replace_all_with_bytes(haystack, &mut result, |mat, _, dst| {\"", "\" is guaranteed that it is cheap to clone.\"", "\" searches:\"", "\" Setting this configuration does not change the time complexity for\"", "\" This is principally used as an input to the\"", "\"     .build(&[\\\"samwise\\\", \\\"sam\\\"])\"", "\" equivalence class represents a set of bytes that does not discriminate\"", "Result < AhoCorasick , BuildError >", "\" Return the total number of patterns matched by this automaton.\"", "Result < () , std :: io :: Error >", "\" Sets the starting state configuration for the automaton.\"", "\" data, then it is likely acceptable to panic (by calling `unwrap()` or\"", "\" idea is that most of the time searching will be spent near the starting\"", "Vec < u8 >", "\" match.\"", "\" either leftmost-first or leftmost-longest match semantics. Stated\"", "\" # Example: leftmost-first searching\"", "doc", "\" `input` may be any type that is cheaply convertible to an `Input`. This\"", "\" use a [`noncontiguous::NFA`]. A noncontiguous NFA is the fastest to\"", "\" automaton, with the default being [`AhoCorasick::new`]. However, there\"", "\" // don't let the difference fool you. With such a small number of\"", "self . aut . try_find_iter (input) ?", "MatchKind", "f . debug_tuple (\"AhoCorasick\")", "\" When this option is enabled, searching will be performed without\"", "\" was asked for (and vice versa), even if the underlying automaton\"", "\" The default is [`MatchKind::Standard`], which corresponds to the match\"", "\"     (PatternID::must(1), 13, 18),\"", "(* * self) . is_start (sid)", "\"     },\"", "\"     matches.push(mat);\"", "\" Currently, there are four choices:\"", "A", "\" ac.replace_all_with_bytes(haystack, &mut result, |mat, _, dst| {\"", "f", "\" * 21MB for a [`contiguous::NFA`] in 275ms.\"", "StateID", "F", "\"FindOverlappingIter\"", "\" depending on the search configuration, it is possible for a search to\"", "\"     Some(PatternID::must(1)),\"", "\" `replace_with` slice given. Matches correspond to the same matches as\"", "\"     PatternID::must(2),\"", "\" doesn't support overlapping searches. (Only searchers built with\"", "self", "\"     Match::must(0, 22..28),\"", "\" let result = ac.try_replace_all_bytes(haystack, &[\\\"x\\\", \\\"y\\\", \\\"z\\\"])?;\"", "\" This is the fallible version of [`AhoCorasick::stream_find_iter`].\"", "\" do it.\"", "\" memory, but will typically execute searches the fastest.\"", "\" from all possible bytes to their corresponding equivalence class. Each\"", "\"     .expect(\\\"should have a match\\\");\"", "\" let mat = ac.find(Input::new(haystack).earliest(true))\"", "\"     // The final 'foo' is not found because it is not adjacent to the\"", "\" standard match semantics supported by textbook descriptions of the\"", "\" };\"", "\" This limit is expressed in terms of the depth of a state, i.e., the\"", "\" // the NFAs above. For a large number of patterns, it is easy for the\"", "\" what the noncontiguous NFA supports. In which case, building a contiguous\"", "\" This is the fallible version of [`AhoCorasick::replace_all_with`].\"", "\" reports a match as soon as it is found. This corresponds to the\"", "I", ":: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , \"FindOverlappingIter\" , & & self . 0 ,)", "\" searches unconditionally. There's no way to disable one or the other.\"", "MatchError", "AhoCorasickBuilder :: new", "\" the given reader, and write the replacements to the given\"", "std :: io :: Error", "\" internal implementation choice. So we smooth things out and ensure\"", "\" * 1.6GB for a [`dfa::DFA`] in 1.88s.\"", "\" or some combination of both. A first approximation for the scale at which\"", "\" Returns an error if the start state configuration does not support the\"", "state", "e", "\" length of the haystack.\"", "\" )?;\"", "\" even when the matches overlap.\"", "\" Use a DFA. Warning: DFAs typically use a large amount of memory.\"", "self . aut . try_stream_replace_all (rdr , wtr , replace_with)", "\" search.\"", "self . aut . try_find_iter (input)", "\" Note that both methods return iterators that produce `Result` values.\"", "AhoCorasickBuilder :: default ()", "\" those configurations are a static property of your program, then it is\"", "\" One example is that only Aho-Corasicker searchers built with\"", "\" After all matches are replaced, the writer is _not_ flushed.\"", "\" configurations:\"", "\" usage.\"", "\"     .map(|mat| mat.pattern())\"", "\" search and stream searching) are only supported when using the\"", "\" By default, this is set to a low but non-zero number. Setting this to\"", "\" This example shows the difference in heap usage between a few\"", "self . aut . memory_usage ()", "\"     Match::must(0, 0..6),\"", "\" Enable ASCII-aware case insensitive matching.\"", "\" iterators that produce `Result` values. The difference is that this\"", "\" [`MatchKind::LeftmostLongest`] if you want to match how POSIX regex engines\"", "\" cannot always be used, and is generally treated as a heuristic. It\"", "\"NoncontiguousNFA\"", "(* * self) . try_find (input)", "\" Replace all matches with a corresponding value in the `replace_with`\"", "\" [`MatchKind::LeftmostFirst`] or [`MatchKind::LeftmostLongest`] semantics.\"", "\" let mut result = String::new();\"", "\" Returns the location of the first match according to the match\"", "AhoCorasick { aut : :: core :: clone :: Clone :: clone (& self . aut) , kind : :: core :: clone :: Clone :: clone (& self . kind) , start_kind : :: core :: clone :: Clone :: clone (& self . start_kind) , }", "& mut Self", "\" running an anchored search will result in an error (or a panic\"", "\" the given `Input` configuration.\"", "\"         wtr.write_all(mat.pattern().as_usize().to_string().as_bytes())\"", "\"     (PatternID::must(0), 28, 33),\"", "\" [`Input`], it's possible to provide an `Input` directly in order to\"", ":: core :: clone :: Clone :: clone (& self . aut)", "contiguous :: Builder", "Result < String , MatchError >", "\" Currently, prefilters are typically only active when building searchers\"", "\" // will reveal that the rate of growth of the DFA is far bigger than\"", "\" (if any). If the closure returns `true`, then it continues to the next\"", "\" Replacements are determined by the index of the matching pattern.\"", "\" implementation to use. Since all Aho-Corasick automatons are built\"", "\" # Ok::<(), Box<dyn std::error::Error>>(())\"", "\" The closure accepts three parameters: the match found, the text of\"", "\" on the number of patterns.\"", "\" Returns the type of starting search configuration supported by this\"", "\" let patterns = &[\\\"append\\\", \\\"appendage\\\", \\\"app\\\"];\"", "\" [`AhoCorasick::find_iter`].\"", "\" that order), then `Samwise` can never participate in a match because\"", "\" # Fallibility\"", "\" the core `Automaton` trait. Basically, we provide all of the marker traits\"", "\" non-overlapping searches from `O(n + p)` to `O(n)`, where `n` is the\"", "W", "\" This example shows how to replace matches with some other string:\"", "\" respect to case for ASCII letters (`a-z` and `A-Z`) only.\"", "\"     haystack.as_bytes(),\"", "\" let ac = AhoCorasick::builder()\"", "dfa :: Builder", "\" possible for it to attempt to construct, for example, a contiguous\"", "\" then use a sparse representation.\"", "\" difference is that every byte will be forced into its own distinct\"", "\" We don't really *need* to put this here, since the underlying automaton\"", "\"     AhoCorasick, Anchored, Input, Match, MatchKind, StartKind,\"", "{ let cnfa = self . nfa_contiguous . build_from_noncontiguous (& nfa) ? ; (Arc :: new (cnfa) , AhoCorasickKind :: ContiguousNFA) }", "\" To give a quick idea of the differences between Aho-Corasick\"", "return (Arc :: new (dfa) , AhoCorasickKind :: DFA)", "\" state of the automaton, so states near the start state should use a\"", "\" its internal buffer. The one requirement is that the internal buffer\"", "\" assert_eq!(\\\"abcd\\\", &haystack[mat.start()..mat.end()]);\"", "\" * Running a search that requires [`MatchKind::Standard`] semantics (such\"", "\" differently, overlapping searches require one to build the searcher\"", "\" example above):\"", ":: core :: clone :: Clone", "| e | std :: io :: Error :: new (std :: io :: ErrorKind :: Other , e)", "\" The advantage of this map is that the size of the transition table can\"", "BuildError", "allow", "replace_with", "\" Create a new builder for configuring an Aho-Corasick automaton.\"", "match self . nfa_contiguous . build_from_noncontiguous (& nfa) { Ok (nfa) => { return (Arc :: new (nfa) , AhoCorasickKind :: ContiguousNFA) ; } # [allow (unused_variables)] Err (_err) => { } }", "\" * You might want to use [`AhoCorasickBuilder::kind`] to set your searcher\"", "\"     .try_find_overlapping_iter(Input::new(haystack))?\"", "\" [`AhoCorasick::try_replace_all_with`].\"", "\"     .match_kind(MatchKind::LeftmostFirst)\"", "\" memory but is generally slower, since the next transition in a sparse\"", "\" `#states * k * sizeof(u32)` where `k` is the number of equivalence\"", "\" corresponding to the earliest pattern given to the automaton. The\"", "\" The only \\\"catch\\\" to using a contiguous NFA is that, because of its variety\"", "(* * self)", "\" [`MatchKind::Standard`] semantics support overlapping searches. Using\"", "\"     .kind(Some(AhoCorasickKind::ContiguousNFA))\"", "\" // The correct leftmost-longest match here is 'abcd', but since we\"", "\" Replace all matches using a closure called on each match.\"", "\" 'StartKind::Unanchored' is used (both are the default). It *might*\"", "\" This panics when [`AhoCorasick::try_replace_all_bytes`] would return an\"", "\" is the total number of patterns being compiled). Setting this to\"", "f . debug_tuple (\"AhoCorasick\") . field (& self . aut) . finish ()", "\" let input = Input::new(haystack).range(4..).anchored(Anchored::Yes);\"", "\" Aho-Corasick automatons can also use a fair bit of memory. To get\"", "\" A trait that effectively gives us practical dynamic dispatch over anything\"", "\" The `AhoCorasick` type supports a few basic ways of constructing an\"", "\" let mut state = OverlappingState::start();\"", "\" callers may want to provide a buffered writer.\"", "\" it will be found:\"", "FindIter < 'a , 'h >", "AhoCorasickBuilder :: new () . build (patterns)", "\" yieled until the stream is exhausted.\"", "\" This iterator yields elements of type `Result<Match, std::io::Error>`,\"", "other", "\" to, how matches are determined, simple case insensitivity, whether to use a\"", "\" Returns an iterator of overlapping matches.\"", "\" some kind of reason to use a specific Aho-Corasick implementation. For\"", "\" Most of the search routines accept anything that can be cheaply converted\"", "\" semantics that this automaton was constructed with.\"", "\"AhoCorasick::try_find_overlapping_iter is not expected to fail\"", "self . kind = kind", ":: core :: clone :: Clone :: clone (& self . kind)", "\" search type. But we do keep this here for API behavior consistency.\"", "\" [`AhoCorasick::try_replace_all_with_bytes`].\"", "Result < FindOverlappingIter < 'a , 'h > , MatchError >", "self . aut . min_pattern_len ()", "\" The builder provides a way to configure a number of things, including\"", "\"AhoCorasick::try_replace_all_with should not fail\"", "\" ac.try_find_overlapping(haystack, &mut state)?;\"", "\" values yield by the iterator come from whether the given reader returns\"", "\" # Example: anchored iteration\"", "\" Returns the length of the longest pattern matched by this automaton.\"", "\" [`AhoCorasick::try_stream_find_iter`] methods.\"", "Some", "100", "\" let input = Input::new(\\\"abcd\\\").anchored(Anchored::Yes);\"", "\" be built, has moderate memory usage and is typically the slowest to\"", "\" one is debugging the underlying automaton.\"", "\"     PatternID::must(1),\"", "Send", "enforce_anchored_consistency (self . start_kind , input . get_anchored ())", "* self", "\" ac.try_stream_replace_all(\"", "\" do less work in that case.)\"", "\" use aho_corasick::{\"", "\" the same `Input` is given to subsequent calls, then all subsequent\"", "\" and [`AhoCorasick::try_find_overlapping_iter`] methods.\"", "\" equivalence class. This is useful for debugging the actual generated\"", "\" assert_eq!(\\\"x the z to the xage\\\", result);\"", "self . try_find_overlapping (input , state) . expect (\"AhoCorasick::try_find_overlapping is not expected to fail\")", "\" randomly selected titles from Wikipedia:\"", "\" let input = Input::new(haystack).earliest(true);\"", "\" They always both work. But the DFA in this crate specifically only\"", "\" This is the infallible version of [`AhoCorasick::try_find`].\"", "\" the next transition in a dense representation can be computed in a\"", "Option < & Prefilter >", "\" searcher was compiled with leftmost-first match semantics. In this\"", "\" assert_eq!(None, state.get_match());\"", "input", "enforce_anchored_consistency (self . start_kind , Anchored :: No)", "\" writer. Matches correspond to the same matches as reported by\"", "return (Arc :: new (nfa) , AhoCorasickKind :: ContiguousNFA)", "\" use aho_corasick::{AhoCorasick, Match, MatchKind};\"", "\" ]).unwrap();\"", "Option < AhoCorasickKind >", "\" let ac = AhoCorasick::new(&[\"", "& mut :: core :: fmt :: Formatter", "std :: io :: Error :: new (std :: io :: ErrorKind :: Other , e)", "\"     Match::must(1, 22..31),\"", "\" caller only asked for support for unanchored searches. Maybe that's\"", "\" * For all other options, their defaults are almost certainly what you want.\"", "\" an error will be returned. In contrast, when `None` is used, it is\"", "\" let replace_with = &[\\\"sloth\\\", \\\"grey\\\", \\\"slow\\\"];\"", "\" [`AhoCorasick::try_replace_all_bytes`].\"", "\" If there was a problem reading from the given reader or writing to the\"", "\" let haystack = \\\"fooquuxbar foo\\\";\"", ":: core :: fmt :: Formatter :: debug_struct_field5_finish (f , \"AhoCorasickBuilder\" , \"nfa_noncontiguous\" , & self . nfa_noncontiguous , \"nfa_contiguous\" , & self . nfa_contiguous , \"dfa\" , & self . dfa , \"kind\" , & self . kind , \"start_kind\" , & & self . start_kind ,)", "Err", "Debug", "\" NFA will fail and (by default) `AhoCorasick` will automatically fall\"", "\" said, building an automaton can be fairly costly because of high constant\"", "\" );\"", "u8", "\" // patterns, the difference is small, but a bigger number of patterns\"", "\" The lifetime `'a` refers to the lifetime of the corresponding\"", "\" This option is enabled by default and should never be disabled unless\"", "\" The previous example can be easily adapted to implement your own\"", "self . nfa_contiguous . build_from_noncontiguous (& nfa)", "\" `Sam` will always take priority.\"", "\" This shows how to anchor the search, such that all matches must begin\"", "\" // told the search to quit as soon as it knows a match has occurred,\"", "self . try_replace_all (haystack , replace_with)", "! want . is_anchored ()", "\" transitions because it lets one see the transitions defined on actual\"", "\" Replace all matches using raw bytes with a corresponding value in the\"", "self . aut . try_find (& input . into () . earliest (true)) . expect (\"AhoCorasick::try_find is not expected to fail\") . is_some ()", "\" DFA. Indeed, when no specific [`AhoCorasickKind`] is used (which is the\"", "& mut Vec < u8 >", "input . get_anchored ()", "StartKind :: Both", "MatchError :: invalid_input_anchored", "\" # Resource usage\"", "\" # Example: basic usage\"", "self . try_replace_all_bytes (haystack , replace_with) . expect (\"AhoCorasick::try_replace_all_bytes should not fail\")", "Result < StateID , MatchError >", "sid", "\" [`regex-automata` crate](https://docs.rs/regex-automata).\"", "\" * Running an unanchored search with an automaton that only supports\"", "\" semantics supported by the standard textbook description of the\"", "\" occurred, even if it doesn't correspond to the leftmost-first match.\"", "\" should avoiding providing a buffered reader, if possible. However,\"", "FindOverlappingIter (self . aut . try_find_overlapping_iter (input) ?)", "\" semantics if desired.\"", "\" If `None` is given, then one may use [`AhoCorasick::kind`] to determine\"", "\"     AhoCorasick, Input, Match,\"", "\" uses.\"", "\" leftmost-first or leftmost-longest semantics, this might result in a\"", "String", "P", "\" reported by [`AhoCorasick::find_iter`].\"", "\" This panics when [`AhoCorasick::try_find_iter`] would return an error.\"", "& mut AhoCorasickBuilder", "\" The underlying Aho-Corasick automaton. It's one of\"", "\" Aho-Corasick implementation. This choice is typically based primarily\"", "\" Note that when this is set to [`StartKind::Unanchored`], then\"", "\" And finally, leftmost-longest semantics:\"", "\" let input = Input::new(\\\"foo abcd\\\").anchored(Anchored::Yes);\"", "\" get an error.\"", "\" let mat = ac.find(haystack).expect(\\\"should have a match\\\");\"", "self . aut . match_kind ()", "\"kind\"", "\" call. (Indeed, if the first `try_find_overlapping` call succeeds and\"", "& & self . 0", "\" The `AhoCorasick` type provides a number of methods for searching, as one\"", "\" version of the [`AhoCorasick::try_find_iter`] method.\"", "self . try_replace_all_with (haystack , dst , replace_with) . expect (\"AhoCorasick::try_replace_all_with should not fail\")", "\" # let haystack = b\\\"append the app to the appendage\\\";\"", "\" searcher.\"", "\" ];\"", "Ok", "Input < 'h >", "\" may use [`AhoCorasick::try_find_overlapping`] to implement their own\"", "\" })?;\"", "\" also often faster than a noncontiguous NFA, but a little slower than a\"", "FindOverlappingIter < 'a , 'h >", "\" [`AhoCorasickBuilder::start_kind`] method. Its documentation goes into more\"", "Automaton", "index", "\" execute a search.\"", "want . is_anchored ()", "\"AhoCorasickBuilder\"", "noncontiguous :: NFA", "__self_discr == __arg1_discr", "\" assert_eq!(Some(Match::must(0, 0..7)), ac.find(\\\"samwise\\\"));\"", "\" use aho_corasick::{AhoCorasick, Input, MatchKind, PatternID};\"", "\" In this example, we will find all overlapping matches that start at\"", "\" assert_eq!(0, ac.min_pattern_len());\"", "self . nfa_noncontiguous . build (patterns)", "& str", "self . nfa_noncontiguous . ascii_case_insensitive (yes)", "automatically_derived", "\" replacement is stopped.\"", "\" which Aho-Corasick implementation was chosen.\"", "\" sub-optimal for a particular workload.\"", "pid", "\" there is no borrowed data. Without these, the main `AhoCorasick` type would\"", "FindOverlappingIter", "{ (Arc :: new (nfa) , AhoCorasickKind :: NoncontiguousNFA) }", "\" internally (which always supports both unanchored and anchored\"", "\" `0` is almost never what you want, since it is likely to make searches\"", "\" number of transitions from the starting state of the automaton. The\"", "\" might expect. Depending on how the Aho-Corasick automaton was built and\"", "\" semantics for a particular set of patterns in a specific order:\"", "FnMut (& Match , & [u8] , & mut W) -> Result < () , std :: io :: Error >", "\" // While this shows the DFA being the biggest here by a small margin,\"", "\" iterators *ought* to be, so currently an error is returned. Callers\"", "\" Search for and replace all matches of this automaton in\"", "dfa", "self . nfa_contiguous . ascii_case_insensitive (yes)", "\" configure the search. In this example, we show how to use the\"", "\"     // anchored.\"", "\" use std::io::Write;\"", "\" input with respect to the current state of the underlying searcher.\"", "\" occur. And if one _does_ occur, then it's a bug in your program.\"", "\" # Example: anchored overlapping search returns an error\"", "\" or do stream searching.\"", "\" assert_eq!(Some(Match::must(1, 0..3)), ac.try_find(input)?);\"", "\" Setting this guarantees that the searcher returned uses the chosen\"", "\" stream. Matches correspond to the same matches as reported by\"", "Prefilter", "AhoCorasick", "self . aut . max_pattern_len ()", "\" that impls `Automaton`, but without needing to add a bunch of bounds to\"", "self . nfa_contiguous", "\" ac.find_overlapping(haystack, &mut state);\"", "\" an error. For example, when the Aho-Corasick searcher is built with\"", "\" a noncontiguous NFA, has excellent memory usage and is typically a\"", "\" std::io::Error>`, where an error is yielded if there was a problem\"", ":: core :: intrinsics :: discriminant_value (self)", "\" assert_eq!(\\\"abc\\\", &haystack[mat.start()..mat.end()]);\"", "\" [`AhoCorasick`] searcher.\"", "Arc :: new", "\" idea to build an automaton once and reuse it as much as possible.\"", "\" the stream given, where the first byte has index `0`. Matches are\"", "\" regex engines execute searches for `pat1|pat2|..|patN`. Use\"", "AhoCorasick { aut , kind , start_kind : self . start_kind , }", "\" of compression tricks, it may not be able to support automatons as large as\"", "std :: io :: ErrorKind :: Other", "\"     AhoCorasick, Anchored, Input, Match, StartKind,\"", "\" [`dfa::DFA`]. A DFA is very slow to build, uses exorbitant amounts of\"", "(* * self) . is_match (sid)", "\" use aho_corasick::{AhoCorasickBuilder, PatternID};\"", "\" });\"", ":: core :: intrinsics :: discriminant_value", "\" since this stream searching routine always does an unanchored search.\"", "core :: fmt :: Debug", "B", "\" ac.try_replace_all_with(haystack, &mut result, |mat, _, dst| {\"", "self . aut . try_replace_all_with (haystack , dst , replace_with)", "\" [`MatchKind::Standard`] semantics support overlapping searches.)\"", "automaton :: FindIter < 'a , 'h , Arc < dyn AcAutomaton > >", "\" assert_eq!(4, ac.max_pattern_len());\"", "AsRef < [u8] >", "[B]", "\" those failure transitions.\"", "\" default. Or just use [`StartKind::Both`] to support both types of searches.\"", ":: core :: fmt :: Formatter :: debug_struct_field5_finish", "self . dfa . match_kind (kind)", "\" [`StartKind::Unanchored`] is the default.\"", "\" alphabet is used, automaton compilation becomes faster as well.\"", "\" case, the search is stopped as soon as it is known that a match has\"", "\" and only if it can match the empty string:\"", "self . aut . try_find (& input)", "\"     ac.try_find_overlapping(input.clone(), &mut state)?;\"", "\" `p` is the combined length of all patterns being searched. With that\"", "self . dfa . start_kind (kind)", "\" This panics when `replace_with.len()` does not equal\"", "FnMut (& Match , & [u8] , & mut Vec < u8 >) -> bool", "AhoCorasickKind :: NoncontiguousNFA", "\" implementation. If that implementation could not be constructed, then\"", "\"     .ascii_case_insensitive(true)\"", "\" let input = Input::new(haystack).anchored(Anchored::Yes);\"", "\" given writer, then the corresponding `io::Error` is returned and all\"", "\" [`MatchKind::LeftmostFirst`] and [`MatchKind::LeftmostLongest`]. The\"", "enforce_anchored_consistency (self . start_kind , Anchored :: No) ?", "self . try_find_overlapping_iter (input) . expect (\"AhoCorasick::try_find_overlapping_iter is not expected to fail\")", "\" all rooted in the automaton construction and search configurations. If\"", "\" supports it.\"", "\" If the beginning of the search is changed to where a match begins, then\"", "\" let patterns = &[\\\"apple\\\", \\\"maple\\\", \\\"snapple\\\"];\"", "\"     .build(&[\\\"foobar\\\", \\\"bruce\\\", \\\"triskaidekaphobia\\\", \\\"springsteen\\\"])\"", "self . 0 . next ()", "\" Note that there is no corresponding fallible routine for this method.\"", "& input", "\" units of bytes.\"", "\" Use a noncontiguous NFA.\"", "\" desired search configuration. See the internal 'AhoCorasick::start_kind'\"", "depth", "self . try_replace_all_with_bytes (haystack , dst , replace_with) . expect (\"AhoCorasick::try_replace_all_with_bytes should not fail\")", "\" This also returns an error if the searcher does not support stream\"", "\" assert_eq!(None, ac.try_find(input)?);\"", "\" // No more match matches to be found.\"", "\" with [`MatchKind::Standard`] (it is the default).\"", "\" This includes patterns that may never participate in a match. For\"", "\"     .unwrap();\"", "\" absolves the caller of needing to check for errors on every search\"", "\" use aho_corasick::{AhoCorasick, MatchKind, PatternID};\"", "\"     let mat = result?;\"", "(* * self) . is_dead (sid)", "\" Returns the length of the shortest pattern matched by this automaton.\"", "\" [`StartKind::Both`] is used, then both unanchored and anchored searches\"", ":: core :: intrinsics :: discriminant_value (other)", "\" Construction can fail in generally one way: when the inputs provided are\"", "\" can be useful to disable this if the prefilter is observed to be\"", "\" Search the given reader and replace all matches of this automaton\"", "\" the match and a byte buffer with which to write the replaced text\"", "self . nfa_noncontiguous . match_kind (kind)", "\" assert_eq!(3, ac.find_iter(haystack).count());\"", "self . nfa_noncontiguous . dense_depth (depth)", "\" The lifetime `'a` refers to the lifetime of the `AhoCorasick` automaton.\"", "\" make the right choice for you. Beware that if you use [`StartKind::Both`]\"", "\" # Example: anchored leftmost-first searching\"", "\" automatons from millions of patterns.) Otherwise, the small additional time\"", "\" Note that any matches with boundaries that don't fall on a valid UTF-8\"", "\" _and_ you set [`AhoCorasickKind::DFA`], then the DFA will essentially be\"", "(* * self) . try_find_overlapping (input , state)", "\"     dst.extend(mat.pattern().as_usize().to_string().bytes());\"", "AhoCorasickBuilder { nfa_noncontiguous : :: core :: clone :: Clone :: clone (& self . nfa_noncontiguous) , nfa_contiguous : :: core :: clone :: Clone :: clone (& self . nfa_contiguous) , dfa : :: core :: clone :: Clone :: clone (& self . dfa) , kind : :: core :: clone :: Clone :: clone (& self . kind) , start_kind : :: core :: clone :: Clone :: clone (& self . start_kind) , }", "\" # Example: implementing your own overlapping iteration\"", "\" Build an Aho-Corasick automaton using the configuration set on this\"", "\" example, if [`MatchKind::LeftmostFirst`] match semantics are used, and\"", "\"AhoCorasick::try_find_overlapping is not expected to fail\"", "\" do so. Why? Because for the DFA, supporting both essentially requires\"", "\" this does not yield any speed advantages. Namely, even when this is\"", "\" This returns an error when this Aho-Corasick searcher does not support\"", "\" transitions. Other states will generally use a sparse representation.\"", "\" searches. But this can be toggled with [`AhoCorasickBuilder::start_kind`].)\"", "self . try_find (input)", "\" match. Matches correspond to the same matches as reported by\"", "\" This is effectively equivalent to the iterator returned by\"", "\" once the iterator is constructed, the iteration itself will never\"", "\" when the Aho-Corasick searcher does not support unanchored searches\"", "\" time. If only the haystack comes from user or untrusted data, then there\"", "self . nfa_noncontiguous . prefilter (yes)", "\" More to the point, the memory usage increases superlinearly as this\"", "\" detail about each choice.\"", "\"     |mat, _, wtr| {\"", "Result < () , MatchError >", "enforce_anchored_consistency (self . start_kind , Anchored :: No) . map_err (| e | std :: io :: Error :: new (std :: io :: ErrorKind :: Other , e)) ?", "\" This is the infallible version of [`AhoCorasick::try_replace_all`].\"", "\" Stopping the replacement by returning `false` (continued from the\"", "\"     ac.find(\\\"xxx bar xxx\\\").map(|m| m.pattern()),\"", "\" [`AhoCorasick::try_find_overlapping_iter`].\"", "\" Aho-Corasick algorithm. Namely, matches are reported as soon as they\"", "\" with [`AhoCorasickBuilder::kind`]. For this reason, it's generally a good\"", "\" `replace_with[2]`.\"", "\" Every Aho-Corasick automaton is capable of having two start states: one\"", "\" dense representation. States further away from the start state would\"", "non_exhaustive", "\" This shows how to anchor the search, so that even if the haystack\"", "self . start_kind", "\" space usage can decrease substantially. Moreover, since a smaller\"", "self . aut . try_find_overlapping_iter (input)", "\" The lifetime `'h` refers to the lifetime of the haystack being searched.\"", "\" Returns an iterator of overlapping matches. Stated differently, this\"", "self . try_stream_find_iter (rdr) . expect (\"AhoCorasick::try_stream_find_iter should not fail\")", "AhoCorasickKind :: ContiguousNFA", "\" [`AhoCorasick::try_stream_find_iter`]. Note that both methods return\"", "self . aut . try_stream_find_iter (rdr)", "cnfa", "\"AhoCorasick::try_stream_find_iter should not fail\"", "AhoCorasickBuilder :: default", "\" disabled, a byte class map is still used while searching. The only\"", "\" will correctly return errors if the caller requests an unsupported\"", "\" are found. Moreover, this is the only way to get overlapping matches\"", "\" a concrete idea of how much memory is being used, try using the\"", "self . try_replace_all_bytes (haystack , replace_with)", "\" assert!(!ac.is_match(\\\"xxx qux xxx\\\"));\"", "\" to `unwrap()` (or `expect()`) both build and search time calls.\"", "\" reasonable to call infallible routines since you know an error will never\"", "\" assert_eq!(\\\"0 the 2 to the 0age\\\", result);\"", "\" This example shows how to search for occurrences of multiple patterns\"", "\" would otherwise. (For standard semantics, matches are always\"", "\" stream searches. (Only searchers built with [`MatchKind::Standard`]\"", "\" assert_eq!(Some(Match::must(1, 22..31)), state.get_match());\"", "\" being that the iterator checks for errors before construction and\"", "\" * `None` (the default) instructs the searcher to choose the \\\"best\\\"\"", "\" A debug settting for whether to attempt to shrink the size of the\"", "\" Set the desired match semantics.\"", "\" Because there may be an added non-trivial cost to supporting both, it\"", "& Self", ":: core :: fmt :: Formatter :: debug_tuple_field1_finish", "AsRef < str >", "self . aut . try_replace_all_bytes (haystack , replace_with)", "\" duplicated to support both simultaneously. This results in very high memory\"", "{ return (Arc :: new (dfa) , AhoCorasickKind :: DFA) ; }", "\" An automaton for searching multiple strings in linear time.\"", "\" let haystack = \\\"foo bar baz\\\";\"", "\" increase the size of the automaton.\"", "\" # Example: earliest leftmost-first searching\"", "\" leftmost matches.\"", "match self { AhoCorasickKind :: NoncontiguousNFA => \"NoncontiguousNFA\" , AhoCorasickKind :: ContiguousNFA => \"ContiguousNFA\" , AhoCorasickKind :: DFA => \"DFA\" , }", "\" * [`AhoCorasickKind::NoncontiguousNFA`] instructs the searcher to\"", "\" that our automatons have, in addition to `Debug` impls and requiring that\"", "\" taken when building the automaton.\"", "want", "\" error.\"", "Result < Match , std :: io :: Error >", "\" An iterator that reports Aho-Corasick matches in a stream.\"", "! # [allow (non_exhaustive_omitted_patterns)] match self . start_kind { StartKind :: Both => true , _ => false , }", "\" used for convenience and when you know the search will never return an\"", "\" The difference is that this routine returns an error if _construction_\"", "\" number increases.\"", "\" let matches: Vec<PatternID> = ac\"", "\"     .find_overlapping_iter(haystack)\"", "\" semantics that this automaton was constructed with, and according\"", "\" // The specific Aho-Corasick kind chosen is not guaranteed!\"", "\" In general, you should probably stick to the default unless you have\"", "self . try_find_overlapping (input , state)", "\" return an error. For example, when the Aho-Corasick searcher\"", "\"     automaton::OverlappingState,\"", "\" assert_eq!(b\\\"The slow grey sloth.\\\".to_vec(), result);\"", "& self . nfa_noncontiguous", "\" let haystack = \\\"append the app to the appendage\\\";\"", "AhoCorasickKind", "self . nfa_noncontiguous . build (patterns) ?", "self . try_find_overlapping_iter (input)", "\" let result = ac.replace_all_bytes(haystack, &[\\\"x\\\", \\\"y\\\", \\\"z\\\"]);\"", "\" Note that setting this to [`MatchKind::LeftmostFirst`] or\"", "\" the given `Input` configuration or if overlapping search is not\"", "\" let patterns = &[\\\"fox\\\", \\\"brown\\\", \\\"quick\\\"];\"", "\" Create a new Aho-Corasick automaton using the default configuration.\"", "self . dfa . build_from_noncontiguous (& nfa)", "\" This panics when [`AhoCorasick::try_find_overlapping`] would\"", "self . try_find (input) . expect (\"AhoCorasick::try_find is not expected to fail\")", "self . try_stream_find_iter (rdr)", "\" This is the fallible version of [`AhoCorasick::find_overlapping`].\"", "\" Returns the approximate total amount of heap used by this automaton, in\"", "\" do.\"", "\" Replacements are determined by the index of the matching pattern. For\"", "\" assert_eq!(\\\"0 the 2 to the appendage\\\", result);\"", "\" assert_eq!(expected, matches);\"", "\"nfa_contiguous\"", "\" A builder for configuring an Aho-Corasick automaton.\"", "\" let mut matches = vec![];\"", "(Arc < dyn AcAutomaton > , AhoCorasickKind)", "(Arc :: new (dfa) , AhoCorasickKind :: DFA)", "self . aut . try_find_overlapping (& input , state)", "\" The match kind is important because it determines what kinds of\"", "\" Returns true if and only if this automaton matches the haystack at any\"", "\" # Search configuration\"", "\" matches are returned. Also, some operations (such as overlapping\"", "\" assert_eq!(Some(Match::must(2, 11..14)), state.get_match());\"", "\" This shows how to build a searcher that supports both unanchored and\"", "\" let mut result = vec![];\"", "\" [`contiguous::NFA`]. A contiguous NFA is a little slower to build than\"", "\" Also note that even if an `AhoCorasick` searcher is using an NFA\"", "\"dfa\"", "self . 0", "\" Aho-Corasick automaton.\"", "\" infallible routines would panic.\"", "& self . dfa", "self . nfa_contiguous . build_from_noncontiguous (& nfa) ?", "nfa . patterns_len ()", "\" underlying stream. The iterator terminates only when the underlying stream\"", "\" the given `Input` configuration or does not support overlapping\"", "\" * Use [`AhoCorasickBuilder::match_kind`] to configure your searcher\"", "\" In these examples, we demonstrate the differences between match\"", "\" not peak memory usage. For example, building a contiguous NFA requires\"", "{ self . build_auto (nfa) }", "\" noncontiguous NFA is freed.)\"", "\" to build a searcher that supports both unanchored and anchored searches\"", "\" underlying automaton, but full Unicode handling requires a fair bit of\"", "Result < StreamFindIter < 'a , R > , MatchError >", "\" constructing the Aho-Corasick automaton (which is `O(p)` where `p`\"", "\"     .try_find_iter(Input::new(haystack))?\"", "\" use aho_corasick::AhoCorasick;\"", "\"     Match::must(2, 11..14),\"", "\" back to a noncontiguous NFA. (This typically only happens when building\"", "\" An iterator of overlapping matches in a particular haystack.\"", "R", "! # [allow (non_exhaustive_omitted_patterns)] match self . start_kind { StartKind :: Both => true , _ => false , } && nfa . patterns_len () <= 100", "\" use aho_corasick::{AhoCorasick, StartKind};\"", "\" representation. However, it is unlikely that increasing this number\"", "AhoCorasickBuilder", "\" supported by the configuration set via this method. This means,\"", "\" use aho_corasick::{AhoCorasick, Anchored, Input, MatchKind, StartKind};\"", "\" * [`AhoCorasickKind::ContiguousNFA`] instructs the searcher to use a\"", "\"     Match::must(2, 0..3),\"", "\" be added in the future. The ASCII case works via a simple hack to the\"", "\"     dst.push_str(&mat.pattern().as_usize().to_string());\"", "\" requiring that all impls of `Automaton` do so, which would be not great.\"", "\" Returns an iterator of non-overlapping matches in the given\"", "\" to the given `Input` configuration.\"", "Err (MatchError :: invalid_input_unanchored ())", "\" * [`AhoCorasickKind::DFA`] instructs the searcher to use a\"", "\"     .match_kind(MatchKind::LeftmostLongest)\"", "\"nfa_noncontiguous\"", "\" # Example: configuring a search\"", "\" let patterns = &[\\\"FOO\\\", \\\"bAr\\\", \\\"BaZ\\\"];\"", "\" search that visits less of the haystack than [`AhoCorasick::find`]\"", "MatchError :: invalid_input_unanchored", "AhoCorasickBuilder :: new ()", "\"AhoCorasick::try_find_iter is not expected to fail\"", "\" Replace all matches using raw bytes with a closure called on each\"", "input . into () . earliest (true)", "\" # if !cfg!(target_pointer_width = \\\"64\\\") { return; }\"", "\" Each item yielded by the iterator is an `Result<Match,\"", "\" Standard semantics:\"", "\" implementation of Aho-Corasick is used.\"", "\" for searching. The infallible methods panic if an error occurs, and can be\"", "have", "\" This panics when [`AhoCorasick::try_replace_all_with`] would return an\"", "\" * 99MB for a [`noncontiguous::NFA`] in 240ms.\"", "\" # use aho_corasick::{AhoCorasick, MatchKind, PatternID};\"", "\" support stream searches.\"", "\" Enabling this option does not change the search algorithm, but it may\"", "\" #    .unwrap();\"", "* * self", "\"     matches.push((mat.pattern(), mat.start(), mat.end()));\"", "\" that supports the dense versus sparse representation trade off. Not all\"", "\" assert_eq!(3, ac.min_pattern_len());\"", "\" [`AhoCorasick::try_find_iter`] methods.\"", "Into < Input < 'h > >", "\" Instead, matches can be accessed via [`OverlappingState::get_match`]\"", "\" An iterator of non-overlapping matches in a particular haystack.\"", "\" builder.\"", "crate :: automaton :: private :: Sealed", "\" report an error.\"", "\" anchored searches *always* report an error when only unanchored support\"", "Arc :: new (nfa)", "\" infallible API). Notably, this includes stream and overlapping\"", "\" Matches correspond to the same matches as reported by\"", "match have { StartKind :: Both => Ok (()) , StartKind :: Unanchored if ! want . is_anchored () => Ok (()) , StartKind :: Unanchored => Err (MatchError :: invalid_input_anchored ()) , StartKind :: Anchored if want . is_anchored () => Ok (()) , StartKind :: Anchored => Err (MatchError :: invalid_input_unanchored ()) , }", "Err (MatchError :: invalid_input_anchored ())", "enforce_anchored_consistency (self . start_kind , input . get_anchored ()) ?", "\" Aho-Corasick algorithm.\"", "\" Namely, the NFAs in this crate support both unanchored and anchored\"", ":: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , \"StreamFindIter\" , & & self . 0 ,)", "usize"}
  [split-expanded-lib] DeclsVisitor: Visiting module 'automaton'. Required imports for module: {"\" This trait primarily exists for niche use cases such as:\"", "\" and if you concatenated all of the chunks together, you'd reproduce the\"", "\" even when the matches overlap.\"", "f . write_fmt (format_args ! (\" >\"))", "(* * self) . pattern_len (pid)", "Some (Err (err))", "Automaton", "\" [`noncontiguous::NFA`](crate::nfa::noncontiguous::NFA),\"", "& 'a A", "return Some (self . buffer_reported_pos .. end)", "FnMut (& Match , & [u8] , & mut Vec < u8 >) -> bool", "mat = Some (get_match (aut , sid , 0 , at))", "return Ok (None)", "\" state.\"", "FindIter { aut , input , last_match_end : None , }", "\" entire contents of the stream, byte-for-byte.\"", "\" overlap while we retain bytes from a previous `read` call in memory.\"", "return Ok (())", "Span :: from (state . at .. input . end ())", "StreamChunkIter :: new (self , rdr) ?", "\" the presiding behavior of most general purpose regex engines.\"", "Some (1)", ":: core :: panicking :: panic (\"assertion failed: m.is_empty()\")", "\" // Show that it works for standard searches.\"", "\" through the automaton depending on whether the search is anchored or\"", "Input < 'h >", "& mut W", "R", "\"already checked that no match error can occur\"", "\" The unanchored starting state of this automaton.\"", "chunk", "format_args ! (\"  \")", "crate :: nfa :: noncontiguous :: NFA", "self . input . set_start (m . end ())", "Result < StateID , MatchError >", "return Err (MatchError :: unsupported_overlapping (self . match_kind ()))", "self . start_state (input . get_anchored ()) ?", "& self . aut", "\" the last search call terminated in and the current offset of the search\"", "\" Replaces all non-overlapping matches in `haystack` with\"", "{ if true { if ! false { { :: core :: panicking :: panic_fmt (format_args ! (\"unreachable\")) ; } } } }", "\" starting location of the next search to the ending location of the last\"", "\" states: dead states, start states and match states. It even accounts for\"", "\" contracts as well. For example, `Automaton::is_dead` should only returns\"", "\" Returns the total number of matches for the given state ID.\"", "Iterator < Item = (u8 , StateID) >", "Some (m . end ())", "self . it . next ()", "prev_end", "haystack . len ()", "\" implementation.\"", "match pre . find_in (input . haystack () , span) . into_option () { None => return Ok (None) , Some (i) => { if i > at { at = i ; continue ; } } }", "OverlappingState :: start", "\" for correctness. Indeed, in this crate, implementations of `Automaton`\"", "\" to handle the case of a match that is split by two different\"", "(* * self) . start_state (anchored)", "self . buffer_reported_pos += r . len ()", "f . write_fmt (format_args ! (\"*>\")) ?", "aut . prefilter () . is_some ()", "\"     let mut mat = None;\"", "\"         let len = aut.pattern_len(pid);\"", "\" Returns the length, in bytes, of the shortest pattern in this\"", "Option < Match >", "aut . is_start (sid)", "aut . next_state (input . get_anchored () , sid , input . haystack () [state . at])", "\" Specifically, this tries to succinctly distinguish the different types of\"", "get_match (aut , sid , i , state . at + 1)", "continue", "break", "match self . it . next () { None => return None , Some (Err (err)) => return Some (Err (err)) , Some (Ok (StreamChunk :: NonMatch { .. })) => { } Some (Ok (StreamChunk :: Match { mat , .. })) => { return Some (Ok (mat)) ; } }", "{ }", "\"         mat = Some(get_match(sid, at));\"", "if input . is_done () { return Ok (()) ; }", "if earliest { return Ok (mat) ; }", "& dyn :: core :: fmt :: Debug", "\" Returns true if the given ID represents a \\\"special\\\" state. A special\"", "names", "\" let mut state = OverlappingState::start();\"", "if ! aut . is_start (sid) { :: core :: panicking :: panic (\"assertion failed: aut.is_start(sid)\" ,) }", "(* * self) . is_dead (sid)", "\" # Special states\"", "\" Returns the heap memory usage, in bytes, used by this automaton.\"", "\"NonMatch\"", "{ if earliest { try_find_fwd_imp (aut , input , None , Anchored :: No , true) } else { try_find_fwd_imp (aut , input , None , Anchored :: No , false) } }", "Prefilter", "if self . buf . buffer () . len () >= self . buf . min_buffer_len () { self . buffer_pos = self . buf . min_buffer_len () ; self . buffer_reported_pos -= self . buf . buffer () . len () - self . buf . min_buffer_len () ; self . buf . roll () ; }", "\"OverlappingState\"", "Some (m)", ":: core :: fmt :: Formatter :: debug_struct_field1_finish (f , \"StreamFindIter\" , \"it\" , & & self . it ,)", "(* * self) . match_len (sid)", "\"     Match::must(2, 22..25),\"", "Result < String , MatchError >", "\" still has a `next` method and is iterator-like enough to be fine.)\"", "while let Some ((class , next)) = it . next () { let (prev_start , prev_end , prev_next) = match cur { Some (x) => x , None => { cur = Some ((class , class , next)) ; continue ; } } ; if prev_next == next { cur = Some ((prev_start , class , prev_next)) ; } else { cur = Some ((class , class , next)) ; return Some ((prev_start , prev_end , prev_next)) ; } }", "self . at", "\" or not in order to avoid following failure transitions. Other\"", "\" * A dead state is a state that cannot be left once entered. All transitions\"", "\" active. Otherwise, treating it as special has no purpose and winds up\"", "(* * self) . is_match (sid)", "\" and matches and in order to do that, we really just cannot treat our\"", "if ! aut . match_kind () . is_standard () { return Err (MatchError :: unsupported_stream (aut . match_kind ())) ; }", "\" Currently, this trait is sealed. That means users of this crate can write\"", "& A", "StateID", "Some (i + 1)", "\" transitions, such that any adjacent transitions mapped to the same\"", "prev_next", "W", "(u8 , u8 , StateID)", "self . match_kind () . is_standard ()", "self . handle_overlapping_empty_match (m)", "\" # Errors\"", "OverlappingState :: start ()", "\" overlaps with the end bounds of the former.\"", "input . haystack () [state . at]", "\" the haystack has been reached.\"", "\" [`AhoCorasick::find_overlapping_iter`](crate::AhoCorasick::find_overlapping_iter)\"", "\"             return Ok(mat);\"", "f . write_fmt (format_args ! (\"D \")) ?", "impl Iterator < Item = (u8 , u8 , StateID) > + 'a", "\" given will advance through the haystack itself. Callers can detect the end\"", "\" * Using an NFA or DFA directly, bypassing the top-level\"", "\" The typical way this is used is when the start state is entered during\"", "\" Note that we mark this cold and forcefully prevent inlining because\"", "Option < std :: io :: Result < StreamChunk > >", "self . input . set_start (self . input . start () . checked_add (1) . unwrap ())", "aut . match_len (sid)", "& [\"aut\" , \"rdr\" , \"buf\" , \"start\" , \"sid\" , \"absolute_pos\" , \"buffer_pos\" , \"buffer_reported_pos\" ,]", "FindOverlappingIter < 'a , 'h , A >", "f . write_fmt (format_args ! (\"*>\"))", "FnMut (& Match , & [u8] , & mut W) -> std :: io :: Result < () >", "\" trait permits doing that in a backwards compatible fashion. On other the\"", "\" * A match state is a state that indicates one or more patterns have\"", "Result < FindIter < 'a , 'h , A > , MatchError >", "Sized", "(* * self) . match_kind ()", "[u8]", "StreamFindIter < 'a , A , R >", "\" calls to `rdr.read()`. This isn't strictly needed if all we needed to\"", "Some (start .. end)", "get_match", "FindIter", "\" routine. We keep things simple by not using prefilters or worrying about\"", "Ok (StreamFindIter { it : StreamChunkIter :: new (self , rdr) ? , })", "\"already checked that no match error can occur here\"", "& self . buf", "\" 1. It came from a call to `Automaton::start_state`, or\"", "{ :: core :: panicking :: panic_fmt (format_args ! (\"unreachable\")) ; }", "it", "\" The position we're currently at within `buf`.\"", "at = i", "\"buffer_pos\"", "self . last_match_end", "aut . match_kind ()", "format_args ! (\"* \")", "self . try_replace_all_with_bytes (haystack , & mut dst , | mat , _ , dst | { dst . extend (replace_with [mat . pattern ()] . as_ref ()) ; true } ,) ?", "input . get_anchored () . is_anchored ()", ":: core :: fmt :: Formatter :: debug_struct_fields_finish", "\" Create a new overlapping state that begins at the start state.\"", "\"     .match_kind(MatchKind::LeftmostFirst)\"", "self . search ()", "StreamChunkIter { aut , rdr , buf : crate :: util :: buffer :: Buffer :: new (aut . max_pattern_len ()) , start , sid : start , absolute_pos : 0 , buffer_pos : 0 , buffer_reported_pos : 0 , }", "try_find_overlapping_fwd_imp (aut , input , None , state)", "self . patterns_len ()", "\" be used to skip ahead and quickly look for candidate matches. Unlike dead\"", "\" there is a difference between where the match started and the position\"", "! haystack . is_char_boundary (m . start ()) || ! haystack . is_char_boundary (m . end ())", "(& replace_with . len () , & self . patterns_len ())", "wtr . write_all (bytes)", "\" is reported if there was a problem reading from the underlying stream.\"", "Ok (mat)", "\" The index into the matching patterns of the next match to report if the\"", "Some (m . end ()) == self . last_match_end", "| e | { let kind = std :: io :: ErrorKind :: Other ; std :: io :: Error :: new (kind , e) }", "\" an error is reported if there was a problem reading from the underlying\"", "& Input < '_ >", "\" strings or streams.\"", "\" this offset.\"", "& & self . state", "try_find_fwd_imp (aut , input , None , Anchored :: No , true)", "if self . buffer_reported_pos < end { return Some (self . buffer_reported_pos .. end) ; }", "\" of all explicitly defined transitions. The iterator yields ranges of\"", "wtr", "\" rolling the buffer.\"", "{ :: core :: fmt :: Formatter :: debug_struct_field2_finish (f , \"Match\" , \"bytes\" , __self_0 , \"mat\" , & __self_1 ,) }", "aut . max_pattern_len ()", "\" matches in this match state.\"", "\" Returns an iterator of overlapping matches with this automaton\"", "& 'a Self", "input . get_earliest ()", "& & self . it", "\" correctness of implementations of this trait to avoid undefined behavior.\"", "StreamChunk :: NonMatch", "\" state ID for the underlying automaton. Valid state IDs can only be\"", "\" quite a bit of code, comparatively. Keeping this code out of the main\"", "Ok (StreamChunk :: Match { bytes , mat })", "i > at", "\"buf\"", "\"bytes\"", "\" Return an iterator of transitions in a sparse format given an iterator\"", "return Some (Ok (mat))", "replace_with (& mat , bytes , & mut wtr)", "\" itself.\"", "wtr . write_all (bytes) ?", "\" (2) is not strictly necessary, but makes intuitive sense and matches\"", "[& dyn :: core :: fmt :: Debug]", "\" While it is never incorrect to ignore start states during a search\"", "std :: io :: Error :: new", "\" A dead state is a type of \\\"sink\\\" in a finite state machine. It\"", "while let Some (result) = it . next () { let chunk = result ? ; match chunk { StreamChunk :: NonMatch { bytes , .. } => { wtr . write_all (bytes) ? ; } StreamChunk :: Match { bytes , mat } => { replace_with (& mat , bytes , & mut wtr) ? ; } } }", "\" [`AhoCorasick::try_find_iter`](crate::AhoCorasick::try_find_iter)\"", "\" (This doesn't actually implement the `Iterator` trait because it returns\"", "std :: io :: Result < StreamChunk >", "self . get_eof_non_match_chunk ()", "try_find_fwd_imp (aut , input , None , Anchored :: Yes , earliest)", "\" overlapping is that of match and start states.)\"", "& self . input", "\"         None => break,\"", "self . buffer_reported_pos .. end", "\" `anchored` should be [`Anchored::Yes`] when executing an anchored\"", "it . next ()", "if let Some (pre) = pre { match pre . find_in (input . haystack () , input . get_span ()) { Candidate :: None => return Ok (None) , Candidate :: Match (m) => return Ok (Some (m)) , Candidate :: PossibleStartOfMatch (i) => { at = i ; } } }", "MatchError :: unsupported_overlapping (self . match_kind ())", "Result < FindOverlappingIter < 'a , 'h , Self > , MatchError >", "self . buffer_reported_pos", "next", "\"     Match::must(0, 0..6),\"", "\" The idea here is that each chunk represents either a match or a non-match,\"", "& [& dyn :: core :: fmt :: Debug]", "FindIter :: new (self , input)", "let Some (r) = self . get_non_match_chunk (mat)", "aut . next_state (anchored , sid , input . haystack () [at])", "\" 2. It came from a previous call to `Automaton::next_state` with a\"", "_", "try_find_fwd_imp (aut , input , Some (pre) , Anchored :: No , true)", ":: core :: fmt :: Formatter :: debug_struct_field4_finish", "\" Note that this trait defines a number of default methods, such as\"", "self . sid = self . start", "{ at = i ; }", "\" Returns a prefilter, if available, that can be used to accelerate\"", "\" Records the end offset of the most recent match. This is necessary to\"", "\"     // Start states can be match states!\"", "\" matches.\"", "OverlappingState { mat : None , id : None , at : 0 , next_match_index : None , }", "cur", "if aut . is_start (id) { f . write_fmt (format_args ! (\"*>\")) ? ; } else { f . write_fmt (format_args ! (\"* \")) ? ; }", "let Some ((class , next)) = it . next ()", "r . len ()", "aut . is_match (id)", "aut . prefilter ()", "| mat , _ , dst | { dst . extend (replace_with [mat . pattern ()] . as_ref ()) ; true }", "& Prefilter", "if let Some (i) = state . next_match_index { let len = aut . match_len (sid) ; if i < len { state . next_match_index = Some (i + 1) ; state . mat = Some (get_match (aut , sid , i , state . at + 1)) ; return Ok (()) ; } state . at += 1 ; state . next_match_index = None ; state . mat = None ; }", "\" A `None` value indicates the start state of the corresponding\"", "Some (Ok (StreamChunk :: Match { bytes , mat }))", "\" true if the given state ID is actually a dead state.\"", "\" restriction may be lifted in the future, but sealing the trait permits\"", "if aut . is_dead (sid) { return Ok (()) ; } else if aut . is_match (sid) { state . next_match_index = Some (1) ; state . mat = Some (get_match (aut , sid , 0 , state . at + 1)) ; return Ok (()) ; } else if let Some (pre) = pre { if true { if ! aut . is_start (sid) { :: core :: panicking :: panic (\"assertion failed: aut.is_start(sid)\" ,) } } let span = Span :: from (state . at .. input . end ()) ; match pre . find_in (input . haystack () , span) . into_option () { None => return Ok (()) , Some (i) => { if i > state . at { state . at = i ; continue ; } } } } else { }", "\"id\"", "\" caller can do is construct it and pass it around to permit search routines\"", "std :: io :: Result < Match >", "start .. end", "\" loop {\"", "\" (Obviously this crate isn't a regex engine, but we choose to match\"", "state . next_match_index = None", "m", "{ let kind = std :: io :: ErrorKind :: Other ; std :: io :: Error :: new (kind , e) }", "self . try_replace_all_with (haystack , & mut dst , | mat , _ , dst | { dst . push_str (replace_with [mat . pattern ()] . as_ref ()) ; true } ,)", "\" The source of bytes we read from.\"", "\" stream. The iterator terminates only when the underlying stream reaches\"", "\" strings from `replace_with` depending on the pattern that\"", "\"last_match_end\"", "m = self . handle_overlapping_empty_match (m) ?", "& self . buffer_pos", "\" The type variable `A` refers to the implementation of the [`Automaton`]\"", "Option < core :: ops :: Range < usize > >", "\" on a dead state lead back to itself. The dead state is meant to be treated\"", "! replace_with (& m , & haystack [m . start () .. m . end ()] , dst)", "\" automaton. We cannot use the actual ID, since any one automaton may\"", "return Some (start .. end)", "\" to the caller. Basically, whenever we find a match, we look to see if\"", "class", "state . at = i", "\" this value.\"", "Ok (Some (m))", "self . buf . buffer () [r]", "\" This iterator yields elements of type `io::Result<Match>`, where an error\"", "\" assert_eq!(expected, matches);\"", "for & byte in self . buf . buffer () [self . buffer_pos ..] . iter () { self . sid = self . aut . next_state (Anchored :: No , self . sid , byte) ; self . absolute_pos += 1 ; if self . aut . is_match (self . sid) { break ; } }", "\" (1) is necessary because we principally make progress by setting the\"", "state", "| mat , _ , wtr | { wtr . write_all (replace_with [mat . pattern ()] . as_ref ()) }", "Option < StateID >", "StreamChunkIter < 'a , A , R >", "self . id", "\" not required to do so.\"", "\" _possible_ to do in the future.\"", "\" result to `wtr`. The `replace_with` slice must have length equal to\"", "\" * `Automaton::next_state`, when given a valid state ID, always returns\"", "\" have many start states, and which one is in use depends on search-time\"", "\" let patterns = &[\\\"append\\\", \\\"appendage\\\", \\\"app\\\"];\"", "self . input . start () . checked_add (1) . unwrap ()", "crate :: util :: buffer :: Buffer", "if let Some (pre) = aut . prefilter () { if earliest { try_find_fwd_imp (aut , input , Some (pre) , Anchored :: No , true) } else { try_find_fwd_imp (aut , input , Some (pre) , Anchored :: No , false) } } else { if earliest { try_find_fwd_imp (aut , input , None , Anchored :: No , true) } else { try_find_fwd_imp (aut , input , None , Anchored :: No , false) } }", "\" let ac = AhoCorasick::new(patterns).unwrap();\"", "\" automaton only supports unanchored searches but the given configuration\"", "\" panics.\"", "\" [`AhoCorasick::try_replace_all_with_bytes`](crate::AhoCorasick::try_replace_all_with_bytes)\"", "self . aut . try_find_overlapping (& self . input , & mut self . state) . expect (\"already checked that no match error can occur here\")", "\"                 // As above, standard semantics require that we return\"", "\" A trait that abstracts over Aho-Corasick automata.\"", "\" Executes a search and returns a match if one is found.\"", "\"absolute_pos\"", "\" The `'r` lifetime refers to the lifetime of the stream chunk iterator.\"", "\" This iterator will report all possible matches in a particular haystack,\"", "aut . is_special (sid)", "self . aut . next_state (Anchored :: No , self . sid , byte)", "self . buffer_reported_pos < self . buf . buffer () . len ()", "& haystack [last_match .. m . start ()]", "\" supported by the underlying automaton. For example, if the underlying\"", "\" to use or even know about this trait. Indeed, the top level\"", "\" like this to deal with the \\\"replacement\\\" API, which needs to know which\"", "\" a state is treated as special if it is a dead, match or start state:\"", "\" Returns true if the given ID represents a match state.\"", "{ f . write_fmt (format_args ! (\"* \")) ? ; }", "if let Some (r) = self . get_eof_non_match_chunk () { self . buffer_reported_pos += r . len () ; let bytes = & self . buf . buffer () [r] ; return Some (Ok (StreamChunk :: NonMatch { bytes })) ; }", "state . next_match_index . unwrap_or (0)", "{ return Some (Ok (mat)) ; }", "if aut . is_match (sid) { let i = state . next_match_index . unwrap_or (0) ; let len = aut . match_len (sid) ; if i < len { state . next_match_index = Some (i + 1) ; state . mat = Some (get_match (aut , sid , i , input . start ())) ; return Ok (()) ; } }", "inline", "self . buf . buffer ()", "\"input\"", "\" Creates a new non-overlapping iterator. If the given automaton would\"", "\" The state of the automaton.\"", "\" [`AhoCorasick`](crate::AhoCorasick) searcher. Currently, these include\"", "Ok (FindOverlappingIter { aut : self , input , state , })", "\" let nfa = NFA::builder()\"", "\" to try to skip ahead and look for match candidates more quickly than\"", ":: core :: fmt :: Formatter", "m = self . search () ?", "\" current value. Subsequent calls to an overlapping search pick up at\"", "match cur { Some (x) => x , None => { cur = Some ((class , class , next)) ; continue ; } }", "if prev_next == next { cur = Some ((prev_start , class , prev_next)) ; } else { cur = Some ((class , class , next)) ; return Some ((prev_start , prev_end , prev_next)) ; }", "\" anchored searches, but do make sure our search is correct for all possible\"", "byte", "* right_val", "m . end ()", "\" for more documentation and examples.\"", "\" Returns true if the given ID represents a start state.\"", "\" `Automaton`, it is required to know whether the search is anchored\"", "cold", "self . last_match_end = Some (m . end ())", "Some ((class , class , next))", "if m . is_empty () { m = self . handle_overlapping_empty_match (m) ? ; }", "{ dst . push_str (replace_with [mat . pattern ()] . as_ref ()) ; true }", "\" The input parameters to give to each search call.\"", "& mut self . rdr", "& self . patterns_len ()", "\" Implementations of `Automaton` in this crate \\\"unspecialize\\\" start\"", "true", ":: core :: clone :: Clone :: clone (& self . mat)", "at", "crate :: nfa :: contiguous :: NFA", "None", "\"     .build(&[\\\"samwise\\\", \\\"sam\\\"])\"", "if true { if ! aut . is_start (sid) { :: core :: panicking :: panic (\"assertion failed: aut.is_start(sid)\" ,) } }", "\" entered. When a match state is entered, the match semantics dictate\"", "core :: iter :: from_fn (move | | { while let Some ((class , next)) = it . next () { let (prev_start , prev_end , prev_next) = match cur { Some (x) => x , None => { cur = Some ((class , class , next)) ; continue ; } } ; if prev_next == next { cur = Some ((prev_start , class , prev_next)) ; } else { cur = Some ((class , class , next)) ; return Some ((prev_start , prev_end , prev_next)) ; } } if let Some ((start , end , next)) = cur . take () { return Some ((start , end , next)) ; } None })", "FindOverlappingIter", "match self . buf . fill (& mut self . rdr) { Err (err) => return Some (Err (err)) , Ok (true) => { } Ok (false) => { if let Some (r) = self . get_eof_non_match_chunk () { self . buffer_reported_pos += r . len () ; let bytes = & self . buf . buffer () [r] ; return Some (Ok (StreamChunk :: NonMatch { bytes })) ; } return None ; } }", "\" matched at the position in the haystack when the match state was\"", "\" when a search enters a start state because it may mean that a prefilter can\"", "aut . pattern_len (pid)", "String :: with_capacity", "try_find_fwd (& self , input)", "cur . take ()", "\" from.\"", "\" then we need to return a 'NonMatch' chunk.\"", "return None", "\" has unspecified behavior if the state ID given to it is not a valid\"", "Ok (dst)", "\"FindOverlappingIter\"", "\" // if the given automaton does not support unanchored searches.\"", "\"     Ok(mat)\"", "\" This type provides limited introspection capabilities. The only thing a\"", "std :: io :: Read", "\" if invalid inputs are given to it. For example, `Automaton::next_state`\"", "result", "try_find_fwd", "Some (Ok (StreamChunk :: NonMatch { bytes }))", "Vec < u8 >", "{ if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! (\"streaming replace_all requires a replacement for every pattern in the automaton\" ,) ,) ,) ; } }", "false", "\" non-None value.\"", "self . input", "\" * `Automaton::start_state` always returns a valid state ID or an error or\"", "\" trait used to execute the search.\"", "end", "\" Write a prefix \\\"state\\\" indicator for fmt::Debug impls. It always writes\"", "\" Returns the pattern ID for the match state given by `sid` at the\"", "\"     automaton::Automaton,\"", "\" corresponds to a start state. Namely, it always correct to treat start\"", "& Self", "m . start () .. m . end ()", "Span :: from", ":: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! (\"streaming replace_all requires a replacement for every pattern in the automaton\" ,) ,) ,)", "state . at = input . start ()", "if aut . is_dead (id) { f . write_fmt (format_args ! (\"D \")) ? ; } else if aut . is_match (id) { if aut . is_start (id) { f . write_fmt (format_args ! (\"*>\")) ? ; } else { f . write_fmt (format_args ! (\"* \")) ? ; } } else if aut . is_start (id) { f . write_fmt (format_args ! (\" >\")) ? ; } else { f . write_fmt (format_args ! (\"  \")) ? ; }", "\" state is a dead, match or start state.\"", "StreamChunkIter :: new (self , rdr) . map_err (| e | { let kind = std :: io :: ErrorKind :: Other ; std :: io :: Error :: new (kind , e) })", "self . buffer_pos - mat . len ()", "\"next_match_index\"", "{ try_find_fwd_imp (aut , input , Some (pre) , Anchored :: No , false) }", "Option < (u8 , u8 , StateID) >", "self . absolute_pos += 1", "\" Upon success, the state ID returned is guaranteed to be valid for\"", "self . rdr", "StreamChunk :: Match { bytes , mat }", "last_match", "\" which case, no more matches should be reported at the current position\"", "if i < len { state . next_match_index = Some (i + 1) ; state . mat = Some (get_match (aut , sid , i , input . start ())) ; return Ok (()) ; }", "\" Typically a prefilter is only available when there are a small (<100)\"", "\" implementations may ignore `anchored` altogether and depend on\"", "(* * self) . patterns_len ()", "\" yourself. This might be useful for implementing search on non-contiguous\"", "Result < StreamChunkIter < 'a , A , R > , MatchError >", "\"     while at < haystack.len() {\"", "\" state, or if the index is greater than or equal to the total number of\"", "\" not advance and thus does not terminate.\"", "self . handle_overlapping_empty_match (m) ?", ":: core :: panicking :: panic_fmt (format_args ! (\"unreachable\"))", "\" that are needed to support certain `MatchKind` semantics.)\"", "(* * self) . next_state (anchored , sid , byte)", "if ! m . is_empty () { :: core :: panicking :: panic (\"assertion failed: m.is_empty()\") }", "& mut String", ":: core :: fmt :: Result", "\" configuration.\"", "self . buffer_reported_pos < end", "state . at .. input . end ()", "Err", "\"StreamChunkIter\"", "self . buffer_pos ..", "\" # Ok::<(), Box<dyn std::error::Error>>(())\"", "\" A single chunk yielded by the stream chunk iterator.\"", "Some (get_match (aut , sid , 0 , state . at + 1))", "\" The absolute position over the entire stream.\"", "state . id", "\" fn find<A: Automaton>(\"", "MatchKind", "\" [`AhoCorasick::try_stream_replace_all_with`](crate::AhoCorasick::try_stream_replace_all_with)\"", "self . aut . try_find (& self . input) . expect (\"already checked that no match error can occur\")", "aut . min_pattern_len ()", "self . get_pre_roll_non_match_chunk ()", "pre . find_in (input . haystack () , input . get_span ())", "\" [`AhoCorasick::try_stream_find_iter`](crate::AhoCorasick::try_stream_find_iter)\"", "std :: io :: Result < () >", "\" A roll buffer for managing bytes from `rdr`. Basically, this is used\"", "! false", "\" higher level search routines in terms of the lower level automata API.\"", "{ if let Some (i) = state . next_match_index { let len = aut . match_len (sid) ; if i < len { state . next_match_index = Some (i + 1) ; state . mat = Some (get_match (aut , sid , i , state . at + 1)) ; return Ok (()) ; } state . at += 1 ; state . next_match_index = None ; state . mat = None ; } sid }", ":: core :: panicking :: assert_failed", "self . try_find_iter (Input :: new (haystack))", "\" matched. Depending on the [`MatchKind`] of the automaton, a search may\"", ":: core :: clone :: Clone", "aut . match_kind () . is_standard () || input . get_earliest ()", "at += 1", "& str", "\" matched. The `replace_with` slice must have length equal to\"", "mat", "\" iterator always advances and 2) empty matches never overlap with other\"", "Vec :: with_capacity", "(at - len)", "Option < & Prefilter >", "if earliest { try_find_fwd_imp (aut , input , Some (pre) , Anchored :: No , true) } else { try_find_fwd_imp (aut , input , Some (pre) , Anchored :: No , false) }", "\" and match states, it is never necessary to explicitly handle start states\"", "move | | { while let Some ((class , next)) = it . next () { let (prev_start , prev_end , prev_next) = match cur { Some (x) => x , None => { cur = Some ((class , class , next)) ; continue ; } } ; if prev_next == next { cur = Some ((prev_start , class , prev_next)) ; } else { cur = Some ((class , class , next)) ; return Some ((prev_start , prev_end , prev_next)) ; } } if let Some ((start , end , next)) = cur . take () { return Some ((start , end , next)) ; } None }", "aut", "& mut OverlappingState", "\" one has been found, and nothing otherwise.\"", "aut . start_state (Anchored :: No)", "{ dst . extend (replace_with [mat . pattern ()] . as_ref ()) ; true }", "Input :: new (haystack)", "std :: io :: Write", "std :: io :: ErrorKind :: Other", "& haystack [last_match ..]", "crate", "\" This has unspecified behavior when given an invalid state ID.\"", "\" should be reused for subsequent searches on the same `Input`. The state\"", "Option < std :: io :: Result < Match > >", "loop { if self . aut . is_match (self . sid) { let mat = self . get_match () ; if let Some (r) = self . get_non_match_chunk (mat) { self . buffer_reported_pos += r . len () ; let bytes = & self . buf . buffer () [r] ; return Some (Ok (StreamChunk :: NonMatch { bytes })) ; } self . sid = self . start ; let r = self . get_match_chunk (mat) ; self . buffer_reported_pos += r . len () ; let bytes = & self . buf . buffer () [r] ; return Some (Ok (StreamChunk :: Match { bytes , mat })) ; } if self . buffer_pos >= self . buf . buffer () . len () { if let Some (r) = self . get_pre_roll_non_match_chunk () { self . buffer_reported_pos += r . len () ; let bytes = & self . buf . buffer () [r] ; return Some (Ok (StreamChunk :: NonMatch { bytes })) ; } if self . buf . buffer () . len () >= self . buf . min_buffer_len () { self . buffer_pos = self . buf . min_buffer_len () ; self . buffer_reported_pos -= self . buf . buffer () . len () - self . buf . min_buffer_len () ; self . buf . roll () ; } match self . buf . fill (& mut self . rdr) { Err (err) => return Some (Err (err)) , Ok (true) => { } Ok (false) => { if let Some (r) = self . get_eof_non_match_chunk () { self . buffer_reported_pos += r . len () ; let bytes = & self . buf . buffer () [r] ; return Some (Ok (StreamChunk :: NonMatch { bytes })) ; } return None ; } } } let start = self . absolute_pos ; for & byte in self . buf . buffer () [self . buffer_pos ..] . iter () { self . sid = self . aut . next_state (Anchored :: No , self . sid , byte) ; self . absolute_pos += 1 ; if self . aut . is_match (self . sid) { break ; } } self . buffer_pos += self . absolute_pos - start ; }", "& __self_0", "{ if i > state . at { state . at = i ; continue ; } }", "\" here to avoid undefined behavior. Instead, this was done to make it\"", "if let Some (r) = self . get_non_match_chunk (mat) { self . buffer_reported_pos += r . len () ; let bytes = & self . buf . buffer () [r] ; return Some (Ok (StreamChunk :: NonMatch { bytes })) ; }", "* * self", "self . sid = self . aut . next_state (Anchored :: No , self . sid , byte)", "\"state\"", "return Some (self . buffer_reported_pos .. self . buf . buffer () . len ())", "anchored . is_anchored () && m . start () > input . start ()", "\"     Match::must(0, 22..28),\"", "dst", "\" bytes between candidates.\"", "\" [`contiguous::NFA`](crate::nfa::contiguous::NFA) and\"", "\" An iterator of overlapping matches in a particular haystack.\"", "\" do was report matches, but here we are reporting chunks of non-matches\"", "\" [`OverlappingState::start`] when starting a new search. That same state\"", "return Err (MatchError :: unsupported_stream (aut . match_kind ()))", "\" Note that this only reports bytes up to `buffer.len() -\"", "try_find_fwd_imp (aut , input , Some (pre) , Anchored :: No , false)", "get_match (aut , sid , i , input . start ())", "(prev_start , prev_end , prev_next)", "get_match (aut , sid , 0 , state . at + 1)", "MatchError :: unsupported_overlapping", "format_args ! (\"replace_all requires a replacement for every pattern in the automaton\" ,)", "\" stream as non-overlapping blocks of bytes. We need to permit some\"", ":: core :: fmt :: Formatter :: debug_struct_field3_finish (f , \"FindOverlappingIter\" , \"aut\" , & self . aut , \"input\" , & self . input , \"state\" , & & self . state ,)", "left_val", "\" their semantics.) The \\\"intuitive sense\\\" here is that we want to report\"", "Some (self . buffer_reported_pos .. self . buf . buffer () . len ())", "\" sentinel indicating that the search should terminate.\"", "if self . aut . is_match (self . sid) { break ; }", "\" Returns the length of the pattern for the given ID.\"", ":: core :: fmt :: Formatter :: debug_struct_field2_finish (f , \"Match\" , \"bytes\" , __self_0 , \"mat\" , & __self_1 ,)", "try_find_overlapping_fwd_imp", "\"         // they're seen. Otherwise, we continue until we see a dead state\"", "Ok (StreamChunk :: NonMatch { bytes })", "i > state . at", "replace_with (& m , & haystack [m . start () .. m . end ()] , dst)", "loop { match self . it . next () { None => return None , Some (Err (err)) => return Some (Err (err)) , Some (Ok (StreamChunk :: NonMatch { .. })) => { } Some (Ok (StreamChunk :: Match { mat , .. })) => { return Some (Ok (mat)) ; } } }", "{ :: core :: fmt :: Formatter :: debug_struct_field1_finish (f , \"NonMatch\" , \"bytes\" , & __self_0 ,) }", ":: core :: option :: Option :: Some (format_args ! (\"replace_all requires a replacement for every pattern in the automaton\" ,) ,)", "match (& replace_with . len () , & self . patterns_len ()) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! (\"streaming replace_all requires a replacement for every pattern in the automaton\" ,) ,) ,) ; } } }", "& 'a T", "B", "\" about the previous search. For example, when multiple patterns match at the\"", "& __self_1", "\" search and [`Anchored::No`] otherwise. For some implementations of\"", "(* * self) . max_pattern_len ()", "\" it enters a dead state or sees the end of the haystack.\"", "MatchError :: invalid_input_anchored", "\" conceivable that I might want to add new required methods, and sealing the\"", "\" # Sealed\"", "m . is_empty ()", "\" search knows whether to report another matching pattern or continue with\"", "if Some (m . end ()) == self . last_match_end { self . input . set_start (self . input . start () . checked_add (1) . unwrap ()) ; m = self . search () ? ; }", "haystack . is_char_boundary (m . end ())", "1", "let Some (i) = state . next_match_index", "\" are dead or contain matches.\"", "\"         if matches!(aut.match_kind(), MatchKind::Standard) {\"", "\" Callers should always provide a fresh state constructed via\"", "\" NON-overlapping matches. So for example, given the patterns 'a' and\"", "\" // Run an unanchored search for 'aut' in 'haystack'. Return the first match\"", "& self . last_match_end", "Input :: new", "& replace_with . len ()", "if aut . is_match (sid) { mat = Some (get_match (aut , sid , 0 , at)) ; if earliest { return Ok (mat) ; } }", "& self . state", "\" // But also works when using leftmost-first. Notice how the match result\"", "i < len", "e", "\" Note that implementations may choose to return false when the given ID\"", "\" optimizations. For example, if one is in a start state, it may be legal\"", "Result < Vec < u8 > , MatchError >", "if true { if ! false { { :: core :: panicking :: panic_fmt (format_args ! (\"unreachable\")) ; } } }", "StreamChunkIter :: new", "Iterator", "& [B]", "& * left_val", "\" current state is a match state. Note that this may be 1 greater than\"", "\" min_buffer_len`, as it's not possible to know whether the bytes\"", "\"     Anchored, Match, MatchError, MatchKind,\"", "try_find_overlapping_fwd_imp (aut , input , Some (pre) , state)", "if input . get_anchored () . is_anchored () { return Err (MatchError :: invalid_input_anchored ()) ; }", "\" // seen according to the automaton's match semantics. This returns an error\"", "\" is possible for `Automaton::is_special(sid)` to return false while\"", "kind", "\" that error is returned here.\"", "prev_start", "aut . is_match (sid)", "{ while let Some ((class , next)) = it . next () { let (prev_start , prev_end , prev_next) = match cur { Some (x) => x , None => { cur = Some ((class , class , next)) ; continue ; } } ; if prev_next == next { cur = Some ((prev_start , class , prev_next)) ; } else { cur = Some ((class , class , next)) ; return Some ((prev_start , prev_end , prev_next)) ; } } if let Some ((start , end , next)) = cur . take () { return Some ((start , end , next)) ; } None }", "match chunk { StreamChunk :: NonMatch { bytes , .. } => { wtr . write_all (bytes) ? ; } StreamChunk :: Match { bytes , mat } => { replace_with (& mat , bytes , & mut wtr) ? ; } }", "\" the search at the next position. Additionally, it also tracks which state\"", "try_find_overlapping_fwd (& self , input , state)", "Some (Ok (mat))", "__self_1", "\" stop once a match is seen, or it may continue looking for matches until\"", "\"start\"", "replace_with (& mat , bytes , & mut wtr) ?", "if let Some ((start , end , next)) = cur . take () { return Some ((start , end , next)) ; }", "\"     Match::must(2, 11..14),\"", "\"                 // immediately once a match is found.\"", "Span :: from (at .. input . end ())", "if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! (\"replace_all requires a replacement for every pattern in the automaton\" ,) ,) ,) ; }", "(* * self) . memory_usage ()", "(* * self) . is_special (sid)", "dyn :: core :: fmt :: Debug", "if self . buffer_pos >= self . buf . buffer () . len () { if let Some (r) = self . get_pre_roll_non_match_chunk () { self . buffer_reported_pos += r . len () ; let bytes = & self . buf . buffer () [r] ; return Some (Ok (StreamChunk :: NonMatch { bytes })) ; } if self . buf . buffer () . len () >= self . buf . min_buffer_len () { self . buffer_pos = self . buf . min_buffer_len () ; self . buffer_reported_pos -= self . buf . buffer () . len () - self . buf . min_buffer_len () ; self . buf . roll () ; } match self . buf . fill (& mut self . rdr) { Err (err) => return Some (Err (err)) , Ok (true) => { } Ok (false) => { if let Some (r) = self . get_eof_non_match_chunk () { self . buffer_reported_pos += r . len () ; let bytes = & self . buf . buffer () [r] ; return Some (Ok (StreamChunk :: NonMatch { bytes })) ; } return None ; } } }", ":: core :: fmt :: Formatter :: debug_struct_field1_finish", "{ if i > at { at = i ; continue ; } }", "\" # Panics\"", "[& self . aut , & self . rdr , & self . buf , & self . start , & self . sid , & self . absolute_pos , & self . buffer_pos , & & self . buffer_reported_pos ,]", "anchored", "x", "Vec :: with_capacity (haystack . len ())", "\"     let mat = match state.get_match() {\"", "Some (self . buffer_reported_pos .. end)", "sid = aut . next_state (anchored , sid , input . haystack () [at])", "Ok (())", "dst . extend (replace_with [mat . pattern ()] . as_ref ())", ":: core :: fmt :: Formatter :: debug_struct_fields_finish (f , \"StreamChunkIter\" , names , values ,)", "\"             if aut.is_dead(sid) {\"", "input . is_done ()", "self . next_match_index", "if aut . prefilter () . is_some () && ! input . get_anchored () . is_anchored () { let pre = aut . prefilter () . unwrap () ; try_find_overlapping_fwd_imp (aut , input , Some (pre) , state) } else { try_find_overlapping_fwd_imp (aut , input , None , state) }", "self . buf . buffer () [self . buffer_pos ..] . iter ()", "StreamChunk", "\"     }\"", "input . haystack ()", "__self_0", "\"     .unwrap();\"", "String :: with_capacity (haystack . len ())", "FindIter < 'a , 'h , Self >", "self . buffer_reported_pos .. self . buf . buffer () . len ()", "\" from the stream given.\"", "\" will only treat start states as \\\"special\\\" when a prefilter is enabled and\"", "\" adding new required methods in a backwards compatible fashion.\"", "\" The state ID of the state at which the search was in when the call\"", "state . next_match_index", "(prev_start , class , prev_next)", "\" The start position of the search is mutated during iteration.\"", "\" Replaces all non-overlapping matches in `haystack` by calling the\"", "self . buf . buffer () . len ()", ":: core :: fmt :: Formatter :: debug_struct_field3_finish", ":: core :: fmt :: Formatter :: debug_struct_field2_finish", "\"     if aut.is_match(sid) {\"", "self . try_replace_all_with_bytes (haystack , & mut dst , | mat , _ , dst | { dst . extend (replace_with [mat . pattern ()] . as_ref ()) ; true } ,)", "\"     Match::must(2, 0..3),\"", "A", "\"mat\"", "match (& replace_with . len () , & self . patterns_len ()) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! (\"replace_all requires a replacement for every pattern in the automaton\" ,) ,) ,) ; } } }", "\" For most use cases, it is not expected that users will need\"", "0", "self . aut . try_find (& self . input)", "& mut Self", ":: core :: panicking :: panic", "\"sid\"", "MatchError", "self . sid", "self . start", "\" Return a match chunk for the given match. It is assumed that the match\"", "i", "{ try_find_overlapping_fwd_imp (aut , input , None , state) }", "\" something with a lifetime attached to a buffer it owns, but that's OK. It\"", "state . next_match_index = Some (i + 1)", "state . mat = Some (get_match (aut , sid , 0 , state . at + 1))", "\"                 }\"", "Err (MatchError :: unsupported_stream (aut . match_kind ()))", "state . at += 1", "\"Match\"", "if self . buffer_reported_pos < self . buf . buffer () . len () { return Some (self . buffer_reported_pos .. self . buf . buffer () . len ()) ; }", "\" would otherwise be accomplished by walking the automaton.\"", "m . start () > input . start ()", "* self", "while state . at < input . end () { sid = aut . next_state (input . get_anchored () , sid , input . haystack () [state . at]) ; if aut . is_special (sid) { state . id = Some (sid) ; if aut . is_dead (sid) { return Ok (()) ; } else if aut . is_match (sid) { state . next_match_index = Some (1) ; state . mat = Some (get_match (aut , sid , 0 , state . at + 1)) ; return Ok (()) ; } else if let Some (pre) = pre { if true { if ! aut . is_start (sid) { :: core :: panicking :: panic (\"assertion failed: aut.is_start(sid)\" ,) } } let span = Span :: from (state . at .. input . end ()) ; match pre . find_in (input . haystack () , span) . into_option () { None => return Ok (()) , Some (i) => { if i > state . at { state . at = i ; continue ; } } } } else { } } state . at += 1 ; }", "if i > at { at = i ; continue ; }", "if aut . is_match (sid) { state . next_match_index = Some (1) ; state . mat = Some (get_match (aut , sid , 0 , state . at + 1)) ; return Ok (()) ; } else if let Some (pre) = pre { if true { if ! aut . is_start (sid) { :: core :: panicking :: panic (\"assertion failed: aut.is_start(sid)\" ,) } } let span = Span :: from (state . at .. input . end ()) ; match pre . find_in (input . haystack () , span) . into_option () { None => return Ok (()) , Some (i) => { if i > state . at { state . at = i ; continue ; } } } } else { }", "\" `Automaton::is_start` predicates can then be used to determine which kind\"", "format_args ! (\" >\")", "\" states as non-special. Implementations must return true for states that\"", ":: core :: fmt :: Formatter :: debug_struct_field4_finish (f , \"OverlappingState\" , \"mat\" , & self . mat , \"id\" , & self . id , \"at\" , & self . at , \"next_match_index\" , & & self . next_match_index ,)", "self . input . start () . checked_add (1)", "\" look for candidate matches without having to walk the automaton on the\"", "last_match = m . end ()", "Err (MatchError :: unsupported_empty ())", "\" [`AhoCorasick::try_replace_all_with`](crate::AhoCorasick::try_replace_all_with)\"", "& & self . last_match_end", "& self . buf . buffer () [r]", "at < input . end ()", "Some (get_match (aut , sid , i , input . start ()))", "aut . start_state (input . get_anchored ())", "\" assert_eq!(Some(Match::must(1, 0..3)), find(&nfa, b\\\"samwise\\\")?);\"", "String", "\"     let mut at = 0;\"", "! (* left_val == * right_val)", "{ if let Some (r) = self . get_eof_non_match_chunk () { self . buffer_reported_pos += r . len () ; let bytes = & self . buf . buffer () [r] ; return Some (Ok (StreamChunk :: NonMatch { bytes })) ; } return None ; }", "haystack", "F", "match self { StreamChunk :: NonMatch { bytes : __self_0 } => { :: core :: fmt :: Formatter :: debug_struct_field1_finish (f , \"NonMatch\" , \"bytes\" , & __self_0 ,) } StreamChunk :: Match { bytes : __self_0 , mat : __self_1 } => { :: core :: fmt :: Formatter :: debug_struct_field2_finish (f , \"Match\" , \"bytes\" , __self_0 , \"mat\" , & __self_1 ,) } }", "\" Since checking whether a state is special by doing three different\"", "doc", "\"     };\"", "replace_with [mat . pattern ()] . as_ref ()", "\" and the search should advance to the next position.)\"", "\" '' (an empty string) against the haystack 'a', without the special\"", "\" [`Automaton::try_find_overlapping_iter`] method.\"", "state . at < input . end ()", "i + 1", "\"         // Standard semantics require matches to be reported as soon as\"", "\" slowing down the overall search because it results in ping-ponging between\"", ":: core :: fmt :: Debug", "wtr . write_all (replace_with [mat . pattern ()] . as_ref ())", "\" match. But if a match is empty, then this results in a search that does\"", "buffer_mat_start > self . buffer_reported_pos", "Some ((prev_start , class , prev_next))", "Result < StreamFindIter < 'a , Self , R > , MatchError >", "[\"aut\" , \"rdr\" , \"buf\" , \"start\" , \"sid\" , \"absolute_pos\" , \"buffer_pos\" , \"buffer_reported_pos\" ,]", "aut . is_start (id)", "\" This chunk machinery is a bit complicated and it isn't strictly required\"", "state . at", "\" Return the match result of the most recent search to execute with this\"", "let Some (r) = self . get_pre_roll_non_match_chunk ()", "{ wtr . write_all (bytes) ? ; }", "\"             }\"", "\" valid state ID.\"", "replace_with", "return Some (Err (err))", "[B]", "{ if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! (\"replace_all requires a replacement for every pattern in the automaton\" ,) ,) ,) ; } }", "\" this automaton.\"", "& self . absolute_pos", "Iterator < Item = (u8 , u8 , StateID) >", "aut . prefilter () . is_some () && ! input . get_anchored () . is_anchored ()", "\" let haystack = \\\"append the app to the appendage\\\";\"", "\" searches for this automaton.\"", "\" `replace_with` closure given.\"", "\"         let pid = aut.match_pattern(sid, 0);\"", "pre . find_in (input . haystack () , span) . into_option ()", "state . mat = Some (get_match (aut , sid , i , state . at + 1))", "\"         // or the end of the haystack.\"", "self . buffer_pos >= self . buf . buffer () . len ()", "dst . extend (& haystack [last_match .. m . start ()])", "\" Performs a state transition from `sid` for `byte` and returns the next\"", "aut . prefilter () . unwrap ()", "self . buffer_pos", "\" The lifetime `'h` refers to the lifetime of the haystack being searched.\"", "cur = Some ((prev_start , class , prev_next))", "try_find_fwd_imp (aut , input , None , Anchored :: No , false)", "\" Executes a overlapping search with this automaton using the given\"", "if input . is_done () { return Ok (None) ; }", "private :: Sealed", "\"             } else if aut.is_match(sid) {\"", "m . start ()", "\" (except for the start of the search of course), knowing whether one has\"", "\" Replaces all non-overlapping matches in `rdr` with strings from\"", "{ let sid = aut . start_state (input . get_anchored ()) ? ; if aut . is_match (sid) { let i = state . next_match_index . unwrap_or (0) ; let len = aut . match_len (sid) ; if i < len { state . next_match_index = Some (i + 1) ; state . mat = Some (get_match (aut , sid , i , input . start ())) ; return Ok (()) ; } } state . at = input . start () ; state . id = Some (sid) ; state . next_match_index = None ; state . mat = None ; sid }", "if aut . is_dead (sid) { return Ok (mat) ; } else if aut . is_match (sid) { let m = get_match (aut , sid , 0 , at + 1) ; if ! (anchored . is_anchored () && m . start () > input . start ()) { mat = Some (m) ; if earliest { return Ok (mat) ; } } } else if let Some (pre) = pre { if true { if ! aut . is_start (sid) { :: core :: panicking :: panic (\"assertion failed: aut.is_start(sid)\" ,) } } let span = Span :: from (at .. input . end ()) ; match pre . find_in (input . haystack () , span) . into_option () { None => return Ok (None) , Some (i) => { if i > at { at = i ; continue ; } } } } else { if true { if ! false { { :: core :: panicking :: panic_fmt (format_args ! (\"unreachable\")) ; } } } }", "if aut . is_start (id) { f . write_fmt (format_args ! (\" >\")) ? ; } else { f . write_fmt (format_args ! (\"  \")) ? ; }", "\" This routine may panic or return incorrect results when the given state\"", "\" * Implementing your own custom search routine by walking the automaton\"", "\" This example shows how one might implement a basic but correct search\"", "\" use aho_corasick::{\"", ":: core :: clone :: Clone :: clone (& self . next_match_index)", "\" A match state is always associated with one or more pattern IDs that\"", "\" match is found, this will always correctly report `None`.\"", "\"     Match::must(1, 22..31),\"", "if input . get_anchored () . is_anchored () { try_find_fwd_imp (aut , input , None , Anchored :: Yes , earliest) } else if let Some (pre) = aut . prefilter () { if earliest { try_find_fwd_imp (aut , input , Some (pre) , Anchored :: No , true) } else { try_find_fwd_imp (aut , input , Some (pre) , Anchored :: No , false) } } else { if earliest { try_find_fwd_imp (aut , input , None , Anchored :: No , true) } else { try_find_fwd_imp (aut , input , None , Anchored :: No , false) } }", "\" checks would be too expensive inside a fast search loop, the\"", "\" };\"", "if self . aut . is_match (self . sid) { let mat = self . get_match () ; if let Some (r) = self . get_non_match_chunk (mat) { self . buffer_reported_pos += r . len () ; let bytes = & self . buf . buffer () [r] ; return Some (Ok (StreamChunk :: NonMatch { bytes })) ; } self . sid = self . start ; let r = self . get_match_chunk (mat) ; self . buffer_reported_pos += r . len () ; let bytes = & self . buf . buffer () [r] ; return Some (Ok (StreamChunk :: Match { bytes , mat })) ; }", "Ok", "\" number of patterns built into the automaton.\"", "input . start ()", "\" assert_eq!(Some(Match::must(0, 0..7)), find(&nfa, b\\\"samwise\\\")?);\"", "Result < FindIter < 'a , 'h , Self > , MatchError >", "crate :: util :: buffer :: Buffer :: new (aut . max_pattern_len ())", "MatchError :: invalid_input_anchored ()", "\" let expected = vec![\"", "& mut :: core :: fmt :: Formatter", "\" iterator function keeps it smaller and more amenable to inlining\"", "\" ```\"", "\" [`Automaton::is_special`] method is provided for quickly checking whether\"", "\" conservative step.\"", "\" Returns the match semantics that this automaton was built with.\"", "& & self . next_match_index", "\" This does not advance the input forward. It just executes a search\"", "Err (err)", "\" in the haystack.\"", "aut . match_pattern (sid , index)", "\" was set to an anchored search, then this must return an error.\"", "\" not.\"", "dst . push_str (& haystack [last_match .. m . start ()])", "err", "f . write_fmt (format_args ! (\"D \"))", "Self", "\" entered a start state can be useful for certain classes of performance\"", "self . buffer_pos = self . buf . min_buffer_len ()", "Candidate :: Match", ":: core :: option :: Option :: Some", "self . state . get_match ()", "\" Typically, `index` is only ever greater than `0` when implementing an\"", "\" to use it to track state, and to ask whether a match has been found.\"", "\"     ac.find_overlapping(haystack, &mut state);\"", "aut . min_pattern_len () == 0", "earliest", "FindIter :: new", "* left_val", "f", "while at < input . end () { sid = aut . next_state (anchored , sid , input . haystack () [at]) ; if aut . is_special (sid) { if aut . is_dead (sid) { return Ok (mat) ; } else if aut . is_match (sid) { let m = get_match (aut , sid , 0 , at + 1) ; if ! (anchored . is_anchored () && m . start () > input . start ()) { mat = Some (m) ; if earliest { return Ok (mat) ; } } } else if let Some (pre) = pre { if true { if ! aut . is_start (sid) { :: core :: panicking :: panic (\"assertion failed: aut.is_start(sid)\" ,) } } let span = Span :: from (at .. input . end ()) ; match pre . find_in (input . haystack () , span) . into_option () { None => return Ok (None) , Some (i) => { if i > at { at = i ; continue ; } } } } else { if true { if ! false { { :: core :: panicking :: panic_fmt (format_args ! (\"unreachable\")) ; } } } } } at += 1 ; }", "& self . rdr", "\" This returns `None` if there is nothing to report. Otherwise, this\"", "! (anchored . is_anchored () && m . start () > input . start ())", "let Some (result) = it . next ()", "replace_with [mat . pattern ()]", "if aut . is_special (sid) { state . id = Some (sid) ; if aut . is_dead (sid) { return Ok (()) ; } else if aut . is_match (sid) { state . next_match_index = Some (1) ; state . mat = Some (get_match (aut , sid , 0 , state . at + 1)) ; return Ok (()) ; } else if let Some (pre) = pre { if true { if ! aut . is_start (sid) { :: core :: panicking :: panic (\"assertion failed: aut.is_start(sid)\" ,) } } let span = Span :: from (state . at .. input . end ()) ; match pre . find_in (input . haystack () , span) . into_option () { None => return Ok (()) , Some (i) => { if i > state . at { state . at = i ; continue ; } } } } else { } }", "state . mat = None", "if ! false { { :: core :: panicking :: panic_fmt (format_args ! (\"unreachable\")) ; } }", "\"     automaton::OverlappingState,\"", "state . id = Some (sid)", "(start , end , next)", "self . get_non_match_chunk (mat)", "StreamChunkIter :: new (self , rdr)", "rdr", "! haystack . is_char_boundary (m . end ())", "if aut . is_special (sid) { if aut . is_dead (sid) { return Ok (mat) ; } else if aut . is_match (sid) { let m = get_match (aut , sid , 0 , at + 1) ; if ! (anchored . is_anchored () && m . start () > input . start ()) { mat = Some (m) ; if earliest { return Ok (mat) ; } } } else if let Some (pre) = pre { if true { if ! aut . is_start (sid) { :: core :: panicking :: panic (\"assertion failed: aut.is_start(sid)\" ,) } } let span = Span :: from (at .. input . end ()) ; match pre . find_in (input . haystack () , span) . into_option () { None => return Ok (None) , Some (i) => { if i > at { at = i ; continue ; } } } } else { if true { if ! false { { :: core :: panicking :: panic_fmt (format_args ! (\"unreachable\")) ; } } } } }", ":: core :: panicking :: AssertKind :: Eq", "\" Handles the special case of an empty match by ensuring that 1) the\"", "input . get_span ()", "\"                 return Ok(mat);\"", "self . aut . try_find_overlapping (& self . input , & mut self . state)", "self . buffer_reported_pos -= self . buf . buffer () . len () - self . buf . min_buffer_len ()", "state . mat", "\" [`Automaton::try_find`] and [`Automaton::try_find_iter`], which implement\"", "PatternID", "for m in self . try_find_iter (Input :: new (haystack)) ? { dst . extend (& haystack [last_match .. m . start ()]) ; last_match = m . end () ; if ! replace_with (& m , & haystack [m . start () .. m . end ()] , dst) { break ; } }", "& * right_val", "\" This example shows how to manually iterate over all overlapping matches. If\"", "automatically_derived", "aut . start_state (Anchored :: No) ?", "\" let mut matches = vec![];\"", "Some (pre)", "Anchored :: No", "{ f . write_fmt (format_args ! (\"  \")) ? ; }", "\" the main state transition and the \\\"special\\\" state logic.\"", "\"it\"", "& mut dst", "\" This trait is not safe to implement so that code may rely on the\"", "if i < len { state . next_match_index = Some (i + 1) ; state . mat = Some (get_match (aut , sid , i , state . at + 1)) ; return Ok (()) ; }", "& self . it", "get_match (self . aut , self . sid , 0 , self . absolute_pos)", "& 'static _", "\" Executes a non-overlapping search with this automaton using the given\"", "state . mat = Some (get_match (aut , sid , i , input . start ()))", "self . absolute_pos - start", "& self", "\" the ending bounds of a prior match.\"", "\" please file an issue and we can discuss it. This was *mostly* done as a\"", "T", "& Match", "mat . pattern ()", "StreamChunkIter :: new (self , rdr) . map_err (| e | { let kind = std :: io :: ErrorKind :: Other ; std :: io :: Error :: new (kind , e) }) ?", "let Some (r) = self . get_eof_non_match_chunk ()", "& self . id", "return Ok (mat)", "f . write_fmt (format_args ! (\"* \"))", "\" the beginning of the search as given by the caller regardless of its\"", "! haystack . is_char_boundary (m . start ())", "(* * self) . match_pattern (sid , index)", "cur = Some ((class , class , next))", "\" `EOF`.\"", "\" hand, if you have a solid use case for implementing the trait yourself,\"", "\" handling empty matches like this is extremely rare and does require\"", "\" return an error on a search with the given input configuration, then\"", "self . buf", "Some ((prev_start , prev_end , prev_next))", "\" * A start state is a state that a search begins in. It is useful to know\"", "\"     let mut sid = aut.start_state(Anchored::No)?;\"", "\" This has unspecified behavior when given an invalid pattern\"", "\" as a sentinel indicating that the search should stop and return a match if\"", "haystack . is_char_boundary (m . start ())", "(anchored . is_anchored () && m . start () > input . start ())", "if let Some (pre) = pre { if true { if ! aut . is_start (sid) { :: core :: panicking :: panic (\"assertion failed: aut.is_start(sid)\" ,) } } let span = Span :: from (state . at .. input . end ()) ; match pre . find_in (input . haystack () , span) . into_option () { None => return Ok (()) , Some (i) => { if i > state . at { state . at = i ; continue ; } } } } else { }", "\"     aut: A,\"", "\" `index` given.\"", "\" overlapping search. Otherwise, it's likely that your search only cares\"", "\" instead, but this shows how to correctly use an `OverlappingState`.\"", "Anchored", "len", "Match :: new", "if i > state . at { state . at = i ; continue ; }", "self . aut . is_match (self . sid)", "let Some ((start , end , next)) = cur . take ()", "try_find_fwd_imp", "FindOverlappingIter { aut : self , input , state , }", "self . aut", "! aut . match_kind () . is_standard ()", "\" retrieved in one of two ways: calling `Automaton::start_state` or calling\"", "StreamChunk < 'r >", "! aut . is_start (sid)", "str", "\" The position of the search.\"", "\" This iterator is constructed via the [`Automaton::try_stream_find_iter`]\"", "core :: ops :: Range < usize >", "format_args ! (\"D \")", "self . buf . fill (& mut self . rdr)", "\" or if the search should continue (for `MatchKind::LeftmostFirst` and\"", "let Some (pre) = aut . prefilter ()", "self", "pid", "self . input . start ()", "state . next_match_index = Some (1)", "\"rdr\"", "\"     nfa::noncontiguous::NFA,\"", "at - len", "\" # Safety\"", "\"     AhoCorasick, Input, Match,\"", "if ! haystack . is_char_boundary (m . start ()) || ! haystack . is_char_boundary (m . end ()) { continue ; }", "Match :: new (pid , (at - len) .. at)", "\" generic routines over this trait but cannot implement it themselves. This\"", "| mat , _ , dst | { dst . push_str (replace_with [mat . pattern ()] . as_ref ()) ; true }", "\"assertion failed: m.is_empty()\"", ":: core :: panicking :: panic_fmt", "& self . next_match_index", "\"         at += 1;\"", "& m", "self . match_kind ()", "& & self . buffer_reported_pos", "\" Returns the starting state for the given anchor mode.\"", "{ replace_with (& mat , bytes , & mut wtr) ? ; }", "\"\"", "\" states when a prefilter is not active or enabled. In this case, it\"", "pre", "\" ) -> Result<Option<Match>, MatchError> {\"", "Some", "self . buf . buffer () . len () >= self . buf . min_buffer_len ()", "pre . find_in (input . haystack () , span)", "\" handle a corner case for preventing empty matches from overlapping with\"", "\" ID is invalid. A state ID is valid if and only if:\"", "\" corresponds to a state whose transitions all loop back to itself. That\"", "self . try_find_iter (Input :: new (haystack)) ?", "& self . mat", "StreamChunk :: NonMatch { bytes }", "\"         Match::new(pid, (at - len)..at)\"", "(at - len) .. at", "std :: io :: Error :: new (kind , e)", "Input < '_ >", "input . get_anchored ()", ":: core :: fmt :: Formatter :: debug_struct_field3_finish (f , \"FindIter\" , \"aut\" , & self . aut , \"input\" , & self . input , \"last_match_end\" , & & self . last_match_end ,)", "\" same position, this state tracks the last reported pattern so that the next\"", "self . try_stream_replace_all_with (rdr , wtr , | mat , _ , wtr | { wtr . write_all (replace_with [mat . pattern ()] . as_ref ()) } ,)", "if buffer_mat_start > self . buffer_reported_pos { let start = self . buffer_reported_pos ; let end = buffer_mat_start ; return Some (start .. end) ; }", "self . it", "last_match .. m . start ()", "anchored . is_anchored ()", "\" about this trait, nor does it implement it itself.\"", "r", "\" This panics if `self.aut.is_match(self.sid)` isn't true.\"", "\" chunks it can copy and which it needs to replace.\"", "(* * self) . prefilter ()", "start", "core :: iter :: from_fn", "AsRef < str >", "\" The underlying automaton to do the search.\"", "\" factors (such as whether the search is anchored or not).\"", "StreamChunkIter", "mat . len ()", "\" for a stream searcher that just reports matches. But we do need something\"", "sid", "at .. input . end ()", "\" [`dfa::DFA`](crate::dfa::DFA).\"", "FindOverlappingIter < 'a , 'h , Self >", "\" The iterator terminates only when the underlying stream reaches `EOF`.\"", "aut . is_dead (sid)", "format_args ! (\"unreachable\")", "Option < usize >", "state . at + 1", "Match", "\" Implementations may panic on unsupported values of `anchored`, but are\"", "f . write_fmt (format_args ! (\"  \"))", "& [& self . aut , & self . rdr , & self . buf , & self . start , & self . sid , & self . absolute_pos , & self . buffer_pos , & & self . buffer_reported_pos ,]", "\" `MatchKind::LeftmostLongest`) until a dead state is seen or the end of\"", "return Some (Ok (StreamChunk :: Match { bytes , mat }))", "\" The lifetime `'a` refers to the lifetime of the [`Automaton`]\"", "\" assumes that the given match ends at the current `buffer_pos`.\"", "\" Replaces all non-overlapping matches in `rdr` by calling the\"", "\" [`AhoCorasick::try_replace_all`](crate::AhoCorasick::try_replace_all)\"", "& 'r [u8]", "aut . start_state (input . get_anchored ()) ?", "\" If a search does not find any matches, then it is expected to clear\"", "\" When `id` is None (i.e., we are starting a search), this is set to\"", "impl Iterator < Item = (u8 , StateID) > + 'a", "\" state are combined into a single range.\"", "aut . match_kind () . is_standard ()", "& haystack [m . start () .. m . end ()]", "\" ends at the current `buffer_pos`.\"", "\" Return any unreported bytes as a non-match up to the end of the buffer.\"", "f . write_fmt (format_args ! (\" >\")) ?", "return Err (MatchError :: invalid_input_anchored ())", "\" [`AhoCorasick::try_replace_all_bytes`](crate::AhoCorasick::try_replace_all_bytes)\"", "FindIter < 'a , 'h , A >", "(class , class , next)", "self . try_replace_all_with (haystack , & mut dst , | mat , _ , dst | { dst . push_str (replace_with [mat . pattern ()] . as_ref ()) ; true } ,) ?", "MatchError :: unsupported_stream", "self . get_match ()", "\" automaton.\"", "& mut core :: fmt :: Formatter < '_ >", "\" We seal the `Automaton` trait for now. It's a big trait, and it's\"", "\" }\"", "get_match (aut , sid , 0 , at)", "\" This trait encodes a notion of \\\"special\\\" states in an automaton. Namely,\"", "\"         }\"", "\" method.\"", "\" of a search when neither an error nor a match is returned.\"", "\" The automaton used to drive the search.\"", "MatchError :: unsupported_empty ()", "\" Note that currently this crate does not rely on the safety property defined\"", "dst . extend (& haystack [last_match ..])", "Anchored :: Yes", "span", "self . buf . min_buffer_len ()", "\" the state is special. The `Automaton::is_dead`, `Automaton::is_match` and\"", "\" `replace_with` closure given and writing the result to `wtr`.\"", "\" [`AhoCorasick::try_find_overlapping_iter`](crate::AhoCorasick::try_find_overlapping_iter)\"", "(* * self) . is_start (sid)", "\" terminated. When this is a match state, `last_match` must be set to a\"", "AsRef < [u8] >", "\" The type variable `R` refers to the `io::Read` stream that is being read\"", "return Some ((prev_start , prev_end , prev_next))", "bool", "Some (get_match (aut , sid , 0 , at))", "self . get_match_chunk (mat)", "Ok (None)", "match state . id { None => { let sid = aut . start_state (input . get_anchored ()) ? ; if aut . is_match (sid) { let i = state . next_match_index . unwrap_or (0) ; let len = aut . match_len (sid) ; if i < len { state . next_match_index = Some (i + 1) ; state . mat = Some (get_match (aut , sid , i , input . start ())) ; return Ok (()) ; } } state . at = input . start () ; state . id = Some (sid) ; state . next_match_index = None ; state . mat = None ; sid } Some (sid) => { if let Some (i) = state . next_match_index { let len = aut . match_len (sid) ; if i < len { state . next_match_index = Some (i + 1) ; state . mat = Some (get_match (aut , sid , i , state . at + 1)) ; return Ok (()) ; } state . at += 1 ; state . next_match_index = None ; state . mat = None ; } sid } }", "\" exactly two printable bytes to the given formatter.\"", "\" `Automaton::is_start(sid)` returns true.\"", "\" let nfa = NFA::new(&[\\\"samwise\\\", \\\"sam\\\"]).unwrap();\"", "* left_val == * right_val", "self . state", "\" The primary correctness guarantees are:\"", ":: core :: option :: Option :: Some (format_args ! (\"streaming replace_all requires a replacement for every pattern in the automaton\" ,) ,)", "\" This iterator is constructed via the [`Automaton::try_find_iter`] method.\"", "MatchError :: unsupported_stream (aut . match_kind ())", "if ! replace_with (& m , & haystack [m . start () .. m . end ()] , dst) { break ; }", "self . buf . buffer () . len () . saturating_sub (self . buf . min_buffer_len ())", "if aut . min_pattern_len () == 0 { return Err (MatchError :: unsupported_empty ()) ; }", "\" ID. A pattern ID is valid if and only if it is less than\"", "\" `Automaton::patterns_len`.\"", "StreamChunk :: Match", "input", "right_val", "result ?", "& mat", "let Some (pre) = pre", "Some (sid)", "f . write_fmt (format_args ! (\"  \")) ?", "\" Returns the length, in bytes, of the longest pattern in this automaton.\"", "mat = Some (m)", "try_find_overlapping_fwd", "\" of special state it is.\"", "Candidate :: None", "\" `replace_with` depending on the pattern that matched, and writes the\"", "match pre . find_in (input . haystack () , input . get_span ()) { Candidate :: None => return Ok (None) , Candidate :: Match (m) => return Ok (Some (m)) , Candidate :: PossibleStartOfMatch (i) => { at = i ; } }", "\" Return the match at the current position for the current state.\"", "core :: fmt :: Result", "if aut . is_match (id) { if aut . is_start (id) { f . write_fmt (format_args ! (\"*>\")) ? ; } else { f . write_fmt (format_args ! (\"* \")) ? ; } } else if aut . is_start (id) { f . write_fmt (format_args ! (\" >\")) ? ; } else { f . write_fmt (format_args ! (\"  \")) ? ; }", "at + 1", "\" you need this, you might consider using\"", "\" Look for any bytes that should be reported as a non-match just before\"", "\" [`AhoCorasick`](crate::AhoCorasick) searcher does not expose any details\"", "\" # Example\"", "\"         sid = aut.next_state(Anchored::No, sid, haystack[at]);\"", "{ wtr . write_all (replace_with [mat . pattern ()] . as_ref ()) }", "\"aut\"", "\" This iterator yields elements of type `io::Result<StreamChunk>`, where\"", "\" In general, the rest of the methods on `Automaton` need to uphold their\"", "buffer_mat_start", "return Err (MatchError :: unsupported_empty ())", "\" been searched and EOF has been hit when trying to fill the buffer.\"", "input . end ()", "! m . is_empty ()", "if aut . is_match (sid) { let m = get_match (aut , sid , 0 , at + 1) ; if ! (anchored . is_anchored () && m . start () > input . start ()) { mat = Some (m) ; if earliest { return Ok (mat) ; } } } else if let Some (pre) = pre { if true { if ! aut . is_start (sid) { :: core :: panicking :: panic (\"assertion failed: aut.is_start(sid)\" ,) } } let span = Span :: from (at .. input . end ()) ; match pre . find_in (input . haystack () , span) . into_option () { None => return Ok (None) , Some (i) => { if i > at { at = i ; continue ; } } } } else { if true { if ! false { { :: core :: panicking :: panic_fmt (format_args ! (\"unreachable\")) ; } } } }", "Err (MatchError :: invalid_input_anchored ())", "\" Return a non-match chunk, if necessary, just before reporting a match.\"", ":: core :: panicking :: panic (\"assertion failed: aut.is_start(sid)\" ,)", "aut . is_dead (id)", "{ cur = Some ((class , class , next)) ; return Some ((prev_start , prev_end , prev_next)) ; }", ":: core :: fmt :: Formatter :: debug_struct_field1_finish (f , \"NonMatch\" , \"bytes\" , & __self_0 ,)", "crate :: dfa :: DFA", "for m in self . try_find_iter (Input :: new (haystack)) ? { if ! haystack . is_char_boundary (m . start ()) || ! haystack . is_char_boundary (m . end ()) { continue ; } dst . push_str (& haystack [last_match .. m . start ()]) ; last_match = m . end () ; if ! replace_with (& m , & haystack [m . start () .. m . end ()] , dst) { break ; } }", "\"FindIter\"", "self . buf . roll ()", "! input . get_anchored () . is_anchored ()", "self . buffer_pos += self . absolute_pos - start", "& self . buffer_reported_pos", "\"StreamFindIter\"", "Some (get_match (aut , sid , i , state . at + 1))", "format_args ! (\"streaming replace_all requires a replacement for every pattern in the automaton\" ,)", "\" A chunk that precisely contains a match.\"", "& mut wtr", "Candidate :: PossibleStartOfMatch", "& self . at", "crate :: util :: buffer :: Buffer :: new", "if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! (\"streaming replace_all requires a replacement for every pattern in the automaton\" ,) ,) ,) ; }", "Some ((start , end , next))", "Result < Option < Match > , MatchError >", "\"     matches.push(mat);\"", "self . mat", "self . search () ?", "haystack [m . start () .. m . end ()]", "\" Returns an iterator of non-overlapping matches with this automaton\"", "values", "\" the total number of matches to report for the current match state. (In\"", "prev_next == next", "StreamFindIter < 'a , Self , R >", "u8", ":: core :: clone :: Clone :: clone (& self . at)", "return Ok (Some (m))", "if let Some (pre) = pre { if true { if ! aut . is_start (sid) { :: core :: panicking :: panic (\"assertion failed: aut.is_start(sid)\" ,) } } let span = Span :: from (at .. input . end ()) ; match pre . find_in (input . haystack () , span) . into_option () { None => return Ok (None) , Some (i) => { if i > at { at = i ; continue ; } } } } else { if true { if ! false { { :: core :: panicking :: panic_fmt (format_args ! (\"unreachable\")) ; } } } }", ":: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! (\"replace_all requires a replacement for every pattern in the automaton\" ,) ,) ,)", "\" following that will participate in a match or not.\"", "\"                 mat = Some(get_match(sid, at + 1));\"", "\"assertion failed: aut.is_start(sid)\"", "Result < () , MatchError >", "if ! self . match_kind () . is_standard () { return Err (MatchError :: unsupported_overlapping (self . match_kind ())) ; }", "format_args ! (\"*>\")", "\" whether it should be returned immediately (for `MatchKind::Standard`)\"", "self . buf . buffer () . len () - self . buf . min_buffer_len ()", "\" See\"", "\" A chunk that does not contain any matches.\"", "FnMut (& Match , & str , & mut String) -> bool", "\"     let get_match = |sid, at| {\"", "\"         if aut.is_special(sid) {\"", "\" of the last byte we returned to the caller. If there's a difference,\"", "\" Returns the total number of patterns compiled into this automaton.\"", "\" This is used for overlapping searches since they need to know something\"", "{ try_find_fwd_imp (aut , input , None , Anchored :: No , false) }", "match pre . find_in (input . haystack () , span) . into_option () { None => return Ok (()) , Some (i) => { if i > state . at { state . at = i ; continue ; } } }", "usize", "\"                     return Ok(mat);\"", "self . absolute_pos", "! self . match_kind () . is_standard ()", "haystack [last_match ..]", "& self . start", "OverlappingState", "(* * self) . min_pattern_len ()", "\" is, once entered, it can never be left. In practice, it serves as a\"", "if let Some (r) = self . get_pre_roll_non_match_chunk () { self . buffer_reported_pos += r . len () ; let bytes = & self . buf . buffer () [r] ; return Some (Ok (StreamChunk :: NonMatch { bytes })) ; }", "Ok (FindIter { aut , input , last_match_end : None , })", ":: core :: clone :: Clone :: clone", "\" This should only be called when the entire contents of the buffer have\"", "core :: fmt :: Formatter < '_ >", "\" [`AhoCorasick::try_stream_replace_all`](crate::AhoCorasick::try_stream_replace_all)\"", "\" based on the current configuration/offsets.\"", "\" Returns true if the given ID represents a dead state.\"", "format_args", "\" The match reported by the most recent overlapping search to use this\"", "\"at\"", "\" The buffer position of the end of the bytes that we last returned\"", "haystack [last_match .. m . start ()]", "bytes", "last_match ..", "\" [`MatchKind`] semantics. (The comments in the code below note the parts\"", "self . buf . buffer () [self . buffer_pos ..]", "Err (MatchError :: unsupported_overlapping (self . match_kind ()))", "\" This iterator yields matches according to the [`MatchKind`] used by this\"", "()", "& self . sid", "\" Most of the APIs on this trait should panic or give incorrect results\"", "input . haystack () [at]", "{ cur = Some ((class , class , next)) ; continue ; }", "\" Implementations must treat all possible values of `byte` as valid.\"", "\" a search. When that happens, one can use a prefilter to skip ahead and\"", "OverlappingState { mat : :: core :: clone :: Clone :: clone (& self . mat) , id : :: core :: clone :: Clone :: clone (& self . id) , at : :: core :: clone :: Clone :: clone (& self . at) , next_match_index : :: core :: clone :: Clone :: clone (& self . next_match_index) , }", "return Some (Ok (StreamChunk :: NonMatch { bytes }))", "return Some ((start , end , next))", "\" [`AhoCorasick::try_find`](crate::AhoCorasick::try_find)\"", "\" This has unspecified behavior if the given ID does not refer to a match\"", "& mut self . state", "(* left_val == * right_val)", "if ! (anchored . is_anchored () && m . start () > input . start ()) { mat = Some (m) ; if earliest { return Ok (mat) ; } }", "f . write_fmt (format_args ! (\"* \")) ?", "\" // has changed!\"", "\" using the given configuration.\"", "\" An iterator that reports matches in a stream.\"", "\" the possible overlappings of different state types. (The only possible\"", "& [u8]", "\"     haystack: &[u8],\"", "\"                 if matches!(aut.match_kind(), MatchKind::Standard) {\"", "index", "\" ];\"", "\" Every search will clear this result automatically, such that if no\"", "StreamFindIter { it : StreamChunkIter :: new (self , rdr) ? , }", "MatchError :: unsupported_empty", "StreamFindIter", "\" This iterator is constructed via the\"", "Ok (StreamChunkIter { aut , rdr , buf : crate :: util :: buffer :: Buffer :: new (aut . max_pattern_len ()) , start , sid : start , absolute_pos : 0 , buffer_pos : 0 , buffer_reported_pos : 0 , })", "sid = aut . next_state (input . get_anchored () , sid , input . haystack () [state . at])", "\" [`AhoCorasick::try_find_overlapping`](crate::AhoCorasick::try_find_overlapping)\"", "\" about reporting the first pattern ID in a match state.\"", "\" `Automaton::start_state` returning a state that walks a different path\"", "& mut Vec < u8 >", "(* * self)", ":: core :: clone :: Clone :: clone (& self . id)", "if earliest { try_find_fwd_imp (aut , input , None , Anchored :: No , true) } else { try_find_fwd_imp (aut , input , None , Anchored :: No , false) }", "get_match (aut , sid , 0 , at + 1)", "self . start_state (input . get_anchored ())", "\"         Some(mat) => mat,\"", "(u8 , StateID)", "\" This returns an error when the given search configuration is not\"", "\" a valid state ID for all values of `anchored` and `byte`, or otherwise\"", "\" An iterator of non-overlapping matches in a particular haystack.\"", "\" handling, you'd get the matches [0, 1) and [1, 1), where the latter\"", "dst . push_str (replace_with [mat . pattern ()] . as_ref ())", "\"buffer_reported_pos\"", "\" `Automaton::next_state` with a valid state ID.\"", "replace_with . len ()", "id", "dst . push_str (& haystack [last_match ..])", "\" Represents the current state of an overlapping search.\""}
  [split-expanded-lib] DeclsVisitor: Visiting module 'dfa'. Required imports for module: {"byte_classes . alphabet_len ()", "\" but NOT both.\"", "newsid", "\" matches are meant to occur.\"", "for next in dfa . trans [sid ..] [.. stride] . iter_mut () { * next = remap_unanchored [* next] ; }", "\" The closure is guaranteed to be called precisely\"", "\" has already completed, all settings impacting only initial construction\"", "format_args ! (\"dfa::DFA(\\n\")", ":: core :: clone :: Clone :: clone (& self . pattern_lens)", "self", "{ let start = self . special . start_anchored_id ; if start == DFA :: DEAD { Err (MatchError :: invalid_input_anchored ()) } else { Ok (start) } }", "{ oldnextsid = nnfa . next_state (Anchored :: No , state . fail () , byte) ; }", "0 .. self . byte_classes . alphabet_len ()", "dfa . set_matches (unewsid , nnfa . iter_matches (oldsid))", ":: core :: clone :: Clone :: clone (& self . start_kind)", "BuildError :: state_id_overflow", "self . noncontiguous . prefilter (yes)", "\" A DFA implementation of Aho-Corasick.\"", "\" is essentially no added cost for doing so.) It is for this reason that\"", "b", "self . state_len", "f . write_fmt (format_args ! (\"pattern length: {0:?}\\n\" , self . patterns_len ()))", "f . write_fmt (format_args ! (\"dfa::DFA(\\n\")) ?", "anewsid . as_usize () + class", "sparse_transitions (it)", "\" Honestly this is pretty inscrutable... Simplifications are most\"", "0 .. dfa . state_len", "p . memory_usage ()", "\" Enable ASCII-aware case insensitive matching.\"", "\" };\"", "\" searches.\"", "sid . as_usize ()", "\" The DFA transition table. IDs in this table are pre-multiplied. So\"", "self . pattern_lens . len ()", ":: core :: clone :: Clone :: clone (& self . state_len)", "& self . prefilter", "(sid . as_u32 () + u32 :: from (class))", "fmt_state_indicator", "f . write_fmt (format_args ! (\"{0:?} => {1:?}\" , DebugByte (start) , next . as_usize () ,) ,) ?", "format_args ! (\"{0}\" , pid . as_usize ())", "format_args ! (\"alphabet length: {0:?}\\n\" , self . alphabet_len)", "\" Create a new builder for configuring an Aho-Corasick DFA.\"", "self . build_from_noncontiguous (& nnfa)", "self . matches [offset]", ":: core :: fmt :: Formatter", "newsid . as_usize () + usize :: from (class)", "Option < & Prefilter >", "newsid . as_usize ()", "is_anchored [anewsid . as_usize () >> stride2]", "MatchError", "format_args ! (\"state length: {0:?}\\n\" , self . state_len)", "f . write_fmt (format_args ! (\" matches: \")) ?", "f . write_fmt (format_args ! (\", \"))", "\" explicitly handled at search time.\"", "new . max_special_id", "\" The amount of heap memory used, in bytes, by the inner Vecs of\"", "sid . as_usize () + class", "f . write_fmt (format_args ! (\"state length: {0:?}\\n\" , self . state_len)) ?", "Ok (dfa)", "self . matches_memory_usage += PatternID :: SIZE", "sid <= self . special . max_match_id", "{ :: core :: panicking :: panic_fmt (format_args ! (\"match state must have non-empty pids\") ,) ; }", "& mut dfa . special", ":: core :: panicking :: panic (\"assertion failed: self.is_match(sid)\")", "{ let class = usize :: from (class) ; if oldnextsid == noncontiguous :: NFA :: FAIL { dfa . trans [newsid . as_usize () + class] = DFA :: DEAD ; } else { dfa . trans [newsid . as_usize () + class] = oldnextsid ; } }", "\" the fail state ID.\"", "IntoIterator < Item = P >", "\" The exponent with a base 2, such that stride=2^stride2. Given a state\"", "if oldsid == noncontiguous :: NFA :: DEAD || oldsid == noncontiguous :: NFA :: FAIL { remap_unanchored [oldsid] = newsid ; remap_anchored [oldsid] = newsid ; newsid = next_dfa_id (newsid) ; } else if oldsid == nnfa . special () . start_unanchored_id || oldsid == nnfa . special () . start_anchored_id { if oldsid == nnfa . special () . start_unanchored_id { remap_unanchored [oldsid] = newsid ; remap_anchored [oldsid] = DFA :: DEAD ; } else { remap_unanchored [oldsid] = DFA :: DEAD ; remap_anchored [oldsid] = newsid ; is_anchored [newsid . as_usize () >> stride2] = true ; } if state . is_match () { dfa . set_matches (newsid , nnfa . iter_matches (oldsid)) ; } sparse_iter (nnfa , oldsid , & dfa . byte_classes , | _ , class , oldnextsid | { let class = usize :: from (class) ; if oldnextsid == noncontiguous :: NFA :: FAIL { dfa . trans [newsid . as_usize () + class] = DFA :: DEAD ; } else { dfa . trans [newsid . as_usize () + class] = oldnextsid ; } } ,) ; newsid = next_dfa_id (newsid) ; } else { let unewsid = newsid ; newsid = next_dfa_id (newsid) ; let anewsid = newsid ; newsid = next_dfa_id (newsid) ; remap_unanchored [oldsid] = unewsid ; remap_anchored [oldsid] = anewsid ; is_anchored [anewsid . as_usize () >> stride2] = true ; if state . is_match () { dfa . set_matches (unewsid , nnfa . iter_matches (oldsid)) ; dfa . set_matches (anewsid , nnfa . iter_matches (oldsid)) ; } sparse_iter (nnfa , oldsid , & dfa . byte_classes , | byte , class , oldnextsid | { let class = usize :: from (class) ; if oldnextsid == noncontiguous :: NFA :: FAIL { let oldnextsid = if state . fail () == noncontiguous :: NFA :: DEAD { noncontiguous :: NFA :: DEAD } else { nnfa . next_state (Anchored :: No , state . fail () , byte) } ; dfa . trans [unewsid . as_usize () + class] = oldnextsid ; } else { dfa . trans [unewsid . as_usize () + class] = oldnextsid ; dfa . trans [anewsid . as_usize () + class] = oldnextsid ; } } ,) ; }", "if prev_class != Some (class) { f (rep , class , t . next ()) ; prev_class = Some (class) ; }", "self . byte_classes . get (byte)", "kind", "if state . fail () == noncontiguous :: NFA :: DEAD { noncontiguous :: NFA :: DEAD } else { nnfa . next_state (Anchored :: No , state . fail () , byte) }", "\" 2*stride, 3*stride, ...\"", "{ new . start_unanchored_id = old2new (old . start_unanchored_id) ; new . start_anchored_id = DFA :: DEAD ; }", "start == DFA :: DEAD", "i", "remap_unanchored [* next]", "classes . get (rep)", "match anchored { Anchored :: No => { let start = self . special . start_unanchored_id ; if start == DFA :: DEAD { Err (MatchError :: invalid_input_unanchored ()) } else { Ok (start) } } Anchored :: Yes => { let start = self . special . start_anchored_id ; if start == DFA :: DEAD { Err (MatchError :: invalid_input_anchored ()) } else { Ok (start) } } }", "& self . pattern_lens", "remap_anchored [oldsid] = anewsid", "\" Create a new Aho-Corasick DFA using the default configuration.\"", "\" Finishes building a DFA that supports BOTH unanchored and anchored\"", "f (rep , class , noncontiguous :: NFA :: FAIL)", "\" failure transitions everywhere, such that failure transitions are no\"", "\" See\"", "Builder { noncontiguous : noncontiguous :: Builder :: new () , start_kind : StartKind :: Unanchored , byte_classes : true , }", "{ return Err (BuildError :: state_id_overflow (StateID :: MAX . as_u64 () , usize :: MAX . as_u64 () ,) ,) ; }", "PatternID :: SIZE", "\" records the added memory usage.\"", "new . max_match_id = old2new (old . max_match_id)", "self . prefilter", "\"     nfa.try_find(&Input::new(haystack))?,\"", "self . matches_memory_usage", "\" equivalence classes and not on the 256 distinct byte values.\"", ":: alloc :: vec :: Vec :: new ()", "next_dfa_id (newsid)", "remap_unanchored [oldsid] = unewsid", "dfa . trans [anewsid . as_usize () + class]", "\" The closure is called for all transitions with a distinct equivalence\"", "& self . start_kind", "Builder :: new ()", "dfa . set_matches (newsid , nnfa . iter_matches (oldsid))", "\" using a constant number of instructions. However, this comes at\"", "nnfa . states () . len ()", "size_of :: < SmallIndex >", "old2new", "f . write_fmt (format_args ! (\")\\n\")) ?", "| _ , class , oldnextsid | { let class = usize :: from (class) ; if oldnextsid == noncontiguous :: NFA :: FAIL { dfa . trans [newsid . as_usize () + class] = DFA :: DEAD ; } else { dfa . trans [newsid . as_usize () + class] = oldnextsid ; } }", "oldsid . as_usize () << stride2", "size_of :: < SmallIndex > ()", "{ (class . as_u8 () , self . trans [sid . as_usize () + class]) }", "\" A builder may be reused to create more DFAs.\"", "start == end", "\" [`AhoCorasickBuilder::prefilter`](crate::AhoCorasickBuilder::prefilter)\"", "& ByteClasses", "f . write_fmt (format_args ! (\"alphabet length: {0:?}\\n\" , self . alphabet_len)) ?", ":: alloc :: vec :: from_elem (DFA :: DEAD , trans_len)", "remap_unanchored [old . start_unanchored_id]", "self . is_match (sid)", "StateID :: new_unchecked (sid . as_usize () + stride ,)", "nnfa . special ()", "u32 :: from (class)", "& self . matches", "(self . trans . len () * size_of :: < u32 > ())", "& Self", "self . is_dead (sid)", "sparse_iter (nnfa , oldsid , & dfa . byte_classes , | byte , class , mut oldnextsid | { if oldnextsid == noncontiguous :: NFA :: FAIL { if anchored . is_anchored () { oldnextsid = noncontiguous :: NFA :: DEAD ; } else if state . fail () == noncontiguous :: NFA :: DEAD { oldnextsid = noncontiguous :: NFA :: DEAD ; } else { oldnextsid = nnfa . next_state (Anchored :: No , state . fail () , byte) ; } } dfa . trans [newsid . as_usize () + usize :: from (class)] = old2new (oldnextsid ,) ; } ,)", "StartKind", "\" [`AhoCorasickBuilder::match_kind`](crate::AhoCorasickBuilder::match_kind)\"", "StateID", "(sid . as_usize () >> self . stride2) . checked_sub (2) . unwrap ()", "Some", "\" The match semantics built into this DFA.\"", "{ Ok (start) }", "f . write_fmt (format_args ! (\"longest pattern length: {0:?}\\n\" , self . max_pattern_len) ,)", "for index in 0 .. self . state_len { let sid = StateID :: new_unchecked (index << self . stride2) ; if index == 1 { f . write_fmt (format_args ! (\"F {0:06}:\\n\" , sid . as_usize ())) ? ; continue ; } fmt_state_indicator (f , self , sid) ? ; f . write_fmt (format_args ! (\"{0:06}: \" , sid . as_usize ())) ? ; let it = (0 .. self . byte_classes . alphabet_len ()) . map (| class | { (class . as_u8 () , self . trans [sid . as_usize () + class]) }) ; for (i , (start , end , next)) in sparse_transitions (it) . enumerate () { if i > 0 { f . write_fmt (format_args ! (\", \")) ? ; } if start == end { f . write_fmt (format_args ! (\"{0:?} => {1:?}\" , DebugByte (start) , next . as_usize () ,) ,) ? ; } else { f . write_fmt (format_args ! (\"{0:?}-{1:?} => {2:?}\" , DebugByte (start) , DebugByte (end) , next . as_usize () ,) ,) ? ; } } f . write_fmt (format_args ! (\"\\n\")) ? ; if self . is_match (sid) { f . write_fmt (format_args ! (\" matches: \")) ? ; for i in 0 .. self . match_len (sid) { if i > 0 { f . write_fmt (format_args ! (\", \")) ? ; } let pid = self . match_pattern (sid , i) ; f . write_fmt (format_args ! (\"{0}\" , pid . as_usize ())) ? ; } f . write_fmt (format_args ! (\"\\n\")) ? ; } }", "old2new (old . max_special_id)", "& Prefilter", "StateID :: new (trans_len . checked_sub (byte_classes . stride ()) . unwrap ())", "f . write_fmt (format_args ! (\"pattern length: {0:?}\\n\" , self . patterns_len ())) ?", "self . trans [sid . as_usize () + class]", "AsRef < [u8] >", "sid == self . special . start_anchored_id", "t", "f . write_fmt (format_args ! (\" matches: \"))", "self . prefilter . as_ref () . map_or (0 , | p | p . memory_usage ())", "format_args ! (\"stride: {0:?}\\n\" , 1 << self . stride2)", "| e | { BuildError :: state_id_overflow (StateID :: MAX . as_u64 () , e . attempted ()) }", ":: alloc :: vec :: from_elem (false , dfa . state_len)", "dfa . trans [sid ..] [.. stride] . iter_mut ()", "(self . matches . len () * size_of :: < Vec < PatternID > > ())", "size_of :: < Vec < PatternID > >", "\"     Some(Match::must(0, 1..2)),\"", "& self . matches_memory_usage", "StateID :: new_unchecked (0)", "state . fail ()", "BuildError :: state_id_overflow (StateID :: MAX . as_u64 () , usize :: MAX . as_u64 () ,)", "f . write_fmt (format_args ! (\"{0:?} => {1:?}\" , DebugByte (start) , next . as_usize () ,) ,)", "\" The equivalence classes for this DFA. All transitions are defined on\"", "return Err (BuildError :: state_id_overflow (StateID :: MAX . as_u64 () , usize :: MAX . as_u64 () ,) ,)", "nnfa . pattern_lens_raw () . to_vec ()", "noncontiguous :: NFA :: FAIL", "anewsid", "& mut dfa", "f . write_fmt (format_args ! (\"{0}\" , pid . as_usize ())) ?", "byte . as_u8 ()", "\" index 'i', its state identifier is 'i << stride2'. Given a state\"", "& mut Self", "remap_anchored [oldsid] = DFA :: DEAD", "core :: fmt :: Formatter", "fmt_state_indicator (f , self , sid) ?", "\"start_kind\"", "BuildError :: state_id_overflow (StateID :: MAX . as_u64 () , e . attempted ())", "noncontiguous :: NFA", "new . start_unanchored_id = DFA :: DEAD", "ByteClasses", "sparse_transitions (it) . enumerate ()", "& self . max_pattern_len", "\" since failure transitions are pre-computed, supporting both anchored\"", "\" The information required to deduce which states are \\\"special\\\" in this\"", "Anchored", "self . match_len (sid)", "\" Build an Aho-Corasick DFA from the given noncontiguous NFA.\"", "usize :: MAX . as_u64 ()", "remap_unanchored [oldsid] = DFA :: DEAD", "anewsid . as_usize () >> stride2", "\" `byte_classes.alphabet_len()` times, once for every possible class in\"", "classes", "& mut DFA", "format_args ! (\"match kind: {0:?}\\n\" , self . match_kind)", "if true { if ! self . is_match (sid) { :: core :: panicking :: panic (\"assertion failed: self.is_match(sid)\") } }", "\" # Example\"", "\" Namely, the whole point of a DFA is that the FAIL state is completely\"", "dfa . trans . shrink_to_fit ()", "f . write_fmt (format_args ! (\"F {0:06}:\\n\" , sid . as_usize ()))", "nnfa . prefilter ()", "dfa . byte_classes", "dfa . special", "remap_anchored", "nnfa . special () . start_unanchored_id", "self . special . start_unanchored_id", "\" This example shows how to build an `DFA` directly and use it to execute\"", "\" * All failure transitions are pre-computed such that they are never\"", "(sid . as_usize () >> self . stride2)", "dfa . pattern_lens", "\" longer used at search time. This, combined with its uniformly dense\"", "\" It is also possible to implement your own version of `try_find`. See the\"", "\" unconditionally support both anchored and unanchored searches because there\"", "state . is_match ()", "nnfa . special () . start_anchored_id", "newsid . as_usize () + class", "f . write_fmt (format_args ! (\"{0:06}: \" , sid . as_usize ())) ?", "self . noncontiguous . match_kind (kind)", "4", "Anchored :: No", "self . start_kind = kind", "\" These two facts combined mean that every state transition is performed\"", "self . matches [index] . push (pid)", "& mut :: core :: fmt :: Formatter", "if oldnextsid == noncontiguous :: NFA :: FAIL { let oldnextsid = if state . fail () == noncontiguous :: NFA :: DEAD { noncontiguous :: NFA :: DEAD } else { nnfa . next_state (Anchored :: No , state . fail () , byte) } ; dfa . trans [unewsid . as_usize () + class] = oldnextsid ; } else { dfa . trans [unewsid . as_usize () + class] = oldnextsid ; dfa . trans [anewsid . as_usize () + class] = oldnextsid ; }", "new . start_unanchored_id", "dfa . trans [unewsid . as_usize () + class] = oldnextsid", "\" This DFA can only be built by first constructing a [`noncontiguous::NFA`].\"", "Anchored :: Yes", "oldsid == noncontiguous :: NFA :: DEAD || oldsid == noncontiguous :: NFA :: FAIL", "PatternID", "& self . state_len", "DFA { trans : :: alloc :: vec :: from_elem (DFA :: DEAD , trans_len) , matches : :: alloc :: vec :: from_elem (:: alloc :: vec :: Vec :: new () , num_match_states ,) , matches_memory_usage : 0 , pattern_lens : nnfa . pattern_lens_raw () . to_vec () , prefilter : nnfa . prefilter () . cloned () , match_kind : nnfa . match_kind () , state_len , alphabet_len : byte_classes . alphabet_len () , stride2 : byte_classes . stride2 () , byte_classes , min_pattern_len : nnfa . min_pattern_len () , max_pattern_len : nnfa . max_pattern_len () , special : Special :: zero () , }", "nnfa . states () . iter () . with_state_ids ()", "new", "{ self . finish_build_both_starts (nnfa , & mut dfa) ; }", "unewsid", "remap_anchored [old . start_anchored_id]", "self . pattern_lens [pid] . as_usize ()", "Err (MatchError :: invalid_input_unanchored ())", "while byte < usize :: from (t . byte ()) { let rep = byte . as_u8 () ; let class = classes . get (rep) ; byte += 1 ; if prev_class != Some (class) { f (rep , class , noncontiguous :: NFA :: FAIL) ; prev_class = Some (class) ; } }", "DFA :: DEAD", "f . write_fmt (format_args ! (\"prefilter: {0:?}\\n\" , self . prefilter . is_some ())) ?", "for t in nnfa . iter_trans (oldsid) { while byte < usize :: from (t . byte ()) { let rep = byte . as_u8 () ; let class = classes . get (rep) ; byte += 1 ; if prev_class != Some (class) { f (rep , class , noncontiguous :: NFA :: FAIL) ; prev_class = Some (class) ; } } let rep = t . byte () ; let class = classes . get (rep) ; byte += 1 ; if prev_class != Some (class) { f (rep , class , t . next ()) ; prev_class = Some (class) ; } }", "prev_class != Some (class)", "{ self . finish_build_one_start (Anchored :: No , nnfa , & mut dfa) ; }", "oldsid == nnfa . special () . start_unanchored_id || oldsid == nnfa . special () . start_anchored_id", "format_args ! (\"prefilter: {0:?}\\n\" , self . prefilter . is_some ())", "format_args ! (\"shortest pattern length: {0:?}\\n\" , self . min_pattern_len)", "e", "ByteClasses :: singletons ()", "ByteClasses :: singletons", "\" state index (so that's `sid >> stride2`) and then by order in which the\"", ":: alloc :: vec :: from_elem (:: alloc :: vec :: Vec :: new () , num_match_states ,)", "sid ..", "\" via [`Builder::start_kind`]. By default, a DFA only supports unanchored\"", "nnfa . pattern_lens_raw ()", "stride2", "\"     Input, Match,\"", "format_args ! (\"{0:06}: \" , sid . as_usize ())", "Option < Prefilter >", "u8", "pids", "{ f . write_fmt (format_args ! (\"{0:?}-{1:?} => {2:?}\" , DebugByte (start) , DebugByte (end) , next . as_usize () ,) ,) ? ; }", "self . alphabet_len", "is_anchored [newsid . as_usize () >> stride2] = true", "{ let start = self . special . start_unanchored_id ; if start == DFA :: DEAD { Err (MatchError :: invalid_input_unanchored ()) } else { Ok (start) } }", "& self . alphabet_len", "bool", "\" making the memory usage of such a DFA ever bigger. (The NFAs in this crate\"", "\" The alphabet size, or total number of equivalence classes, for this\"", "for i in 0 .. dfa . state_len { let sid = i << stride2 ; if is_anchored [i] { for next in dfa . trans [sid ..] [.. stride] . iter_mut () { * next = remap_anchored [* next] ; } } else { for next in dfa . trans [sid ..] [.. stride] . iter_mut () { * next = remap_unanchored [* next] ; } } }", "()", "remap_anchored [old . max_match_id]", "t . next ()", "{ let unewsid = newsid ; newsid = next_dfa_id (newsid) ; let anewsid = newsid ; newsid = next_dfa_id (newsid) ; remap_unanchored [oldsid] = unewsid ; remap_anchored [oldsid] = anewsid ; is_anchored [anewsid . as_usize () >> stride2] = true ; if state . is_match () { dfa . set_matches (unewsid , nnfa . iter_matches (oldsid)) ; dfa . set_matches (anewsid , nnfa . iter_matches (oldsid)) ; } sparse_iter (nnfa , oldsid , & dfa . byte_classes , | byte , class , oldnextsid | { let class = usize :: from (class) ; if oldnextsid == noncontiguous :: NFA :: FAIL { let oldnextsid = if state . fail () == noncontiguous :: NFA :: DEAD { noncontiguous :: NFA :: DEAD } else { nnfa . next_state (Anchored :: No , state . fail () , byte) } ; dfa . trans [unewsid . as_usize () + class] = oldnextsid ; } else { dfa . trans [unewsid . as_usize () + class] = oldnextsid ; dfa . trans [anewsid . as_usize () + class] = oldnextsid ; } } ,) ; }", "\" A convenience method for returning a new Aho-Corasick DFA builder.\"", "is_anchored [anewsid . as_usize () >> stride2] = true", "self . byte_classes", "\" mechanisms:\"", "\" The length of the longest pattern in this automaton.\"", "(0 .. self . byte_classes . alphabet_len ()) . map (| class | { (class . as_u8 () , self . trans [sid . as_usize () + class]) })", "oldsid . as_usize ()", "yes", "f . write_fmt (format_args ! (\"match kind: {0:?}\\n\" , self . match_kind)) ?", "oldnextsid = nnfa . next_state (Anchored :: No , state . fail () , byte)", ":: core :: clone :: Clone :: clone (& self . matches_memory_usage ,)", "(self . trans . len () * size_of :: < u32 > ()) + (self . matches . len () * size_of :: < Vec < PatternID > > ())", "\"byte_classes\"", "StateID :: new (trans_len . checked_sub (byte_classes . stride ()) . unwrap ()) . map_err (| e | { BuildError :: state_id_overflow (StateID :: MAX . as_u64 () , e . attempted ()) })", "f . write_fmt (format_args ! (\"byte classes: {0:?}\\n\" , self . byte_classes)) ?", "if oldnextsid == noncontiguous :: NFA :: FAIL { if anchored . is_anchored () { oldnextsid = noncontiguous :: NFA :: DEAD ; } else if state . fail () == noncontiguous :: NFA :: DEAD { oldnextsid = noncontiguous :: NFA :: DEAD ; } else { oldnextsid = nnfa . next_state (Anchored :: No , state . fail () , byte) ; } }", "new . start_anchored_id", "sid . as_u32 () + u32 :: from (class)", "remap_unanchored [oldsid] = newsid", "trans_len . checked_sub (byte_classes . stride ())", "| class | { (class . as_u8 () , self . trans [sid . as_usize () + class]) }", "dfa . trans [newsid . as_usize () + class] = oldnextsid", "nnfa . iter_trans (oldsid)", "{ if oldnextsid == noncontiguous :: NFA :: FAIL { if anchored . is_anchored () { oldnextsid = noncontiguous :: NFA :: DEAD ; } else if state . fail () == noncontiguous :: NFA :: DEAD { oldnextsid = noncontiguous :: NFA :: DEAD ; } else { oldnextsid = nnfa . next_state (Anchored :: No , state . fail () , byte) ; } } dfa . trans [newsid . as_usize () + usize :: from (class)] = old2new (oldnextsid ,) ; }", "nnfa . byte_classes () . clone ()", ":: core :: clone :: Clone :: clone (& self . match_kind)", ":: alloc :: vec :: Vec :: new", "\" compiled away. That is, DFA construction involves pre-computing the\"", "old2new (old . start_unanchored_id)", "is_anchored [i]", "BuildError", "self . special . max_match_id", "\" 'matches'.\"", "self . trans", "I", "if ! at_least_one { { :: core :: panicking :: panic_fmt (format_args ! (\"match state must have non-empty pids\") ,) ; } }", "{ dfa . trans [newsid . as_usize () + class] = oldnextsid ; }", "unewsid . as_usize ()", "\" let patterns = &[\\\"b\\\", \\\"abc\\\", \\\"abcd\\\"];\"", "MatchKind", "\" The length of the shortest pattern in this automaton.\"", "self . max_pattern_len", "\"noncontiguous\"", "self . noncontiguous . build (patterns)", "{ nnfa . special () . max_match_id . as_usize () . checked_sub (1) . unwrap () . checked_mul (2) . unwrap () }", "\" re-shuffle states afterward to ensure that our states still look like\"", "DFA { trans : :: core :: clone :: Clone :: clone (& self . trans) , matches : :: core :: clone :: Clone :: clone (& self . matches) , matches_memory_usage : :: core :: clone :: Clone :: clone (& self . matches_memory_usage ,) , pattern_lens : :: core :: clone :: Clone :: clone (& self . pattern_lens) , prefilter : :: core :: clone :: Clone :: clone (& self . prefilter) , match_kind : :: core :: clone :: Clone :: clone (& self . match_kind) , state_len : :: core :: clone :: Clone :: clone (& self . state_len) , alphabet_len : :: core :: clone :: Clone :: clone (& self . alphabet_len) , stride2 : :: core :: clone :: Clone :: clone (& self . stride2) , byte_classes : :: core :: clone :: Clone :: clone (& self . byte_classes) , min_pattern_len : :: core :: clone :: Clone :: clone (& self . min_pattern_len) , max_pattern_len : :: core :: clone :: Clone :: clone (& self . max_pattern_len) , special : :: core :: clone :: Clone :: clone (& self . special) , }", "dfa . matches . shrink_to_fit ()", "index == 1", "b . as_u8 ()", "remap_unanchored [oldsid]", "\" );\"", "self . pattern_lens [pid]", "if index == 1 { f . write_fmt (format_args ! (\"F {0:06}:\\n\" , sid . as_usize ())) ? ; continue ; }", "old . start_unanchored_id", "Ok", "u32", "oldsid == nnfa . special () . start_unanchored_id", "self . trans [(sid . as_u32 () + u32 :: from (class)) . as_usize ()]", "for next in dfa . trans [sid ..] [.. stride] . iter_mut () { * next = remap_anchored [* next] ; }", ":: core :: fmt :: Formatter :: debug_struct_field3_finish", "{ nnfa . special () . max_match_id . as_usize () . checked_sub (1) . unwrap () }", "if start == end { f . write_fmt (format_args ! (\"{0:?} => {1:?}\" , DebugByte (start) , next . as_usize () ,) ,) ? ; } else { f . write_fmt (format_args ! (\"{0:?}-{1:?} => {2:?}\" , DebugByte (start) , DebugByte (end) , next . as_usize () ,) ,) ? ; }", "& noncontiguous :: NFA", "(self . trans . len () * size_of :: < u32 > ()) + (self . matches . len () * size_of :: < Vec < PatternID > > ()) + self . matches_memory_usage", "byte_classes . stride ()", "(self . trans . len () * size_of :: < u32 > ()) + (self . matches . len () * size_of :: < Vec < PatternID > > ()) + self . matches_memory_usage + (self . pattern_lens . len () * size_of :: < SmallIndex > ())", "\" one needs access to the [`Automaton`] trait implementation.\"", "sid . as_usize () >> self . stride2", "oldsid == noncontiguous :: NFA :: FAIL", "\" instead of the IDs being 0, 1, 2, 3, ..., they are 0*stride, 1*stride,\"", "\" The total number of states in this DFA.\"", "sparse_iter (nnfa , oldsid , & dfa . byte_classes , | byte , class , oldnextsid | { let class = usize :: from (class) ; if oldnextsid == noncontiguous :: NFA :: FAIL { let oldnextsid = if state . fail () == noncontiguous :: NFA :: DEAD { noncontiguous :: NFA :: DEAD } else { nnfa . next_state (Anchored :: No , state . fail () , byte) } ; dfa . trans [unewsid . as_usize () + class] = oldnextsid ; } else { dfa . trans [unewsid . as_usize () + class] = oldnextsid ; dfa . trans [anewsid . as_usize () + class] = oldnextsid ; } } ,)", "byte += 1", "self . matches", "f . write_fmt (format_args ! (\"{0:?}-{1:?} => {2:?}\" , DebugByte (start) , DebugByte (end) , next . as_usize () ,) ,) ?", "f (rep , class , t . next ())", "\" their behavior is identical.\"", "& mut core :: fmt :: Formatter", "\" not by orders of magnitude.\"", "* next", "byte_classes . stride2 ()", "self . finish_build_both_starts (nnfa , & mut dfa)", "\" a DFA's support for anchored and unanchored searches can be configured\"", "anchored", "f . write_fmt (format_args ! (\"state length: {0:?}\\n\" , self . state_len))", "oldsid", "start", "for (oldsid , state) in nnfa . states () . iter () . with_state_ids () { let newsid = old2new (oldsid) ; if state . is_match () { dfa . set_matches (newsid , nnfa . iter_matches (oldsid)) ; } sparse_iter (nnfa , oldsid , & dfa . byte_classes , | byte , class , mut oldnextsid | { if oldnextsid == noncontiguous :: NFA :: FAIL { if anchored . is_anchored () { oldnextsid = noncontiguous :: NFA :: DEAD ; } else if state . fail () == noncontiguous :: NFA :: DEAD { oldnextsid = noncontiguous :: NFA :: DEAD ; } else { oldnextsid = nnfa . next_state (Anchored :: No , state . fail () , byte) ; } } dfa . trans [newsid . as_usize () + usize :: from (class)] = old2new (oldnextsid ,) ; } ,) ; }", "nnfa . states () . iter ()", "state_len . checked_shl (byte_classes . stride2 () . as_u32 ())", "self . byte_classes = yes", "sparse_iter", "\" use aho_corasick::{\"", "f . write_fmt (format_args ! (\"F {0:06}:\\n\" , sid . as_usize ())) ?", "format_args ! (\"{0:?}-{1:?} => {2:?}\" , DebugByte (start) , DebugByte (end) , next . as_usize () ,)", ":: alloc :: vec :: from_elem (DFA :: DEAD , nnfa . states () . len () ,)", "\" Set the desired match semantics.\"", "usize :: MAX", "format_args ! (\"\\n\")", "match state_len . checked_shl (byte_classes . stride2 () . as_u32 ()) { Some (trans_len) => trans_len , None => { return Err (BuildError :: state_id_overflow (StateID :: MAX . as_u64 () , usize :: MAX . as_u64 () ,) ,) ; } }", "{ let class = usize :: from (class) ; if oldnextsid == noncontiguous :: NFA :: FAIL { let oldnextsid = if state . fail () == noncontiguous :: NFA :: DEAD { noncontiguous :: NFA :: DEAD } else { nnfa . next_state (Anchored :: No , state . fail () , byte) } ; dfa . trans [unewsid . as_usize () + class] = oldnextsid ; } else { dfa . trans [unewsid . as_usize () + class] = oldnextsid ; dfa . trans [anewsid . as_usize () + class] = oldnextsid ; } }", "\" for more documentation and examples.\"", "StateID :: new_unchecked", "if start == DFA :: DEAD { Err (MatchError :: invalid_input_anchored ()) } else { Ok (start) }", "old2new (oldsid)", "if oldnextsid == noncontiguous :: NFA :: FAIL { dfa . trans [newsid . as_usize () + class] = DFA :: DEAD ; } else { dfa . trans [newsid . as_usize () + class] = oldnextsid ; }", "\" Use a [`Builder`] if you want to change the configuration.\"", "format_args ! (\"{0:?} => {1:?}\" , DebugByte (start) , next . as_usize () ,)", "dfa . trans [newsid . as_usize () + class]", "f . write_fmt (format_args ! (\"{0}\" , pid . as_usize ()))", "Err (MatchError :: invalid_input_anchored ())", "it", "\" about, since they use the actual bytes instead of equivalence classes.\"", "format_args", "(sid . as_usize () >> self . stride2) - 2", "\" great cost. The memory usage of a DFA can be quite exorbitant.\"", "nnfa . max_pattern_len ()", "for b in byte ..= 255 { let rep = b . as_u8 () ; let class = classes . get (rep) ; if prev_class != Some (class) { f (rep , class , noncontiguous :: NFA :: FAIL) ; prev_class = Some (class) ; } }", "\" welcome.\"", "\" The length of each pattern. This is used to compute the start offset\"", "\" automaton. Since using this method requires that initial construction\"", "continue", "new . max_special_id = old2new (old . max_special_id)", "\" DEAD, MATCH, ..., START-UNANCHORED, START-ANCHORED, NON-MATCH, ...\"", "\" Build an Aho-Corasick DFA from the given iterator of patterns.\"", "dfa . trans [sid ..]", "Ok (())", ":: core :: clone :: Clone :: clone", "self . noncontiguous", "if state . fail () == noncontiguous :: NFA :: DEAD { oldnextsid = noncontiguous :: NFA :: DEAD ; } else { oldnextsid = nnfa . next_state (Anchored :: No , state . fail () , byte) ; }", "\" states in the same transition table. This way, we avoid needing to\"", "& self . noncontiguous", "\" are no longer relevant.\"", "old . max_match_id", "automatically_derived", "remap_anchored [oldsid] = newsid", "& self . byte_classes", "\" When possible, prefer using [`AhoCorasick`](crate::AhoCorasick) instead of\"", "nnfa . states () . len () . checked_mul (2) . unwrap () . checked_sub (4)", "Self", "(self . pattern_lens . len () * size_of :: < SmallIndex > ())", "DFA", "format_args ! (\", \")", "nnfa . states () . len () . checked_mul (2) . unwrap ()", "byte_classes . stride2 () . as_u32 ()", "if state . is_match () { dfa . set_matches (newsid , nnfa . iter_matches (oldsid)) ; }", "if anchored . is_anchored () { oldnextsid = noncontiguous :: NFA :: DEAD ; } else if state . fail () == noncontiguous :: NFA :: DEAD { oldnextsid = noncontiguous :: NFA :: DEAD ; } else { oldnextsid = nnfa . next_state (Anchored :: No , state . fail () , byte) ; }", "self . prefilter . as_ref ()", "nnfa . states () . len () . checked_mul (2)", "StateID :: new (trans_len . checked_sub (byte_classes . stride ()) . unwrap ()) . map_err (| e | { BuildError :: state_id_overflow (StateID :: MAX . as_u64 () , e . attempted ()) }) ?", "dfa . state_len", "MatchError :: invalid_input_anchored", "F", "f . write_fmt (format_args ! (\"shortest pattern length: {0:?}\\n\" , self . min_pattern_len) ,)", "\" Sets the starting state configuration for the automaton.\"", "\" This usually permits one to just import the `DFA` type.\"", "usize", "format_args ! (\"memory usage: {0:?}\\n\" , self . memory_usage ())", "patterns", "trans_len", "if oldsid == nnfa . special () . start_unanchored_id { remap_unanchored [oldsid] = newsid ; remap_anchored [oldsid] = DFA :: DEAD ; } else { remap_unanchored [oldsid] = DFA :: DEAD ; remap_anchored [oldsid] = newsid ; is_anchored [newsid . as_usize () >> stride2] = true ; }", "if start == DFA :: DEAD { Err (MatchError :: invalid_input_unanchored ()) } else { Ok (start) }", "sid", "newsid = next_dfa_id (newsid)", "self . finish_build_one_start (Anchored :: Yes , nnfa , & mut dfa)", "f . write_fmt (format_args ! (\"shortest pattern length: {0:?}\\n\" , self . min_pattern_len) ,) ?", "\" [`AhoCorasickBuilder::ascii_case_insensitive`](crate::AhoCorasickBuilder::ascii_case_insensitive)\"", "(class . as_u8 () , self . trans [sid . as_usize () + class])", "u32 :: from", "\" This should never be enabled unless you're debugging an automaton.\"", "if prev_class != Some (class) { f (rep , class , noncontiguous :: NFA :: FAIL) ; prev_class = Some (class) ; }", "p", "nnfa . special () . max_match_id . as_usize () . checked_sub (1)", "\" support for anchored and unanchored search configurations. Namely,\"", "sid <= self . special . max_special_id", "self . special", "f . write_fmt (format_args ! (\"{0:?}-{1:?} => {2:?}\" , DebugByte (start) , DebugByte (end) , next . as_usize () ,) ,)", "nnfa", "StateID :: MAX", "next_dfa_id", "& self . min_pattern_len", "if state . is_match () { dfa . set_matches (unewsid , nnfa . iter_matches (oldsid)) ; dfa . set_matches (anewsid , nnfa . iter_matches (oldsid)) ; }", "nnfa . special () . max_match_id . as_usize () . checked_sub (1) . unwrap () . checked_mul (2)", "if anchored . is_anchored () { new . start_unanchored_id = DFA :: DEAD ; new . start_anchored_id = old2new (old . start_anchored_id) ; } else { new . start_unanchored_id = old2new (old . start_unanchored_id) ; new . start_anchored_id = DFA :: DEAD ; }", "newsid . as_usize () >> stride2", "prev_class", ":: core :: clone :: Clone :: clone (& self . matches)", "self . matches [index]", "\" Moreover, unlike the NFAs in this crate, it is costly for a DFA to\"", ":: core :: clone :: Clone :: clone (& self . byte_classes)", "size_of :: < u32 >", "self . matches . len () * size_of :: < Vec < PatternID > > ()", "StateID :: new_unchecked (index << self . stride2)", "\" It is potentially multiple orders of magnitude greater than a\"", "self . match_pattern (sid , i)", ":: core :: fmt :: Formatter :: debug_struct_field3_finish (f , \"Builder\" , \"noncontiguous\" , & self . noncontiguous , \"start_kind\" , & self . start_kind , \"byte_classes\" , & & self . byte_classes ,)", "Err (BuildError :: state_id_overflow (StateID :: MAX . as_u64 () , usize :: MAX . as_u64 () ,) ,)", "\"     automaton::Automaton,\"", "f . write_fmt (format_args ! (\"stride: {0:?}\\n\" , 1 << self . stride2))", "\" A builder for configuring an Aho-Corasick DFA.\"", "usize :: from (class)", "core :: fmt :: Result", "num_match_states", "new . max_match_id", "\" `byte_classes` settings on this builder are respected. The other\"", "1 << stride2", "impl Iterator < Item = PatternID >", "if oldsid == nnfa . special () . start_unanchored_id || oldsid == nnfa . special () . start_anchored_id { if oldsid == nnfa . special () . start_unanchored_id { remap_unanchored [oldsid] = newsid ; remap_anchored [oldsid] = DFA :: DEAD ; } else { remap_unanchored [oldsid] = DFA :: DEAD ; remap_anchored [oldsid] = newsid ; is_anchored [newsid . as_usize () >> stride2] = true ; } if state . is_match () { dfa . set_matches (newsid , nnfa . iter_matches (oldsid)) ; } sparse_iter (nnfa , oldsid , & dfa . byte_classes , | _ , class , oldnextsid | { let class = usize :: from (class) ; if oldnextsid == noncontiguous :: NFA :: FAIL { dfa . trans [newsid . as_usize () + class] = DFA :: DEAD ; } else { dfa . trans [newsid . as_usize () + class] = oldnextsid ; } } ,) ; newsid = next_dfa_id (newsid) ; } else { let unewsid = newsid ; newsid = next_dfa_id (newsid) ; let anewsid = newsid ; newsid = next_dfa_id (newsid) ; remap_unanchored [oldsid] = unewsid ; remap_anchored [oldsid] = anewsid ; is_anchored [anewsid . as_usize () >> stride2] = true ; if state . is_match () { dfa . set_matches (unewsid , nnfa . iter_matches (oldsid)) ; dfa . set_matches (anewsid , nnfa . iter_matches (oldsid)) ; } sparse_iter (nnfa , oldsid , & dfa . byte_classes , | byte , class , oldnextsid | { let class = usize :: from (class) ; if oldnextsid == noncontiguous :: NFA :: FAIL { let oldnextsid = if state . fail () == noncontiguous :: NFA :: DEAD { noncontiguous :: NFA :: DEAD } else { nnfa . next_state (Anchored :: No , state . fail () , byte) } ; dfa . trans [unewsid . as_usize () + class] = oldnextsid ; } else { dfa . trans [unewsid . as_usize () + class] = oldnextsid ; dfa . trans [anewsid . as_usize () + class] = oldnextsid ; } } ,) ; }", "sparse_iter (nnfa , oldsid , & dfa . byte_classes , | _ , class , oldnextsid | { let class = usize :: from (class) ; if oldnextsid == noncontiguous :: NFA :: FAIL { dfa . trans [newsid . as_usize () + class] = DFA :: DEAD ; } else { dfa . trans [newsid . as_usize () + class] = oldnextsid ; } } ,)", "\" a DFA will typically have better search speed than a `contiguous::NFA`, but\"", "index", "(self . trans . len () * size_of :: < u32 > ()) + (self . matches . len () * size_of :: < Vec < PatternID > > ()) + self . matches_memory_usage + (self . pattern_lens . len () * size_of :: < SmallIndex > ()) + self . prefilter . as_ref () . map_or (0 , | p | p . memory_usage ())", ":: core :: fmt :: Debug", "{ nnfa . next_state (Anchored :: No , state . fail () , byte) }", "* next = remap_unanchored [* next]", "sid == DFA :: DEAD", "new . start_anchored_id = DFA :: DEAD", "self . start_kind", "t . byte ()", "prev_class = Some (class)", "Builder :: new", "dfa . pattern_lens . shrink_to_fit ()", "! self . is_match (sid)", "\" [`AhoCorasickBuilder`](crate::AhoCorasickBuilder). Of the shared options,\"", "match self . start_kind { StartKind :: Unanchored | StartKind :: Anchored => nnfa . states () . len () , StartKind :: Both => { nnfa . states () . len () . checked_mul (2) . unwrap () . checked_sub (4) . unwrap () } }", "\" entered this state. When a search stops, it returns a match if one has\"", "dfa . trans", "\" [`AhoCorasickBuilder::byte_classes`](crate::AhoCorasickBuilder::byte_classes)\"", "Result < StateID , MatchError >", "f . write_fmt (format_args ! (\"\\n\"))", "pid", "nnfa . match_kind ()", "old2new (old . start_anchored_id)", "at_least_one = true", ":: core :: panicking :: panic_fmt (format_args ! (\"match state must have non-empty pids\") ,)", "sparse_transitions", "\" Finishes building a DFA for either unanchored or anchored searches,\"", "\" [`contiguous::NFA`](crate::nfa::contiguous::NFA) for example. In exchange,\"", "nnfa . special () . max_match_id", "\" Unless you have a small number of patterns or memory usage is not a concern\"", "byte", "\" settings only apply to the initial construction of the Aho-Corasick\"", "f . write_fmt (format_args ! (\")\\n\"))", "dfa . matches", "\" any implicitly defined transitions, the given closure is called with\"", "fmt_state_indicator (f , self , sid)", "MatchError :: invalid_input_unanchored ()", "new . start_anchored_id = remap_anchored [old . start_anchored_id]", "Err", "\" # Ok::<(), Box<dyn std::error::Error>>(())\"", "nnfa . states ()", "& dfa . byte_classes", "byte < usize :: from (t . byte ())", "f . write_fmt (format_args ! (\"memory usage: {0:?}\\n\" , self . memory_usage ()))", "\" Iterate over all possible equivalence class transitions in this state.\"", "self . matches . len ()", "class", "Builder :: default", "for (i , (start , end , next)) in sparse_transitions (it) . enumerate () { if i > 0 { f . write_fmt (format_args ! (\", \")) ? ; } if start == end { f . write_fmt (format_args ! (\"{0:?} => {1:?}\" , DebugByte (start) , next . as_usize () ,) ,) ? ; } else { f . write_fmt (format_args ! (\"{0:?}-{1:?} => {2:?}\" , DebugByte (start) , DebugByte (end) , next . as_usize () ,) ,) ? ; } }", ":: core :: clone :: Clone :: clone (& self . special)", "remap_anchored [old . max_special_id]", "sid == self . special . start_unanchored_id", "usize :: from (t . byte ())", "\" DFA.\"", "if self . byte_classes { nnfa . byte_classes () . clone () } else { ByteClasses :: singletons () }", "{ for next in dfa . trans [sid ..] [.. stride] . iter_mut () { * next = remap_unanchored [* next] ; } }", "Vec < Vec < PatternID > >", "Builder", "& self . special", "\" and unanchored searches requires a duplication of the transition table,\"", "f . write_fmt (format_args ! (\"memory usage: {0:?}\\n\" , self . memory_usage ())) ?", "\" or equal to alphabet_len. We do things this way so that we can use\"", "if ! self . is_match (sid) { :: core :: panicking :: panic (\"assertion failed: self.is_match(sid)\") }", "self . noncontiguous . build (patterns) ?", "\" Both [`DFA::new`] and [`Builder::build`] do this for you automatically, but\"", "! self . is_dead (sid)", "trans_len . checked_sub (byte_classes . stride ()) . unwrap ()", "format_args ! (\")\\n\")", "f . write_fmt (format_args ! (\"longest pattern length: {0:?}\\n\" , self . max_pattern_len) ,) ?", "Special :: zero ()", "Builder :: default ()", "{ self . finish_build_one_start (Anchored :: Yes , nnfa , & mut dfa) }", "{ StateID :: new_unchecked (oldsid . as_usize () << stride2) }", "Ok (start)", "old2new (old . max_match_id)", "state . fail () == noncontiguous :: NFA :: DEAD", "\" A DFA provides the best possible search performance (in this crate) via two\"", "\" [`Automaton::try_find`]:\"", "dfa . trans [newsid . as_usize () + class] = DFA :: DEAD", "\" Note that when this method is used, only the `start_kind` and\"", "old", "Default", "f . write_fmt (format_args ! (\"dfa::DFA(\\n\"))", "remap_anchored [oldsid]", "dfa . trans [sid ..] [.. stride]", "remap_anchored [* next]", "self . byte_classes . alphabet_len ()", "dfa", "unewsid . as_usize () + class", "self . trans . len ()", ".. stride", "{ dfa . trans [unewsid . as_usize () + class] = oldnextsid ; dfa . trans [anewsid . as_usize () + class] = oldnextsid ; }", ":: core :: clone :: Clone :: clone (& self . max_pattern_len)", "sid == self . special . start_unanchored_id || sid == self . special . start_anchored_id", "nnfa . prefilter () . cloned ()", "\" ascending order.\"", "P", "is_anchored [newsid . as_usize () >> stride2]", "if i > 0 { f . write_fmt (format_args ! (\", \")) ? ; }", "if is_anchored [i] { for next in dfa . trans [sid ..] [.. stride] . iter_mut () { * next = remap_anchored [* next] ; } } else { for next in dfa . trans [sid ..] [.. stride] . iter_mut () { * next = remap_unanchored [* next] ; } }", "match self . start_kind { StartKind :: Both => { self . finish_build_both_starts (nnfa , & mut dfa) ; } StartKind :: Unanchored => { self . finish_build_one_start (Anchored :: No , nnfa , & mut dfa) ; } StartKind :: Anchored => { self . finish_build_one_start (Anchored :: Yes , nnfa , & mut dfa) } }", ":: core :: panicking :: panic", "\" than the NFAs in this crate.\"", "format_args ! (\"longest pattern length: {0:?}\\n\" , self . max_pattern_len)", "{ ByteClasses :: singletons () }", "f . write_fmt (format_args ! (\"{0:06}: \" , sid . as_usize ()))", "new . start_unanchored_id = remap_unanchored [old . start_unanchored_id]", "DFA :: builder ()", "doc", "\" A debug setting for whether to attempt to shrink the size of the\"", "SmallIndex", "Iterator < Item = PatternID >", "nnfa . states () . len () . checked_mul (2) . unwrap () . checked_sub (4) . unwrap ()", "oldnextsid", "\" automaton's alphabet or not.\"", "\" [`Automaton`] documentation for an example.\"", "\" and search performance is critical, a DFA is usually not the best choice.\"", "\" class, even those not explicitly represented in this sparse state. For\"", "\" this type directly. Using a `DFA` directly is typically only necessary when\"", "\" assert_eq!(\"", "\" of a match.\"", "Vec < PatternID >", "inline", ":: core :: clone :: Clone :: clone (& self . alphabet_len)", "| byte , class , oldnextsid | { let class = usize :: from (class) ; if oldnextsid == noncontiguous :: NFA :: FAIL { let oldnextsid = if state . fail () == noncontiguous :: NFA :: DEAD { noncontiguous :: NFA :: DEAD } else { nnfa . next_state (Anchored :: No , state . fail () , byte) } ; dfa . trans [unewsid . as_usize () + class] = oldnextsid ; } else { dfa . trans [unewsid . as_usize () + class] = oldnextsid ; dfa . trans [anewsid . as_usize () + class] = oldnextsid ; } }", "dfa . trans [anewsid . as_usize () + class] = oldnextsid", "nnfa . special () . max_match_id . as_usize () . checked_sub (1) . unwrap ()", "\" representation, are the two most important factors in why it's faster\"", "self . matches [offset] . len ()", "old . max_special_id", "anewsid . as_usize ()", "f . write_fmt (format_args ! (\", \")) ?", "! at_least_one", "end", "e . attempted ()", "nnfa . min_pattern_len ()", "usize :: from", "(sid . as_u32 () + u32 :: from (class)) . as_usize ()", "f . write_fmt (format_args ! (\"byte classes: {0:?}\\n\" , self . byte_classes))", "format_args ! (\"pattern length: {0:?}\\n\" , self . patterns_len ())", "nnfa . special () . max_match_id . as_usize () . checked_sub (1) . unwrap () . checked_mul (2) . unwrap ()", "format_args ! (\"F {0:06}:\\n\" , sid . as_usize ())", "\"\"", "Prefilter", "nnfa . byte_classes ()", "state_len", "dfa . trans [newsid . as_usize () + usize :: from (class)]", ":: core :: clone :: Clone :: clone (& self . noncontiguous)", "Automaton", "\" Namely, disabling byte classes makes transitions easier to reason\"", "dfa . stride2", "dfa . trans [unewsid . as_usize () + class]", "{ BuildError :: state_id_overflow (StateID :: MAX . as_u64 () , e . attempted ()) }", "byte ..= 255", "match self . start_kind { StartKind :: Unanchored | StartKind :: Anchored => { nnfa . special () . max_match_id . as_usize () . checked_sub (1) . unwrap () } StartKind :: Both => { nnfa . special () . max_match_id . as_usize () . checked_sub (1) . unwrap () . checked_mul (2) . unwrap () } }", "self . matches [offset] [index]", "Special :: zero", "anchored . is_anchored ()", "[u8]", "stride", "{ remap_unanchored [oldsid] = DFA :: DEAD ; remap_anchored [oldsid] = newsid ; is_anchored [newsid . as_usize () >> stride2] = true ; }", "2", "if self . is_match (sid) { f . write_fmt (format_args ! (\" matches: \")) ? ; for i in 0 .. self . match_len (sid) { if i > 0 { f . write_fmt (format_args ! (\", \")) ? ; } let pid = self . match_pattern (sid , i) ; f . write_fmt (format_args ! (\"{0}\" , pid . as_usize ())) ? ; } f . write_fmt (format_args ! (\"\\n\")) ? ; }", "DFA :: builder () . build (patterns)", "f", "\" [`Builder::build_from_noncontiguous`] permits doing it explicitly.\"", "\" A sentinel state ID indicating that a search should stop once it has\"", "Builder { noncontiguous : :: core :: clone :: Clone :: clone (& self . noncontiguous) , start_kind : :: core :: clone :: Clone :: clone (& self . start_kind) , byte_classes : :: core :: clone :: Clone :: clone (& self . byte_classes) , }", "core :: fmt :: Debug", "format_args ! (\" matches: \")", "old . start_anchored_id", "is_anchored", "\"assertion failed: self.is_match(sid)\"", "f . write_fmt (format_args ! (\"match kind: {0:?}\\n\" , self . match_kind))", ":: core :: clone :: Clone :: clone (& self . trans)", "\" This builder has a subset of the options available to a\"", "oldsid == noncontiguous :: NFA :: DEAD", "offset", "i << stride2", "\" This only applies when using [`Builder::build`] and not\"", "0usize", "f . write_fmt (format_args ! (\"stride: {0:?}\\n\" , 1 << self . stride2)) ?", "\" let nfa = DFA::new(patterns).unwrap();\"", "self . special . max_special_id", ":: core :: clone :: Clone :: clone (& self . min_pattern_len)", "size_of :: < Vec < PatternID > > ()", "StartKind :: Unanchored", "new . start_anchored_id = old2new (old . start_anchored_id)", "& self . stride2", "0 .. self . match_len (sid)", "remap_unanchored", "None", "class . as_u8 ()", "noncontiguous :: Builder :: new", "& & self . byte_classes", "old2new (oldnextsid ,)", "& self . match_kind", "next", "| byte , class , mut oldnextsid | { if oldnextsid == noncontiguous :: NFA :: FAIL { if anchored . is_anchored () { oldnextsid = noncontiguous :: NFA :: DEAD ; } else if state . fail () == noncontiguous :: NFA :: DEAD { oldnextsid = noncontiguous :: NFA :: DEAD ; } else { oldnextsid = nnfa . next_state (Anchored :: No , state . fail () , byte) ; } } dfa . trans [newsid . as_usize () + usize :: from (class)] = old2new (oldnextsid ,) ; }", "\" [`Builder::build_from_noncontiguous`].\"", "state", "Some (class)", "\" identifier 'sid', its state index is 'sid >> stride2'.\"", "DFA :: builder", "format_args ! (\"byte classes: {0:?}\\n\" , self . byte_classes)", "StateID :: new_unchecked (oldsid . as_usize () << stride2)", "1", "dfa . trans [newsid . as_usize () + usize :: from (class)] = old2new (oldnextsid ,)", "& nnfa", "\" at this ID.\"", "\" DFA. Note that the actual number of transitions in each state is\"", "StateID :: new", "nnfa . iter_matches (oldsid)", "oldnextsid == noncontiguous :: NFA :: FAIL", "dfa . set_matches (anewsid , nnfa . iter_matches (oldsid))", "\" N.B. DFAs, unlike NFAs, do not have any notion of a FAIL state.\"", ":: core :: panicking :: panic_fmt", "for i in 0 .. self . match_len (sid) { if i > 0 { f . write_fmt (format_args ! (\", \")) ? ; } let pid = self . match_pattern (sid , i) ; f . write_fmt (format_args ! (\"{0}\" , pid . as_usize ())) ? ; }", "nnfa . next_state (Anchored :: No , state . fail () , byte)", "\" Disabling this confers no performance benefit at search time.\"", "size_of :: < u32 > ()", "format_args ! (\"match state must have non-empty pids\")", "false", "StartKind :: Anchored", "nnfa . special () . max_match_id . as_usize ()", "rep", "& self . trans", "self . pattern_lens", "\" bitshifting to go from a state ID to an index into 'matches'.\"", "\" stride=2^stride2, where stride is the smallest power of 2 greater than\"", "noncontiguous :: NFA :: DEAD", ":: core :: clone :: Clone", "(0 .. self . byte_classes . alphabet_len ())", "\" Adds the given pattern IDs as matches to the given state and also\"", "\" ```\"", "Vec < StateID >", ":: core :: clone :: Clone :: clone (& self . stride2)", "MatchError :: invalid_input_anchored ()", "self . finish_build_one_start (Anchored :: No , nnfa , & mut dfa)", "\" let haystack = \\\"abcd\\\";\"", "! self . is_dead (sid) && sid <= self . special . max_match_id", "\" A prefilter for accelerating searches, if one exists.\"", "| oldsid : StateID | { StateID :: new_unchecked (oldsid . as_usize () << stride2) }", "new . max_match_id = remap_anchored [old . max_match_id]", "true", "| p | p . memory_usage ()", "& mut Builder", "sid . as_usize () + stride", "self . match_kind", "self . special . start_anchored_id", "self . pattern_lens . len () * size_of :: < SmallIndex > ()", ":: core :: clone :: Clone :: clone (& self . prefilter)", "new . max_special_id = remap_anchored [old . max_special_id]", "Result < DFA , BuildError >", "Special", "index << self . stride2", "f . write_fmt (format_args ! (\"\\n\")) ?", "f . write_fmt (format_args ! (\"alphabet length: {0:?}\\n\" , self . alphabet_len))", "(sid . as_usize () >> self . stride2) . checked_sub (2)", "{ nnfa . states () . len () . checked_mul (2) . unwrap () . checked_sub (4) . unwrap () }", "\" searches. It works by inter-leaving unanchored states with anchored\"", "| sid : StateID | StateID :: new_unchecked (sid . as_usize () + stride ,)", "oldsid == nnfa . special () . start_anchored_id", "\" Enable heuristic prefilter optimizations.\"", "StateID :: MAX . as_u64 ()", "FnMut (u8 , u8 , StateID)", "\" been found, otherwise no match. A DFA always has an actual dead state\"", "self . noncontiguous . ascii_case_insensitive (yes)", "i > 0", "0", ":: core :: fmt :: Result", "new . start_unanchored_id = old2new (old . start_unanchored_id)", ":: alloc :: vec :: from_elem", "for (oldsid , state) in nnfa . states () . iter () . with_state_ids () { if oldsid == noncontiguous :: NFA :: DEAD || oldsid == noncontiguous :: NFA :: FAIL { remap_unanchored [oldsid] = newsid ; remap_anchored [oldsid] = newsid ; newsid = next_dfa_id (newsid) ; } else if oldsid == nnfa . special () . start_unanchored_id || oldsid == nnfa . special () . start_anchored_id { if oldsid == nnfa . special () . start_unanchored_id { remap_unanchored [oldsid] = newsid ; remap_anchored [oldsid] = DFA :: DEAD ; } else { remap_unanchored [oldsid] = DFA :: DEAD ; remap_anchored [oldsid] = newsid ; is_anchored [newsid . as_usize () >> stride2] = true ; } if state . is_match () { dfa . set_matches (newsid , nnfa . iter_matches (oldsid)) ; } sparse_iter (nnfa , oldsid , & dfa . byte_classes , | _ , class , oldnextsid | { let class = usize :: from (class) ; if oldnextsid == noncontiguous :: NFA :: FAIL { dfa . trans [newsid . as_usize () + class] = DFA :: DEAD ; } else { dfa . trans [newsid . as_usize () + class] = oldnextsid ; } } ,) ; newsid = next_dfa_id (newsid) ; } else { let unewsid = newsid ; newsid = next_dfa_id (newsid) ; let anewsid = newsid ; newsid = next_dfa_id (newsid) ; remap_unanchored [oldsid] = unewsid ; remap_anchored [oldsid] = anewsid ; is_anchored [anewsid . as_usize () >> stride2] = true ; if state . is_match () { dfa . set_matches (unewsid , nnfa . iter_matches (oldsid)) ; dfa . set_matches (anewsid , nnfa . iter_matches (oldsid)) ; } sparse_iter (nnfa , oldsid , & dfa . byte_classes , | byte , class , oldnextsid | { let class = usize :: from (class) ; if oldnextsid == noncontiguous :: NFA :: FAIL { let oldnextsid = if state . fail () == noncontiguous :: NFA :: DEAD { noncontiguous :: NFA :: DEAD } else { nnfa . next_state (Anchored :: No , state . fail () , byte) } ; dfa . trans [unewsid . as_usize () + class] = oldnextsid ; } else { dfa . trans [unewsid . as_usize () + class] = oldnextsid ; dfa . trans [anewsid . as_usize () + class] = oldnextsid ; } } ,) ; } }", "\" * All states use a dense representation for their transitions.\"", "MatchError :: invalid_input_unanchored", "\"     dfa::DFA,\"", "noncontiguous :: Builder :: new ()", "self . stride2", "self . min_pattern_len", "for pid in pids { self . matches [index] . push (pid) ; self . matches_memory_usage += PatternID :: SIZE ; at_least_one = true ; }", "sid . as_u32 ()", "\" The matches for every match state in this DFA. This is first indexed by\"", "self . trans . len () * size_of :: < u32 > ()", "\"Builder\"", "byte_classes", "* next = remap_anchored [* next]", "0 .. self . state_len", "noncontiguous :: Builder", "StartKind :: Both", "oldnextsid = noncontiguous :: NFA :: DEAD", "Vec < SmallIndex >", "at_least_one", "\" [`AhoCorasickBuilder::start_kind`](crate::AhoCorasickBuilder::start_kind)\"", "255", "f . write_fmt (format_args ! (\"prefilter: {0:?}\\n\" , self . prefilter . is_some ()))"}
  [split-expanded-lib] DeclsVisitor: Visiting module 'nfa'. Required imports for module: {"[StateID]", "state [2] = old_to_new [state [2] . as_usize ()] . as_u32 ()", "self . sparse [p] . link", "\" information is useful for keeping correct buffer sizes when searching\"", "\" dead, match or start with just a few comparisons on the ID itself:\"", "state [2 ..] [.. alphabet_len] . iter_mut ()", "fmt_state_indicator", "state [State :: KIND] & 0xFF", "if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: None ,) ; }", "& mut :: core :: fmt :: Formatter", "\" the only time a `State` is actually constructed is in `Debug` impls.)\"", "\" table. The ID return corresponds to the index at which the `N`\"", "self . nfa . pattern_lens . len ()", "\" This is only necessary when ASCII case insensitivity is enabled, since\"", "\" given.\"", "State { sparse : :: core :: clone :: Clone :: clone (& self . sparse) , dense : :: core :: clone :: Clone :: clone (& self . dense) , matches : :: core :: clone :: Clone :: clone (& self . matches) , fail : :: core :: clone :: Clone :: clone (& self . fail) , depth : :: core :: clone :: Clone :: clone (& self . depth) , }", "format_args ! (\"match kind: {0:?}\\n\" , self . match_kind)", "31", "\" since comparisons with FAIL occur in perf critical parts of the search,\"", "prev . map_or (self . states [sid] . sparse , | p | self . sparse [p] . link)", "\" Building failure transitions is the most interesting part of building\"", "while let Some (id) = queue . pop_front () { let mut prev_link = None ; while let Some (link) = self . nfa . next_link (id , prev_link) { prev_link = Some (link) ; let t = self . nfa . sparse [link] ; if seen . contains (t . next) { continue ; } queue . push_back (t . next) ; seen . insert (t . next) ; if is_leftmost && self . nfa . states [t . next] . is_match () { self . nfa . states [t . next] . fail = NFA :: DEAD ; continue ; } let mut fail = self . nfa . states [id] . fail ; while self . nfa . follow_transition (fail , t . byte) == NFA :: FAIL { fail = self . nfa . states [fail] . fail ; } fail = self . nfa . follow_transition (fail , t . byte) ; self . nfa . states [t . next] . fail = fail ; self . nfa . copy_matches (fail , t . next) ? ; } if ! is_leftmost { self . nfa . copy_matches (self . nfa . special . start_unanchored_id , id) ? ; } }", "\" is follow the transitions in the trie by consuming one transition for\"", "u32tosid (repr [trans_offset + i * 4 + 2])", "classes_len", "self . builder . prefilter", "\" (This is the same technique used for fully compiled DFAs in\"", "self . noncontiguous . ascii_case_insensitive (yes)", "if link_dst == StateID :: ZERO { self . states [dst] . matches = new_match_link ; } else { self . matches [link_dst] . link = new_match_link ; }", "Some (t)", "\" failure transition for S3, you already know the failure transitions\"", "state [1] = old_to_new [state [1] . as_usize ()] . as_u32 ()", "\"     nfa::noncontiguous::NFA,\"", "& self . state_len", "& mut self . nfa", "\" be performed in linear time. Specifically, a failure transition is\"", "\" state to terminate, namely, finding the next state should never return\"", "\" information is useful for detecting whether an automaton matches the\"", "\" when a match state can be reached via a failure transition. In which\"", "\" for states that are densified. It could be done, but actually removing\"", "self . nfa . states [id]", "QueuedSet { set : Some (BTreeSet :: new ()) , }", "self . nfa . states [id] . fail", "trans_offset + i * 4 + 1", "self . sparse [new_link] = Transition { byte , next , link : StateID :: ZERO , }", ":: core :: fmt :: Formatter :: debug_struct_field3_finish (f , \"Builder\" , \"noncontiguous\" , & self . noncontiguous , \"dense_depth\" , & self . dense_depth , \"byte_classes\" , & & self . byte_classes ,)", "\" to the FAIL state.\"", "\" A builder for configuring an Aho-Corasick contiguous NFA.\"", "\" match at any position. This is also required for finding the next\"", "old_len == 1", "\" Create a new builder for configuring an Aho-Corasick contiguous NFA.\"", "\" textbook formulation of the Aho-Corasick algorithm, with a couple small\"", "{ None }", "(ulink , alink)", "\" Disabling this confers no performance benefit at search time.\"", "u32tosid (repr [trans_offset + i * 4 + 3])", "dst . extend (core :: iter :: repeat (noncontiguous :: NFA :: FAIL . as_u32 ()) . take (classes . alphabet_len ()) ,)", "! self . is_dead (sid) && sid <= self . special . max_match_id", "f . write_fmt (format_args ! (\"\\n\"))", "break", "self . dense [start ..] [.. alphabet_len] . iter_mut ()", "& mut Self", "& mut Builder", "self . nfa . special . start_unanchored_id = new_start_uid", "self . nfa . byte_classes . get (b)", "index_to_state_id", ".. alphabet_len", "\" 'KIND' above. Namely, a sparse state embeds the number of transitions\"", "state [2 + classes_len ..] [.. trans_len] . iter_mut ()", "core :: iter :: repeat (noncontiguous :: NFA :: FAIL . as_u32 ())", "\" A set of states. Each state defines its own transitions, a fail\"", "packed", "loop { let unext = self . nfa . next_link (start_uid , uprev_link) ; let anext = self . nfa . next_link (start_aid , aprev_link) ; let (ulink , alink) = match (unext , anext) { (Some (ulink) , Some (alink)) => (ulink , alink) , (None , None) => break , _ => { :: core :: panicking :: panic (\"internal error: entered unreachable code\" ,) } } ; uprev_link = Some (ulink) ; aprev_link = Some (alink) ; self . nfa . sparse [alink] . next = self . nfa . sparse [ulink] . next ; }", "\" The underlying representation of sparse or dense transitions for a state.\"", "{ StateTrans :: Dense { class_to_next : :: core :: clone :: Clone :: clone (__self_0) , } }", "\" transition in the same state (or `StateID::ZERO` if it is the last\"", "self . min_pattern_len", "self . nfa . next_link (start_aid , aprev_link)", "nfa . pattern_lens", "dst . push (kind)", "\" (containing the format of the state, the failure transition and, for\"", "repr [trans_offset + i * 4 + 1]", "i > 0", "\" achieved by explicitly setting every transition to the FAIL state.\"", "\" anyway. In the former case, making them dense is fine because they're\"", "class", "\" state IDs depend on how much space has already been used in the\"", "\" The total number of states in this NFA.\"", "self . nfa . special . max_match_id = self . nfa . special . start_anchored_id", "old . max_special_id", "\" otherwise.\"", "self . nfa . states [t . next] . fail = fail", "\" This tends to best balance between memory usage and performance. In\"", "fail", "& self . min_pattern_len", "\" start state. This effectively permits the Aho-Corasick automaton to\"", "StateID :: new (self . sparse . len ()) . map_err (| e | { BuildError :: state_id_overflow (StateID :: MAX . as_u64 () , e . attempted () ,) })", "self . nfa . sparse [link]", "self . densify () ?", "\" A debug setting for whether to attempt to shrink the size of the\"", "StateID :: new (i) . unwrap ()", "dst [start + usize :: from (classes . get (t . byte ()))] = t . next () . as_u32 ()", "if i >= class_to_next . len () { return None ; }", "self . nfa . sparse [link] . next ()", "chunk [len] = classes . get (t . byte ())", "Option < BTreeSet < StateID > >", "impl Fn (StateID) -> StateID", ":: core :: fmt :: Result", "\" A sparse representation of transitions for a state, where only non-FAIL\"", ":: core :: clone :: Clone :: clone (& self . max_pattern_len)", "| p | p . memory_usage ()", "\" The reason for this is that under leftmost semantics, a start state\"", "f . write_fmt (format_args ! (\"match kind: {0:?}\\n\" , self . match_kind))", "Anchored :: Yes", "f . write_fmt (format_args ! (\"shortest pattern length: {0:?}\\n\" , self . min_pattern_len ,) ,)", "Match :: default", "\" unanchored standard search to enter a DEAD state. But an anchored\"", "force_dense || old_len > State :: MAX_SPARSE_TRANSITIONS", "NFA { repr : :: core :: clone :: Clone :: clone (& self . repr) , pattern_lens : :: core :: clone :: Clone :: clone (& self . pattern_lens) , state_len : :: core :: clone :: Clone :: clone (& self . state_len) , prefilter : :: core :: clone :: Clone :: clone (& self . prefilter) , match_kind : :: core :: clone :: Clone :: clone (& self . match_kind) , alphabet_len : :: core :: clone :: Clone :: clone (& self . alphabet_len) , byte_classes : :: core :: clone :: Clone :: clone (& self . byte_classes) , min_pattern_len : :: core :: clone :: Clone :: clone (& self . min_pattern_len) , max_pattern_len : :: core :: clone :: Clone :: clone (& self . max_pattern_len) , special : :: core :: clone :: Clone :: clone (& self . special) , }", "len", "self . sparse [link_prev] . link", "\" the Aho-Corasick automaton, because they are what allow searches to\"", "& self . max_pattern_len", "\" a 'c' byte, so we don't need to re-scan it. We can then pick back up\"", "new_start_uid", "\" NFA is 2^24-1.\"", "NFA", "\" as there is a transition from S5 to S6 for the byte 'c'. If no such\"", "Vec < StateID >", "\" The number of entries in this vector corresponds to the total number of\"", "m", "if self . builder . match_kind . is_leftmost_first () && saw_match { continue 'PATTERNS ; }", "start_uid == t . next ()", "state . fail", "StateID :: new (i)", "dense", "return u32tosid (repr [trans_offset + i * 4])", ":: core :: clone :: Clone :: clone (__self_0)", "\" For example, when determining the failure state for S3, by our\"", "& (pid & (1 << 31))", "newsid . as_usize ()", "set", "\" into the 'KIND'. Basically, \\\"sparse\\\" is a state kind too, but it's the\"", "opposite_ascii_case", "old_to_new [state [1] . as_usize ()]", "\" rare.\"", "\" observng the 'c' byte. At this point, the next byte is 'e' but state\"", "\" The length, in bytes, of the shortest pattern in this automaton. This\"", "old . start_unanchored_id", "IntoIterator < Item = P >", ":: core :: clone :: Clone :: clone (& self . match_kind)", "Match", "self . states [src]", "StateID :: from_u32_unchecked", "\" FAIL state.\"", "remap", "self . sparse [head] . byte", "for byte in 0 ..= 255 { let new_link = self . alloc_transition () ? ; self . sparse [new_link] = Transition { byte , next , link : StateID :: ZERO , } ; if prev_link == StateID :: ZERO { self . states [prev] . sparse = new_link ; } else { self . sparse [prev_link] . link = new_link ; } prev_link = new_link ; }", "(& byte , & self . sparse [link_next] . byte)", "\" Note that `N` is equal to `NFA::byte_classes::alphabet_len()`. This is\"", "{ let trans_len = State :: sparse_trans_len (state) ; let classes_len = u32_len (trans_len) ; (classes_len , trans_len) }", "if State :: kind (state) == State :: KIND_DENSE { let start = 2 + alphabet_len ; state [start] . as_usize () } else { let trans_len = State :: sparse_trans_len (state) ; let classes_len = u32_len (trans_len) ; let start = 2 + classes_len + trans_len ; state [start] . as_usize () }", "return u32tosid (repr [o + 2])", "PatternID :: new (i) . map_err (| e | { BuildError :: pattern_id_overflow (PatternID :: MAX . as_u64 () , e . attempted () ,) })", "core :: fmt :: Debug", "self . follow_transition_sparse (sid , byte)", "if ! is_leftmost { self . nfa . copy_matches (self . nfa . special . start_unanchored_id , id) ? ; }", "(unext , anext)", "if self . builder . ascii_case_insensitive { let b = opposite_ascii_case (b) ; self . byteset . set_range (b , b) ; }", "new . start_unanchored_id = remap [old . start_unanchored_id]", "\" Create a new Aho-Corasick contiguous NFA using the default\"", "t . link", "self . builder . dense_depth", "\" can be reconstructed from the `Automaton` API if necessary.\"", "\" Create a new Aho-Corasick noncontiguous NFA using the default\"", "StateID :: new (next_avail . as_usize () . checked_sub (3) . unwrap () ,)", "if self . nfa . sparse [link] . next () == NFA :: FAIL { self . nfa . sparse [link] . next = start_uid ; }", "next_avail . as_usize () . checked_sub (1)", "state . dense . as_usize ()", "core :: iter :: from_fn", "self . dense . len ()", "\" Create a new builder for configuring an Aho-Corasick noncontiguous NFA.\"", "self . nfa . alloc_state (0)", "\" point of the dead state is to act as a sink that can never be escaped.\"", "{ match (& 0 , & index) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: None ,) ; } } } ; packed & ! (1 << 31) }", "self . pattern_lens [pid]", "for next in self . dense [start ..] [.. alphabet_len] . iter_mut () { * next = map (* next) ; }", "\" will return an error. Often, since building a contiguous NFA is relatively\"", "(0 , 1)", "self . nfa . states [t . next]", "\" at specific points in order to report the correct match location. In\"", "& self . builder", "ntrans % 4", "0 ..= 255", "State :: kind", "\" where `n ~ len(subject)` and `m ~ len(all patterns)`. We would instead\"", "if kind == State :: KIND_DENSE { (0 , alphabet_len) } else if kind == State :: KIND_ONE { (0 , 1) } else { let trans_len = State :: sparse_trans_len (state) ; let classes_len = u32_len (trans_len) ; (classes_len , trans_len) }", "\" Attempts to convert the transition representation of a subset of states\"", "\" This NFA represents the \\\"core\\\" implementation of Aho-Corasick in this\"", "self . states . iter () . with_state_ids ()", "for (i , & chunk) in repr [o + 2 ..] [.. classes_len] . iter () . enumerate () { let classes = chunk . to_ne_bytes () ; if classes [0] == class { return u32tosid (repr [trans_offset + i * 4]) ; } if classes [1] == class { return u32tosid (repr [trans_offset + i * 4 + 1]) ; } if classes [2] == class { return u32tosid (repr [trans_offset + i * 4 + 2]) ; } if classes [3] == class { return u32tosid (repr [trans_offset + i * 4 + 3]) ; } }", "p . memory_usage ()", "StateID :: new_unchecked (0)", "nnfa", "PatternID :: new (i) . map_err (| e | { BuildError :: pattern_id_overflow (PatternID :: MAX . as_u64 () , e . attempted () ,) }) ?", "& [StateID]", "self . nfa . alloc_state (depth) ?", "state [2 + classes_len ..]", "\" state without borrowing the NFA. This permits mutating other parts of\"", "StateID :: new (self . dense . len ()) . map_err (| e | { BuildError :: state_id_overflow (StateID :: MAX . as_u64 () , e . attempted () ,) }) ?", "\" This is `StateID::ZERO` if and only if this state has zero transitions.\"", "prev_link = Some (link)", "for i in next_avail . as_usize () .. self . nfa . states . len () { let sid = StateID :: new (i) . unwrap () ; if ! self . nfa . states [sid] . is_match () { continue ; } remapper . swap (& mut self . nfa , sid , next_avail) ; next_avail = StateID :: new (next_avail . one_more ()) . unwrap () ; }", "\"       /       /\"", "prefilter :: Builder :: new (builder . match_kind)", "self . iter_matches (sid)", "fmt_state_indicator (f , self , sid)", "(StateTrans :: Sparse { classes , nexts , } , fail ,)", "self . nfa . byte_classes", "BuildError", "u32tosid (repr [o + 2])", "\" Return the ID of the state that this transition points to.\"", "\" we've seen so far. Recall that we've seen 'abc' in the subject string,\"", "\"       /         /         /\"", "core :: cmp :: max (self . nfa . max_pattern_len , pat . len () ,)", "f . write_fmt (format_args ! (\"state length: {0:?}\\n\" , self . state_len)) ?", "sid = self . states [sid] . fail ()", "\" A sentinel state ID indicating that a search should stop once it has\"", "while let Some (link) = self . nfa . next_link (id , prev_link) { prev_link = Some (link) ; let t = self . nfa . sparse [link] ; if seen . contains (t . next) { continue ; } queue . push_back (t . next) ; seen . insert (t . next) ; if is_leftmost && self . nfa . states [t . next] . is_match () { self . nfa . states [t . next] . fail = NFA :: DEAD ; continue ; } let mut fail = self . nfa . states [id] . fail ; while self . nfa . follow_transition (fail , t . byte) == NFA :: FAIL { fail = self . nfa . states [fail] . fail ; } fail = self . nfa . follow_transition (fail , t . byte) ; self . nfa . states [t . next] . fail = fail ; self . nfa . copy_matches (fail , t . next) ? ; }", "next_avail . as_usize () . checked_sub (3) . unwrap ()", "\" the start state. In the latter case, they are probably dense already\"", "\" transitions are explicitly represented, including transitions to the\"", "format_args ! (\"state length: {0:?}\\n\" , self . states . len ())", "self . states [prev]", "{ BuildError :: pattern_id_overflow (PatternID :: MAX . as_u64 () , e . attempted () ,) }", "doc", "BuildError :: pattern_too_long", "format_args ! (\"state length: {0:?}\\n\" , self . state_len)", "remap [old . start_unanchored_id]", "classes [i / 4]", "& self . states [sid]", "\" The first transition for each state is determined by `State::sparse`.\"", "StateID :: from_u32_unchecked (state [1])", "right_val", "Ok (sid)", "\" the NFA during iteration. Namely, one can access the transition pointed\"", "it", "f . write_fmt (format_args ! (\"prefilter: {0:?}\\n\" , self . prefilter . is_some ()) ,)", "self . sparse . len ()", "\" The maximum number of transitions to encode as a sparse state. Usually\"", "kind | (class << 8)", "\" Transitions stored in a dense representation.\"", "\" A dense set of transitions to other states. The transitions may\"", "Special :: zero", "match (& i , & self . nfa . pattern_lens . len ()) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! (\"expected number of patterns to match pattern ID\" ,) ,) ,) ; } } }", "trans_offset", "Some ((class , next))", "\" A convenience method for returning a new Aho-Corasick noncontiguous NFA\"", "\" A pointer to `NFA::trans` corresponding to the head of a linked list\"", "StateTrans :: Sparse", "link = t . link", "o + 2 + classes_len", "\" doing the next state lookup. In this way, FAIL is more of a sentinel\"", "start", "& mut [u32]", "u32 :: try_from (old_len)", "state . dense", "\" state to the starting state. (For the special sentinel states DEAD and\"", "old_start_aid", "noncontiguous :: NFA", "oldsid", "return NFA :: DEAD", "\" Allocate and add a fresh state to the underlying NFA and return its\"", "self . matches . len () * core :: mem :: size_of :: < Match > ()", "self . nfa . alloc_state (0) ?", "remap [old . max_match_id]", "StateID :: new_unchecked (1)", "self . nfa . states [fail]", "& noncontiguous :: State", "for (oldsid , state) in nnfa . states () . iter () . with_state_ids () { if oldsid == noncontiguous :: NFA :: FAIL { index_to_state_id [oldsid] = NFA :: FAIL ; continue ; } let force_dense = state . depth () . as_usize () < self . dense_depth ; let newsid = State :: write (nnfa , oldsid , state , & nfa . byte_classes , & mut nfa . repr , force_dense ,) ? ; index_to_state_id [oldsid] = newsid ; }", "2 + classes_len + trans_len", "\" longer be created for new states. Otherwise, it returns the state ID of\"", ":: core :: panicking :: panic_fmt", "link_prev", "& byte", "StateTrans < 'a >", "\" because failure transitions always point back to a proper suffix of\"", "impl Iterator < Item = (u8 , StateID) > + '_", "\" The first state is always the fail state, which is used only as a\"", "& self . noncontiguous", "State :: match_len (self . alphabet_len , & self . repr [sid . as_usize () ..])", "\" transition, and the high 24 bits correspond to the next state ID.\"", "format_args ! (\"alphabet length: {0:?}\\n\" , self . alphabet_len)", "f . write_fmt (format_args ! (\"noncontiguous::NFA(\\n\"))", "PatternID", "format_args ! (\"         matches: \")", "link = m . link", "\" longest semantics, but they do it by building a queue of matches at\"", "\" when one needs access to the [`Automaton`] trait implementation.\"", "\" may extend past the end of the encoding of the state.)\"", "\" returns an inert set that nevers adds anything and always reports\"", "\" performance since states with a higher number of transitions tend to\"", "\" binary sparse representation to the given `dst` slice. `classes` should\"", "\" S2 (the previous state) to S5. So we follow that transition and check\"", "self . nfa . states [start_aid] . fail = NFA :: DEAD", "self . sparse [link] = Transition { byte , next , link : link_next , }", "format_args ! (\"noncontiguous::NFA(\\n\")", "\" longer be created for new states.\"", "\" We generally only densify states that are close to the start state.\"", "t . next", "self . nfa . next_link (id , prev_link)", "Builder :: default", "f . write_fmt (format_args ! (\"{0:06}({1:06}): \" , sid . as_usize () , state . fail . as_usize () ,) ,) ?", "trans_offset + i * 4", "\" of the sentinel values below, then it's a sparse state and the kind\"", "next_avail . as_usize () . checked_sub (2) . unwrap ()", "\" each byte in the subject string. If we reach a match state, then we can\"", "link_next == StateID :: ZERO", "\"    is_fail(sid): sid == NFA::FAIL\"", "\" This must be done after building the initial trie, since trie\"", "& index_to_state_id", "self . nfa . add_transition (prev , b , next)", "m . pid", "\"\\nProvides a contiguous NFA implementation of Aho-Corasick.\\n\\nThis is a low-level API that generally only needs to be used in niche\\ncircumstances. When possible, prefer using [`AhoCorasick`](crate::AhoCorasick)\\ninstead of a contiguous NFA directly. Using an `NFA` directly is typically only\\nnecessary when one needs access to the [`Automaton`] trait implementation.\\n\"", "\" binary dense representation to the given `dst` slice. `classes` should\"", "\" The length, in bytes, of the longest pattern in this automaton. This\"", "for next in state [2 + classes_len ..] [.. trans_len] . iter_mut () { * next = old_to_new [next . as_usize ()] . as_u32 () ; }", "s . dense . as_usize () + class", "\" Return an inert set that returns `false` for every state ID membership\"", "self . nfa . special", "noncontiguous :: Builder :: new", "StateID :: new (sid . as_usize () . checked_add (len) . unwrap ()) . unwrap ()", "f . write_fmt (format_args ! (\", \")) ?", "self . nfa . states [self . nfa . special . start_anchored_id] . is_match ()", "byte == t . byte", "{ 1 + State :: match_len (alphabet_len , state) }", "\" Set the failure transitions on the start state to loop back to the\"", "\" ```ignore\"", "map (state . fail)", "Ok (nfa)", "dst . push (old . fail () . as_u32 ())", "{ StateTrans :: One { class : :: core :: clone :: Clone :: clone (__self_0) , next : :: core :: clone :: Clone :: clone (__self_1) , } }", "self . dense . len () * StateID :: SIZE", "while let Some (link) = self . nfa . next_link (start_uid , prev_link) { prev_link = Some (link) ; if self . nfa . sparse [link] . next () == start_uid { self . nfa . sparse [link] . next = NFA :: DEAD ; if dense != StateID :: ZERO { let b = self . nfa . sparse [link] . byte ; let class = usize :: from (self . nfa . byte_classes . get (b)) ; self . nfa . dense [dense . as_usize () + class] = NFA :: DEAD ; } } }", "SmallIndex :: new (depth) . expect (\"patterns longer than SmallIndex::MAX are not allowed\")", "self . states . push (State { sparse : StateID :: ZERO , dense : StateID :: ZERO , matches : StateID :: ZERO , fail : self . special . start_unanchored_id , depth , })", "\" particular, the *vast majority* of all states in a typical Aho-Corasick\"", "& state [2 + classes_len ..] [.. trans_len]", "new . max_special_id", "remapper", "i += 1", "\" # Ok::<(), Box<dyn std::error::Error>>(())\"", "BTreeSet :: new", "format_args ! (\"longest pattern length: {0:?}\\n\" , self . max_pattern_len)", "\" permits an optimization where states near the starting state have their\"", "f . write_fmt (format_args ! (\"         matches: \"))", "fail = self . nfa . states [fail] . fail", "\" filling in the failure transitions between states, similar to what is\"", "state [State :: KIND] . low_u16 () . high_u8 ()", "\" automaton's alphabet or not.\"", "\" A builder for configuring an Aho-Corasick noncontiguous NFA.\"", "old . fail ()", "\" A prefilter for quickly skipping to candidate matches, if pertinent.\"", "self . link", "self . nfa . sparse", "\" effect, this makes the algorithm have worst case `O(n * m)` complexity,\"", "if classes [2] == class { return u32tosid (repr [trans_offset + i * 4 + 2]) ; }", "len += 1", "\" When this is zero (which is true for most states in the default\"", "saw_match", "prev", "\" automatically chosen based on the old state.\"", "self . sparse [link_next] . link", "\" searching.\"", "self . nfa . alloc_state (depth)", "start_aid", "old_len", "\"internal error: entered unreachable code\"", "f . write_fmt (format_args ! (\", \"))", "\" matching pattern IDs for match states.\"", "State :: match_len (alphabet_len , state)", "\"         /\"", "(class , next)", "\" transition existed, we could keep following the failure transitions\"", "automatically_derived", "for i in 0 .. self . nfa . states . len () { let sid = StateID :: new (i) . unwrap () ; if sid == NFA :: DEAD || sid == NFA :: FAIL { continue ; } if self . nfa . states [sid] . depth . as_usize () >= self . builder . dense_depth { continue ; } let dense = self . nfa . alloc_dense_state () ? ; let mut prev_link = None ; while let Some (link) = self . nfa . next_link (sid , prev_link) { prev_link = Some (link) ; let t = self . nfa . sparse [link] ; let class = usize :: from (self . nfa . byte_classes . get (t . byte)) ; let index = dense . as_usize () + class ; self . nfa . dense [index] = t . next ; } self . nfa . states [sid] . dense = dense ; }", "\" Set the transition for the given byte to the state ID given.\"", "* right_val", "s . dense == StateID :: ZERO", "self . nfa . min_pattern_len = core :: cmp :: min (self . nfa . min_pattern_len , pat . len () ,)", "usize :: MAX", "self . build_from_noncontiguous (& nnfa)", "remapper . swap (& mut self . nfa , old_start_uid , new_start_uid)", "map (* next)", "\" state, which could be made a constant but is a little trickier to do.\"", "prev_link == StateID :: ZERO", "\" we want it to be as tight as possible and not waste any registers.\"", "self . sparse [prev_link] . link = new_link", "\" 'abcd', 'b', 'bcd' and 'cd':\"", "if sid == NFA :: FAIL { f . write_fmt (format_args ! (\"F {0:06}:\\n\" , sid . as_usize ())) ? ; continue ; }", "& & self . depth", "state [State :: KIND] . low_u16 ()", "size_of :: < SmallIndex > ()", "noncontiguous :: Builder", "self . sparse [new_link] = Transition { byte , next , link : head , }", "\" formulation described in textbooks, with some tweaks to support leftmost\"", "\" Create a new set of `N` transitions in this NFA's dense transition\"", "f . write_fmt (format_args ! (\"prefilter: {0:?}\\n\" , self . prefilter . is_some ()) ,) ?", "self . states [sid]", "\" This requires that the state has no transitions added to it already.\"", "format_args", "\" transition is followed whenever there exists no transition on the\"", "Some (BTreeSet :: new ())", "format_args ! (\"{0}\" , pid . as_usize ())", "dst . push (kind | (class << 8))", "self . repr . len () * size_of :: < u32 > ()", "SmallIndex :: new (pat . len ()) . map_err (| _ | BuildError :: pattern_too_long (pid , pat . len ())) ?", "8", "\" We don't actually use recursion to implement this, but instead, use a\"", "f . write_fmt (format_args ! (\"{0:?}-{1:?} => {2:?}\" , DebugByte (start) , DebugByte (end) , sid . as_usize () ,) ,)", "StateID :: new (self . states . len ())", "& self . fail", "\" A sentinel value indicating that the state uses a special \\\"one\"", "\" regex-automata.)\"", "\"byte_classes\"", "\" state). If the ID would overflow `StateID`, then this returns an error.\"", "self . dense . extend (core :: iter :: repeat (NFA :: FAIL) . take (self . byte_classes . alphabet_len ()) ,)", "None", "255", "repr [o]", "self . nfa . sparse [alink]", "{ ByteClasses :: singletons () }", "| pid | pid . as_u32 ()", "self . nfa . add_match (prev , pid) ?", "\" make the unanchored starting state dense, and thus in turn make\"", "StateID :: SIZE", "self . nfa . states [t . next] . fail = NFA :: DEAD", "BuildError :: pattern_id_overflow", "self . sparse [head] . next", "\" this NFA.\"", "(& StateID :: ZERO , & self . states [prev] . sparse)", "Builder { match_kind : :: core :: clone :: Clone :: clone (& self . match_kind) , prefilter : :: core :: clone :: Clone :: clone (& self . prefilter) , ascii_case_insensitive : :: core :: clone :: Clone :: clone (& self . ascii_case_insensitive ,) , dense_depth : :: core :: clone :: Clone :: clone (& self . dense_depth) , }", "if oldsid == noncontiguous :: NFA :: FAIL { index_to_state_id [oldsid] = NFA :: FAIL ; continue ; }", "chunk [len - 1]", "\" instructs any search to stop and return any currently recorded match,\"", "{ State :: match_len (alphabet_len , state) }", "Option < StateID >", "NFA :: builder () . build (patterns)", ":: core :: fmt :: Formatter", "trans_offset + i * 4 + 2", "true", "\" [`AhoCorasickBuilder::ascii_case_insensitive`](crate::AhoCorasickBuilder::ascii_case_insensitive)\"", "\" never be a valid state ID (by making sure it points to a place in the\"", "repr [trans_offset + i * 4]", "State :: len", "start + 1 + index", "f . write_fmt (format_args ! (\"longest pattern length: {0:?}\\n\" , self . max_pattern_len) ,) ?", "\"ascii_case_insensitive\"", "StateID :: new (self . matches . len ()) . map_err (| e | { BuildError :: state_id_overflow (StateID :: MAX . as_u64 () , e . attempted () ,) }) ?", "self . matches != StateID :: ZERO", "\" like to achieve a `O(n + m)` worst case complexity.\"", "\"        /         -------   -------\"", "(None , None)", "size_of :: < SmallIndex >", "()", "PatternID :: new (i)", "\"        \\\\         --------\"", "(start < dst . len ())", "\" The transitions for this state, where each transition is packed\"", "head", "if kind == State :: KIND_ONE { let fail = StateID :: from_u32_unchecked (state [1]) ; let class = state [State :: KIND] . low_u16 () . high_u8 () ; let next = state [2] ; (StateTrans :: One { class , next } , fail) } else { let fail = StateID :: from_u32_unchecked (state [1]) ; let trans_len = State :: sparse_trans_len (state) ; let classes_len = u32_len (trans_len) ; let classes = & state [2 ..] [.. classes_len] ; let nexts = & state [2 + classes_len ..] [.. trans_len] ; (StateTrans :: Sparse { classes , nexts , } , fail ,) }", "dst", "\" containing all of the matches for this state.\"", "if self . builder . ascii_case_insensitive { QueuedSet :: active () } else { QueuedSet :: inert () }", ":: core :: clone :: Clone :: clone (& self . alphabet_len)", "queue . pop_front ()", "self . dense_depth = depth", "old . start_anchored_id", ":: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! (\"expected number of patterns to match pattern ID\" ,) ,) ,)", "\"depth\"", "\" A contiguous NFA implementation of Aho-Corasick.\"", "\" [`Builder::build_from_noncontiguous`] permits doing it explicitly.\"", "Automaton", "repr [trans_offset + i * 4 + 2]", "StateTrans :: Dense { class_to_next }", ":: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! (\"state must have zero transitions\") ,) ,)", "\" Returns the failure transition for this state.\"", "f . write_fmt (format_args ! (\")\\n\"))", "next_avail", "\" construction depends on transitions to `fail_id` to determine whether a\"", "{ if i >= class_to_next . len () { return None ; } let class = i . as_u8 () ; let next = StateID :: from_u32_unchecked (class_to_next [i]) ; i += 1 ; Some ((class , next)) }", ":: core :: clone :: Clone :: clone (& self . dense)", ":: core :: clone :: Clone :: clone (& self . pattern_lens)", "if start_uid == t . next () || seen . contains (t . next) { continue ; }", "StateID :: new (self . states . len ()) . map_err (| e | { BuildError :: state_id_overflow (StateID :: MAX . as_u64 () , e . attempted () ,) }) ?", "self . state_len", "& [u32]", "ntrans % 4 == 0", "sid <= self . special . max_special_id", "class << 8", "self . nfa . states", "\" `N` is determined via `NFA::byte_classes::alphabet_len`.\"", "repr [trans_offset + i * 4 + 3]", "core :: cmp :: min", "if self . builder . ascii_case_insensitive { let b = opposite_ascii_case (b) ; self . nfa . add_transition (prev , b , next) ? ; }", "\" This isn't necessary for correctness, since any missing transition is\"", "& noncontiguous :: NFA", "head_dst", "MatchKind :: default", "nnfa . max_pattern_len ()", "\"fail\"", "\"Compiler\"", "\" state and thus don't get densified.\"", "{ self . nfa . special . max_match_id }", "self . pattern_lens", "\" on streams.\"", "Option < Prefilter >", "self . nfa . states [fail] . fail", "format_args ! (\"state must have zero transitions\")", "\" The DEAD state is a sentinel state like the FAIL state. The DEAD state\"", "Transition { byte , next , link : StateID :: ZERO , }", "self . alloc_transition () ?", "classes [1] == class", "self . noncontiguous . build (patterns)", "new . start_anchored_id = remap [old . start_anchored_id]", "{ if i == 0 { i += 1 ; Some ((class , StateID :: from_u32_unchecked (next))) } else { None } }", "\" state, one must follow the previous state's failure transition before\"", "\" Namely, disabling byte classes makes transitions easier to reason\"", "i * 4", "\" text we're searching (called the \\\"subject\\\" string), all we need to do\"", "\" crate. Namely, constructing this NFA involving building a trie and then\"", "self . sparse [link_next] . next", "\" trie can be used in a simplistic way. At any given position in the\"", "\" faster state transitions, currently, its limit on the number of states\"", "while self . matches [link] . link != StateID :: ZERO { link = self . matches [link] . link ; }", "loop { let o = sid . as_usize () ; let kind = repr [o] & 0xFF ; if kind == State :: KIND_DENSE { let next = u32tosid (repr [o + 2 + usize :: from (class)]) ; if next != NFA :: FAIL { return next ; } } else if kind == State :: KIND_ONE { if class == repr [o] . low_u16 () . high_u8 () { return u32tosid (repr [o + 2]) ; } } else { let trans_len = kind . as_usize () ; let classes_len = u32_len (trans_len) ; let trans_offset = o + 2 + classes_len ; for (i , & chunk) in repr [o + 2 ..] [.. classes_len] . iter () . enumerate () { let classes = chunk . to_ne_bytes () ; if classes [0] == class { return u32tosid (repr [trans_offset + i * 4]) ; } if classes [1] == class { return u32tosid (repr [trans_offset + i * 4 + 1]) ; } if classes [2] == class { return u32tosid (repr [trans_offset + i * 4 + 2]) ; } if classes [3] == class { return u32tosid (repr [trans_offset + i * 4 + 3]) ; } } } if anchored . is_anchored () { return NFA :: DEAD ; } sid = u32tosid (repr [o + 1]) ; }", "\" Note that this only applies to the NFA after it has been constructed.\"", "& Self", "self . nfa . matches . push (Match :: default ())", "Result < NFA , BuildError >", "classes . alphabet_len ()", "i == 0", "id1", "& * right_val", "self . states [dst] . matches", "sid . as_usize ()", "self . matches [link_src] . link", "sid", "\" Like `follow_transition`, but always uses the sparse representation.\"", "move | | { if link == StateID :: ZERO { return None ; } let m = self . matches [link] ; link = m . link ; Some (m . pid) }", "\" transitions, since deleting transitions from this particular sparse\"", "self . close_start_state_loop_for_leftmost ()", "\" Return an active set that tracks state ID membership.\"", "QueuedSet", "if ! (old_start_uid < old_start_aid) { :: core :: panicking :: panic (\"assertion failed: old_start_uid < old_start_aid\" ,) }", "\" number of transitions given.\"", "f . write_fmt (format_args ! (\")\\n\")) ?", "state [start]", ":: core :: panicking :: panic (\"assertion failed: old_start_uid < old_start_aid\" ,)", "\" we wind up searching the subject string potentially many times. In\"", "if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! (\"state must not be dense yet\") ,) ,) ; }", "\" A `State`'s in memory representation is not ever actually materialized\"", "class == repr [o] . low_u16 () . high_u8 ()", "if classes [3] == class { return u32tosid (repr [trans_offset + i * 4 + 3]) ; }", "\" Add a match for the given pattern ID to the state for the given ID.\"", "\" A representation of a sparse NFA state for an Aho-Corasick automaton.\"", "\" indexed by `PatternID`.\"", "& self . repr", "self . states [sid] . matches", "map", ":: core :: fmt :: Debug", "nnfa . special ()", "self . nfa . sparse [link] . next () == start_uid", "State :: remap (nfa . alphabet_len , & index_to_state_id , state) ?", "state [2 ..]", "self . noncontiguous", "Some (m . pid)", "f . write_fmt (format_args ! (\"\\n\")) ?", "self . nfa . byte_classes = self . byteset . byte_classes ()", "f . write_fmt (format_args ! (\"F {0:06}:\\n\" , NFA :: FAIL . as_usize ())) ?", "index_to_state_id [oldsid] = NFA :: FAIL", "\" This routine creates failure transitions according to the standard\"", "f", "match (& 0 , & (pid & (1 << 31))) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: None ,) ; } } }", "match self { StateTrans :: Sparse { classes : __self_0 , nexts : __self_1 } => { StateTrans :: Sparse { classes : :: core :: clone :: Clone :: clone (__self_0) , nexts : :: core :: clone :: Clone :: clone (__self_1) , } } StateTrans :: One { class : __self_0 , next : __self_1 } => { StateTrans :: One { class : :: core :: clone :: Clone :: clone (__self_0) , next : :: core :: clone :: Clone :: clone (__self_1) , } } StateTrans :: Dense { class_to_next : __self_0 } => { StateTrans :: Dense { class_to_next : :: core :: clone :: Clone :: clone (__self_0) , } } }", "\" Return the link following the one given. If the one given is the last\"", "\" Do note that this is only legal to call on a sparse state. So for\"", "\" It contains the transitions to the next state, a failure transition for\"", "\"     S0 - c - S5 - e - S6 - f - S7*\"", "\" This usually permits one to just import the `NFA` type.\"", "\" example, \\\"one transition\\\" state is not a sparse state, so it would not\"", "\" transition and a set of indices corresponding to matches.\"", "StateTrans :: One { class : :: core :: clone :: Clone :: clone (__self_0) , next : :: core :: clone :: Clone :: clone (__self_1) , }", "while link_src != StateID :: ZERO { let new_match_link = StateID :: new (self . matches . len ()) . map_err (| e | { BuildError :: state_id_overflow (StateID :: MAX . as_u64 () , e . attempted () ,) }) ? ; self . matches . push (Match { pid : self . matches [link_src] . pid , link : StateID :: ZERO , }) ; if link_dst == StateID :: ZERO { self . states [dst] . matches = new_match_link ; } else { self . matches [link_dst] . link = new_match_link ; } link_dst = new_match_link ; link_src = self . matches [link_src] . link ; }", "core :: cmp :: min (self . nfa . min_pattern_len , pat . len () ,)", "if state . dense != StateID :: ZERO { let start = state . dense . as_usize () ; for next in self . dense [start ..] [.. alphabet_len] . iter_mut () { * next = map (* next) ; } }", "i / 4", "\" This example shows how to build an `NFA` directly and use it to execute\"", "\" marginally slower to build, but has higher throughput and can sometimes use\"", "if is_leftmost && self . nfa . states [t . next] . is_match () { self . nfa . states [t . next] . fail = NFA :: DEAD ; }", "ByteClasses :: singletons ()", "loop { let next = self . follow_transition (sid , byte) ; if next != NFA :: FAIL { return next ; } if anchored . is_anchored () { return NFA :: DEAD ; } sid = self . states [sid] . fail () ; }", "self . states . iter ()", "Builder { match_kind : MatchKind :: default () , prefilter : true , ascii_case_insensitive : false , dense_depth : 3 , }", "\" the new state created.\"", "\" way, we avoid doing extra memory lookups.\"", "\" all appear before any NON-MATCH state, like so:\"", "\" Initializes the unanchored start state by making it dense. This is\"", "\" states have been added, the states are shuffled such that the above\"", "if packed & (1 << 31) == 0 { state [start + 1 + index] } else { match (& 0 , & index) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: None ,) ; } } } ; packed & ! (1 << 31) }", "next_avail . as_usize () . checked_sub (1) . unwrap ()", "\" Doing this at construction time while keeping a low memory footprint isn't\"", "next . as_usize ()", ":: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: None ,)", "core :: iter :: from_fn (move | | { if link == StateID :: ZERO { return None ; } let m = self . matches [link] ; link = m . link ; Some (m . pid) })", "\"builder\"", "\" Returns a slice containing the length of each pattern in this searcher.\"", "\" A set of state identifiers used to avoid revisiting the same state multiple\"", "t . byte ()", "self . states . swap (id1 . as_usize () , id2 . as_usize ())", "\" In order to minimize heap usage and to avoid additional construction costs,\"", "\" Return an iterator over every explicitly defined transition in this\"", "\" Very hand wavy... But the code complexity that results from this is\"", "u32tosid (repr [trans_offset + i * 4])", "self . nfa . special . start_anchored_id = self . nfa . alloc_state (0) ?", "\" allocation, where as the former uses a separate allocation for each state.\"", "{ let trans_len = State :: sparse_trans_len (state) ; let classes_len = u32_len (trans_len) ; state [1] = old_to_new [state [1] . as_usize ()] . as_u32 () ; for next in state [2 + classes_len ..] [.. trans_len] . iter_mut () { * next = old_to_new [next . as_usize ()] . as_u32 () ; } }", "\" A prefilter for accelerating searches, if one exists.\"", "\" useful to avoid the performance and memory overhead of maintaining this\"", "\"prefilter\"", "\" initially follow the transition from S0 to S1 and wind up in S3 after\"", "\" are no longer relevant.\"", "uprev_link = Some (ulink)", "f . write_fmt (format_args ! (\"{0}\" , pid . as_usize ())) ?", "\" set when it is not needed.\"", "BuildError :: state_id_overflow (StateID :: MAX . as_u64 () , e . attempted () ,)", "class_to_next . len ()", "SmallIndex :: new", "\" The sparse or dense representation of the transitions for this state.\"", "self . special . max_match_id", "dst . len ()", "\"Builder\"", "& mut self . sparse [link]", "\" The trick comes when searching a subject string like 'abcef'. We'll\"", "{ u32 :: try_from (old_len) . unwrap () }", "\" Computes the number of u32 values needed to represent one byte per the\"", "is_match", "\" link for the given state, then return `None`.\"", "\" just by comparing our current state ID with a particular value. In this\"", "format_args ! (\"anchored start state should be at index 3\")", "\" Encode the \\\"old\\\" state transitions from a noncontiguous NFA to its\"", "Transition { byte , next , link : link_next , }", "(& 0 , & index)", "old_to_new [state [1] . as_usize ()] . as_u32 ()", "newsid", "SmallIndex :: new (pat . len ())", "State :: len (self . alphabet_len , is_match , raw)", "\" is recursively. That is, if you know the failure transitions for every\"", "\" with the search starting at S5 and complete our match.\"", "\" A convenience method for returning a new Aho-Corasick contiguous NFA\"", "kind_len + fail_len + classes_len + trans_len + match_len", "if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! (\"expected number of patterns to match pattern ID\" ,) ,) ,) ; }", "\" state.) Instead, this points to the position that is guaranteed to\"", "core :: fmt :: Formatter", "& self . dense_depth", "state [2 + classes_len ..] [.. trans_len]", "Transition :: default", "\" let nfa = NFA::new(patterns).unwrap();\"", "\" state.\"", "nfa . repr", "\" configuration), then this state has no dense representation.\"", "* next", "\" the slice must correspond to the start of the state, but the slice may\"", "self . byte", "saw_match || self . nfa . states [prev] . is_match ()", "\" That is, we have a failure transition from S3 to S5, which is followed\"", "\" do. The alternative would be making the FAIL ID point to the second\"", "& self . trans", "State { fail : :: core :: clone :: Clone :: clone (& self . fail) , match_len : :: core :: clone :: Clone :: clone (& self . match_len) , trans : :: core :: clone :: Clone :: clone (& self . trans) , }", "u32 :: try_from (old_len) . unwrap ()", "id", "self . prefilter . as_ref ()", "\" state came from.\"", "self . dense [start ..]", "nfa . byte_classes", "(0 , alphabet_len)", "\" this state is from the start state of the NFA.\"", "\" `false` for every member test.\"", "if packed & (1 << 31) == 0 { packed } else { 1 }", "{ QueuedSet :: inert () }", "\" and the matches implied by visiting this state (if any).\"", "repr [o + 1]", "2 ..", "(state [State :: KIND] & 0xFF) . as_usize ()", "(self . repr . len () * size_of :: < u32 > ())", "\" always zero. Otherwise it is always bigger than zero.\"", "nnfa . min_pattern_len ()", "{ match (& byte , & self . sparse [link_next] . byte) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: None ,) ; } } } ; self . sparse [link_next] . next = next ; }", "\" during a search with a contiguous NFA. Doing so would be too slow. (Indeed,\"", "\" Generally a very small minority of states have a dense representation\"", "self . next", "State :: match_pattern (self . alphabet_len , raw , i)", "Anchored", "if is_leftmost && self . nfa . states [t . next] . is_match () { self . nfa . states [t . next] . fail = NFA :: DEAD ; continue ; }", "(self . pattern_lens . len () * size_of :: < SmallIndex > ())", "\" `is_match` should be true if this state is a match state and false\"", "& StateID :: ZERO", "for t in self . iter_trans (sid) { if byte <= t . byte { if byte == t . byte { return t . next ; } break ; } }", "while let Some (link) = self . nfa . next_link (start_uid , prev_link) { prev_link = Some (link) ; let t = self . nfa . sparse [link] ; if start_uid == t . next () || seen . contains (t . next) { continue ; } queue . push_back (t . next) ; seen . insert (t . next) ; if is_leftmost && self . nfa . states [t . next] . is_match () { self . nfa . states [t . next] . fail = NFA :: DEAD ; } }", "self . nfa . sparse [link] . next = NFA :: DEAD", "self . nfa . follow_transition (prev , b)", "self . nfa . follow_transition (fail , t . byte)", "if s . dense == StateID :: ZERO { self . follow_transition_sparse (sid , byte) } else { let class = usize :: from (self . byte_classes . get (byte)) ; self . dense [s . dense . as_usize () + class] }", "\" current state's failure transition.\"", "match (& 0 , & index) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: None ,) ; } } }", "new", "StateID :: new", "f . write_fmt (format_args ! (\"alphabet length: {0:?}\\n\" , self . alphabet_len) ,) ?", "return Ok (())", "seen", "while let Some (link) = self . nfa . next_link (start_uid , prev_link) { prev_link = Some (link) ; if self . nfa . sparse [link] . next () == NFA :: FAIL { self . nfa . sparse [link] . next = start_uid ; } }", "if i >= nexts . len () { return None ; }", "* self", "\" the last.\"", "NFA { match_kind : builder . match_kind , states : :: alloc :: vec :: Vec :: new () , sparse : :: alloc :: vec :: Vec :: new () , dense : :: alloc :: vec :: Vec :: new () , matches : :: alloc :: vec :: Vec :: new () , pattern_lens : :: alloc :: vec :: Vec :: new () , prefilter : None , byte_classes : ByteClasses :: singletons () , min_pattern_len : usize :: MAX , max_pattern_len : 0 , special : Special :: zero () , }", "if next != NFA :: FAIL { prev = next ; } else { let next = self . nfa . alloc_state (depth) ? ; self . nfa . add_transition (prev , b , next) ? ; if self . builder . ascii_case_insensitive { let b = opposite_ascii_case (b) ; self . nfa . add_transition (prev , b , next) ? ; } prev = next ; }", "if ntrans % 4 == 0 { ntrans >> 2 } else { (ntrans >> 2) + 1 }", ":: core :: clone :: Clone :: clone (& self . fail)", "Vec < SmallIndex >", "if ! is_match { 0 } else { State :: match_len (alphabet_len , state) }", "QueuedSet { set : None }", "prev_link = new_link", ":: core :: option :: Option :: Some (format_args ! (\"state must have zero transitions\") ,)", "Ok (id)", "\" Before shuffling begins, our states look something like this:\"", "f . write_fmt (format_args ! (\"F {0:06}:\\n\" , NFA :: FAIL . as_usize ()))", "if link == StateID :: ZERO { self . states [sid] . matches = new_match_link ; } else { self . matches [link] . link = new_match_link ; }", "self . nfa . special . start_unanchored_id", "\" Both [`NFA::new`] and [`Builder::build`] do this for you automatically, but\"", "chunk", "State :: match_pattern", "old . is_match ()", "\" the other AC implementations I know of (Perl, Snort, many on GitHub).\"", "\" N.B. There isn't anything particularly magical about 127 here. I\"", "self . nfa . alloc_dense_state ()", "usize :: from (self . nfa . byte_classes . get (t . byte))", "\" current state for the current input byte. If there is no other proper\"", "if State :: kind (state) == State :: KIND_DENSE { 2 + alphabet_len } else { let trans_len = State :: sparse_trans_len (state) ; let classes_len = u32_len (trans_len) ; 2 + classes_len + trans_len }", "\"match_kind\"", "remap [old . max_special_id]", "self . builder . match_kind", "remapper . swap (& mut self . nfa , old_start_aid , new_start_aid)", "\"         /                      /\"", "\" many transitions, then it would be quite slow to do a linear scan on\"", "format_args ! (\"{0:?} => {1:?}\" , DebugByte (start) , sid . as_usize () ,)", "self . iter_matches (sid) . enumerate ()", "& self . byte_classes", "sid <= self . special . max_match_id", "\" Returns the pattern ID corresponding to the given index for the state\"", "self . repr", "\" this NFA has no contiguous memory allocation for its transition table. Each\"", "\" strategy similar to this at construction time.)\"", "\" speaking, you shouldn't expect to run into this limit if the number of\"", "State :: write_dense_trans", "self . nfa . prefilter . is_some ()", "self . nfa . dense . push (NFA :: DEAD)", "self . nfa . states . len ()", "\" actual dead state at this ID.\"", "\" whose ID is always known and constant is the first state. Subsequent\"", "\" trie). We know we can transition back to S5 because we've already seen\"", "self . nfa . sparse [alink] . next", "{ self . matches [link] . link = new_match_link ; }", "1 << 31", "classes [3]", "SmallIndex", "continue", "self . sparse [link_prev]", "ntrans >> 2", "link_dst", "{ let fail = StateID :: from_u32_unchecked (state [1]) ; let trans_len = State :: sparse_trans_len (state) ; let classes_len = u32_len (trans_len) ; let classes = & state [2 ..] [.. classes_len] ; let nexts = & state [2 + classes_len ..] [.. trans_len] ; (StateTrans :: Sparse { classes , nexts , } , fail ,) }", "self . matches [link_dst] . link", "\" [`AhoCorasickBuilder::byte_classes`](crate::AhoCorasickBuilder::byte_classes)\"", "1", "Self", "Anchored :: No", "\" The \\\"in memory\\\" representation a single dense or sparse state.\"", "\" typically much less than 256 (the maximum value).\"", "\"patterns longer than SmallIndex::MAX are not allowed\"", "self . build_trie (patterns)", "\" sparse, are defined on equivalence classes and not on the 256 distinct\"", "format_args ! (\"Transition(byte: {0:X?}, next: {1:?}, link: {2:?})\" , self . byte , self . next () . as_usize () , self . link () . as_usize () ,)", "* next = map (* next)", ":: core :: panicking :: panic", "core :: mem :: size_of :: < Transition >", "4", "State :: kind (state)", "crate", "\" possible previous state that could be visited (e.g., when computing the\"", "I", "if kind == State :: KIND_ONE { state [1] = old_to_new [state [1] . as_usize ()] . as_u32 () ; state [2] = old_to_new [state [2] . as_usize ()] . as_u32 () ; } else { let trans_len = State :: sparse_trans_len (state) ; let classes_len = u32_len (trans_len) ; state [1] = old_to_new [state [1] . as_usize ()] . as_u32 () ; for next in state [2 + classes_len ..] [.. trans_len] . iter_mut () { * next = old_to_new [next . as_usize ()] . as_u32 () ; } }", "\" A single transition in a non-contiguous NFA.\"", "Compiler :: new", "aprev_link", "\" );\"", "loop { let raw = & self . repr [sid . as_usize () ..] ; if raw . is_empty () { break ; } let is_match = self . is_match (sid) ; let state = State :: read (self . alphabet_len , is_match , raw) ; fmt_state_indicator (f , self , sid) ? ; f . write_fmt (format_args ! (\"{0:06}({1:06}): \" , sid . as_usize () , state . fail . as_usize () ,) ,) ? ; state . fmt (f) ? ; f . write_fmt (format_args ! (\"\\n\")) ? ; if self . is_match (sid) { f . write_fmt (format_args ! (\"         matches: \")) ? ; for i in 0 .. state . match_len { let pid = State :: match_pattern (self . alphabet_len , raw , i) ; if i > 0 { f . write_fmt (format_args ! (\", \")) ? ; } f . write_fmt (format_args ! (\"{0}\" , pid . as_usize ())) ? ; } f . write_fmt (format_args ! (\"\\n\")) ? ; } if sid == NFA :: DEAD { f . write_fmt (format_args ! (\"F {0:06}:\\n\" , NFA :: FAIL . as_usize ())) ? ; } let len = State :: len (self . alphabet_len , is_match , raw) ; sid = StateID :: new (sid . as_usize () . checked_add (len) . unwrap ()) . unwrap () ; }", "move | | { if link == StateID :: ZERO { return None ; } let t = self . sparse [link] ; link = t . link ; Some (t) }", "\" states), it follows that we can determine whether a state is a fail,\"", "left_val", "\" the state has been densified prior to calling this.\"", "state . depth ()", "\" The first match for each state is determined by `State::matches`.\"", "\" Return the byte for which this transition is defined.\"", "index", "'PATTERNS : for (i , pat) in patterns . into_iter () . enumerate () { let pid = PatternID :: new (i) . map_err (| e | { BuildError :: pattern_id_overflow (PatternID :: MAX . as_u64 () , e . attempted () ,) }) ? ; let pat = pat . as_ref () ; let patlen = SmallIndex :: new (pat . len ()) . map_err (| _ | BuildError :: pattern_too_long (pid , pat . len ())) ? ; self . nfa . min_pattern_len = core :: cmp :: min (self . nfa . min_pattern_len , pat . len () ,) ; self . nfa . max_pattern_len = core :: cmp :: max (self . nfa . max_pattern_len , pat . len () ,) ; match (& i , & self . nfa . pattern_lens . len ()) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! (\"expected number of patterns to match pattern ID\" ,) ,) ,) ; } } } ; self . nfa . pattern_lens . push (patlen) ; if self . builder . prefilter { self . prefilter . add (pat) ; } let mut prev = self . nfa . special . start_unanchored_id ; let mut saw_match = false ; for (depth , & b) in pat . iter () . enumerate () { saw_match = saw_match || self . nfa . states [prev] . is_match () ; if self . builder . match_kind . is_leftmost_first () && saw_match { continue 'PATTERNS ; } self . byteset . set_range (b , b) ; if self . builder . ascii_case_insensitive { let b = opposite_ascii_case (b) ; self . byteset . set_range (b , b) ; } let next = self . nfa . follow_transition (prev , b) ; if next != NFA :: FAIL { prev = next ; } else { let next = self . nfa . alloc_state (depth) ? ; self . nfa . add_transition (prev , b , next) ? ; if self . builder . ascii_case_insensitive { let b = opposite_ascii_case (b) ; self . nfa . add_transition (prev , b , next) ? ; } prev = next ; } } self . nfa . add_match (prev , pid) ? ; }", "\"        /       ----------------\"", "self . set_anchored_start_state ()", "chunk [len]", "\" Re-maps all state IDs in this NFA according to the `map` function\"", "\" usually only takes a fraction of the time it takes to build a noncontiguous\"", "link != StateID :: ZERO", "self . nfa . next_link (start_uid , uprev_link)", "\" use a sort of \\\"premultiplied\\\" state identifier where the only state\"", "\" corresponds to the number of transitions in the state.\"", "\" S3 has no transition for 'e', so the search fails. We then would need\"", "anchored . is_anchored ()", "if State :: match_len (alphabet_len , state) == 1 { 1 } else { 1 + State :: match_len (alphabet_len , state) }", "usize :: from (self . byte_classes . get (byte))", "\" I couldn't find any that implement leftmost semantics like this.\"", "\" point to a FAIL state, in which case, the search should try the\"", "0xFF", "let Some (id) = queue . pop_front ()", "\" Note that depth is currently not used in this non-contiguous NFA. It\"", "Transition { byte : :: core :: default :: Default :: default () , next : :: core :: default :: Default :: default () , link : :: core :: default :: Default :: default () , }", "remapper . swap (& mut self . nfa , sid , next_avail)", "self . nfa . dense [index] = t . next", "self . nfa . add_transition (prev , b , next) ?", "\" A pointer to `NFA::matches` corresponding to the head of a linked list\"", "\" be legal to call this method on such a state.\"", "Compiler :: new (self)", "impl Iterator < Item = PatternID > + '_", "StateID", "format_args ! (\"{0:?}-{1:?} => {2:?}\" , DebugByte (start) , DebugByte (end) , sid . as_usize () ,)", "format_args ! (\"shortest pattern length: {0:?}\\n\" , self . min_pattern_len ,)", "Compiler :: new (self) ?", "Vec < Transition >", "self . nfa . dense . shrink_to_fit ()", "dense . as_usize () + class", "\" A pointer to a row of `N` transitions in `NFA::dense`. These\"", "\" This sets up the initial prefix trie that makes up the Aho-Corasick\"", "\" concrete evidence that this materially helps matters, but it's easy to\"", "\"   DEAD, FAIL, START, START, MATCH... NON-MATCH...\"", "\"assertion failed: old_start_uid < old_start_aid\"", "matches_len", "\" classes computed for the noncontiguous NFA that the given state came\"", "fail_len", ":: core :: panicking :: AssertKind :: Eq", ".. trans_len", "nfa . pattern_lens . shrink_to_fit ()", "\" This does not update the transitions of any state to account for the\"", "\" the standard Aho-Corasick construction, there are no transitions to\"", "self . noncontiguous . match_kind (kind)", "\" transition).\"", "state [start + 1 + index]", "\" The alphabet size, or total number of equivalence classes, for this\"", "& nfa . byte_classes", "false", "Remapper :: new", "\" heap memory than a noncontiguous NFA. Since building a contiguous NFA\"", "Ok (self . nfa)", "\" search time, which is even worse than what Perl is doing. ---AG\"", "\" NFA.\"", "self . matches [link_src]", "\" Each transition contains three pieces of information: the byte it\"", "link_next != StateID :: ZERO && byte > self . sparse [link_next] . byte", "StateID :: new (self . dense . len ()) . map_err (| e | { BuildError :: state_id_overflow (StateID :: MAX . as_u64 () , e . attempted () ,) })", "self . nfa . states [sid] . dense", "match self . set { None => false , Some (ref set) => set . contains (& state_id) , }", "\" Adding failure transitions to a trie is fairly simple, but subtle. The\"", "& self . states", "ByteClasses :: singletons", "self . ascii_case_insensitive = yes", "self . nfa . dense [index]", "\" The state this should transition to if the current symbol is\"", "self . states . len () * core :: mem :: size_of :: < State > () + self . sparse . len () * core :: mem :: size_of :: < Transition > () + self . matches . len () * core :: mem :: size_of :: < Match > () + self . dense . len () * StateID :: SIZE", "\" start of the slice must correspond to the start of the state, but the\"", "self . shuffle ()", "\" transitions is going to be exceptionally rare, and if it did have this\"", "QueuedSet :: active", "aprev_link = Some (alink)", "Builder :: new ()", "self", "\" `byte_classes` settings on this builder are respected. The other\"", "state . fail = map (state . fail)", "\" in every automaton, but only used when leftmost-{first,longest} match\"", "\" representation more than other states.\"", "\" in a contiguous NFA. (noncontiguous::NFA::FAIL does point to a valid\"", "\" The second state (index 1) is always the dead state. Dead states are\"", "f . write_fmt (format_args ! (\"longest pattern length: {0:?}\\n\" , self . max_pattern_len) ,)", "\" Encode the \\\"old\\\" state from a noncontiguous NFA to its binary\"", "start + usize :: from (classes . get (t . byte ()))", "(ntrans >> 2) + 1", "core :: fmt :: Result", "self . nfa . states [prev] . is_match ()", "\" of a match.\"", "\" that the latter represents all of its states and transitions in a single\"", ":: core :: clone :: Clone :: clone (& self . repr)", "\" transitions stored in a sparse fashion. (This non-contiguous NFA uses\"", "Builder :: default ()", ":: core :: marker :: Copy", "\" };\"", "PatternID :: from_u32_unchecked (pid)", "\" impl without needing to store a separate map from state index to state\"", "\" Note that one should not set transitions to the FAIL state. It is not\"", "Special", "\" Note that this is indexed by byte equivalence classes and not\"", "t", "if len > 0 { let repeat = chunk [len - 1] ; while len < 4 { chunk [len] = repeat ; len += 1 ; } dst . push (u32 :: from_ne_bytes (chunk)) ; }", "State :: write (nnfa , oldsid , state , & nfa . byte_classes , & mut nfa . repr , force_dense ,) ?", "\" Follow the transition for the given byte in the given state. If no such\"", "for (depth , & b) in pat . iter () . enumerate () { saw_match = saw_match || self . nfa . states [prev] . is_match () ; if self . builder . match_kind . is_leftmost_first () && saw_match { continue 'PATTERNS ; } self . byteset . set_range (b , b) ; if self . builder . ascii_case_insensitive { let b = opposite_ascii_case (b) ; self . byteset . set_range (b , b) ; } let next = self . nfa . follow_transition (prev , b) ; if next != NFA :: FAIL { prev = next ; } else { let next = self . nfa . alloc_state (depth) ? ; self . nfa . add_transition (prev , b , next) ? ; if self . builder . ascii_case_insensitive { let b = opposite_ascii_case (b) ; self . nfa . add_transition (prev , b , next) ? ; } prev = next ; } }", "\" transition exists, then the FAIL state ID is returned.\"", "raw . is_empty ()", "chunk . to_ne_bytes () [i % 4]", "\" this implementation represents the transitions of all states as distinct\"", "\" need to follow. For example, look at the trie for the patterns\"", "{ if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! (\"expected number of patterns to match pattern ID\" ,) ,) ,) ; } }", "core :: iter :: repeat (noncontiguous :: NFA :: FAIL . as_u32 ()) . take (classes . alphabet_len ())", "\" This NFA can only be built by first constructing a [`noncontiguous::NFA`].\"", "0xFE", "\" feasible, which is primarily why there are two different NFA types: one\"", "\" `state` should be the the raw binary encoding of a state. (The start of\"", "for t in nnfa . iter_trans (oldsid) { dst [start + usize :: from (classes . get (t . byte ()))] = t . next () . as_u32 () ; }", "for (i , (start , end , sid)) in it { if i > 0 { f . write_fmt (format_args ! (\", \")) ? ; } if start == end { f . write_fmt (format_args ! (\"{0:?} => {1:?}\" , DebugByte (start) , sid . as_usize () ,) ,) ? ; } else { f . write_fmt (format_args ! (\"{0:?}-{1:?} => {2:?}\" , DebugByte (start) , DebugByte (end) , sid . as_usize () ,) ,) ? ; } }", "self . set", "id2", "self . nfa . prefilter", "\" the most active state.)\"", "\" A single match in a non-contiguous NFA.\"", "f . write_fmt (format_args ! (\"{0:?}-{1:?} => {2:?}\" , DebugByte (start) , DebugByte (end) , sid . as_usize () ,) ,) ?", "bool", "& mut nfa . repr [newsid . as_usize () ..]", "state [2 ..] [.. classes_len]", "\" case, you'll want to copy the matches (if any) from the state reached\"", "packed & (1 << 31)", "\" This is exposed for convenience when building a contiguous NFA. But it\"", "trans_offset + i * 4 + 3", "\" isn't a sparse state, then the return value is unspecified.\"", "self . nfa . special . max_special_id", "\" Aho-Corasick automaton, so we can specialize them using a very compact\"", "127", "__self_1", "(class << 8)", "\" defined, then it is automatically assumed to lead to the FAIL state.\"", "self . nfa . dense [dense . as_usize () + class]", "newsid == NFA :: FAIL", "self . nfa . special . start_anchored_id = new_start_aid", "nfa . special", "\" into a u32. The low 8 bits correspond to the byte class for the\"", "u32 :: from", "(old_start_uid < old_start_aid)", "\" represent a lot of wasteful work.\"", "\" failure transition is followed.)\"", "self . matches [link] . link = new_match_link", "self . sparse [link_next]", "| t | (t . byte , t . next)", "\" automaton have only 1 transition and are usually farther from the start\"", "kind == State :: KIND_DENSE", "if let Some (ref mut set) = self . set { set . insert (state_id) ; }", "state . dense != StateID :: ZERO", "\" information, which we need when building the contiguous NFA.\"", "\" entries from `NFA::sparse` is likely more expensive than it's worth.\"", "self . set_anchored_start_state () ?", "core :: mem :: size_of :: < State > ()", "\" 'class_to_next[classes.get(byte)]' is correct. The number of\"", "! is_leftmost", "ByteClassSet :: empty", "\" opportunity for compression tricks to reduce the heap memory used. Indeed,\"", "StateTrans :: Sparse { classes , nexts , }", "\" state to the name `next` value.\"", "& mut nfa . repr", "let Some (link) = self . nfa . next_link (id , prev_link)", "SmallIndex :: new (depth)", "\" leftmost-longest.\"", "packed & ! (1 << 31)", ":: alloc :: vec :: Vec :: new ()", "f . write_fmt (format_args ! (\"shortest pattern length: {0:?}\\n\" , self . min_pattern_len ,) ,) ?", "\" the end of the pattern.\"", "Transition :: default ()", ":: core :: clone :: Clone :: clone (& self . match_len)", "format_args ! (\"expected number of patterns to match pattern ID\" ,)", "\"     S0 --- b - S5* - c - S6 - d - S7*\"", "\"          - a - S1 - b - S2* - c - S3 - d - S4*\"", "next_avail = StateID :: new (next_avail . one_more ()) . unwrap ()", "\"     nfa.try_find(&Input::new(haystack))?,\"", "! old . is_match ()", "self . iter_matches (sid) . count ()", "& self . repr [sid . as_usize () ..]", "nnfa . states () . len ()", "f . write_fmt (format_args ! (\"{0}\" , pid . as_usize ()))", "self . add_unanchored_start_state_loop ()", "\" transitions that appear after a match state in the trie. This is\"", "\" to by the link via `self.sparse[link]`.\"", "\" use a [`contiguous::NFA`](crate::nfa::contiguous::NFA) instead. It is\"", "if kind == State :: KIND_ONE { let t = nnfa . iter_trans (oldsid) . next () . unwrap () ; let class = u32 :: from (classes . get (t . byte ())) ; dst . push (kind | (class << 8)) ; dst . push (old . fail () . as_u32 ()) ; dst . push (t . next () . as_u32 ()) ; } else { dst . push (kind) ; dst . push (old . fail () . as_u32 ()) ; State :: write_sparse_trans (nnfa , oldsid , classes , dst) ? ; }", "\" transitions are explicitly represented.\"", "{ dst . push (kind) ; dst . push (old . fail () . as_u32 ()) ; State :: write_sparse_trans (nnfa , oldsid , classes , dst) ? ; }", "PatternID :: from_u32_unchecked", "kind_len + fail_len + classes_len", "if self . nfa . states [self . nfa . special . start_anchored_id] . is_match () { self . nfa . special . max_match_id = self . nfa . special . start_anchored_id ; }", "link_src = self . matches [link_src] . link", "\" their behavior is identical.\"", "self . sparse [link_prev] . link = link", "\"     Some(Match::must(0, 1..2)),\"", "\" For example, let's say we built an Aho-Corasick automaton with the\"", "f . write_fmt (format_args ! (\"{0:?} => {1:?}\" , DebugByte (start) , sid . as_usize () ,) ,) ?", "\" This builder has a subset of the options available to a\"", "Vec < u32 >", "& & self . set", "\" Swaps the states at `id1` and `id2`.\"", "nnfa . iter_matches (oldsid) . count ()", ":: core :: clone :: Clone :: clone (& self . prefilter)", "if start == end { f . write_fmt (format_args ! (\"{0:?} => {1:?}\" , DebugByte (start) , sid . as_usize () ,) ,) ? ; } else { f . write_fmt (format_args ! (\"{0:?}-{1:?} => {2:?}\" , DebugByte (start) , DebugByte (end) , sid . as_usize () ,) ,) ? ; }", "inline", "1 + State :: match_len (alphabet_len , state)", "\" Since a contiguous NFA uses various tricks for compression and to achieve\"", ":: core :: panicking :: panic_fmt (format_args ! (\"equivalence classes are never empty\") ,)", "{ StateTrans :: Sparse { classes : :: core :: clone :: Clone :: clone (__self_0) , nexts : :: core :: clone :: Clone :: clone (__self_1) , } }", "2 + classes_len ..", "core :: mem :: size_of :: < State >", "if ! self . nfa . states [sid] . is_match () { continue ; }", "sparse_transitions (self . transitions ()) . filter (| & (_ , _ , sid) | sid != NFA :: FAIL)", "nnfa . states ()", ":: core :: fmt :: Formatter :: debug_struct_field4_finish (f , \"Builder\" , \"match_kind\" , & self . match_kind , \"prefilter\" , & self . prefilter , \"ascii_case_insensitive\" , & self . ascii_case_insensitive , \"dense_depth\" , & & self . dense_depth ,)", "SmallIndex :: new (pat . len ()) . map_err (| _ | BuildError :: pattern_too_long (pid , pat . len ()))", "State :: sparse_trans_len", "\" Perhaps simplest way to think about adding these failure transitions\"", ":: core :: clone :: Clone :: clone", "State :: write_sparse_trans", "(1 << 31) | pid", "(& 0 , & (matches_len & (1 << 31)))", "self . alloc_match () ?", "self . nfa . sparse . push (Transition :: default ())", "noncontiguous :: State", "self . nfa . sparse [link] . byte", "\" let patterns = &[\\\"b\\\", \\\"abc\\\", \\\"abcd\\\"];\"", "\" A sentinel value indicating that the state uses a dense representation.\"", "old", ":: core :: clone :: Clone :: clone (& self . noncontiguous)", "\" classes. Instead, these are useful for building the DFA when desired.\"", "{ if link == StateID :: ZERO { return None ; } let t = self . sparse [link] ; link = t . link ; Some (t) }", "\" correlate with very active states.\"", "format_args ! (\", \")", "\" exists. (Well, they do, but they aren't followed. Instead, the state's\"", "\" Get the number of sparse transitions in this state. This can never\"", "if byte == self . sparse [head] . byte { self . sparse [head] . next = next ; return Ok (()) ; }", "trans_len", "StateID :: new (next_avail . as_usize () . checked_sub (1) . unwrap () ,)", "(& 3 , & old_start_aid . as_usize ())", "\" is defined for, the state it transitions to and a link to the next\"", "| _ | BuildError :: pattern_too_long (pid , pat . len ())", "if newsid == NFA :: FAIL { continue ; }", "dst . push (u32 :: from_ne_bytes (chunk))", "f . write_fmt (format_args ! (\"memory usage: {0:?}\\n\" , self . memory_usage ()))", "if sid == NFA :: DEAD { f . write_fmt (format_args ! (\"F {0:06}:\\n\" , NFA :: FAIL . as_usize ())) ? ; }", "\" The FAIL state mostly just corresponds to the ID of any transition on a\"", "\" The easiest path is to just make the FAIL state a runtime value, but\"", "\" match states are inter-leaved with non-match states. Once all of the\"", "\" may in the future, but it is used in the contiguous NFA. Namely, it\"", "noncontiguous :: NFA :: FAIL . as_u32 ()", "\" Use a [`Builder`] if you want to change the configuration.\"", "\"nfa\"", "i", "State :: remap", ".. classes_len", "builder", "f . write_fmt (format_args ! (\"pattern length: {0:?}\\n\" , self . patterns_len ()) ,)", "Builder", "\" dense states.\"", "len == 4", "\" extend past the end of the encoding of the state.)\"", "\" about, since they use the actual bytes instead of equivalence classes.\"", "State { sparse : StateID :: ZERO , dense : StateID :: ZERO , matches : StateID :: ZERO , fail : self . special . start_unanchored_id , depth , }", ":: alloc :: vec :: from_elem (NFA :: DEAD , nnfa . states () . len () ,)", "builder . match_kind", "matches_len & (1 << 31)", "self . repr [sid . as_usize () ..]", "\" of the previous state and check whether the incoming transition is\"", "\"dense_depth\"", "\"         /               /         /\"", "\" The failure transitions for this trie are defined from S2 to S5,\"", "\" use this for building the DFA. We store it on the NFA since it's easy\"", "self . sparse . len () * core :: mem :: size_of :: < Transition > ()", "self . match_kind", "\" during a search since we don't always need all values and thus would\"", "sid == NFA :: FAIL", "if self . is_match (sid) { f . write_fmt (format_args ! (\"         matches: \")) ? ; for (i , pid) in self . iter_matches (sid) . enumerate () { if i > 0 { f . write_fmt (format_args ! (\", \")) ? ; } f . write_fmt (format_args ! (\"{0}\" , pid . as_usize ())) ? ; } f . write_fmt (format_args ! (\"\\n\")) ? ; }", "StateID :: new (sid . as_usize () . checked_add (len) . unwrap ())", "(class , StateID :: from_u32_unchecked (next))", "\" a sparse representation for all states unconditionally.) In any case,\"", "[0 ; 4]", "\" very mild.\"", "\" predicates hold.\"", "\" A dense representation of transitions for a state, where all\"", "\" building the NFA, but don't use it in the NFA's states. Instead, we\"", "& * left_val", "f . write_fmt (format_args ! (\"pattern length: {0:?}\\n\" , self . patterns_len ()) ,) ?", "kind_len + fail_len", "anchored", "state [State :: KIND]", "old_to_new [next . as_usize ()]", "if matches_len == 1 { let pid = nnfa . iter_matches (oldsid) . next () . unwrap () . as_u32 () ; match (& 0 , & (pid & (1 << 31))) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: None ,) ; } } } ; dst . push ((1 << 31) | pid) ; } else { match (& 0 , & (matches_len & (1 << 31))) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: None ,) ; } } } ; dst . push (matches_len . as_u32 ()) ; dst . extend (nnfa . iter_matches (oldsid) . map (| pid | pid . as_u32 ())) ; }", "move | | match self . trans { StateTrans :: Sparse { classes , nexts } => { if i >= nexts . len () { return None ; } let chunk = classes [i / 4] ; let class = chunk . to_ne_bytes () [i % 4] ; let next = StateID :: from_u32_unchecked (nexts [i]) ; i += 1 ; Some ((class , next)) } StateTrans :: One { class , next } => { if i == 0 { i += 1 ; Some ((class , StateID :: from_u32_unchecked (next))) } else { None } } StateTrans :: Dense { class_to_next } => { if i >= class_to_next . len () { return None ; } let class = i . as_u8 () ; let next = StateID :: from_u32_unchecked (class_to_next [i]) ; i += 1 ; Some ((class , next)) } }", "byte > self . sparse [link_next] . byte", "if kind == State :: KIND_ONE { if class == repr [o] . low_u16 () . high_u8 () { return u32tosid (repr [o + 2]) ; } } else { let trans_len = kind . as_usize () ; let classes_len = u32_len (trans_len) ; let trans_offset = o + 2 + classes_len ; for (i , & chunk) in repr [o + 2 ..] [.. classes_len] . iter () . enumerate () { let classes = chunk . to_ne_bytes () ; if classes [0] == class { return u32tosid (repr [trans_offset + i * 4]) ; } if classes [1] == class { return u32tosid (repr [trans_offset + i * 4 + 1]) ; } if classes [2] == class { return u32tosid (repr [trans_offset + i * 4 + 2]) ; } if classes [3] == class { return u32tosid (repr [trans_offset + i * 4 + 3]) ; } } }", "if link == StateID :: ZERO { None } else { Some (link) }", "pat . len ()", "byte", "\" and the automaton does indeed have a non-empty suffix, 'c', that could\"", "State :: match_pattern (self . alphabet_len , & self . repr [sid . as_usize () ..] , index ,)", "StateID :: new (next_avail . as_usize () . checked_sub (3) . unwrap () ,) . unwrap ()", "if len == 4 { dst . push (u32 :: from_ne_bytes (chunk)) ; chunk = [0 ; 4] ; len = 0 ; }", "self . nfa", "self . fill_failure_transitions () ?", "\" breadth first search of the automaton. Our base case is the start\"", "\"set\"", "NFA :: DEAD", "0", "nnfa . pattern_lens_raw () . to_vec ()", "self . states [dst] . matches = new_match_link", "\" another part of the automaton that corresponds to a suffix of what\"", "\" settings only apply to the initial construction of the Aho-Corasick\"", ":: core :: clone :: Clone :: clone (& self . state_len)", "\" Note that when this method is used, only the `dense_depth` and\"", "& self . matches", ":: core :: clone :: Clone :: clone (& self . min_pattern_len)", "head == StateID :: ZERO || byte < self . sparse [head] . byte", "{ if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! (\"state must have zero transitions\") ,) ,) ; } }", "is_leftmost", "{ f . write_fmt (format_args ! (\"{0:?}-{1:?} => {2:?}\" , DebugByte (start) , DebugByte (end) , sid . as_usize () ,) ,) ? ; }", "new_max_match_id", "(t . byte , t . next)", "self . nfa . sparse . shrink_to_fit ()", "Transition", "format_args ! (\"{0:06}({1:06}): \" , sid . as_usize () , state . fail . as_usize () ,)", "(state [State :: KIND] & 0xFF)", "State :: kind (state) == State :: KIND_DENSE", "\"    is_dead(sid): sid == NFA::DEAD\"", "dst . extend (nnfa . iter_matches (oldsid) . map (| pid | pid . as_u32 ()))", "if byte == t . byte { return t . next ; }", "\" The depth of this state. Specifically, this is the distance from this\"", "pat . as_ref ()", "prev = next", "self . builder . match_kind . is_leftmost () && start . is_match ()", "\" [`AhoCorasickBuilder::dense_depth`](crate::AhoCorasickBuilder::dense_depth)\"", "sid == self . special . start_unanchored_id", "classes [2]", "remapper . remap (& mut self . nfa)", "\" Set the limit on how many states use a dense representation for their\"", "if i > 0 { f . write_fmt (format_args ! (\", \")) ? ; }", "pat", "BuildError :: pattern_too_long (pid , pat . len ())", "self . sparse [prev_link] . link", "Iterator < Item = PatternID >", "dst . push ((1 << 31) | pid)", "link_src", "\" Returns a set that tracked queued states.\"", "self . nfa . special . max_special_id = if self . nfa . prefilter . is_some () { self . nfa . special . start_anchored_id } else { self . nfa . special . max_match_id }", "self . nfa . init_full_state (start_uid , NFA :: FAIL)", "\"byteset\"", "self . match_kind = kind", "& (matches_len & (1 << 31))", "Some (link)", "\" test.\"", "self . nfa . pattern_lens . push (patlen)", "fail = self . nfa . follow_transition (fail , t . byte)", "\" at 'c' would finally succeed. The problem with this approach is that\"", "state . fmt (f) ?", "\" The third state (index 2) is generally intended to be the starting or\"", "\" what has been seen so far. Thus, following a failure transition after\"", "self . nfa . prefilter = self . prefilter . build ()", "if self . builder . match_kind . is_leftmost () && start . is_match () { let mut prev_link = None ; while let Some (link) = self . nfa . next_link (start_uid , prev_link) { prev_link = Some (link) ; if self . nfa . sparse [link] . next () == start_uid { self . nfa . sparse [link] . next = NFA :: DEAD ; if dense != StateID :: ZERO { let b = self . nfa . sparse [link] . byte ; let class = usize :: from (self . nfa . byte_classes . get (b)) ; self . nfa . dense [dense . as_usize () + class] = NFA :: DEAD ; } } } }", "sparse_transitions (self . iter_trans (sid) . map (| t | (t . byte , t . next)) ,) . enumerate ()", "& self . pattern_lens", "class_to_next [i]", "\"          - c - S8 - d - S9*\"", "self . nfa . states [self . nfa . special . start_anchored_id]", "dense != StateID :: ZERO", "self . states . len ()", "\"\"", "\" increased in the future. If the limit is reached, building a contiguous NFA\"", "kind_len", "\" This returns an error if `dst` became so big that `StateID`s can no\"", "Ok (Compiler { builder , prefilter , nfa : NFA { match_kind : builder . match_kind , states : :: alloc :: vec :: Vec :: new () , sparse : :: alloc :: vec :: Vec :: new () , dense : :: alloc :: vec :: Vec :: new () , matches : :: alloc :: vec :: Vec :: new () , pattern_lens : :: alloc :: vec :: Vec :: new () , prefilter : None , byte_classes : ByteClasses :: singletons () , min_pattern_len : usize :: MAX , max_pattern_len : 0 , special : Special :: zero () , } , byteset : ByteClassSet :: empty () , })", "Compiler { builder , prefilter , nfa : NFA { match_kind : builder . match_kind , states : :: alloc :: vec :: Vec :: new () , sparse : :: alloc :: vec :: Vec :: new () , dense : :: alloc :: vec :: Vec :: new () , matches : :: alloc :: vec :: Vec :: new () , pattern_lens : :: alloc :: vec :: Vec :: new () , prefilter : None , byte_classes : ByteClasses :: singletons () , min_pattern_len : usize :: MAX , max_pattern_len : 0 , special : Special :: zero () , } , byteset : ByteClassSet :: empty () , }", "anext", "self . nfa . pattern_lens", "\" patterns is under 1 million. It is plausible that this limit will be\"", "State :: KIND_ONE", "! (old_start_uid < old_start_aid)", "\" Transitions stored in a sparse representation via a linked list.\"", "\" The loop is only closed when two conditions are met: the start state\"", "* left_val", "self . states [prev] . dense != StateID :: ZERO", "\" Another sentinel state ID indicating that a search should move through\"", "old_len > State :: MAX_SPARSE_TRANSITIONS", "nnfa . iter_matches (oldsid) . next () . unwrap ()", "core :: mem :: size_of :: < Match > ()", "& self . prefilter", "\" A compiler uses a builder configuration and builds up the NFA formulation\"", "self . transitions ()", "! self . nfa . states [sid] . is_match ()", "\" Build an Aho-Corasick contiguous NFA from the given noncontiguous NFA.\"", "saw_match = saw_match || self . nfa . states [prev] . is_match ()", "& mut Vec < u32 >", "self . sparse [head] . link", "\" a match implies looking for a match that starts after the one that has\"", "nnfa . iter_trans (oldsid) . next () . unwrap ()", "f . write_fmt (format_args ! (\"state length: {0:?}\\n\" , self . state_len))", "\" Note that like `State`, we don't typically construct values of this type\"", "if force_dense || old_len > State :: MAX_SPARSE_TRANSITIONS { State :: KIND_DENSE } else if old_len == 1 && ! old . is_match () { State :: KIND_ONE } else { u32 :: try_from (old_len) . unwrap () }", "\" `NFA::byte_classes::alphabet_len()` entries beginning at `State::dense`\"", "\" [`AhoCorasickBuilder::match_kind`](crate::AhoCorasickBuilder::match_kind)\"", "NFA :: builder", "\" Read a state's binary encoding to its in-memory representation.\"", "State :: write_sparse_trans (nnfa , oldsid , classes , dst)", "usize", "next_avail . one_more ()", "kind == State :: KIND_ONE", "\" The length, in bytes, of each pattern in this NFA. This slice is\"", "\"   is_match(sid): NFA::FAIL < sid && sid <= max_match_id\"", "MatchKind :: default ()", "if self . nfa . prefilter . is_some () { self . nfa . special . start_anchored_id } else { self . nfa . special . max_match_id }", "remap [old . start_anchored_id]", "\" The information required to deduce which states are \\\"special\\\" in this\"", "\" Shuffle the states so that they appear in this sequence:\"", "& 3", "\" transitions is always equivalent to 'classes.alphabet_len()'.\"", "if classes [0] == class { return u32tosid (repr [trans_offset + i * 4]) ; }", "self . matches . push (Match :: default ())", "next_avail . as_usize () . checked_sub (2)", "return next", "while let Some (link) = self . nfa . next_link (sid , prev_link) { prev_link = Some (link) ; let t = self . nfa . sparse [link] ; let class = usize :: from (self . nfa . byte_classes . get (t . byte)) ; let index = dense . as_usize () + class ; self . nfa . dense [index] = t . next ; }", "\" key issue is that you might have multiple failure transition that you\"", "\" Then it's just a simple matter of swapping the two START states with\"", "if anchored . is_anchored () { return NFA :: DEAD ; }", "& self . ascii_case_insensitive", ":: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! (\"anchored start state should be at index 3\") ,) ,)", "usize :: from (classes . get (t . byte ()))", "self . states", "\" to compute while visiting the patterns.\"", "! (start < dst . len ())", "\"         \\\\       /\"", "\" of the slice must correspond to the start of the state, but the slice\"", "\" Iterate over all of the matches for the given state ID.\"", "self . states . len () * core :: mem :: size_of :: < State > ()", "builder . ascii_case_insensitive", "(head , self . sparse [head] . link)", "\" every state that has no corresponding proper suffix.\"", "\" It is indexed by `PatternID` and has length `NFA::patterns_len`.\"", "self . byte_classes . get (byte)", "StateID :: new (dst . len ())", "\" A \\\"one transition\\\" state that is never a match state.\"", "\" Build an Aho-Corasick noncontiguous NFA from the given iterator of\"", "match anchored { Anchored :: No => Ok (self . special . start_unanchored_id) , Anchored :: Yes => Ok (self . special . start_anchored_id) , }", "\" A set of equivalence classes in terms of bytes. We compute this while\"", "byte < self . sparse [link_next] . byte", "if class == repr [o] . low_u16 () . high_u8 () { return u32tosid (repr [o + 2]) ; }", "Option < & Prefilter >", "sparse_transitions", "self . matches [link] . link", "\" Enable heuristic prefilter optimizations.\"", "self . nfa . sparse [ulink] . next", "& & self . byteset", "self . matches [new_match_link] . pid = pid", "\" Create a new entry in `NFA::trans`, if there's room, and return that\"", "| p | p . clone ()", "self . sparse [new_link]", "opposite_ascii_case (b)", "\" set is inert, this always returns false.\"", "f . write_fmt (format_args ! (\"byte classes: {0:?}\\n\" , self . byte_classes))", "Builder :: new", "Special :: zero ()", "StateID :: new (next_avail . one_more ()) . unwrap ()", "new . start_anchored_id", "Vec < Match >", "sid != NFA :: FAIL", "\" The state that should be transitioned to if the current byte in the\"", "self . states [sid] . fail ()", "{ :: core :: panicking :: panic_fmt (format_args ! (\"equivalence classes are never empty\") ,) ; }", "sid == NFA :: DEAD || sid == NFA :: FAIL", "let Some (link) = self . nfa . next_link (sid , prev_link)", "\" Setup the anchored start state by copying all of the transitions and\"", "self . sparse [head]", "\" # Example\"", "self . nfa . special . max_match_id = new_max_match_id", "\" in this NFA from sparse to dense. This can greatly improve search\"", "f . write_fmt (format_args ! (\"contiguous::NFA(\\n\")) ?", "\" Normally, missing transitions map back to the failure state, but the\"", "\" transitions begin. So `id+0` is the first transition and `id+(N-1)` is\"", "\" This needs to be small enough to permit each of the sentinel values for\"", "\"   DEAD, FAIL, MATCH..., START, START, NON-MATCH...\"", "yes", "f . write_fmt (format_args ! (\"state length: {0:?}\\n\" , self . states . len ())) ?", "& self . match_kind", "\" than a state that one actually transitions into. In particular, it is\"", "old_to_new [state [2] . as_usize ()] . as_u32 ()", "f . write_fmt (format_args ! (\"alphabet length: {0:?}\\n\" , self . alphabet_len) ,)", "link_next", "\" When `force_dense` is true, then the encoded state will always use a\"", "map (t . next)", "SmallIndex :: SIZE", "& ByteClasses", "Result < Compiler < 'a > , BuildError >", "o", "queue", ":: core :: panicking :: panic (\"internal error: entered unreachable code\" ,)", "self . nfa . copy_matches (start_uid , start_aid)", "for (i , pid) in self . iter_matches (sid) . enumerate () { if i > 0 { f . write_fmt (format_args ! (\", \")) ? ; } f . write_fmt (format_args ! (\"{0}\" , pid . as_usize ())) ? ; }", "\" defined for.\"", ":: core :: clone :: Clone :: clone (& self . trans)", "& state_id", "\" The match semantics built into this NFA.\"", "StateID :: new (next_avail . as_usize () . checked_sub (2) . unwrap () ,) . unwrap ()", "\" N.B. I came up with this algorithm on my own, and after scouring all of\"", "self . nfa . init_full_state (start_uid , NFA :: FAIL) ?", ":: core :: option :: Option :: Some (format_args ! (\"expected number of patterns to match pattern ID\" ,) ,)", "id2 . as_usize ()", "Iterator < Item = Transition >", "\" The raw NFA representation. Each state is packed with a header\"", "classes [3] == class", "i . as_u8 ()", "set . contains (& state_id)", "self . depth", "\" assumptions, we already know that there is a failure transition from\"", ":: core :: clone :: Clone :: clone (& self . depth)", "\" the last two MATCH states.\"", "self . follow_transition (sid , byte)", "repr", "patterns", "usize :: from (class)", "\" NFA, the overall build time is not much slower. Thus, in most cases, a\"", "\" very compact representation for them.\"", "StateID :: new (next_avail . one_more ())", "id1 . as_usize ()", "\" This should never be enabled unless you're debugging an automaton.\"", "\" search performance. For this reason, it is almost always a good idea to\"", "self . nfa . copy_matches (self . nfa . special . start_unanchored_id , id)", "link_src != StateID :: ZERO", ":: alloc :: vec :: from_elem", "if byte <= t . byte { if byte == t . byte { return t . next ; } break ; }", "self . nfa . copy_matches (self . nfa . special . start_unanchored_id , id) ?", "\" just picked it because I figured any sparse state with this many\"", "pat . iter ()", "\" actually look at the FAIL state itself, this works out.\"", "raw", "state . match_len", "new . start_unanchored_id", "\" of an Aho-Corasick automaton. This roughly corresponds to the standard\"", "alphabet_len", "state_id", "self . alphabet_len", "e . attempted ()", "\"QueuedSet\"", "\" Remap state IDs in-place.\"", "\" Set the desired match semantics.\"", "state [start] . as_usize ()", ":: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! (\"state must not be dense yet\") ,) ,)", "self . nfa . states . shrink_to_fit ()", "self . byteset", "& self . alphabet_len", "{ 1 }", "\" let haystack = \\\"abcd\\\";\"", "\" given. The `index` provided must be less than the number of pattern IDs\"", "patlen", "if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! (\"anchored start state should be at index 3\") ,) ,) ; }", "f . write_fmt (format_args ! (\"F {0:06}:\\n\" , sid . as_usize ())) ?", "\" These are by far the most common state, so we use a specialized and\"", "\" include a subset of failure transitions. Namely, we omit any failure\"", "State :: write_dense_trans (nnfa , oldsid , classes , dst) ?", "t . next = map (t . next)", "ntrans", "core :: iter :: repeat (NFA :: FAIL) . take (self . byte_classes . alphabet_len ())", "Compiler", "self . special . start_anchored_id", "Iterator < Item = (u8 , StateID) >", "{ match (& 0 , & (matches_len & (1 << 31))) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: None ,) ; } } } ; dst . push (matches_len . as_u32 ()) ; dst . extend (nnfa . iter_matches (oldsid) . map (| pid | pid . as_u32 ())) ; }", "u32 :: try_from", "\" stores anything and always returns `false` for every member test. This is\"", "state . depth () . as_usize () < self . dense_depth", "\" Return the ID of the next match.\"", "Vec < State >", "continue 'PATTERNS", ":: core :: clone :: Clone :: clone (& self . ascii_case_insensitive ,)", "MatchKind", "pid", "self . byteset . byte_classes ()", "f . write_fmt (format_args ! (\"memory usage: {0:?}\\n\" , self . memory_usage ())) ?", "State :: write (nnfa , oldsid , state , & nfa . byte_classes , & mut nfa . repr , force_dense ,)", "self . matches [new_match_link]", "classes [1]", ":: core :: fmt :: Formatter :: debug_struct_field1_finish", "nnfa . pattern_lens_raw ()", "start == end", "\" will fail or not. If it does, you can always fall back to a noncontiguous\"", "self . states [prev] . sparse = new_link", "sid . as_usize () ..", "link = self . matches [link] . link", "Compiler < 'a >", "byte == self . sparse [head] . byte", "if dense != StateID :: ZERO { let b = self . nfa . sparse [link] . byte ; let class = usize :: from (self . nfa . byte_classes . get (b)) ; self . nfa . dense [dense . as_usize () + class] = NFA :: DEAD ; }", "self . prefilter", "\" NFA. Dense states always have this many transitions.\"", "old_start_uid", "\" Instead, a `State` exposes a number of static methods for reading certain\"", "nexts . len ()", "\" The length of the longest pattern in this automaton.\"", "\" The offset of where the \\\"kind\\\" of a state is stored. If it isn't one\"", "while link_next != StateID :: ZERO && byte > self . sparse [link_next] . byte { link_prev = link_next ; link_next = self . sparse [link_next] . link ; }", "while len < 4 { chunk [len] = repeat ; len += 1 ; }", "link_next != StateID :: ZERO", "& Special", "\" state back to the start state with transitions to the dead state.\"", "self . byteset . set_range (b , b)", "Some ((class , StateID :: from_u32_unchecked (next)))", "{ if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: None ,) ; } }", "new . max_match_id", "return t . next", "f . write_fmt (format_args ! (\"state length: {0:?}\\n\" , self . states . len ()))", "b", "\" equal to 'class'.\"", "self . matches [link_src] . pid", "o + 2 + usize :: from (class)", "MatchError", "core :: mem :: size_of :: < Match >", "(pid & (1 << 31))", "state [2]", "\" transition table.\"", "self . nfa . sparse [ulink]", "\" including states that have a dense representation for transitions.\"", "byte <= t . byte", "format_args ! (\")\\n\")", "self . builder . ascii_case_insensitive", "& index", "\" state, whose failure transition is just a transition to itself.\"", "link_next == StateID :: ZERO || byte < self . sparse [link_next] . byte", "\" haystack does not have a corresponding transition defined in this\"", "Fn (StateID) -> StateID", "self . trans", "Compiler :: new (self) ? . compile (patterns) ?", "self . nfa . copy_matches (fail , t . next)", "if ! (start < dst . len ()) { { :: core :: panicking :: panic_fmt (format_args ! (\"equivalence classes are never empty\") ,) ; } }", "pat . iter () . enumerate ()", "2 + classes_len", "State :: MAX_SPARSE_TRANSITIONS", "\" Remove the start state loop by rewriting any transitions on the start\"", "\" Returns the total number of matching pattern IDs in this state. Calling\"", "self . nfa . states [t . next] . is_match ()", "index_to_state_id [oldsid] = newsid", "NFA { match_kind : :: core :: clone :: Clone :: clone (& self . match_kind) , states : :: core :: clone :: Clone :: clone (& self . states) , sparse : :: core :: clone :: Clone :: clone (& self . sparse) , dense : :: core :: clone :: Clone :: clone (& self . dense) , matches : :: core :: clone :: Clone :: clone (& self . matches) , pattern_lens : :: core :: clone :: Clone :: clone (& self . pattern_lens) , prefilter : :: core :: clone :: Clone :: clone (& self . prefilter) , byte_classes : :: core :: clone :: Clone :: clone (& self . byte_classes) , min_pattern_len : :: core :: clone :: Clone :: clone (& self . min_pattern_len) , max_pattern_len : :: core :: clone :: Clone :: clone (& self . max_pattern_len) , special : :: core :: clone :: Clone :: clone (& self . special) , }", "\" Returns a slice of all states in this non-contiguous NFA.\"", "& self . special", "self . sparse . push (Transition :: default ())", "new_start_aid", "next_avail . as_usize ()", "BuildError :: state_id_overflow", "for i in 0 .. state . match_len { let pid = State :: match_pattern (self . alphabet_len , raw , i) ; if i > 0 { f . write_fmt (format_args ! (\", \")) ? ; } f . write_fmt (format_args ! (\"{0}\" , pid . as_usize ())) ? ; }", "{ self . sparse [prev_link] . link = new_link ; }", "\" tweaks to support \\\"leftmost\\\" semantics.\"", "self . noncontiguous . build (patterns) ?", "\" During construction, the start states are the first ones added and the\"", "\" this type directly. Using an `NFA` directly is typically only necessary\"", "repr [o + 2]", "trans", "seen . insert (t . next)", "self . states . len () * core :: mem :: size_of :: < State > () + self . sparse . len () * core :: mem :: size_of :: < Transition > () + self . matches . len () * core :: mem :: size_of :: < Match > () + self . dense . len () * StateID :: SIZE + self . pattern_lens . len () * SmallIndex :: SIZE", "self . nfa . states [t . next] . fail", "self . nfa . next_link (sid , prev_link)", "self . nfa . init_full_state (start_aid , NFA :: FAIL)", "! (* left_val == * right_val)", "seen . contains (t . next)", "\" never exposed in the `Automaton` interface.\"", "uprev_link", "byte_classes", "& self . byteset", "format_args ! (\"prefilter: {0:?}\\n\" , self . prefilter . is_some ())", "\" S3 to S6 and S6 to S8. Moreover, state S2 needs to track that it\"", "\" A builder may be reused to create more NFAs.\"", "\" for S0, S1 and S2), then you can simply follow the failure transition\"", "\" states with a lot of transitions are either very rare, or occur near\"", "pid & (1 << 31)", "core :: mem :: size_of :: < Transition > ()", "\" a single transition associated with each state that points back to\"", ":: core :: fmt :: Formatter :: debug_struct_field1_finish (f , \"QueuedSet\" , \"set\" , & & self . set ,)", "\" This is useful for efficiently initializing start/dead states.\"", "self . special . start_unanchored_id", "self . states [src] . matches", "f . write_fmt (format_args ! (\"contiguous::NFA(\\n\"))", "StateTrans :: Dense { class_to_next : :: core :: clone :: Clone :: clone (__self_0) , }", "\" there are only ever two start states (which follow all of the match\"", "\" Iterate over all of the transitions for the given state ID.\"", "self . build_trie (patterns) ?", "Ok", "(& i , & self . nfa . pattern_lens . len ())", "self . nfa . special . start_unanchored_id = self . nfa . alloc_state (0) ?", "self . nfa . states [start_aid]", "len = 0", "\" This is useful for manually iterating over the transitions in a single\"", "(classes_len , trans_len)", "self . nfa . states [prev]", "self . sparse [p]", "\" patterns in this automaton.\"", "old . fail () . as_u32 ()", "if self . byte_classes { nnfa . byte_classes () . clone () } else { ByteClasses :: singletons () }", "f . write_fmt (format_args ! (\"match kind: {0:?}\\n\" , self . match_kind)) ?", "class_to_next", "if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! (\"state must have zero transitions\") ,) ,) ; }", "\" transition table, then we can determine what \\\"kind\\\" of state we're in\"", "& self . nfa . pattern_lens . len ()", "(StateTrans :: One { class , next } , fail)", "start < dst . len ()", "StateID :: new (next_avail . as_usize () . checked_sub (2) . unwrap () ,)", "self . pid", "self . nfa . states [sid]", "sid = u32tosid (repr [o + 1])", "& mut self . nfa . states [start_uid]", "kind", "if kind == State :: KIND_DENSE { let fail = StateID :: from_u32_unchecked (state [1]) ; let class_to_next = & state [2 ..] [.. alphabet_len] ; (StateTrans :: Dense { class_to_next } , fail) } else if kind == State :: KIND_ONE { let fail = StateID :: from_u32_unchecked (state [1]) ; let class = state [State :: KIND] . low_u16 () . high_u8 () ; let next = state [2] ; (StateTrans :: One { class , next } , fail) } else { let fail = StateID :: from_u32_unchecked (state [1]) ; let trans_len = State :: sparse_trans_len (state) ; let classes_len = u32_len (trans_len) ; let classes = & state [2 ..] [.. classes_len] ; let nexts = & state [2 + classes_len ..] [.. trans_len] ; (StateTrans :: Sparse { classes , nexts , } , fail ,) }", "new_match_link", "\" suffix, then the failure transition points back to the starting state.\"", "\" `alphabet_len` should be the total number of transitions defined for\"", "depth", "(ntrans >> 2)", "\" A noncontiguous NFA implementation of Aho-Corasick.\"", "src", "self . sparse [head] . next = next", "StateID :: new (self . dense . len ())", "link_next = self . sparse [link_next] . link", "start + 1", "\" Create a new entry in `NFA::matches`, if there's room, and return that\"", "\" state already exists or not.\"", "if i == 0 { i += 1 ; Some ((class , StateID :: from_u32_unchecked (next))) } else { None }", "sid = StateID :: new (sid . as_usize () . checked_add (len) . unwrap ()) . unwrap ()", "\" sentinel. Namely, in the final NFA, no transition into the fail state\"", "link_dst == StateID :: ZERO", "(& 0 , & (pid & (1 << 31)))", "{ (ntrans >> 2) + 1 }", "core :: cmp :: max", "p", "repr [o + 2 ..] [.. classes_len] . iter () . enumerate ()", "\" cases where there exists no other transition for the current input byte\"", "u32tosid (repr [o + 2 + usize :: from (class)])", "\" be more than State::MAX_SPARSE_TRANSITIONS, as all states with more\"", "repr [o + 2 ..]", "self . match_len", "(& StateID :: ZERO , & self . states [prev] . dense)", "StateID :: new (self . sparse . len ())", "\" semantics are enabled. Specifically, they instruct search to stop\"", "\" [`AhoCorasickBuilder`](crate::AhoCorasickBuilder). Of the shared options,\"", "state [1] . as_usize ()", "\" implementations to agree, but rather, the contiguous NFA and the DFA\"", "\" Note that this contains a complete set of all transitions in this NFA,\"", "& self . dense", "fmt_state_indicator (f , self , sid) ?", "\" with a seeming hack at *search* time instead of encoding it into the\"", "\" builder.\"", "alink", "\" FAIL, their depth is always 0.) The depth of a starting state is 0.\"", "\" faster by making some states use a dense representation.\"", "format_args ! (\"byte classes: {0:?}\\n\" , self . byte_classes)", "ByteClasses", "byte < self . sparse [head] . byte", "self . matches [link_dst] . link != StateID :: ZERO", "self . states . len () * core :: mem :: size_of :: < State > () + self . sparse . len () * core :: mem :: size_of :: < Transition > () + self . matches . len () * core :: mem :: size_of :: < Match > ()", "s . dense", "self . init_unanchored_start_state () ?", "self . iter_matches (sid) . nth (index) . unwrap ()", "& 'a [u32]", "\" The idea here is that if we know how special states are laid out in our\"", "\" Sets all transitions on the dead state to point back to the dead state.\"", "self . byte_classes = yes", "self . nfa . max_pattern_len = core :: cmp :: max (self . nfa . max_pattern_len , pat . len () ,)", "self . prefilter . add (pat)", "return None", "len - 1", "self . nfa . pattern_lens . shrink_to_fit ()", "self . pattern_lens . len () * SmallIndex :: SIZE", "State :: KIND_DENSE", "for t in nnfa . iter_trans (oldsid) { dst . push (t . next () . as_u32 ()) ; }", "unext", "if kind == State :: KIND_DENSE { state [1] = old_to_new [state [1] . as_usize ()] . as_u32 () ; for next in state [2 ..] [.. alphabet_len] . iter_mut () { * next = old_to_new [next . as_usize ()] . as_u32 () ; } } else if kind == State :: KIND_ONE { state [1] = old_to_new [state [1] . as_usize ()] . as_u32 () ; state [2] = old_to_new [state [2] . as_usize ()] . as_u32 () ; } else { let trans_len = State :: sparse_trans_len (state) ; let classes_len = u32_len (trans_len) ; state [1] = old_to_new [state [1] . as_usize ()] . as_u32 () ; for next in state [2 + classes_len ..] [.. trans_len] . iter_mut () { * next = old_to_new [next . as_usize ()] . as_u32 () ; } }", "len > 0", "\" [`Builder::build_from_noncontiguous`].\"", ":: core :: clone :: Clone", "u32", "Result < () , BuildError >", "prefilter :: Builder", "\" It is also possible to implement your own version of `try_find`. See the\"", "\" until we reach the start state, which is the failure transition for\"", "\" Inserts the given state ID into this set. (If the set is inert, then\"", "\" following patterns: 'abcd' and 'cef'. The trie looks like this:\"", "start_uid == t . next () || seen . contains (t . next)", "self . nfa . max_pattern_len", "StateID :: MAX", "State :: read (self . alphabet_len , is_match , raw)", "start . is_match ()", "link", "StateID :: new (dst . len ()) . map_err (| e | { BuildError :: state_id_overflow (StateID :: MAX . as_u64 () , e . attempted () ,) }) ?", "nnfa . prefilter () . map (| p | p . clone ())", "self . matches [link_dst] . link = new_match_link", "index_to_state_id [oldsid]", "nnfa . iter_matches (oldsid) . next () . unwrap () . as_u32 ()", "self . repr . len ()", "patterns . into_iter () . enumerate ()", "sparse_transitions (self . transitions ())", "\" automaton for our patterns in this case looks like this:\"", "nfa . alphabet_len", "self . dense_depth", "let Some (link) = self . nfa . next_link (start_uid , prev_link)", "dense . as_usize ()", "u32 :: from_ne_bytes", "& state [2 ..] [.. alphabet_len]", "self . nfa . states [sid] . is_match ()", ":: core :: fmt :: Formatter :: debug_struct_field4_finish", "State :: remap (nfa . alphabet_len , & index_to_state_id , state)", "self . nfa . states [sid] . dense = dense", "\" entered this state. When a search stops, it returns a match if one\"", "Ok (self . special . start_unanchored_id)", "| & (_ , _ , sid) | sid != NFA :: FAIL", "\" transitions correspond precisely to what is obtained by traversing\"", "VecDeque :: new ()", "\"       \\\\                  /\"", "\" `sparse`, but permits constant time lookup.\"", "\" that does a little extra work to compact itself and make state transitions\"", "if self . states [prev] . dense != StateID :: ZERO { let dense = self . states [prev] . dense ; let class = usize :: from (self . byte_classes . get (byte)) ; self . dense [dense . as_usize () + class] = next ; }", "State :: KIND", "\" byte values. That means 'class_to_next[byte]' is wrong and\"", "\" Like sparse transitions, each match has a link to the next match in the\"", "s . dense . as_usize ()", "next_avail . as_usize () .. self . nfa . states . len ()", "f . write_fmt (format_args ! (\"F {0:06}:\\n\" , sid . as_usize ()))", "\" is a match state and the match kind is leftmost-first or\"", "sid . as_usize () . checked_add (len)", "StateTrans :: Sparse { classes : :: core :: clone :: Clone :: clone (__self_0) , nexts : :: core :: clone :: Clone :: clone (__self_1) , }", "self . states [prev] . sparse", "StateID :: new (self . matches . len ())", "& 'a Builder", "self . is_dead (sid)", "& self . states [prev] . dense", "if next != NFA :: FAIL { return next ; }", "self . nfa . follow_transition (fail , t . byte) == NFA :: FAIL", "\"State\"", "\" for more documentation and examples.\"", "Match { pid : :: core :: default :: Default :: default () , link : :: core :: default :: Default :: default () , }", "self . nfa . states [sid] . depth . as_usize ()", "\" The number of pattern IDs in this state. For a non-match state, this is\"", "\" from.\"", "repr [o + 2 ..] [.. classes_len] . iter ()", "{ Some (link) }", "BuildError :: pattern_id_overflow (PatternID :: MAX . as_u64 () , e . attempted () ,)", "old_start_uid < old_start_aid", "\" Thus, the returned number is never 0 for all correct calls.\"", "& self . match_len", "\" state gets its own allocation.\"", "\" transition\\\" encoding. In practice, non-match states with one transition\"", "self . nfa . states [sid] . depth . as_usize () >= self . builder . dense_depth", ":: core :: default :: Default :: default", "State :: write_dense_trans (nnfa , oldsid , classes , dst)", "if sid == NFA :: DEAD || sid == NFA :: FAIL { continue ; }", "\" Note that this doesn't remove the sparse representation of transitions\"", "start ..", "format_args ! (\"pattern length: {0:?}\\n\" , self . patterns_len ())", "{ BuildError :: state_id_overflow (StateID :: MAX . as_u64 () , e . attempted () ,) }", "for (sid , state) in self . states . iter () . with_state_ids () { if sid == NFA :: FAIL { f . write_fmt (format_args ! (\"F {0:06}:\\n\" , sid . as_usize ())) ? ; continue ; } fmt_state_indicator (f , self , sid) ? ; f . write_fmt (format_args ! (\"{0:06}({1:06}): \" , sid . as_usize () , state . fail . as_usize () ,) ,) ? ; let it = sparse_transitions (self . iter_trans (sid) . map (| t | (t . byte , t . next)) ,) . enumerate () ; for (i , (start , end , sid)) in it { if i > 0 { f . write_fmt (format_args ! (\", \")) ? ; } if start == end { f . write_fmt (format_args ! (\"{0:?} => {1:?}\" , DebugByte (start) , sid . as_usize () ,) ,) ? ; } else { f . write_fmt (format_args ! (\"{0:?}-{1:?} => {2:?}\" , DebugByte (start) , DebugByte (end) , sid . as_usize () ,) ,) ? ; } } f . write_fmt (format_args ! (\"\\n\")) ? ; if self . is_match (sid) { f . write_fmt (format_args ! (\"         matches: \")) ? ; for (i , pid) in self . iter_matches (sid) . enumerate () { if i > 0 { f . write_fmt (format_args ! (\", \")) ? ; } f . write_fmt (format_args ! (\"{0}\" , pid . as_usize ())) ? ; } f . write_fmt (format_args ! (\"\\n\")) ? ; } }", "self . pattern_lens . len () * size_of :: < SmallIndex > ()", "{ let trans_len = State :: sparse_trans_len (state) ; let classes_len = u32_len (trans_len) ; 2 + classes_len + trans_len }", "\" Note that unlike DEAD, this does not actually point to a valid state\"", "\" the dead state.\"", "format_args ! (\"Match(pid: {0:?}, link: {1:?})\" , self . pattern () . as_usize () , self . link () . as_usize () ,)", "self . queued_set ()", ":: core :: option :: Option :: Some", "Remapper :: new (& self . nfa , 0)", "for next in state [2 ..] [.. alphabet_len] . iter_mut () { * next = old_to_new [next . as_usize ()] . as_u32 () ; }", "\"     Input, Match,\"", "\" contiguous NFA does not have the desired capacity. (The total number of NFA\"", "& self . states [prev] . sparse", "Ok (())", "\" If it has any transitions, then this panics. It will also panic if\"", "\" automaton. There are also a couple Java libraries that support leftmost\"", "Builder { noncontiguous : :: core :: clone :: Clone :: clone (& self . noncontiguous) , dense_depth : :: core :: clone :: Clone :: clone (& self . dense_depth) , byte_classes : :: core :: clone :: Clone :: clone (& self . byte_classes) , }", "core :: iter :: from_fn (move | | { if link == StateID :: ZERO { return None ; } let t = self . sparse [link] ; link = t . link ; Some (t) })", "format_args ! (\"memory usage: {0:?}\\n\" , self . memory_usage ())", ":: core :: clone :: Clone :: clone (& self . special)", "\" in this table.\"", "self . nfa . init_full_state (start_aid , NFA :: FAIL) ?", "\" technically incorrect, but it wastes space. If a transition is not\"", "\" byte values.\"", "State", "StateID :: ZERO", "self . builder . match_kind . is_leftmost_first ()", "next != NFA :: FAIL", "classes . get (t . byte ())", "while link != StateID :: ZERO { let t = & mut self . sparse [link] ; t . next = map (t . next) ; link = t . link ; }", "old_to_new", "classes [2] == class", "self . byte_classes", "\" a fail_id.\"", "\" Returns true if and only if the given state ID is in this set. If the\"", "\" This is `StateID::ZERO` if and only if this state is not a match state.\"", "StateTrans :: One { class , next }", "repr [o] . low_u16 ()", "\" This packing is why the max state ID allowed for a contiguous\"", "\" in this state.\"", "StateID :: MAX . as_u64 ()", "force_dense", "\" Returns the length, in number of u32s, of this state.\"", "packed & (1 << 31) == 0", "self . states . len () * core :: mem :: size_of :: < State > () + self . sparse . len () * core :: mem :: size_of :: < Transition > ()", "\"matches\"", "self . iter_matches (sid) . nth (index)", "* left_val == * right_val", "self . add_dead_state_loop ()", "if ! is_match { 0 } else if State :: match_len (alphabet_len , state) == 1 { 1 } else { 1 + State :: match_len (alphabet_len , state) }", "& & self . dense_depth", ":: core :: clone :: AssertParamIsClone < u8 >", "\"     automaton::Automaton,\"", "while self . nfa . follow_transition (fail , t . byte) == NFA :: FAIL { fail = self . nfa . states [fail] . fail ; }", "\" exactly in cases when we are in state S3 but see any byte other than\"", "\" Enable ASCII-aware case insensitive matching.\"", "self . nfa . special . max_match_id", "\" At this point, it should be fairly straight-forward to see how this\"", "self . nfa . copy_matches (start_uid , start_aid) ?", "self . noncontiguous . prefilter (yes)", "& Prefilter", "Prefilter", "Some (ulink)", "Ok (self . special . start_anchored_id)", "StateID :: from_u32_unchecked (next)", "if self . is_match (sid) { f . write_fmt (format_args ! (\"         matches: \")) ? ; for i in 0 .. state . match_len { let pid = State :: match_pattern (self . alphabet_len , raw , i) ; if i > 0 { f . write_fmt (format_args ! (\", \")) ? ; } f . write_fmt (format_args ! (\"{0}\" , pid . as_usize ())) ? ; } f . write_fmt (format_args ! (\"\\n\")) ? ; }", "AsRef < [u8] >", "chunk . to_ne_bytes ()", "{ let trans_len = State :: sparse_trans_len (state) ; let classes_len = u32_len (trans_len) ; let start = 2 + classes_len + trans_len ; state [start] . as_usize () }", "{ let class = usize :: from (self . byte_classes . get (byte)) ; self . dense [s . dense . as_usize () + class] }", "* next = old_to_new [next . as_usize ()] . as_u32 ()", "\" defined after following the failure transition.\"", "classes [0]", "m . link", "self . nfa . dense [dense . as_usize () + class] = NFA :: DEAD", "kind . as_usize ()", "\" Return the ID of the next transition.\"", "self . nfa . states [sid] . depth", "\" representation.\"", ":: core :: clone :: Clone :: clone (& self . sparse)", "\" configuration.\"", "StateID :: from", "match (& byte , & self . sparse [link_next] . byte) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: None ,) ; } } }", "match (unext , anext) { (Some (ulink) , Some (alink)) => (ulink , alink) , (None , None) => break , _ => { :: core :: panicking :: panic (\"internal error: entered unreachable code\" ,) } }", "dst . push (matches_len . as_u32 ())", "Default", "self . sparse [link]", "& nnfa", "4u8", "prefilter :: Builder :: new (builder . match_kind) . ascii_case_insensitive (builder . ascii_case_insensitive)", ":: core :: option :: Option :: Some (format_args ! (\"anchored start state should be at index 3\") ,)", "0 .. state . match_len", "& mut nfa . special", "\" has been found, otherwise no match. A contiguous NFA always has an\"", "NFA :: FAIL", ":: core :: fmt :: Formatter :: debug_struct_field3_finish", "self . states [sid] . sparse", "\" # Panics\"", "self . sparse [prev_link]", "s", "\" automatically assumed to be mapped to the FAIL state. We do this to\"", "t . byte", "p . clone ()", "\"          a - S1 - b - S2 - c - S3 - d - S4*\"", "Match { pid : self . matches [link_src] . pid , link : StateID :: ZERO , }", "([0 ; 4] , 0)", "prev_link", "BTreeSet < StateID >", "\" is somewhat smaller than what a noncontiguous NFA can achieve. Generally\"", "\" \\\"else\\\" branch.\"", ":: core :: fmt :: Formatter :: debug_struct_field5_finish", "Compiler :: new (self) ? . compile (patterns)", "StateID :: new (self . states . len ()) . map_err (| e | { BuildError :: state_id_overflow (StateID :: MAX . as_u64 () , e . attempted () ,) })", "self . fill_failure_transitions ()", "{ let next = self . nfa . alloc_state (depth) ? ; self . nfa . add_transition (prev , b , next) ? ; if self . builder . ascii_case_insensitive { let b = opposite_ascii_case (b) ; self . nfa . add_transition (prev , b , next) ? ; } prev = next ; }", "match (& StateID :: ZERO , & self . states [prev] . sparse) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! (\"state must have zero transitions\") ,) ,) ; } } }", "self . prefilter . build ()", "self . sparse [link_next] . next = next", "\" whether the transition connecting S2 to S3 is defined. Indeed, it is,\"", "self . prefilter . as_ref () . map_or (0 , | p | p . memory_usage ())", "& mut core :: fmt :: Formatter < '_ >", "set . insert (state_id)", "f . write_fmt (format_args ! (\"         matches: \")) ?", "\" The element of this NFA's alphabet that this transition is\"", "\" it is not uncommon for a contiguous NFA to use an order of magnitude less\"", "o + 1", "\" ```\"", "state", "\" If no previous link is given, then this returns the first link in the\"", "\" [`Automaton`] documentation for an example.\"", "\" described in any standard textbook description of Aho-Corasick.\"", "self . iter_trans (sid)", "\" Return true if and only if this state is a match state.\"", "ByteClassSet", "\" to restart the search at the next position in 'abcef', which\"", "\" matches from the unanchored starting state with one change: the failure\"", "\" decision across the other Aho-Corasicm automata, so that DEAD\"", "\" These tend to be the most active states and thus benefit from a dense\"", "PatternID :: MAX", "sid == self . special . start_unanchored_id || sid == self . special . start_anchored_id", "& 0", "self . nfa . special . start_anchored_id", "| e | { BuildError :: pattern_id_overflow (PatternID :: MAX . as_u64 () , e . attempted () ,) }", "{ self . matches [link_dst] . link = new_match_link ; }", "{ if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! (\"state must not be dense yet\") ,) ,) ; } }", "old_to_new [next . as_usize ()] . as_u32 ()", "repr [o] . low_u16 () . high_u8 ()", "prefilter", "\" automaton, where every pattern given has a path from the start state to\"", "& state [2 ..] [.. classes_len]", "nnfa . iter_trans (oldsid) . count ()", "i % 4", "nnfa . states () . iter () . with_state_ids ()", "StateID :: new_unchecked", "repr [o + 2 ..] [.. classes_len]", "self . ascii_case_insensitive", "if raw . is_empty () { break ; }", "\" sparse memory allocations. This is where it gets its name from. That is,\"", "\" by the failure transition to the original state you were at.\"", "\" Returns the underlying \\\"special\\\" state information for this NFA.\"", "self . densify ()", "match self . trans { StateTrans :: Sparse { classes , nexts } => { if i >= nexts . len () { return None ; } let chunk = classes [i / 4] ; let class = chunk . to_ne_bytes () [i % 4] ; let next = StateID :: from_u32_unchecked (nexts [i]) ; i += 1 ; Some ((class , next)) } StateTrans :: One { class , next } => { if i == 0 { i += 1 ; Some ((class , StateID :: from_u32_unchecked (next))) } else { None } } StateTrans :: Dense { class_to_next } => { if i >= class_to_next . len () { return None ; } let class = i . as_u8 () ; let next = StateID :: from_u32_unchecked (class_to_next [i]) ; i += 1 ; Some ((class , next)) } }", "\" report that location as a match.\"", "self . matches . push (Match { pid : self . matches [link_src] . pid , link : StateID :: ZERO , })", "\" Perl of course needs leftmost-first semantics, but they implement it\"", "StateID :: new (self . sparse . len ()) . map_err (| e | { BuildError :: state_id_overflow (StateID :: MAX . as_u64 () , e . attempted () ,) }) ?", "t . next () . as_u32 ()", "state [2 ..] [.. alphabet_len]", "\" [`AhoCorasickBuilder::prefilter`](crate::AhoCorasickBuilder::prefilter)\"", "\" This set has an \\\"inert\\\" and an \\\"active\\\" mode. When inert, the set never\"", "dst [start + usize :: from (classes . get (t . byte ()))]", "state [1]", "pid . as_u32 ()", "3", "self . states . iter_mut ()", "\" Return the pattern ID for this match.\"", "end", "self . add_dead_state_loop () ?", "& self . sparse", "\" a match state.\"", "usize :: from (self . nfa . byte_classes . get (b))", "\" Build an Aho-Corasick contiguous NFA from the given iterator of\"", "u32 :: from_ne_bytes (chunk)", "\" The length of each pattern. This is used to compute the start offset\"", "prefilter :: Builder :: new", "Match :: default ()", "self . nfa . byte_classes . get (t . byte)", "\" When building a leftmost automaton, we proceed as above, but only\"", "| e | { BuildError :: state_id_overflow (StateID :: MAX . as_u64 () , e . attempted () ,) }", "return u32tosid (repr [trans_offset + i * 4 + 3])", "Result < StateID , MatchError >", "noncontiguous :: NFA :: FAIL", "link_dst = new_match_link", "if prev_link == StateID :: ZERO { self . states [prev] . sparse = new_link ; } else { self . sparse [prev_link] . link = new_link ; }", "e", "t . next ()", "\" this on a state that isn't a match results in unspecified behavior.\"", "\" Returns the equivalence classes of bytes found while constructing\"", "Transition { byte , next , link : head , }", "{ if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! (\"anchored start state should be at index 3\") ,) ,) ; } }", "\" states it can have is fewer than a noncontiguous NFA.)\"", "\" the first search, the automaton can instruct the search to move to\"", "core :: iter :: from_fn (move | | match self . trans { StateTrans :: Sparse { classes , nexts } => { if i >= nexts . len () { return None ; } let chunk = classes [i / 4] ; let class = chunk . to_ne_bytes () [i % 4] ; let next = StateID :: from_u32_unchecked (nexts [i]) ; i += 1 ; Some ((class , next)) } StateTrans :: One { class , next } => { if i == 0 { i += 1 ; Some ((class , StateID :: from_u32_unchecked (next))) } else { None } } StateTrans :: Dense { class_to_next } => { if i >= class_to_next . len () { return None ; } let class = i . as_u8 () ; let next = StateID :: from_u32_unchecked (class_to_next [i]) ; i += 1 ; Some ((class , next)) } })", "(matches_len & (1 << 31))", "\" When possible, prefer using [`AhoCorasick`](crate::AhoCorasick) instead of\"", "nexts [i]", "Some", ":: core :: clone :: Clone :: clone (& self . states)", "Some (alink)", "\" A state has a row in this table if and only if `State::dense` is\"", "self . iter_trans (sid) . map (| t | (t . byte , t . next))", "link_dst = self . matches [link_dst] . link", "nnfa . byte_classes () . clone ()", "State :: sparse_trans_len (state)", "for t in nnfa . iter_trans (oldsid) { chunk [len] = classes . get (t . byte ()) ; len += 1 ; if len == 4 { dst . push (u32 :: from_ne_bytes (chunk)) ; chunk = [0 ; 4] ; len = 0 ; } }", "match (& StateID :: ZERO , & self . states [prev] . dense) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! (\"state must not be dense yet\") ,) ,) ; } } }", "\" 'd' (that is, we've \\\"failed\\\" to find a match in this portion of our\"", "self . builder . match_kind . is_leftmost ()", "\" the transitions during a search anyway.\"", "(* left_val == * right_val)", "self . nfa . min_pattern_len", "QueuedSet :: inert", "\" not equal to `StateID::ZERO`. When not zero, there are precisely\"", "if classes [1] == class { return u32tosid (repr [trans_offset + i * 4 + 1]) ; }", "if link_next == StateID :: ZERO || byte < self . sparse [link_next] . byte { let link = self . alloc_transition () ? ; self . sparse [link] = Transition { byte , next , link : link_next , } ; self . sparse [link_prev] . link = link ; } else { match (& byte , & self . sparse [link_next] . byte) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: None ,) ; } } } ; self . sparse [link_next] . next = next ; }", "ByteClassSet :: empty ()", "nnfa . byte_classes ()", "& self . sparse [link_next] . byte", "{ let trans_len = kind . as_usize () ; let classes_len = u32_len (trans_len) ; let trans_offset = o + 2 + classes_len ; for (i , & chunk) in repr [o + 2 ..] [.. classes_len] . iter () . enumerate () { let classes = chunk . to_ne_bytes () ; if classes [0] == class { return u32tosid (repr [trans_offset + i * 4]) ; } if classes [1] == class { return u32tosid (repr [trans_offset + i * 4 + 1]) ; } if classes [2] == class { return u32tosid (repr [trans_offset + i * 4 + 2]) ; } if classes [3] == class { return u32tosid (repr [trans_offset + i * 4 + 3]) ; } } }", "\" transitions stored in a dense fashion, but all other states have their\"", "\" potentially lead to another match. Thus, the actual Aho-Corasick\"", "__self_0", "kind_len + fail_len + classes_len + trans_len", "\" search can, and so to can a leftmost search.\"", "self . builder", "Result < StateID , BuildError >", "self . nfa . sparse [link] . next () == NFA :: FAIL", "State :: read", "f . write_fmt (format_args ! (\"Transition(byte: {0:X?}, next: {1:?}, link: {2:?})\" , self . byte , self . next () . as_usize () , self . link () . as_usize () ,) ,)", "\" representation would be fairly expensive.)\"", "old_len == 1 && ! old . is_match ()", "nnfa . iter_matches (oldsid)", "if self . nfa . sparse [link] . next () == start_uid { self . nfa . sparse [link] . next = NFA :: DEAD ; if dense != StateID :: ZERO { let b = self . nfa . sparse [link] . byte ; let class = usize :: from (self . nfa . byte_classes . get (b)) ; self . nfa . dense [dense . as_usize () + class] = NFA :: DEAD ; } }", "StateID :: from (4u8)", "index_to_state_id . iter ()", "\" NFA is when you need the fastest possible construction time, or when a\"", "start . dense", "sid . as_usize () . checked_add (len) . unwrap ()", "core :: fmt :: Formatter < '_ >", "\" transition is changed to the DEAD state, so that for any undefined\"", "format_args ! (\"\\n\")", "\" transitions. Other states will generally use a sparse representation.\"", "& [SmallIndex]", "[State]", "self . sparse", "StateID :: new (next_avail . as_usize () . checked_sub (1) . unwrap () ,) . unwrap ()", "\" `state` should be the the raw binary encoding of a sparse state. (The\"", "NFA :: builder ()", "\" make up the overwhelming majority of all states in any given\"", "\" that does the least amount of work possible to build itself, and another\"", "\" use aho_corasick::{\"", "self . nfa . states [start_uid]", "& mut core :: fmt :: Formatter", "\"\\nProvides a noncontiguous NFA implementation of Aho-Corasick.\\n\\nThis is a low-level API that generally only needs to be used in niche\\ncircumstances. When possible, prefer using [`AhoCorasick`](crate::AhoCorasick)\\ninstead of a noncontiguous NFA directly. Using an `NFA` directly is typically\\nonly necessary when one needs access to the [`Automaton`] trait implementation.\\n\"", "match (& 0 , & (matches_len & (1 << 31))) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: None ,) ; } } }", "{ :: core :: panicking :: panic (\"internal error: entered unreachable code\" ,) }", "PatternID :: MAX . as_u64 ()", "impl Iterator < Item = Transition > + '_", "u32_len (trans_len)", ":: core :: clone :: Clone :: clone (& self . dense_depth)", "\" Matches stored in linked list for each state.\"", "\"   is_start(sid): sid == start_unanchored_id || sid == start_anchored_id\"", "self . states [sid] . matches = new_match_link", "nfa", "State :: match_len (alphabet_len , state) == 1", "\" This sets every possible transition (all 255 of them) for the given\"", "old . max_match_id", "\"sparse\"", "\" state swap.\"", "\" The length of the shortest pattern in this automaton.\"", "StateID :: new (dst . len ()) . map_err (| e | { BuildError :: state_id_overflow (StateID :: MAX . as_u64 () , e . attempted () ,) })", ":: core :: fmt :: Formatter :: debug_struct_field5_finish (f , \"State\" , \"sparse\" , & self . sparse , \"dense\" , & self . dense , \"matches\" , & self . matches , \"fail\" , & self . fail , \"depth\" , & & self . depth ,)", "o + 2", "self . prefilter = yes", "{ if link == StateID :: ZERO { return None ; } let m = self . matches [link] ; link = m . link ; Some (m . pid) }", "match (& 3 , & old_start_aid . as_usize ()) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! (\"anchored start state should be at index 3\") ,) ,) ; } } }", "\" \\\"root\\\" state.\"", "chunk [len] = repeat", "\" (Adding dense transitions for a state doesn't remove its sparse\"", "\" By why do it this way? So that FAIL is a constant. I don't have any\"", "\" The state to transition to when 'class_to_next' yields a transition\"", "self . nfa . matches . shrink_to_fit ()", "State { fail , match_len , trans }", "format_args ! (\"F {0:06}:\\n\" , NFA :: FAIL . as_usize ())", "if head == StateID :: ZERO || byte < self . sparse [head] . byte { let new_link = self . alloc_transition () ? ; self . sparse [new_link] = Transition { byte , next , link : head , } ; self . states [prev] . sparse = new_link ; return Ok (()) ; } else if byte == self . sparse [head] . byte { self . sparse [head] . next = next ; return Ok (()) ; }", "f . write_fmt (format_args ! (\"{0:?} => {1:?}\" , DebugByte (start) , sid . as_usize () ,) ,)", "2 + alphabet_len", "\" corresponds to 'b'. The match would fail, but the next search starting\"", ":: core :: clone :: Clone :: clone (__self_1)", "ulink", "if old . is_match () { let matches_len = nnfa . iter_matches (oldsid) . count () ; if matches_len == 1 { let pid = nnfa . iter_matches (oldsid) . next () . unwrap () . as_u32 () ; match (& 0 , & (pid & (1 << 31))) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: None ,) ; } } } ; dst . push ((1 << 31) | pid) ; } else { match (& 0 , & (matches_len & (1 << 31))) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: None ,) ; } } } ; dst . push (matches_len . as_u32 ()) ; dst . extend (nnfa . iter_matches (oldsid) . map (| pid | pid . as_u32 ())) ; } }", "0 .. self . nfa . states . len ()", "! is_match", "usize :: from", "P", "u8", "\" `state` should be the the raw binary encoding of a state. (The start\"", "(u8 , StateID)", "\" Note that the NFA doesn't actually make use of these equivalence\"", "noncontiguous :: Builder :: new ()", "[u8]", "link_prev = link_next", "\" NFA. (Indeed, the main [`AhoCorasick`](crate::AhoCorasick) type employs a\"", "if link == StateID :: ZERO { return None ; }", ":: core :: default :: Default :: default ()", "StateTrans :: One", "return u32tosid (repr [trans_offset + i * 4 + 1])", "oldsid == noncontiguous :: NFA :: FAIL", "\" transitions are encoded as dense states.\"", "u32tosid (repr [o + 1])", "self . dense [start ..] [.. alphabet_len]", "if kind == State :: KIND_DENSE { dst . push (kind) ; dst . push (old . fail () . as_u32 ()) ; State :: write_dense_trans (nnfa , oldsid , classes , dst) ? ; } else if kind == State :: KIND_ONE { let t = nnfa . iter_trans (oldsid) . next () . unwrap () ; let class = u32 :: from (classes . get (t . byte ())) ; dst . push (kind | (class << 8)) ; dst . push (old . fail () . as_u32 ()) ; dst . push (t . next () . as_u32 ()) ; } else { dst . push (kind) ; dst . push (old . fail () . as_u32 ()) ; State :: write_sparse_trans (nnfa , oldsid , classes , dst) ? ; }", "format_args ! (\"state must not be dense yet\")", "& & self . byte_classes", "format_args ! (\"equivalence classes are never empty\")", "\" or no match otherwise. Generally speaking, it is impossible for an\"", "self . special", "self . states [dst]", "patterns . into_iter ()", ":: core :: clone :: Clone :: clone (& self . matches)", "new . max_match_id = remap [old . max_match_id]", "link == StateID :: ZERO", "\" patterns.\"", "self . matches [link] . link != StateID :: ZERO", "self . dense [dense . as_usize () + class] = next", ":: core :: clone :: Clone :: clone (& self . byte_classes)", "self . builder . match_kind . is_leftmost_first () && saw_match", "self . nfa . sparse [alink] . next = self . nfa . sparse [ulink] . next", "self . matches [link]", "(1 << 31)", "nnfa . iter_matches (oldsid) . next ()", "StateID :: from_u32_unchecked (nexts [i])", "self . byte_classes . alphabet_len ()", "{ if i >= nexts . len () { return None ; } let chunk = classes [i / 4] ; let class = chunk . to_ne_bytes () [i % 4] ; let next = StateID :: from_u32_unchecked (nexts [i]) ; i += 1 ; Some ((class , next)) }", "QueuedSet :: active ()", "if old_len == 1 && ! old . is_match () { State :: KIND_ONE } else { u32 :: try_from (old_len) . unwrap () }", "\" cheap, it can make sense to always try it even if you aren't sure if it\"", "\" ID (guaranteed to be one more than the ID of the previously allocated\"", "\" entry's ID. If there's no room, then an error is returned.\"", "QueuedSet :: inert ()", "self . matches [new_match_link] . pid", "self . sparse [link_next] . byte", "\" things from the raw binary encoding of the state.\"", "\" searching should stop.\"", "& self . depth", "self . nfa . copy_matches (fail , t . next) ?", "State :: write", "\" none exist, we transition to the dead state, which signals that\"", "self . pattern_lens . len ()", "\" levels, it is still quite large and also results in somewhat mediocre\"", ":: core :: option :: Option :: None", "size_of :: < u32 > ()", ":: core :: option :: Option :: Some (format_args ! (\"state must not be dense yet\") ,)", "while self . matches [link_dst] . link != StateID :: ZERO { link_dst = self . matches [link_dst] . link ; }", "\" this is a no-op.)\"", "\" Because a contiguous NFA uses a single allocation, there is a lot more\"", "2", "next", "self . matches [link_dst]", "self . init_unanchored_start_state ()", "if seen . contains (t . next) { continue ; }", "\" If the given state is not a match state or if the index is out of\"", "if self . nfa . states [sid] . depth . as_usize () >= self . builder . dense_depth { continue ; }", "let Some (ref mut set) = self . set", "repr [o] & 0xFF", "len < 4", "self . nfa . dense", "\" transitions, the search will stop.\"", "! (1 << 31)", "[SmallIndex]", "\" Returns the kind of this state.\"", "State :: write_sparse_trans (nnfa , oldsid , classes , dst) ?", "repr [o + 2 + usize :: from (class)]", "is_leftmost && self . nfa . states [t . next] . is_match ()", "nnfa . prefilter ()", "nnfa . iter_trans (oldsid) . next ()", "\" since it uses so much memory.\"", "self . states [prev] . dense", "format_args ! (\"contiguous::NFA(\\n\")", "nnfa . iter_trans (oldsid)", "dst . push (t . next () . as_u32 ())", "\" process. We allow normal transitions out of the start state, but if\"", "repeat", "\" middle of the encoding of the DEAD state). Since we never need to\"", ":: core :: panicking :: assert_failed", "& old_start_aid . as_usize ()", "\" has already completed, all settings impacting only initial construction\"", "next_avail . as_usize () . checked_sub (3)", "\" assert_eq!(\"", "\" a sparse state, the number of transitions), its transitions and any\"", "\" This only includes the low byte.\"", "& self . nfa", "byte_classes . alphabet_len ()", "\" See\"", "\" this is really the only convenient place to compute and store this\"", "\" same transition lookup at 'fail'.\"", "head == StateID :: ZERO", "nnfa . states () . iter ()", "self . nfa . init_full_state (NFA :: DEAD , NFA :: DEAD) ?", ":: core :: clone :: AssertParamIsClone < StateID >", "self . nfa . states [start_aid] . fail", "\" an order of magnitude less memory. The main reason to use a noncontiguous\"", "BTreeSet :: new ()", "\" representation to the given `dst` slice. `classes` should be the byte\"", "nfa . repr [newsid . as_usize () ..]", ":: core :: fmt :: Formatter :: debug_struct_field4_finish (f , \"Compiler\" , \"builder\" , & self . builder , \"prefilter\" , & self . prefilter , \"nfa\" , & self . nfa , \"byteset\" , & & self . byteset ,)", "& i", "return u32tosid (repr [trans_offset + i * 4 + 2])", "i >= class_to_next . len ()", "self . alloc_match ()", "sparse_transitions (self . iter_trans (sid) . map (| t | (t . byte , t . next)) ,)", "\" slice may extend past the end of the encoding of the state.) If this\"", "& self . set", "match_len", "sparse_transitions (self . transitions ()) . filter (| & (_ , _ , sid) | sid != NFA :: FAIL) . enumerate ()", "\" states there are always 0 too. It's not that we need all of the\"", "\"dense\"", ":: core :: default :: Default", "f . write_fmt (format_args ! (\"{0:06}({1:06}): \" , sid . as_usize () , state . fail . as_usize () ,) ,)", "\"     nfa::contiguous::NFA,\"", "[u32]", "self . nfa . sparse [link] . next", "sid == NFA :: DEAD", "f . write_fmt (format_args ! (\"Match(pid: {0:?}, link: {1:?})\" , self . pattern () . as_usize () , self . link () . as_usize () ,) ,)", "self . is_match (sid)", "self . dense [s . dense . as_usize () + class]", "nexts", "& [State]", "if kind == State :: KIND_ONE { (0 , 1) } else { let trans_len = State :: sparse_trans_len (state) ; let classes_len = u32_len (trans_len) ; (classes_len , trans_len) }", "core :: iter :: repeat (NFA :: FAIL)", "o + 2 ..", "state . fmt (f)", "state . sparse", "(self . repr . len () * size_of :: < u32 > ()) + (self . pattern_lens . len () * size_of :: < SmallIndex > ()) + self . prefilter . as_ref () . map_or (0 , | p | p . memory_usage ())", "\" state, if one exists.\"", "old_start_aid . as_usize ()", "self . pattern_lens [pid] . as_usize ()", "matches_len . as_u32 ()", "\" Since the DEAD and FAIL states are always the first two states and\"", "\" Returns the depth of this state. That is, the number of transitions\"", "start_uid", "StateTrans :: Dense", "State :: match_len", "\" the longest proper suffix of the pattern being searched. The failure\"", "\" This only applies when using [`Builder::build`] and not\"", "\" The main difference between a noncontiguous NFA and a contiguous NFA is\"", "state [2] . as_usize ()", "\" be the byte classes computed for the noncontiguous NFA that the given\"", "\" containing all of the transitions for this state.\"", "\" contiguous NFA is the best choice.\"", "new . max_special_id = remap [old . max_special_id]", "StateID :: new (self . matches . len ()) . map_err (| e | { BuildError :: state_id_overflow (StateID :: MAX . as_u64 () , e . attempted () ,) })", "queue . push_back (t . next)", "VecDeque :: new", "\" that is also a match implies that we should never restart the search\"", "chunk = [0 ; 4]", "u32 :: from (classes . get (t . byte ()))", "State < 'a >", "u32tosid", "self . nfa . sparse [link] . next = start_uid", "self . special . max_special_id", "size_of :: < u32 >", "for state in self . states . iter_mut () { state . fail = map (state . fail) ; let mut link = state . sparse ; while link != StateID :: ZERO { let t = & mut self . sparse [link] ; t . next = map (t . next) ; link = t . link ; } if state . dense != StateID :: ZERO { let start = state . dense . as_usize () ; for next in self . dense [start ..] [.. alphabet_len] . iter_mut () { * next = map (* next) ; } } }", "if self . builder . prefilter { self . prefilter . add (pat) ; }", "self . nfa . init_full_state (NFA :: DEAD , NFA :: DEAD)", "\" state that isn't explicitly defined. When one transitions into the FAIL\"", "self . nfa . matches", "\" identifier.\"", "classes", "\" transition lookups on it faster. (Which is worth doing because it's\"", "self . matches . len ()", ":: core :: clone :: AssertParamIsClone < PatternID >", "\"noncontiguous\"", "\" automaton. Since using this method requires that initial construction\"", "core :: iter :: repeat", "for & newsid in index_to_state_id . iter () { if newsid == NFA :: FAIL { continue ; } let state = & mut nfa . repr [newsid . as_usize () ..] ; State :: remap (nfa . alphabet_len , & index_to_state_id , state) ? ; }", "\" dense format. Otherwise, the choice between dense and sparse will be\"", "PatternID :: new", "\"   DEAD, FAIL, START, START, (MATCH | NON-MATCH)...\"", "self . dense [dense . as_usize () + class]", "u32_len", "\" We put DEAD before FAIL so that DEAD is always 0. We repeat this\"", "nfa . repr . shrink_to_fit ()", "nnfa . match_kind ()", "NFA { repr : :: alloc :: vec :: Vec :: new () , pattern_lens : nnfa . pattern_lens_raw () . to_vec () , state_len : nnfa . states () . len () , prefilter : nnfa . prefilter () . map (| p | p . clone ()) , match_kind : nnfa . match_kind () , alphabet_len : byte_classes . alphabet_len () , byte_classes , min_pattern_len : nnfa . min_pattern_len () , max_pattern_len : nnfa . max_pattern_len () , special : Special :: zero () , }", "new_link", "sid == self . special . start_anchored_id", "\" This is where failure transitions come in. Instead of dying at S3 in\"", "StateID :: from_u32_unchecked (class_to_next [i])", "\" automaton. Effectively, it creates the basic structure of the\"", "self . fail", "\" [`Automaton::try_find`]:\"", "newsid . as_usize () ..", "self . dense", "\" The equivalence classes for this NFA. All transitions, dense and\"", "format_args ! (\"F {0:06}:\\n\" , sid . as_usize ())", "\" So all we need to do is move all of the MATCH states so that they\"", "self . nfa . add_match (prev , pid)", "\" already been seen, which is of course therefore not the leftmost match.\"", "if kind == State :: KIND_DENSE { let next = u32tosid (repr [o + 2 + usize :: from (class)]) ; if next != NFA :: FAIL { return next ; } } else if kind == State :: KIND_ONE { if class == repr [o] . low_u16 () . high_u8 () { return u32tosid (repr [o + 2]) ; } } else { let trans_len = kind . as_usize () ; let classes_len = u32_len (trans_len) ; let trans_offset = o + 2 + classes_len ; for (i , & chunk) in repr [o + 2 ..] [.. classes_len] . iter () . enumerate () { let classes = chunk . to_ne_bytes () ; if classes [0] == class { return u32tosid (repr [trans_offset + i * 4]) ; } if classes [1] == class { return u32tosid (repr [trans_offset + i * 4 + 1]) ; } if classes [2] == class { return u32tosid (repr [trans_offset + i * 4 + 2]) ; } if classes [3] == class { return u32tosid (repr [trans_offset + i * 4 + 3]) ; } } }", "! self . is_dead (sid)", "\" While the sparse representation keeps memory usage to somewhat reasonable\"", "self . nfa . alloc_dense_state () ?", "(StateTrans :: Dense { class_to_next } , fail)", "state . depth () . as_usize ()", "self . matches", "nnfa . iter_matches (oldsid) . map (| pid | pid . as_u32 ())", "self . states . len () * core :: mem :: size_of :: < State > () + self . sparse . len () * core :: mem :: size_of :: < Transition > () + self . matches . len () * core :: mem :: size_of :: < Match > () + self . dense . len () * StateID :: SIZE + self . pattern_lens . len () * SmallIndex :: SIZE + self . prefilter . as_ref () . map_or (0 , | p | p . memory_usage ())", "self . max_pattern_len", "u32tosid (repr [trans_offset + i * 4 + 1])", "\" This is useful for reading states consecutively, e.g., in the Debug\"", "matches_len == 1", "f . write_fmt (format_args ! (\"noncontiguous::NFA(\\n\")) ?", "old_to_new [state [2] . as_usize ()]", "\" Copy matches from the `src` state to the `dst` state. This is useful\"", "\" times when filling in failure transitions.\"", "\" corresponds to a match, since its failure transition to S5 is itself\"", "| p | self . sparse [p] . link", "self . alloc_transition ()", "\" empty string or not.\"", "Builder { noncontiguous : noncontiguous :: Builder :: new () , dense_depth : 2 , byte_classes : true , }", "\" it is the only way to visit the same state twice. Otherwise, this\"", "i >= nexts . len ()", ":: alloc :: vec :: Vec :: new", "f . write_fmt (format_args ! (\"byte classes: {0:?}\\n\" , self . byte_classes)) ?", "classes [0] == class", "(self . repr . len () * size_of :: < u32 > ()) + (self . pattern_lens . len () * size_of :: < SmallIndex > ())", "self . nfa . next_link (start_uid , prev_link)", "\" bounds, then this has unspecified behavior.\""}
  [split-expanded-lib] DeclsVisitor: Visiting module 'packed'. Required imports for module: {"self . config . force", "self . imp", "\"assertion failed: bucket < 8\"", "pid . as_usize ()", "cur = cur . add (V :: BYTES)", "candidate . interleave_low_8bit_lanes (swapped)", "\" example, when using a 256-bit vector, Slim Teddy reads 32 bytes at a timr\"", "vqtbl1q_u8 (self , indices)", "\" The order of patterns in each bucket is significant. Namely, they are\"", "{ (SearchKind :: RabinKarp , 0) }", "hicand4", "rk", "Searcher", "target_feature", "candidate . interleave_high_8bit_lanes (swapped)", "if ! c . is_zero () { if let Some (m) = self . teddy . verify (cur . sub (3) , end , c) { return Some (m) ; } }", "\" Fat Teddy uses 16 buckets instead of 8, but reads half as many bytes (as\"", "if ! (haystack [at ..] . len () >= self . minimum_len) { :: core :: panicking :: panic (\"assertion failed: haystack[at..].len() >= self.minimum_len\" ,) }", "start . add (2)", "match self { SearchKind :: Teddy (__self_0) => { :: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , \"Teddy\" , & __self_0 ,) } SearchKind :: RabinKarp => { :: core :: fmt :: Formatter :: write_str (f , \"RabinKarp\") } }", "\" Returns the length, in bytes, of the shortest pattern added.\"", ":: alloc :: vec :: from_elem", "\" this searcher, according to its match semantics, in the given haystack.\"", "! (1 << bit)", "! (patterns . len () >= 1)", "if let Some (m) = self . teddy . verify (cur . sub (3) , end , c) { return Some (m) ; }", "pattern . is_empty ()", "order", "\" There are a few different ways to go about this. One approach is to use an\"", "self . span . start > self . span . end", ":: core :: default :: Default :: default ()", "format_args ! (\"{0:02}: {1:08b}\" , i , self . hi [i])", "self . patterns . is_empty ()", ":: core :: panicking :: panic (\"assertion failed: patterns.len() >= 1\")", "self . by_id . get_unchecked (id . as_usize ())", "x . add (4)", "SlimNeon :: < 4 > :: new_unchecked (patterns)", "start . add (1)", "Builder :: new () . extend (patterns)", "\" this crate.\"", "{ self . span . start = m . end () ; Some (m) }", "1 .. hash_len", "& self . rabinkarp", "\" trait object for use at search time.\"", "SlimNeon < 4 >", "Slim { teddy , masks }", "\" supports, it follows that there must be some kind of indirection at search\"", "\" The patterns we are searching for.\"", "\" Perform a bitwise 'or' of this vector and the one given and return\"", "\" operates on the full 128-bit vector and not on each 64-bit half.) I didn't\"", "self . patterns . memory_usage () + self . rabinkarp . memory_usage ()", ":: core :: panicking :: AssertKind :: Ne", "masks [3] . lo . shuffle_bytes (hlo)", "if patlimit && patterns . len () > 16 { }", "\" provided by the caller. For leftmost-longest, patterns are provided in\"", "match (& (0) , & (patterns . len ())) { (left_val , right_val) => { if * left_val == * right_val { let kind = :: core :: panicking :: AssertKind :: Ne ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! (\"Teddy requires at least one pattern\") ,) ,) ; } } }", "! bytes . is_empty ()", ":: alloc :: __export :: must_use", ":: core :: fmt :: Formatter :: debug_struct_field4_finish (f , \"RabinKarp\" , \"patterns\" , & self . patterns , \"buckets\" , & self . buckets , \"hash_len\" , & self . hash_len , \"hash_2pow\" , & & self . hash_2pow ,)", "for (i , byte) in self . bytes () . iter () . take (len) . enumerate () { nybs [i] = byte & 0xF ; }", "& self . only_teddy_fat", "self . by_id . push (bytes . to_vec ())", ":: core :: fmt :: Formatter :: debug_struct_field2_finish", "\" several buckets to hopefully make the confirmation step faster.\"", "\" assert_eq!(&MatchKind::LeftmostFirst, searcher.match_kind());\"", ":: core :: clone :: Clone :: clone (& self . only_fat)", "teddym . end ()", "\" heuristic for refusing construction of a Teddy searcher. The point here\"", "\" `true` means that 256-bit vectors will be used. As with `fat`, if\"", "\" The bucket index must be less than or equal to `self.buckets.len()`.\"", "\" semantics are used, then the patterns are sorted by their pattern ID\"", "\" This is guaranteed to be greater than zero.\"", "hash", "\" is some bit-shifting done in the critical part of verification that could\"", "map . get (& lonybs)", "self . force = None", "\" The purpose of this function is just to be able to do arithmetic, i.e.,\"", "Some (ForceAlgorithm :: Teddy)", "& haystack [at ..]", "(BUCKETS - 1)", "\" only if the byte occurring at the jth lane in `chunk` is in the bucket\"", "SearchKind :: Teddy (teddy)", "\" Specifically, in a naive multi-pattern matcher, the following is\"", "\" Set the match semantics for this configuration.\"", "self . search_kind", "prev2", "teddy :: Searcher", "& & self . total_pattern_bytes", "IntoIterator < Item = P >", "nybs", "Mask :: members4 (chunk , self . masks)", "nybs [i] = byte & 0xF", ":: core :: fmt :: Formatter :: debug_struct_field4_finish (f , \"Searcher\" , \"patterns\" , & self . patterns , \"rabinkarp\" , & self . rabinkarp , \"search_kind\" , & self . search_kind , \"minimum_len\" , & & self . minimum_len ,)", "P", "self . only_teddy_256bit", ":: core :: panicking :: panic (\"assertion failed: bucket < 16\")", ":: core :: fmt :: Formatter :: debug_struct_field1_finish (f , \"SlimNeon\" , \"slim128\" , & & self . slim128 ,)", "y . cast :: < u16 > () . read_unaligned ()", "& mut core :: fmt :: Formatter < '_ >", "\" is shorter than `len`, then this panics.\"", "self . patterns", "haystack [at .. at + self . hash_len]", "self . lo [byte_lo + 16] |= 1 << bucket", "& self . hash_len", "Option < bool >", "\" Essentially, instead of representing a match at byte offsets, we use\"", "\" Creates a new searcher using \\\"slim\\\" Teddy with 128-bit\"", "self . lo [byte_lo + 16]", "needle . as_ptr ()", ":: alloc :: fmt :: format (format_args ! (\"{0:02}: {1:08b}\" , i , self . lo [i]) ,)", "Some (unsafe { SlimNeon :: < 3 > :: new_unchecked (patterns) })", "self . patterns . add (pattern)", "& 'p Patterns", "y . read ()", "\"       return Match(p.id(), i, i + p.bytes().len())\"", "Match :: new (id , at .. at + pat . len ())", "\" the vector size) instead of the full size of a vector per iteration. For\"", "\" The lifetime `'p` corresponds to the lifetime of the collection of patterns\"", "if ! (BUCKETS == 8 || BUCKETS == 16) { { :: core :: panicking :: panic_fmt (format_args ! (\"Teddy only supports 8 or 16 buckets\") ,) ; } }", "\" is that too many patterns can overwhelm Teddy. But this can be disabled\"", "locand3", "\" Return an iterator of non-overlapping occurrences of the patterns in\"", "\" A fat Teddy mask is like a slim Teddy mask, except that instead of\"", ":: core :: clone :: Clone :: clone (& self . search_kind)", "x . add (n . wrapping_sub (4))", "crate :: Match :: new", "\" candidates (which are fed into the verification routines).\"", "usize :: try_from (self . offset_from (origin))", ":: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , \"Teddy\" , & __self_0 ,)", "Teddy :: new (patterns)", "self . only_teddy_fat", "res0prev0 . and (res1)", "! (V :: BYTES <= self . hi . len ())", "\" Perform a bitwise 'and' of this vector and the one given and return\"", "match self . build_teddy (Arc :: clone (& patterns)) { None => return None , Some (teddy) => teddy , }", "< [Vec < PatternID , > ; BUCKETS] > :: try_from (:: alloc :: vec :: from_elem (:: alloc :: vec :: Vec :: new () , BUCKETS) ,)", "\" https://en.wikipedia.org/wiki/Rabin%E2%80%93Karp_algorithm\"", "match self . config . force { None | Some (ForceAlgorithm :: Teddy) => { let teddy = match self . build_teddy (Arc :: clone (& patterns)) { None => return None , Some (teddy) => teddy , } ; let minimum_len = teddy . minimum_len () ; (SearchKind :: Teddy (teddy) , minimum_len) } Some (ForceAlgorithm :: RabinKarp) => { (SearchKind :: RabinKarp , 0) } }", "prev . wrapping_sub ((old_byte as usize) . wrapping_mul (self . hash_2pow)) . wrapping_shl (1) . wrapping_add (new_byte as usize)", "(V :: BYTES <= self . hi . len ())", "& __self_0", "SlimNeon :: < 3 > :: new_unchecked", "\" significant byte of `vector2` into the least significant position of\"", "\" let haystack = \\\"foofoobar\\\";\"", "V :: BYTES + (BYTES - 1)", "r1", "\" variants will be used. One might use one of the four slim 128-bit vector\"", "vreinterpretq_u64_u8 (vpmaxq_u8 (self , self))", "Builder :: new ()", "UnwindSafe", "end", "\" use aho_corasick::{packed::{MatchKind, Searcher}, PatternID};\"", "self . teddy . verify (cur . sub (3) , end , c)", "if patlimit && patterns . len () > 64 { return None ; }", "id . as_usize () % BUCKETS", ":: alloc :: __export :: must_use ({ :: alloc :: fmt :: format (format_args ! (\"{0:02}: {1:08b}\" , i , self . hi [i]) ,) })", "\" The trait is highly constrained to low level vector operations needed for\"", "self . order . push (id)", "\" Basic usage:\"", "self . config . only_teddy_256bit", "\" assert_eq!(9, mat.end());\"", "\" must either be in bounds or at most one byte past the end of the\"", "self", "Some (true)", "SlimNeon :: < 4 > :: new", "\" Look for a match starting at the `V::BYTES` at and after `cur`. If\"", "\"teddy\"", "\" Shift this vector to the left by three bytes and shift the three most\"", "\" patterns:\"", "t . buckets [bucket]", "at .. at + self . hash_len", "\" actual patterns when using Teddy.\"", "if self . i >= self . patterns . len () { return None ; }", ":: core :: panicking :: panic (\"assertion failed: BITS <= 7\")", "\" Namely, among the patterns in a collection, if they are matched in\"", "\" * The distance between `x` and `x+n` must not overflow `isize`. Similarly\"", "\" A pattern string can be found by its `PatternID`.\"", "Mask < V >", ":: core :: fmt :: Formatter :: debug_struct_field3_finish (f , \"Builder\" , \"config\" , & self . config , \"inert\" , & self . inert , \"patterns\" , & & self . patterns ,)", "\" Call the provided function for each 64-bit lane in this vector. The\"", "\" An undocumented method for forcing the use of the Fat Teddy algorithm.\"", "Teddy < BUCKETS >", "\" Stated differently, this behaves as if `self` and `vector2` were\"", "self . pid", "\" [support]: https://github.com/rust-lang/rust/issues/60551\"", "self . order . sort ()", "\" A convenience function for building `N` vector masks from a fat\"", "& self . 0", "\" When there are multiple possible leftmost matches, the match\"", "bit / BUCKETS", "\" bits correspond to an addition 8 buckets. So that a bitset `00100010` has\"", "\" The collection of patterns, indexed by their identifier.\"", "u16 :: MAX", "unsafe { self . imp . find (hayptr . add (at) , hayptr . add (haystack . len ())) ? }", "* prev0 = res0", "\" assert_eq!(vec![PatternID::ZERO], matches);\"", "\" for this haystack.\"", "\" searchers, then the builder will stop accumulating patterns and render\"", "\" 8 or 16, although it is technically possible. The main hiccup is that there\"", "self . only_256bit == Some (true)", "haystack [span] . len () < teddy . minimum_len ()", "cand1", ":: core :: clone :: Clone :: clone (& self . only_256bit)", "\" # } else {\"", "slim128", "\" tricky given Rust's [current support for const generics][support].\"", "if at + self . hash_len > haystack . len () { return None ; }", ":: core :: fmt :: Formatter :: debug_struct_field3_finish (f , \"Builder\" , \"only_fat\" , & self . only_fat , \"only_256bit\" , & self . only_256bit , \"heuristic_pattern_limits\" , & & self . heuristic_pattern_limits ,)", "let Some (m) = self . teddy . verify (cur . sub (1) , end , c)", "cur = end . sub (V :: Half :: BYTES)", "pat", ":: core :: cmp :: Eq", "\" A builder for constructing a Teddy matcher.\"", "\" Look for the leftmost occurrence of any pattern in this search in the\"", "\" Returns the approximate total amount of heap used by these patterns, in\"", "\"assertion failed: hash_len >= 1\"", "..", "\" If `i` is the index of corresponding lanes, `A` is this vector, `B` is\"", "mask_builders", "\"     if haystack[i..].starts_with(p.bytes()):\"", "minimum_len", "len", "\"     PatternID::must(0),\"", "\" object, but they may.\"", "c . is_zero ()", "\" built but the haystack is smaller than ~34 bytes, then Teddy might not\"", "while x < xend { let vx = x . cast :: < u32 > () . read_unaligned () ; let vy = y . cast :: < u32 > () . read_unaligned () ; if vx != vy { return false ; } x = x . add (4) ; y = y . add (4) ; }", "\" #     target_arch = \\\"x86_64\\\", target_arch = \\\"aarch64\\\",\"", "self . hash_len", "\" support fat Teddy.\"", "& self . only_teddy_256bit", "Send", "patlimit", ":: core :: fmt :: Formatter :: debug_struct_field3_finish (f , \"Searcher\" , \"imp\" , & self . imp , \"memory_usage\" , & self . memory_usage , \"minimum_len\" , & & self . minimum_len ,)", "(cand1 , cand2)", "prev1 = V :: splat (0xFF)", "SlimMaskBuilder", "hash . wrapping_shl (1)", "(BUCKETS == 8 || BUCKETS == 16)", "f . debug_struct (\"FatMaskBuilder\") . field (\"lo\" , & parts_lo) . field (\"hi\" , & parts_hi)", "return self . find_in_slow (haystack , span)", "\" #     assert!(example().is_none());\"", "mask_builders . iter_mut ()", "self . 0", "unsafe { is_equal_raw (haystack . as_ptr () , needle . as_ptr () , needle . len ()) }", "\" Returns the minimum length of a haystack that is required in order for\"", "bucket . iter ()", "ForceAlgorithm :: Teddy", "\" only reading 8 bytes at a time. It's not clear how well it would work, but\"", "\" A generic data structure for doing \\\"fat\\\" Teddy verification.\"", "\" searches and to construct the searchers themselves. Namely, this permits\"", "patterns . len () >= 1", "self . order", "\" patterns. In order to do full verification, callers must provide the\"", "MatchKind", "vx != vy", "cur = cur . add (V :: Half :: BYTES)", "patterns . len () > 64", "\" See `Fat<V, 1>::candidate`.\"", "\"LeftmostLongest\"", "pid", "SlimNeon :: < 2 > :: new (& patterns)", "& Teddy < 8 >", "Fat < V , BYTES >", "{ let (order , by_id) = (& mut self . order , & mut self . by_id) ; order . sort_by (| & id1 , & id2 | { by_id [id1] . len () . cmp (& by_id [id2] . len ()) . reverse () }) ; }", "\" variants into a union. This is essentially isomorphic to the dynamic\"", "& Teddy < 16 >", "\" Use leftmost-longest match semantics, which reports leftmost matches.\"", "\" bytes from the current chunk. This permits aligning the result of\"", "\" assert_eq!(6, mat.end());\"", "patterns . iter ()", ":: core :: clone :: Clone :: clone (& self . total_pattern_bytes ,)", "\" may be increased.\"", "let Some (t) = f (1 , lane)", "\" given bucket must be in the range 0-15.\"", "self . find_in_slow (haystack , span)", ":: core :: fmt :: Formatter :: debug_struct_field3_finish (f , \"FindIter\" , \"searcher\" , & self . searcher , \"haystack\" , & self . haystack , \"span\" , & & self . span ,)", "\" Returns the ID of the pattern that matched.\"", "start . add (3)", "if let Some (m) = self . teddy . verify (cur , end , c) { return Some (m) ; }", "if let Some (m) = self . find_one (cur , end , & mut prev0 , & mut prev1 , & mut prev2) { return Some (m) ; }", "Builder { config , inert : false , patterns : Patterns :: new () , }", "generic :: Slim :: < uint8x16_t , 2 , > :: new (Arc :: clone (patterns))", "if patlimit && patterns . len () > 32 { }", "(self as * const T) . as_usize ()", "\" `i`. Each candidate returned corresponds to the first and second bytes\"", "\" Return the first occurrence of any of the patterns in this searcher,\"", "\" heuristics would otherwise refuse construction.\"", "self . candidate (cur , prev0 , prev1 , prev2)", "\" then check whether that hash corresponds to the same hash for any of the\"", "doc", ":: alloc :: vec :: from_elem (:: alloc :: vec :: Vec :: new () , NUM_BUCKETS ,)", "& NUM_BUCKETS", "self . find_in (haystack , Span :: from (0 .. haystack . len ()))", "\" Verify whether there are any matches starting at `at` in the given\"", "f . debug_struct (\"FatMaskBuilder\") . field (\"lo\" , & parts_lo)", "Patterns", "self . total_pattern_bytes += bytes . len ()", "self . teddy . verify (cur , end , c)", ":: core :: fmt :: Formatter :: debug_struct_field3_finish", "V :: load_unaligned (self . lo [..] . as_ptr ())", "self . only_teddy_fat = yes", "hicand3", "\" claim.\"", "Self", "PatternID :: new", "\" This panics when `haystack[at..].len()` is less than the minimum length\"", "dyn SearcherT", "\" Conceptually it would be nice if we could have a\"", "Span :: from", "Slim < V , 1 >", "vpmaxq_u8 (self , self)", "patterns . len () > 32", "m . end ()", "Some (unsafe { SlimNeon :: < 2 > :: new_unchecked (patterns) })", "fmt :: Formatter < '_ >", "Teddy < 16 >", "teddym", "\" A match type specialized to the Teddy implementations below.\"", "\" (`inline(always)` cannot be used with target_feature.)\"", "\" Swap the 128-bit lanes in this vector.\"", "if ! (self . by_id . len () <= u16 :: MAX as usize) { :: core :: panicking :: panic (\"assertion failed: self.by_id.len() <= u16::MAX as usize\" ,) }", "[SlimMaskBuilder ; BYTES]", "\"haystack\"", "\" Return the pattern with the given identifier. If such a pattern does\"", "& mut V", "RabinKarp { patterns : :: core :: clone :: Clone :: clone (& self . patterns) , buckets : :: core :: clone :: Clone :: clone (& self . buckets) , hash_len : :: core :: clone :: Clone :: clone (& self . hash_len) , hash_2pow : :: core :: clone :: Clone :: clone (& self . hash_2pow) , }", "(& (0) , & (patterns . minimum_len ()))", "\" `0`) in which it was added. The offsets in the `Match` will be relative\"", "\" For leftmost-first, patterns are provided in the same order as were\"", ":: core :: clone :: Clone :: clone (& self . heuristic_pattern_limits ,)", "\" byte occurring at `at + j` in `cur` is in the bucket `i`.\"", "\" in cases where the caller knows better.\"", "\" When `bucket >= 8`.\"", "Some ((id , p))", "Patterns { kind : MatchKind :: default () , by_id : :: alloc :: vec :: Vec :: new () , order : :: alloc :: vec :: Vec :: new () , minimum_len : usize :: MAX , total_pattern_bytes : 0 , }", "\" * Both `start` and `end` must point to the same allocated object and\"", "self . hi [byte_hi]", "\" Returns the match semantics used by these patterns.\"", "\" The factor to subtract out of a hash before updating it with a new\"", "haystack . as_ref ()", "candidate . for_each_64bit_lane (# [inline (always)] | _ , chunk | { let result = self . verify64 (cur , end , chunk) ; cur = cur . add (8) ; result } ,)", "& 'a [u8]", "| & id1 , & id2 | { by_id [id1] . len () . cmp (& by_id [id2] . len ()) . reverse () }", "left_val", "\" Generally, a matcher isn't built if the necessary CPU features aren't\"", "\"     .build()?;\"", "core :: mem :: size_of :: < (Hash , PatternID) > ()", "__self_discr", "BUCKETS == 16", "at + pat . len ()", "\" given bucket must be in the range 0-7.\"", "if true { if ! (BITS <= 7) { :: core :: panicking :: panic (\"assertion failed: BITS <= 7\") } }", "\" given by the `start` and `end` pointers.\"", "& self . teddy", "if cur < end { cur = end . sub (V :: Half :: BYTES) ; prev0 = V :: splat (0xFF) ; prev1 = V :: splat (0xFF) ; if let Some (m) = self . find_one (cur , end , & mut prev0 , & mut prev1) { return Some (m) ; } }", "\" purposes. In reality, options are automatically determined by the nature\"", "SlimNeon :: < 4 > :: new_unchecked", "(:: alloc :: vec :: Vec :: new () , :: alloc :: vec :: Vec :: new () ,)", "\" corresponding to the pattern that appeared earlier when constructing\"", "Option < Searcher >", "\"span\"", "\" This returns true if and only if `*x.add(i) == *y.add(i)` for all\"", "\" all bits set to zero is returned.\"", "c", "\" use aho_corasick::{packed::{MatchKind, Searcher}, PatternID, Span};\"", "SearcherT", "\"assertion failed: pid.as_usize() < self.patterns.len()\"", "\" instruction.\"", "Some", "\" default, leftmost-first match semantics are used.\"", "if self . patterns . len () >= PATTERN_LIMIT { self . inert = true ; self . patterns . reset () ; return self ; }", "\" The patterns we're searching for.\"", "* prev0", "* prev1", "teddy . buckets . iter ()", "if let Some (m) = self . teddy . verify (cur . sub (2) , end , c) { return Some (m) ; }", "Copy", "\" do a careful survey of NEON to see if it could easily support these\"", "\" The masks should correspond to the masks computed for the first and\"", "match (& (0) , & (patterns . minimum_len ())) { (left_val , right_val) => { if * left_val == * right_val { let kind = :: core :: panicking :: AssertKind :: Ne ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! (\"Teddy does not support zero-length patterns\") ,) ,) ; } } }", "& teddy", "\" enum. It works fine, but in my experiments, this generally results in worse\"", "\" future, more knobs may be made available.\"", "128", "self . lo", "\" matching more patterns or matching more bytes in the haystack at once.\"", "parts_hi . push (:: alloc :: __export :: must_use ({ :: alloc :: fmt :: format (format_args ! (\"{0:02}: {1:08b}\" , i , self . hi [i]) ,) }) ,)", "& & self . slim128", "Some (Match { pid , start , end })", "\" When `V` represents a vector bigger than what `MaskBytes` can contain.\"", ":: core :: clone :: Clone :: clone (& self . config)", "f . debug_struct (\"Pattern\")", "Mask { lo : :: core :: clone :: Clone :: clone (& self . lo) , hi : :: core :: clone :: Clone :: clone (& self . hi) , }", "Some (Match :: new (id , at .. at + pat . len ()))", "& self . buckets", "core :: mem :: size_of :: < Vec < (Hash , PatternID) > >", "patterns", "\" minimum length required by this searcher.\"", "self . i >= self . patterns . len ()", "\" used. For Slim Teddy, the bitsets in the lower half are the same as the\"", "self . start", "\" patterns we're looking for.\"", "bucket", ":: core :: clone :: Clone :: clone (& self . hash_2pow)", "\"lit\"", "SlimNeon < 3 >", "\"only_fat\"", "\" Each mask is 32 bytes wide, and at the time of writing, only 256-bit vectors\"", "\" from the previous chunk (`vector2`) with the first `Self::BYTES - 3`\"", "\" # Notes\"", "self . add (p)", "\"Config\"", "\" them is at least equal to `V::BYTES`. That is, it must always be valid\"", "f . debug_struct (\"SlimMaskBuilder\")", ":: core :: marker :: StructuralPartialEq", "\" bytes.\"", "& 'b B", "self . minimum_len = usize :: MAX", "\" match semantics (either leftmost-first or leftmost-longest), then one can\"", "\" This panics if any of the patterns in the collection are empty, or if\"", "hash = self . update_hash (hash , haystack [at] , haystack [at + self . hash_len])", "cur . add (bit / BUCKETS)", "n", "FatVector", "\" while the lifetime `'h` refers to the lifetime of the haystack being\"", "span . start", "Pattern (& self . by_id [id])", "\" # ))) {\"", "\" does not need to be aligned.\"", "\"assertion failed: V::BYTES <= self.lo.len()\"", "()", "\" work.\"", "& self . force", "\" the given position.\"", "masks [3]", "\" repeating the bitsets in the high and low 128-bits in 256-bit vectors, the\"", "match self { ForceAlgorithm :: Teddy => ForceAlgorithm :: Teddy , ForceAlgorithm :: RabinKarp => ForceAlgorithm :: RabinKarp , }", ":: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! (\"Teddy requires at least one pattern\") ,) ,)", "u32", "self . bytes () . iter ()", "teddym . end () . as_usize () . wrapping_sub (hayptr . as_usize ())", "r1 . for_each_low_64bit_lane (r2 , # [inline (always)] | _ , chunk | { let result = self . verify64 (cur , end , chunk) ; cur = cur . add (4) ; result } ,)", "\" Returns true if this pattern is a prefix of the given bytes.\"", "while cur <= end . sub (V :: BYTES) { if let Some (m) = self . find_one (cur , end , & mut prev0 , & mut prev1 , & mut prev2) { return Some (m) ; } cur = cur . add (V :: BYTES) ; }", "(1 << bit)", "pid . as_usize () < self . patterns . len ()", "byte_hi", "bytes . is_empty ()", "self . candidate (cur)", "\" Look for an occurrences of the patterns in this finder in the haystack\"", "\" variant, select the variant we want at build time and convert it to a\"", "at + self . hash_len", "\" A generic data structure for doing \\\"slim\\\" Teddy verification.\"", "end . distance (start)", "\" may not necessarily correspond to the order provided by the caller.\"", "match (& self . hash_len , & bytes . len ()) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: None ,) ; } } }", "self . order . len ()", "Arc :: new (patterns)", "new_byte as usize", "\" be able to run.\"", "xend . cast :: < u32 > () . read_unaligned ()", "\" This is guaranteed to be at least one.\"", "self . buckets . get_unchecked (bucket)", "f . debug_struct (\"SlimMaskBuilder\") . field (\"lo\" , & parts_lo) . field (\"hi\" , & parts_hi)", "\" is set if and only if the nybble `j` is in the bucket `i` at a particular\"", "vdupq_n_u8", "core :: cmp :: min", "\"force\"", "\" The lifetime `'s` refers to the lifetime of the underlying [`Searcher`],\"", "locand3 . and (hicand3)", "bucket < 16", "\" When there are multiple possible leftmost matches, the longest match\"", ":: alloc :: vec :: from_elem (0 , len)", "\" Clears all heap memory associated with this collection of patterns and\"", "r2", "V :: load_unaligned (cur)", "if cur < end { cur = end . sub (V :: Half :: BYTES) ; prev0 = V :: splat (0xFF) ; if let Some (m) = self . find_one (cur , end , & mut prev0) { return Some (m) ; } }", "match n { 0 => true , 1 => x . read () == y . read () , 2 => { x . cast :: < u16 > () . read_unaligned () == y . cast :: < u16 > () . read_unaligned () } 3 => x . cast :: < [u8 ; 3] > () . read () == y . cast :: < [u8 ; 3] > () . read () , _ => { :: core :: panicking :: panic (\"internal error: entered unreachable code\" ,) } }", "& self . total_pattern_bytes", "RabinKarp", "String :: from_utf8_lossy (self . 0)", "self . heuristic_pattern_limits = yes", "\" AVX (`Some(true)`) algorithms.\"", "Searcher { patterns , rabinkarp , search_kind , minimum_len , }", "* self", "i", "candidate_chunk . trailing_zeros () . as_usize ()", "\" `data`.\"", "\" various shuffles so that they can be and-ed together and a possible\"", "& mut prev2", "other", "cur . add (V :: BYTES)", "V :: splat", "self . update_hash (hash , haystack [at] , haystack [at + self . hash_len])", "hayptr", "\" Shift this vector to the left by two bytes and shift the two most\"", "\" high and low 128-bit halves each represent distinct buckets. (Bringing the\"", "\" `half_shift_in_{one,two,three}_bytes` methods in particular are probably\"", "self . heuristic_pattern_limits", "self . buckets . len () * core :: mem :: size_of :: < Vec < (Hash , PatternID) > > ()", "vgetq_lane_u64 (this , 1)", "self . clone ()", "masks [3] . lo", "\" implementation works.\"", ":: core :: clone :: Clone :: clone (__self_0)", "\" avoid marking the routines with `#[target_feature]` and instead mark\"", "BITS <= 7", "if self . only_fat == Some (true) { }", "\"PatternIter\"", "\" bits indictated by the `BITS` type parameter.\"", "i32", "\" operations.\"", "let Some (& bucket) = map . get (& lonybs)", "if let Some (& bucket) = map . get (& lonybs) { t . buckets [bucket] . push (id) ; } else { let bucket = (BUCKETS - 1) - (id . as_usize () % BUCKETS) ; t . buckets [bucket] . push (id) ; map . insert (lonybs , bucket) ; }", "\" This is enabled by default.\"", "\" using leftmost-first match semantics, then when multiple patterns can\"", "Span", "bucket < 8", "[u8]", "needle . len ()", "\"     .match_kind(MatchKind::LeftmostLongest)\"", "SearchKind :: Teddy (:: core :: clone :: Clone :: clone (__self_0))", "core :: fmt :: Result", "\" Runs the verification routine for \\\"fat\\\" Teddy.\"", "self . kind", "locand1", "locand4", "\" On `x86_64` for example, it isn't known until runtime which of 12 possible\"", "return Some (Match { pid , start , end })", "\" Like `Vector::shift_in_two_bytes`, except this is done for each half\"", "\" Intuitively, it would seem like inlining it would be better. However,\"", "super", "\" Create a new generic data structure for Teddy verification.\"", "u16 :: MAX as usize", "\" Returns the first `len` low nybbles from this pattern. If this pattern\"", "\" to use: a 1-byte, 2-byte, 3-byte or 4-byte searcher. The bigger the\"", "\" for a larger set of literals.\"", "patlen > haylen", "SlimNeon :: < 2 > :: new_unchecked", "BUCKETS == 8 || BUCKETS == 16", "masks [0] . lo . shuffle_bytes (hlo)", "\" very short haystacks. When that occurs, the implementation will defer\"", "\" Return a candidate for Teddy (fat or slim) that is searching for 1-byte\"", "\"search_kind\"", "self . total_pattern_bytes", "\" codegen. Another approach, which is what we use here, is dynamic dispatch\"", "(old_byte as usize) . wrapping_mul (self . hash_2pow)", "\" itself inert. At this point, constructing a searcher will always return\"", "SlimNeon :: < 1 > :: new_unchecked (patterns)", "patterns . set_match_kind (self . config . kind)", "core :: fmt :: Formatter < '_ >", "cold", "BYTES <= 4", "\" byte string.\"", "Config { kind : :: core :: clone :: Clone :: clone (& self . kind) , force : :: core :: clone :: Clone :: clone (& self . force) , only_teddy_fat : :: core :: clone :: Clone :: clone (& self . only_teddy_fat) , only_teddy_256bit : :: core :: clone :: Clone :: clone (& self . only_teddy_256bit ,) , heuristic_pattern_limits : :: core :: clone :: Clone :: clone (& self . heuristic_pattern_limits ,) , }", "{ if patlimit && patterns . len () > 16 { } SlimNeon :: < 1 > :: new (& patterns) }", ":: core :: clone :: Clone :: clone (& self . memory_usage)", "teddym . end () . as_usize ()", "self . patterns . len ()", "{ by_id [id1] . len () . cmp (& by_id [id2] . len ()) . reverse () }", "\" want to avoid ever using the slower variant, which one can do by\"", "bytes . len ()", "\"assertion failed: patterns.len() >= 1\"", "32", "\" This panics if the pattern given is empty.\"", "\" Returns the total number of masks required by the patterns in this\"", "format_args", "res1 . shift_in_two_bytes (* prev1)", "PatternIter", ":: core :: clone :: Clone :: clone (& self . patterns)", "self . hi [..]", "\" significant bytes of `vector2` into the least significant position of\"", "hicand", "self . bytes () . len ()", "vorrq_u8", "[FatMaskBuilder ; BYTES]", "generic :: Slim :: < uint8x16_t , 3 , > :: new", "\" resets all state such that it is a valid empty collection.\"", "bucket_index", "FatMaskBuilder :: from_teddy (& teddy)", "id . as_usize ()", "is_prefix", "\" it. (Not impossible. We could introduce another layer that requires\"", "\" address space.\"", "\" readable from `data`.\"", "\" This example shows how to use leftmost-longest semantics instead of the\"", "{ :: core :: panicking :: panic (\"internal error: entered unreachable code\" ,) }", "__self_discr == __arg1_discr", "x < xend", "b", "\" (one bitset per lane), where the ith bit is set in the jth lane if and\"", "vextq_u8 (vector2 , self , 14)", "uint8x16_t", "[Mask < V > ; BYTES]", "\" Since this choice is generally made when the Teddy searcher is constructed\"", "self . patterns . get (id)", "y = y . add (4)", "Builder { only_fat : :: core :: clone :: Clone :: clone (& self . only_fat) , only_256bit : :: core :: clone :: Clone :: clone (& self . only_256bit) , heuristic_pattern_limits : :: core :: clone :: Clone :: clone (& self . heuristic_pattern_limits ,) , }", "\" The masks should correspond to the masks computed for the first,\"", "self . searcher", ":: core :: clone :: AssertParamIsClone < * const u8 >", "self . rabinkarp . memory_usage ()", "\"inert\"", "Builder :: new () . extend (patterns) . build ()", "V :: BYTES <= self . lo . len ()", "byte", "\" Essentially, the `start` and `end` pointers must be valid and point\"", "at ..", "\" // leftmost-first is the default.\"", "Vec < (Hash , PatternID) >", ":: core :: clone :: AssertParamIsClone < [u8 ; 32] >", "pattern . as_ref ()", "\" (16 buckets). Fat Teddy requires AVX2, so if that CPU feature isn't\"", "self . patterns . clone ()", "(self . patterns . len () <= core :: u16 :: MAX as usize)", "let Some (m) = self . find_one (cur , end , & mut prev0 , & mut prev1 , & mut prev2)", "usize", "\" lanes set to zero.\"", "if phash == hash { if let Some (c) = self . verify (pid , haystack , at) { return Some (c) ; } }", "\" Verify whether there are any matches starting at or after `cur` in the\"", ":: core :: fmt :: Debug", "\" This panics when `BYTES` is any value other than 1, 2, 3 or 4.\"", "Pointer", "u8 :: try_from (bucket)", "Config :: new", "\" vectors without checking whether SSSE3 is available or not.\"", "& self . memory_usage", "masks [1] . lo . shuffle_bytes (hlo)", ":: alloc :: fmt :: format (format_args ! (\"{0:02}: {1:08b}\" , i , self . hi [i]) ,)", "format_args ! (\"Teddy requires at least one pattern\")", "yend", "patlimit && patterns . len () > 32", "(self as * const T)", "f . debug_struct (\"Pattern\") . field (\"lit\" , & String :: from_utf8_lossy (self . 0)) . finish ()", ":: core :: clone :: Clone :: clone (& self . inert)", "BYTES", "\"pid\"", "< [Vec < PatternID , > ; BUCKETS] > :: try_from", "SlimMaskBuilder :: default", "None", "Match", "\" allocated object.\"", "(& self . hash_len , & bytes . len ())", "res", "{ :: alloc :: fmt :: format (format_args ! (\"{0:02}: {1:08b}\" , i , self . lo [i]) ,) }", "while cur <= end . sub (V :: BYTES) { if let Some (m) = self . find_one (cur , end , & mut prev0) { return Some (m) ; } cur = cur . add (V :: BYTES) ; }", "\" A packed searcher for quickly finding occurrences of multiple patterns.\"", "cand2", "if vx != vy { return false ; }", "V", ":: alloc :: vec :: from_elem (SlimMaskBuilder :: default () , BYTES ,)", "vgetq_lane_u64", "\" This is the default.\"", "res0 . half_shift_in_one_byte (* prev0)", "self . hi", "Config", "\"order\"", "core :: mem :: size_of :: < Vec < (Hash , PatternID) > > ()", ":: core :: panicking :: panic_fmt (format_args ! (\"only 1, 2, 3 or 4 bytes are supported\") ,)", "\"     .find_iter(\\\"foobar\\\")\"", "res1", "SlimMaskBuilder :: from_teddy (& teddy)", "BUCKETS - 1", "\" is valid.\"", "\" * Both `x` and `y` must point to an initialized value.\"", "if ! true { return None ; }", "\" byte occurring at `at + (j < 16 ? j : j - 16)` in `cur` is in the\"", "teddy . find (& haystack [.. span . end] , span . start)", "haystack [at ..] . len () >= self . minimum_len", "if cur < end { cur = end . sub (V :: Half :: BYTES) ; if let Some (m) = self . find_one (cur , end) { return Some (m) ; } }", "\" Currently we only implement this for AVX on x86_64. It would be nice to\"", "Option < crate :: Match >", "! ! bytes . is_empty ()", "vreinterpretq_u64_u8", "\"FindIter\"", "\" fat Teddy, the haystack window length should be `V::BYTES / 2`, with\"", "let Some (m) = self . teddy . verify (cur . sub (2) , end , c)", "haystack . as_ptr ()", "self . offset_from (origin)", "cur = end . sub (V :: BYTES)", "[u8 ; 32]", "hash_2pow . wrapping_shl (1)", "builder . add (bucket_index , pat . bytes () [i])", "\" Update the hash given based on removing `old_byte` at the beginning\"", "res0prev0 . and (res1prev1) . and (res2)", "by_id [id1] . len () . cmp (& by_id [id2] . len ()) . reverse ()", "\" type are leftmost-first.\"", ":: core :: panicking :: panic", "\" The length of the hashing window. Generally, this corresponds to the\"", "\" that 128-bit vectors will be used (up to SSSE3 instructions) where as\"", "\" they are executing this method in an environment where that attribute\"", "\" Also, it is expected that implementations of this trait will tag this\"", "Some (c)", "if ! (patterns . len () >= 1) { :: core :: panicking :: panic (\"assertion failed: patterns.len() >= 1\") }", "hash % NUM_BUCKETS", "candidate . swap_halves ()", "13", "\" Create a new \\\"fat\\\" Teddy searcher for the given patterns.\"", "< [FatMaskBuilder ; BYTES] > :: try_from", "haylen", "\" assert_eq!(3, mat.start());\"", "& self . minimum_len", "64", "SlimNeon < 1 >", "\" Callers must ensure that SSSE3 is available in the current\"", "\" A non-empty collection of non-empty patterns to search for.\"", "self . teddy", "\" `AsRef<[u64]>` or something.)\"", "if ! (V :: BYTES <= self . hi . len ()) { :: core :: panicking :: panic (\"assertion failed: V::BYTES <= self.hi.len()\" ,) }", "& self . order", "\" searcher.\"", "\" Returns true if and only if `needle` is a prefix of `haystack`.\"", "{ let result = self . verify64 (cur , end , chunk) ; cur = cur . add (4) ; result }", "\" The total number of pattern bytes across the entire collection. This\"", "PatternID", "y . cast :: < u32 > () . read_unaligned ()", "\"Patterns\"", "(hash_len >= 1)", "teddym . start () . as_usize ()", "\" better, typically, since searching for longer substrings usually\"", "self . inert || self . patterns . is_empty ()", "prev1", "\" * The distance being in bounds must not rely on \\\"wrapping around\\\" the\"", ":: core :: clone :: Clone :: clone (& self . minimum_len)", "\" contains enough to implement the verification step after candidates are\"", "hicand1", "FatMaskBuilder", "& Arc < Patterns >", "\" available and Fat Teddy was requested, no matcher will be built.\"", ":: core :: clone :: Clone :: clone (& self . teddy)", "self . order . len () * mem :: size_of :: < PatternID > () + self . by_id . len () * mem :: size_of :: < Vec < u8 > > ()", "Slim < V , 3 >", "7", "rk . hash_len", "this", "PatternIter < '_ >", "Match :: new", "id1", "\" search at `at`.\"", "masks [1] . hi . shuffle_bytes (hhi)", "\" The `Match` returned will include the identifier of the pattern that\"", "Debug", "hash . wrapping_shl (1) . wrapping_add (b as usize)", "teddy . minimum_len ()", "\" should not use it as it is not part of the API stability guarantees of\"", "\" The candidate given should be a collection of 8-bit bitsets (one bitset\"", "chunk . shift_8bit_lane_right :: < 4 > () . and (lomask)", "t", "id", ":: core :: panicking :: panic (\"assertion failed: haystack[at..].len() >= self.minimum_len\" ,)", "t . mask_len ()", "\" Returns the bytes of this pattern.\"", "teddym . pattern () . as_usize ()", "& & self . minimum_len", "& parts_lo", "\" An internal option for forcing the use of a particular packed algorithm.\"", "\" for `y` and `y+n`.\"", "crate :: Match :: new (pid , span)", ":: core :: fmt :: Formatter :: debug_struct_field2_finish (f , \"Teddy\" , \"patterns\" , & self . patterns , \"buckets\" , & & self . buckets ,)", "if * left_val == * right_val { let kind = :: core :: panicking :: AssertKind :: Ne ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! (\"Teddy does not support zero-length patterns\") ,) ,) ; }", "3", "& (patterns . minimum_len ())", "Some (t)", "\" going through dynamic dispatch.\"", "config", "match mask_len { 1 => { if patlimit && patterns . len () > 16 { } SlimNeon :: < 1 > :: new (& patterns) } 2 => { if patlimit && patterns . len () > 32 { } SlimNeon :: < 2 > :: new (& patterns) } 3 => { if patlimit && patterns . len () > 48 { } SlimNeon :: < 3 > :: new (& patterns) } 4 => { SlimNeon :: < 4 > :: new (& patterns) } _ => { None } }", "BITS", "\" Call the provided function for each 64-bit lane in the lower half\"", "& self . by_id", "chunk . shift_8bit_lane_right :: < 4 > ()", "(0)", "self . build_imp (patterns)", "& self . imp", "\" this method.\"", "\" environment, then this returns `None`.\"", "\" Create a new builder for constructing a multi-pattern searcher. This\"", "Builder { config : :: core :: clone :: Clone :: clone (& self . config) , inert : :: core :: clone :: Clone :: clone (& self . inert) , patterns : :: core :: clone :: Clone :: clone (& self . patterns) , }", "self as * const T", "bytes", "core :: cmp :: min (4 , patterns . minimum_len ())", "self . patterns . order", "& & self . masks", "\" A convenience function for building `N` vector masks from a slim\"", "\" Callers must guarantee that at least `BYTES` bytes are readable from\"", "f . debug_struct (\"Pattern\") . field (\"lit\" , & String :: from_utf8_lossy (self . 0))", "if ! (pid . as_usize () < self . patterns . len ()) { :: core :: panicking :: panic (\"assertion failed: pid.as_usize() < self.patterns.len()\" ,) }", "mem :: size_of :: < Vec < u8 > >", "(V , V)", "\"slim128\"", "if needle . len () > haystack . len () { return false ; }", "& self . config", "\" vendor intrinsics, which are also not safe. Callers must ensure that\"", "vqtbl1q_u8", "! (* left_val == * right_val)", "\" the `by_id` slice.\"", "pat . bytes () [.. rk . hash_len]", "& mut Config", "y . cast :: < u16 > ()", "at += 1", "\" `V::BYTES` at and after `cur`. If there isn't one, then a vector with\"", "cur = cur . add (4)", "* mut T", "res0prev0 . and (res1prev1) . and (res2prev2)", "vreinterpretq_u64_u8 (self)", "Config :: new ()", "\" Fat Teddy is useful when searching for a large number of literals.\"", "\" according to its match semantics, in the given haystack starting from\"", "\" raw `start` and `end` pointers.\"", "x . cast :: < [u8 ; 3] > ()", "res0prev0", "\" This example shows how to use a builder to construct a searcher. By\"", "res0 . shift_in_two_bytes (* prev0)", ":: alloc :: vec :: Vec :: new", "\" order in which they should be matched.\"", "\" constructor uses the default configuration.\"", "return None", ":: core :: fmt :: Formatter :: write_str (f , \"RabinKarp\")", "\" If `f` returns `Some`, then iteration over the lanes is stopped and the\"", "right_val", "0xFF", "self . config", "unsafe { SlimNeon :: < 1 > :: new_unchecked (patterns) }", "\" `None` is the default, which results in an automatic selection based\"", "haystack [.. span . end]", "* left_val == * right_val", "\" Aho-Corasick for a small number of patterns). However, callers may\"", "\" The given pointers representing the haystack must be valid to read\"", "\" is used for reporting total heap usage in constant time.\"", "\" used for 128-bit vectors.\"", "return Some (t)", "if ! (bucket < self . buckets . len ()) { :: core :: panicking :: panic (\"assertion failed: bucket < self.buckets.len()\" ,) }", "\" to a haystack one can read. As long as you derive them from, for\"", "\" there isn't one, then `None` is returned.\"", "pat . len ()", "self . search_kind . memory_usage ()", "SearchKind :: Teddy", "\" parameter isn't really meant to be instantiated for any value other than\"", "& & self . hash_2pow", "self . slim128 . find (start , end)", "& self . span", "& self . inert", "\" Create a new \\\"slim\\\" Teddy searcher for the given patterns.\"", "\" vector and the one given, then lane `i` in the resulting vector is set\"", "\" A builder for constructing a packed searcher from a collection of patterns.\"", "self . patterns . get_unchecked (pid)", "\" Shift each 8-bit lane in this vector to the right by the number of\"", "hayptr . add (at)", "pattern", "\" slower than standard techniques (i.e., if there are too many literals).\"", "\" Shift this vector to the left by one byte and shift the most\"", "if ! (bucket < 8) { :: core :: panicking :: panic (\"assertion failed: bucket < 8\") }", "1 <= BYTES", "\" The number of bytes in the vector. That is, this is the size of the\"", "{ :: core :: fmt :: Formatter :: write_str (f , \"RabinKarp\") }", "self . only_teddy_256bit = yes", "cmp :: min", "\" searches to avoid copying all of the patterns, and allows us to keep only\"", "\" ```ignore\"", "& mut :: core :: fmt :: Formatter", "\" right by `Self::BYTES - 2` bytes.\"", "vandq_u8", "< [FatMaskBuilder ; BYTES] > :: try_from (mask_builders) . unwrap ()", "\" immediately following it. This permits combining the last two bytes\"", "! (V :: BYTES <= self . lo . len ())", "x . read ()", ":: core :: clone :: Clone", ":: core :: clone :: Clone :: clone (& self . hash_len)", "\"start\"", "cur . sub (1)", "\" Basically, the mask length corresponds to the type of Teddy searcher\"", "self . span . end", "\"     .add(\\\"foo\\\")\"", "false", "format_args ! (\"Teddy only supports 8 or 16 buckets\")", "\" Update this mask by adding the given byte to the given bucket. The\"", "if pattern . is_empty () { self . inert = true ; self . patterns . reset () ; return self ; }", "id2", "(& NUM_BUCKETS , & self . buckets . len ())", "SlimNeon < 2 >", "\" this is iterating over.\"", "start", "self . build_teddy (Arc :: clone (& patterns))", "generic :: Slim :: < uint8x16_t , 1 , > :: new", "\" length of the shortest pattern (in bytes) is bigger than 4, then the\"", "f . debug_struct (\"SlimMaskBuilder\") . field (\"lo\" , & parts_lo)", "\" Return the first matching pattern in the given haystack, begining the\"", "for (id , pat) in patterns . iter () { let hash = rk . hash (& pat . bytes () [.. rk . hash_len]) ; let bucket = hash % NUM_BUCKETS ; rk . buckets [bucket] . push ((hash , id)) ; }", "\" matched, which corresponds to the index of the pattern (starting from\"", "for pid in bucket . iter () . copied () { let pat = teddy . patterns . get (pid) ; for (i , builder) in mask_builders . iter_mut () . enumerate () { builder . add (bucket_index , pat . bytes () [i]) ; } }", "0usize", "ForceAlgorithm :: RabinKarp", "{ let bucket = (BUCKETS - 1) - (id . as_usize () % BUCKETS) ; t . buckets [bucket] . push (id) ; map . insert (lonybs , bucket) ; }", "& self . lo", "lane", "origin as * const T", "self . force = Some (ForceAlgorithm :: RabinKarp)", "Mask :: members4", "phash == hash", "\" given function is provided the lane index and lane value as a `u64`.\"", "SlimNeon < BYTES >", "\" When `bucket >= 16`.\"", "\" #     example().unwrap()\"", "non_exhaustive", ":: core :: clone :: Clone :: clone (& self . order)", "\" Returns a pointer into the haystack at which the match ends.\"", "\" is chosen.\"", "\" why. Otherwise, it has the potential to violate pointer provenance.)\"", "RefUnwindSafe", "V :: splat (0xFF)", "vorrq_u8 (self , vector2)", "masks [2] . lo", "vgetq_lane_u64 (maxes , 0) == 0", "u16", "x = x . add (4)", ":: core :: panicking :: assert_failed", "V :: BYTES", "Config { kind : MatchKind :: LeftmostFirst , force : None , only_teddy_fat : None , only_teddy_256bit : None , heuristic_pattern_limits : true , }", "self . end", "end . sub (V :: BYTES)", "\" Look for a candidate match (represented as a vector) starting at the\"", ":: core :: panicking :: panic (\"assertion failed: hash_len >= 1\")", "& self . haystack", "1 << (bucket % 8)", "\"i\"", "(bucket % 8)", "kind", "\" the result.\"", "\" This collection of patterns is what is passed around to both execute\"", "let Some (m) = self . verify_bucket (cur , end , bucket)", "\" `mask1` should correspond to a low/high mask for the first byte of all\"", "usize :: try_from (self . offset_from (origin)) . unwrap_unchecked ()", "\" Returns the distance, in units of `T`, between `self` and `origin`.\"", "while cur <= end . sub (V :: Half :: BYTES) { if let Some (m) = self . find_one (cur , end , & mut prev0 , & mut prev1 , & mut prev2) { return Some (m) ; } cur = cur . add (V :: Half :: BYTES) ; }", "\" The order of the patterns provided by this iterator is consistent with the\"", "yend . cast :: < u32 > ()", ":: core :: option :: Option :: None", "locand1 . and (hicand1)", "\"assertion failed: !candidate.is_zero()\"", "crate :: Span { start , end }", "SlimNeon :: < 1 > :: new", "& mut prev0", ":: core :: panicking :: panic (\"assertion failed: self.patterns.len() <= core::u16::MAX as usize\" ,)", "cur . sub (2)", "let Some (t) = f (0 , lane)", "Teddy { patterns : :: core :: clone :: Clone :: clone (& self . patterns) , buckets : :: core :: clone :: Clone :: clone (& self . buckets) , }", ":: core :: clone :: Clone :: clone (& self . 0)", "\"assertion failed: haystack[at..].len() >= self.minimum_len\"", "\" Like `Vector::shift_in_one_byte`, except this is done for each half\"", "self . config . heuristic_pattern_limits", "\" four fat 256-bit vector variants.\"", "Pattern < 'p >", "if ! c . is_zero () { if let Some (m) = self . teddy . verify (cur . sub (1) , end , c) { return Some (m) ; } }", "self . only_fat == Some (true)", "\" And even if we could, it would be tricky to write generic code over\"", "crate :: PatternID :: new_unchecked (teddym . pattern () . as_usize () ,)", "\" this vector.\"", "\" When an algorithm is forced, if a searcher could not be constructed for it,\"", "if let Some (m) = self . teddy . verify (cur . sub (1) , end , c) { return Some (m) ; }", "\"total_pattern_bytes\"", "res0 . half_shift_in_two_bytes (* prev0)", "[u8 ; 3]", "\" the appropriate target features are enabled in the calling function,\"", "{ self . order . sort () ; }", "\" bitsets in the higher half, so that we can search `V::BYTES` bytes at a\"", "\" cases where the haystack (or remainer of the haystack) is too short.\"", "BUCKETS == 8", "\" Note that this collection is not a set. The same pattern can appear more\"", "teddy . patterns . get (pid)", "\" used as the match.\"", "self . inert = true", "locand4 . and (hicand4)", "self . by_id [id]", "& * right_val", "\" Create a new builder for configuring a Teddy matcher.\"", "while cur <= end . sub (V :: Half :: BYTES) { if let Some (m) = self . find_one (cur , end , & mut prev0 , & mut prev1) { return Some (m) ; } cur = cur . add (V :: Half :: BYTES) ; }", "if * left_val == * right_val { let kind = :: core :: panicking :: AssertKind :: Ne ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! (\"Teddy requires at least one pattern\") ,) ,) ; }", "(pid . as_usize () < self . patterns . len ())", "usize :: from (byte & 0xF)", "chunk", "\" The given pointers must be valid to read from.\"", "{ let result = self . verify64 (cur , end , chunk) ; cur = cur . add (8) ; result }", "if patlimit && patterns . len () > 48 { }", "\" Create a vector with 8-bit lanes with the given byte repeated into each\"", "Fat < V , 1 >", "candidate_chunk != 0", "& String :: from_utf8_lossy (self . 0)", "Arc :: clone (patterns)", "\" ], matches);\"", "\" If any of the patterns in the slice given are empty, then this panics.\"", "self . kind = kind", "SlimNeon :: < 1 > :: new (& patterns)", "FnMut (usize , u64) -> Option < T >", ":: core :: clone :: Clone :: clone (& self . hi)", "\"LeftmostFirst\"", "\" second bytes of all patterns that are being searched.\"", "if ! (self . patterns . len () <= core :: u16 :: MAX as usize) { :: core :: panicking :: panic (\"assertion failed: self.patterns.len() <= core::u16::MAX as usize\" ,) }", "\" Returns the number of patterns added to this builder.\"", "\" `haystack` corresponding only to patterns in the given bucket.\"", "! candidate . is_zero ()", "Teddy :: new", "hayptr . as_usize ()", "\" # Some(()) }\"", "Some (unsafe { SlimNeon :: < 4 > :: new_unchecked (patterns) })", "\" assert_eq!(PatternID::ZERO, mat.pattern());\"", "teddy . buckets . iter () . enumerate ()", "Arc :: clone", "if n < 4 { return match n { 0 => true , 1 => x . read () == y . read () , 2 => { x . cast :: < u16 > () . read_unaligned () == y . cast :: < u16 > () . read_unaligned () } 3 => x . cast :: < [u8 ; 3] > () . read () == y . cast :: < [u8 ; 3] > () . read () , _ => { :: core :: panicking :: panic (\"internal error: entered unreachable code\" ,) } } ; }", ":: core :: fmt :: Formatter :: debug_struct_field2_finish (f , \"Mask\" , \"lo\" , & self . lo , \"hi\" , & & self . hi ,)", "(SearchKind :: RabinKarp , 0)", "Some (unsafe { SlimNeon :: < 1 > :: new_unchecked (patterns) })", "(BYTES - 1)", "& self . search_kind", "array . map (| builder | builder . build ())", "! (haystack [at ..] . len () >= self . minimum_len)", "usize :: from", "(old_byte as usize)", "\"     .map(|mat| mat.pattern())\"", "\"assertion failed: V::BYTES <= self.hi.len()\"", "teddy . patterns", "\" Compile a new Rabin-Karp matcher from the patterns given.\"", "Iterator", "cmp :: min (self . minimum_len , bytes . len ())", "PatternID :: new (self . by_id . len ()) . unwrap ()", "\" and number of patterns given to the builder.\"", "| builder | builder . build ()", "\" Returns the approximate total amount of heap used by this type, in\"", "generic :: Slim :: < uint8x16_t , 3 , > :: new (Arc :: clone (patterns))", "\"imp\"", "vextq_u8 (vector2 , self , 15)", "cur <= end . sub (V :: BYTES)", "fmt :: Debug", "return self", "if let Some (c) = self . verify (pid , haystack , at) { return Some (c) ; }", "core :: mem :: size_of :: < PatternID > ()", "by_id [id1] . len ()", "\" Also, the `PatternID` used here is a `u16`.\"", "\" A \\\"fat\\\" Teddy implementation that is generic over both the vector type\"", "f . debug_struct (\"FatMaskBuilder\")", "Pattern", "\" See Slim<V, 1>::find.\"", "(V , V , V , V)", "FindIter < 's , 'h >", "\" right by `Self::BYTES - 1` bytes.\"", "& patterns", "\" When none, this is automatically determined. Otherwise, `false` means\"", "BTreeMap :: new", "result", "Pattern (:: core :: clone :: Clone :: clone (& self . 0))", "if ! c . is_zero () { if let Some (m) = self . teddy . verify (cur . sub (2) , end , c) { return Some (m) ; } }", "x . cast :: < u32 > () . read_unaligned ()", "res1 . half_shift_in_two_bytes (* prev1)", "\"minimum_len\"", "\" checks.\"", "\"masks\"", "\" Return the number of patterns in this collection.\"", "\" Callers must guarantee that at least `Self::HALF::BYTES` bytes are\"", "\" semantics.\"", "& & self . buckets", "\" * Both `start` and `end` must point to an initialized value.\"", ":: core :: clone :: Clone :: clone (& self . force)", ":: alloc :: vec :: Vec :: new ()", ":: core :: fmt :: Formatter :: debug_struct_field2_finish (f , \"Fat\" , \"teddy\" , & self . teddy , \"masks\" , & & self . masks ,)", "\" buckets 1 and 5 set if it's in the lower half, but has buckets 9 and 13 set\"", "vgetq_lane_u64 (this , 0)", "bytes . to_vec ()", "\" But ESMAJ provides something a bit more concrete:\"", "for & b in bytes { hash = hash . wrapping_shl (1) . wrapping_add (b as usize) ; }", "match self . kind { MatchKind :: LeftmostFirst => { self . order . sort () ; } MatchKind :: LeftmostLongest => { let (order , by_id) = (& mut self . order , & mut self . by_id) ; order . sort_by (| & id1 , & id2 | { by_id [id1] . len () . cmp (& by_id [id2] . len ()) . reverse () }) ; } }", ":: core :: fmt :: Formatter :: write_str (f , match self { MatchKind :: LeftmostFirst => \"LeftmostFirst\" , MatchKind :: LeftmostLongest => \"LeftmostLongest\" , } ,)", "\" verification time.\"", "self . len ()", "(bucket < 16)", "Teddy { patterns , buckets }", "Vec < Vec < u8 > >", "\" the order provided by this iterator, then the result is guaranteed\"", "FatMaskBuilder :: from_teddy", "\" the automaton is reported.\"", "\" for i in 0..haystack.len():\"", "\" are sorted by their length in descending order. If leftmost-first\"", "\" on the number of literals and available CPU features.\"", "SlimNeon :: < 3 > :: new_unchecked (patterns)", "\" be quite expensive if `N` is not a multiple of 2.\"", "\" the current CPU.\"", "\" Each 8-bit lane `j` in a vector corresponds to a bitset where the `i`th bit\"", "Fat < V , 3 >", "if true { if ! (bucket < self . buckets . len ()) { :: core :: panicking :: panic (\"assertion failed: bucket < self.buckets.len()\" ,) } }", "\" the least significant byte corresponds to the start of the window). For\"", "by_id [id2] . len ()", "bool", "& [u8]", "\"\"", "needle . len () > haystack . len ()", "\" With respect to the Teddy algorithm, `vector2` is usually a previous\"", "nybs [i]", "\" search. Each mask is 32 bytes wide, although only the first 16 bytes are\"", "self . patterns . minimum_len ()", "locand . and (hicand)", "\" corresponds to the number of bytes to hash. We adapt this to work for\"", "\" per lane), where the ith bit is set in the jth lane if and only if the\"", "SlimNeon :: < 3 > :: new", "cand4", "vshrq_n_u8", "(cand1 , cand2 , cand3)", "self . patterns . order [self . i]", "\" Request the use of 256-bit vectors (true) or 128-bit vectors (false).\"", "PATTERN_LIMIT", "self . bytes ()", "builder", "\" them as `#[inline(always)]` to ensure they get appropriately inlined.\"", "self . memory_usage", ":: core :: clone :: Clone :: clone (& self . buckets)", "at + self . hash_len >= haystack . len ()", "slim128 . minimum_len ()", "res1 . shift_in_one_byte (* prev1)", "\" provided the lane index and lane value as a `u64`. (The high 128-bits\"", "\" it results in better codegen then a enum, although this is a specious\"", "\" Unpack and interleave the 8-bit lanes from the high 128 bits of each\"", "SlimNeon :: < 2 > :: new", ":: core :: panicking :: panic (\"assertion failed: bucket < 8\")", "\" writing, it also supports wasm and aarch64 128-bit vector types as well.\"", "(len >= self . minimum_len ())", "masks [0] . lo", "\" arranged such that the first one to match is the correct match. This\"", "self . order . len () * mem :: size_of :: < PatternID > ()", "masks [2] . lo . shuffle_bytes (hlo)", "format_args ! (\"{0:02}: {1:08b}\" , i , self . lo [i])", "self . only_256bit", "prev2 = V :: splat (0xFF)", "\" A configuration produces a [`packed::Builder`](Builder), which in turn can\"", "& mut self . by_id", "0xF", "swapped", "Vec < PatternID >", "\" Require the use of Fat (true) or Slim (false) Teddy. Fat Teddy uses\"", ":: core :: default :: Default :: default", "& mut Self", "\" and match at once. As more sophisticated algorithms are added, this number\"", "\" corresponds to the index of the pattern (starting from `0`) in which it\"", "\" If the kind is not set, then the default is leftmost-first.\"", "Mask { lo : V :: load_unaligned (self . lo [..] . as_ptr ()) , hi : V :: load_unaligned (self . hi [..] . as_ptr ()) , }", "unsafe { SlimNeon :: < 4 > :: new_unchecked (patterns) }", "self . hi [byte_hi + 16] |= 1 << bucket", "cur . add (4)", "\" the trickiest of the bunch. For AVX2, these are implemented by taking\"", "\" The iterator must yield elements that can be converted into a `&[u8]`.\"", "RabinKarp { patterns : Arc :: clone (patterns) , buckets : :: alloc :: vec :: from_elem (:: alloc :: vec :: Vec :: new () , NUM_BUCKETS ,) , hash_len , hash_2pow , }", "\" packed searching to be effective.\"", "& mut self . order", "fmt :: Result", "cur . add (V :: Half :: BYTES)", "if true { if ! ! candidate . is_zero () { :: core :: panicking :: panic (\"assertion failed: !candidate.is_zero()\" ,) } }", "FindIter < 'a , 'b >", "Option < T >", "Fat { teddy : :: core :: clone :: Clone :: clone (& self . teddy) , masks : :: core :: clone :: Clone :: clone (& self . masks) , }", "teddy :: Builder :: new () . only_256bit (self . config . only_teddy_256bit) . only_fat (self . config . only_teddy_fat) . heuristic_pattern_limits (self . config . heuristic_pattern_limits)", "teddym . pattern ()", "(V , V , V)", "\" Similarly, if the number of patterns given is zero, then this also\"", "\" See `Fat<V, 1>::find_one`.\"", "\" A convenience function for calling `Builder::new()`.\"", "ted . memory_usage ()", "\" all of the lanes will be set to zero in at least one of the vectors\"", "\" match at a particular location, the pattern that was added first is\"", "\" Hash the given bytes.\"", "& * left_val", "self . hi [byte_hi + 16] |= 1 << (bucket % 8)", "teddy :: Builder :: new () . only_256bit (self . config . only_teddy_256bit) . only_fat (self . config . only_teddy_fat)", "& self . slim128", "\" This trait extends the `Vector` trait with additional operations to support\"", "\" vector in memory.\"", "\" small either to avoid spending too much time confirming literals.\"", "patterns . minimum_len ()", "pat . bytes () [i]", ":: core :: default :: Default", "\" another function that is marked as `inline(never)` or just `inline`.\"", "\" allocated object. `x` and `y` do not need to point to the same allocated\"", "\" of two means `hash % NUM_BUCKETS` can compile down to a simple `and`\"", "return Some (c)", "& self . hi", "\" \\\"standard\\\" semantics cannot be easily supported by packed searchers.\"", "self . teddy . verify (cur . sub (2) , end , c)", "yend . cast :: < u32 > () . read_unaligned ()", "cur <= end . sub (V :: Half :: BYTES)", "\" `i` is set if and only if the correspond *byte* is in the ith bucket.\"", "1", "\"     .builder()\"", "t . buckets", "\"     .find_iter(\\\"foobar fooba foofoo\\\")\"", "& (0)", "\" decreases the rate of false positives. Therefore, the number of masks\"", "Teddy", "Span :: from (0 .. haystack . len ())", "\" If candidates are returned, each will be a collection of 8-bit bitsets\"", "\" variants on the same algorithm.\"", "SlimMaskBuilder :: default ()", "parts_lo . push (:: alloc :: __export :: must_use ({ :: alloc :: fmt :: format (format_args ! (\"{0:02}: {1:08b}\" , i , self . lo [i]) ,) }) ,)", "res0 . shift_in_one_byte (* prev0)", "Some (ForceAlgorithm :: RabinKarp)", "if self . inert { return self ; } else if self . patterns . len () >= PATTERN_LIMIT { self . inert = true ; self . patterns . reset () ; return self ; }", "\" variants, or one of the four 256-bit vector variants or even one of the\"", "\" An undocumented method for forcing the use of the Rabin-Karp algorithm.\"", "\" See Slim<V, 1>::find_one.\"", "\" Returns the match kind used by this packed searcher.\"", "\" The configuration of this builder and subsequent matcher.\"", "\" then no searcher will be returned even if an alternative algorithm would\"", "old_byte", "& (patterns . len ())", ":: core :: fmt :: Formatter :: debug_struct_field1_finish", "{ if * left_val == * right_val { let kind = :: core :: panicking :: AssertKind :: Ne ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! (\"Teddy does not support zero-length patterns\") ,) ,) ; } }", "masks [2] . hi", "\" use aho_corasick::{packed::{Builder, MatchKind}, PatternID};\"", "\" By default, leftmost-first match semantics are used.\"", "\" a call out to the current platform's `libc` which might not be inlineable\"", "Match { pid , start , end }", "\" Return a candidate for Teddy (fat or slim) that is searching for 4-byte\"", "\" vector and return the result.\"", "! (self . patterns . len () <= core :: u16 :: MAX as usize)", "\" in ascending order (which corresponds to the caller's order).\"", "\" available, an unsupported target or if the searcher is believed to be\"", "\" * Both `start` and `end` must be valid for reads.\"", "\" too big in order to avoid wasting memory, but we don't want it to be too\"", "cur = cur . add (8)", "vld1q_u8", "\" obligations:\"", "f . debug_struct (\"SlimMaskBuilder\") . field (\"lo\" , & parts_lo) . field (\"hi\" , & parts_hi) . finish ()", "\"assertion failed: !bytes.is_empty()\"", "! (bucket < self . buckets . len ())", "automatically_derived", "self . find_one (cur , end , & mut prev0 , & mut prev1)", "let Some (m) = self . teddy . verify (cur , end , c)", "\" or have other overhead. This routine isn't guaranteed to be a win, but it\"", "\" bucket from a hash will slow down the code considerably. Using a power\"", "[Mask < V > ; 3]", "\" Each mask is used as the target of a shuffle, where the indices for the\"", "\" immediately following it. This permits combining the last three bytes\"", "\" A trait that provides dynamic dispatch over the different possible Teddy\"", "\" half instead of the full 256-bit vector. (Where as `_mm_alignr_epi8`\"", "\" Create a packed builder from this configuration. The builder can be\"", "\" not be used to search a specific haystack. For example, if Teddy was\"", "\" in a way that is not always inlined, you'll need to wrap a call to it in\"", "\" Returns the minimum length, in bytes, that a haystack must be in order\"", "& 's Searcher", "haystack . len ()", "patterns . len () > 48", "(Hash , PatternID)", "\" there is a hash collision, or when a prefix of a pattern matches but\"", "\" Creates a new searcher using \\\"slim\\\" Teddy with 256-bit\"", "map", "{ if patlimit && patterns . len () > 48 { } SlimNeon :: < 3 > :: new (& patterns) }", "\" * It must be the case that `start <= end`.\"", "teddy :: Builder :: new ()", "y . add (4)", "BTreeMap < Box < [u8] > , usize >", "byte_lo", "self . imp . find (hayptr . add (at) , hayptr . add (haystack . len ()))", "\" assert_eq!(vec![PatternID::must(1)], matches);\"", "self . lo [byte_lo]", "\" leftmost-first semantics, but may be different for leftmost-longest\"", "self . i", "y . cast :: < u32 > ()", "if let Some (t) = f (0 , lane) { return Some (t) ; }", "res1prev1", "\" The number of buckets to store our patterns in. We don't want this to be\"", "patterns . len () > 16", "(& (0) , & (patterns . len ()))", "! (BITS <= 7)", "\" Return a candidate for Teddy (fat or slim) that is searching for 2-byte\"", "byte & 0xF", "MatchKind :: LeftmostLongest", "String :: from_utf8_lossy", "\" the number of literals and available CPU features.\"", "\" broadcast it across both halfs of a full vector. The pointer does not\"", "\" environment.\"", ":: core :: clone :: Clone :: clone (& self . kind)", "\" Returns true if and only if this vector has zero in all of its lanes.\"", "vdupq_n_u8 (byte)", "\"rabinkarp\"", "crate :: Match", "\" When true (the default), the number of patterns will be used as a\"", "PatternIter < 'p >", "& self . masks", "\" the specific algorithms used in this crate. In general, it was invented\"", "\" This example shows how to create a searcher from an iterator of patterns.\"", "\" Another approach is to use function pointers and stick each of the possible\"", "(hash , id)", "\" indices and `C` is the resulting vector, then `C = A[B[i]]`.\"", "self . minimum_len = cmp :: min (self . minimum_len , bytes . len ())", "x . cast :: < [u8 ; 3] > () . read ()", "mem :: size_of :: < PatternID >", ".. rk . hash_len", "self . buckets . len ()", "self . patterns . reset ()", "\"Match\"", "\" is returned.\"", "\" make this faster for very short strings.\"", "& bytes . len ()", "\" A \\\"slim\\\" Teddy implementation that is generic over both the vector type\"", "\" bucket `j < 16 ? i : i + 8`.\"", "byte >> 4", "(self as * const T) . distance (origin as * const T)", "0 .. 32", "\" This differs from the [`MatchKind`](crate::MatchKind) type in the top-level\"", "\" In some cases, the underlying packed searcher may not be able to search\"", "\" was added.\"", "\" `haystack[at..]`.\"", "{ if haystack [span] . len () < teddy . minimum_len () { return self . find_in_slow (haystack , span) ; } teddy . find (& haystack [.. span . end] , span . start) }", "Slim { teddy : :: core :: clone :: Clone :: clone (& self . teddy) , masks : :: core :: clone :: Clone :: clone (& self . masks) , }", "y . cast :: < [u8 ; 3] > () . read ()", "hicand2", "\" # Examples\"", "Option < (PatternID , Pattern < 'p >) >", "if pat . is_prefix_raw (cur , end) { let start = cur ; let end = start . add (pat . len ()) ; return Some (Match { pid , start , end }) ; }", "SlimNeon :: < 2 > :: new_unchecked (patterns)", "\" Add the given pattern to this set to match.\"", "for i in 0 .. 32 { parts_lo . push (:: alloc :: __export :: must_use ({ :: alloc :: fmt :: format (format_args ! (\"{0:02}: {1:08b}\" , i , self . lo [i]) ,) }) ,) ; parts_hi . push (:: alloc :: __export :: must_use ({ :: alloc :: fmt :: format (format_args ! (\"{0:02}: {1:08b}\" , i , self . hi [i]) ,) }) ,) ; }", "self . inert", "if let Some (m) = self . find_one (cur , end) { return Some (m) ; }", "\" of the vector instead.\"", "at .. at + pat . len ()", "let Some (c) = self . verify (pid , haystack , at)", "\" lane.\"", "\" Verify whether the pattern with the given id matches at\"", "self . buckets", ":: alloc :: __export :: must_use ({ :: alloc :: fmt :: format (format_args ! (\"{0:02}: {1:08b}\" , i , self . lo [i]) ,) })", "! (BUCKETS == 8 || BUCKETS == 16)", "\" of some byte string, and appending `new_byte` to the end of that same\"", "BUCKETS", "\" Return a candidate for Teddy (fat or slim) that is searching for 3-byte\"", "is_equal_raw (start , self . bytes () . as_ptr () , patlen)", "\" there are some tricky things to figure out in terms of implementation. The\"", "! (1 <= BYTES && BYTES <= 4)", "T", "y . cast :: < [u8 ; 3] > ()", "search_kind", "\" candidates.\"", "* left_val", "Arc :: new (SlimNeon { slim128 })", "(BUCKETS - 1) - (id . as_usize () % BUCKETS)", "format_args ! (\"Teddy does not support zero-length patterns\")", "\" Use a slow (non-packed) searcher.\"", "\" Unpack and interleave the 8-bit lanes from the low 128 bits of each\"", "\"internal error: entered unreachable code\"", "[Mask < V > ; 1]", ":: core :: clone :: Clone :: clone (& self . only_teddy_256bit ,)", "! (bucket < 8)", "Fat < V , 2 >", "\" Returns a pointer into the haystack at which the match starts.\"", "& parts_hi", "\" and that the current CPU supports them. All implementations should\"", "2", ":: core :: panicking :: panic (\"assertion failed: self.by_id.len() <= u16::MAX as usize\" ,)", "\" of each vector are ignored.)\"", "prev0", "SlimMaskBuilder { lo : :: core :: default :: Default :: default () , hi : :: core :: default :: Default :: default () , }", "core :: cmp :: min (4 , self . patterns . minimum_len ())", "self . buckets . len () * core :: mem :: size_of :: < Vec < (Hash , PatternID) > > () + self . patterns . len () * core :: mem :: size_of :: < (Hash , PatternID) > ()", "while cur <= end . sub (V :: Half :: BYTES) { if let Some (m) = self . find_one (cur , end , & mut prev0) { return Some (m) ; } cur = cur . add (V :: Half :: BYTES) ; }", "\" let mat = searcher.find_in(haystack, Span::from(3..haystack.len()))?;\"", "\" raw pointers).\"", "if ! (len >= self . minimum_len ()) { :: core :: panicking :: panic (\"assertion failed: len >= self.minimum_len()\" ,) }", "self . order . clear ()", "haystack", "let Some (m) = self . find_one (cur , end)", "Searcher { patterns : :: core :: clone :: Clone :: clone (& self . patterns) , rabinkarp : :: core :: clone :: Clone :: clone (& self . rabinkarp) , search_kind : :: core :: clone :: Clone :: clone (& self . search_kind) , minimum_len : :: core :: clone :: Clone :: clone (& self . minimum_len) , }", "old_byte as usize", "\"SlimMaskBuilder\"", "[Vec < PatternID > ; BUCKETS]", "\" let searcher = Builder::new()\"", "array", ":: alloc :: vec :: from_elem (0 , len) . into_boxed_slice ()", "\" The masks used as inputs to the shuffle operation to generate\"", "if let Some (t) = f (1 , lane) { return Some (t) ; }", "if yes { self . force = Some (ForceAlgorithm :: Teddy) ; } else { self . force = None ; }", "at", "hash_len >= 1", "Mask :: members3 (chunk , self . masks)", "match self . searcher . find_in (self . haystack , self . span) { None => None , Some (m) => { self . span . start = m . end () ; Some (m) } }", "haystack [at]", "rk . buckets [bucket] . push ((hash , id))", "bit", "self . force", "\" `Self::BYTES` chunk from the haystack and `self` is the chunk\"", "\" if it does occur a lot, it's going to be slow no matter what we do.\"", "self . only_fat = yes", ":: core :: fmt :: Formatter :: debug_struct_field4_finish", "\" If a searcher could not be constructed (either because of an\"", "\" length of the smallest pattern.\"", "prev . wrapping_sub ((old_byte as usize) . wrapping_mul (self . hash_2pow)) . wrapping_shl (1)", "\" needed is the length of the shortest pattern in this searcher. If the\"", "vextq_u8", "masks [2] . hi . shuffle_bytes (hhi)", "\" The order in which patterns are added is significant. Namely, when\"", "0 .. haystack . len ()", "\" A draw back of naively scaling Rabin-Karp to multiple patterns is that\"", "hash = hash . wrapping_shl (1) . wrapping_add (b as usize)", "Arc < dyn SearcherT >", "V :: Half :: BYTES", "\" See `Fat<V, 1>::find`.\"", "vandq_u8 (self , vector2)", "masks", "\" # }\"", "& self . patterns", "self . patterns . len () * core :: mem :: size_of :: < PatternID > ()", "bucket . iter () . copied ()", "\" shuffle are taken from the haystack. AND'ing the shuffles for both the\"", "& pat . bytes () [.. rk . hash_len]", "origin", "\"hash_len\"", "\" need to be aligned.\"", "if self . only_256bit == Some (true) { return None ; }", "\" An iterator over non-overlapping matches from a packed searcher.\"", "rk . buckets", "\" Generally, a larger vector size is better since it either permits\"", "\" Build a searcher from the patterns added to this builder so far.\"", "& self . end", "\" the entire pattern doesn't match. This is hopefully fairly rare, and\"", "self . hi . len ()", "1usize", "\" never passing a haystack shorter than the minimum length returned by\"", "\" and this choice is based on the patterns given and what the current CPU\"", "phash", "self . searcher . find_in (self . haystack , self . span)", "if let Some (m) = self . verify_bucket (cur , end , bucket) { return Some (m) ; }", "\" The number of bits in the vector.\"", "self . by_id . clear ()", "for _ in 1 .. hash_len { hash_2pow = hash_2pow . wrapping_shl (1) ; }", "MatchKind :: default", "pat . bytes ()", "\" # Panics\"", "if cur < end { cur = end . sub (V :: BYTES) ; if let Some (m) = self . find_one (cur , end) { return Some (m) ; } }", "if cur < end { cur = end . sub (V :: Half :: BYTES) ; prev0 = V :: splat (0xFF) ; prev1 = V :: splat (0xFF) ; prev2 = V :: splat (0xFF) ; if let Some (m) = self . find_one (cur , end , & mut prev0 , & mut prev1 , & mut prev2) { return Some (m) ; } }", ":: core :: clone :: Clone :: clone (& self . masks)", "\" See Slim<V, 1>::candidate.\"", "Builder :: new", "locand", "candidate_chunk", "\" and fourth bytes of the patterns being searched. If no candidate is\"", "prev0 = V :: splat (0xFF)", ":: core :: clone :: Clone :: clone (& self . lo)", "\" if and only if the corresponding nybble is in the ith bucket. The index of\"", "! true", "\" The given pointer representing the haystack must be valid to read\"", "\" Unlike the top-level `MatchKind` type, the default match semantics for this\"", "u8 :: try_from (bucket) . unwrap ()", "\" panics.\"", "Option < teddy :: Searcher >", "\" Use leftmost-first match semantics, which reports leftmost matches.\"", "\"kind\"", "self . 0 . len ()", "\" The number of buckets MUST be a power of two. Otherwise, determining the\"", "byte_lo + 16", "\" buckets is either 8 (for \\\"slim\\\" Teddy) or 16 (for \\\"fat\\\" Teddy). The generic\"", "\" A convenience function for calling `Config::new()`.\"", "\" For Fat Teddy, the bitsets are not repeated, but instead, the high half\"", "\" the only time this is called and a match is not found is when there\"", "SlimNeon { slim128 : :: core :: clone :: Clone :: clone (& self . slim128) , }", "\" `Teddy` value.\"", "masks [1] . lo", "\" let mat = searcher.find(\\\"foobar\\\")?;\"", "Vec < Vec < (Hash , PatternID) > >", ":: core :: fmt :: Formatter :: debug_struct_field5_finish (f , \"Config\" , \"kind\" , & self . kind , \"force\" , & self . force , \"only_teddy_fat\" , & self . only_teddy_fat , \"only_teddy_256bit\" , & self . only_teddy_256bit , \"heuristic_pattern_limits\" , & & self . heuristic_pattern_limits ,)", "self . patterns . memory_usage ()", "SlimNeon :: < 3 > :: new (& patterns)", "if let Some (m) = self . find_one (cur , end , & mut prev0) { return Some (m) ; }", "\" to do at least an unaligned load of `V` at `start`.\"", "\" If a candidate is returned, it will be a collection of 8-bit bitsets\"", "for (id , pattern) in t . patterns . iter () { let lonybs = pattern . low_nybbles (t . mask_len ()) ; if let Some (& bucket) = map . get (& lonybs) { t . buckets [bucket] . push (id) ; } else { let bucket = (BUCKETS - 1) - (id . as_usize () % BUCKETS) ; t . buckets [bucket] . push (id) ; map . insert (lonybs , bucket) ; } }", "if ! ! candidate . is_zero () { :: core :: panicking :: panic (\"assertion failed: !candidate.is_zero()\" ,) }", "\" Casts this pointer to `usize`.\"", "\" guaranteed to satisfy the match semantics of this collection of\"", "& self . pid", "is_prefix (bytes , self . bytes ())", "\" The common elements of all \\\"slim\\\" and \\\"fat\\\" Teddy search implementations.\"", "\" than once.\"", "(cand1 , cand2 , cand3 , cand4)", "\" method with a `target_feature` attribute. Callers must ensure that\"", "\" to the start of `haystack` (and not `at`).\"", "{ if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: None ,) ; } }", ":: core :: panicking :: panic (\"assertion failed: V::BYTES <= self.hi.len()\" ,)", "\" `memchr` crate does this.)\"", "masks [1]", "\" If no match could be found, then `None` is returned.\"", "self . by_id", "\" implement this for SSE on x86_64 and NEON on aarch64, with the latter two\"", "\" vectors. If SSSE3 is not available in the current\"", "! c . is_zero ()", "if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: None ,) ; }", "1 << bit", "\" patterns that are being searched.\"", "data", "Option < ForceAlgorithm >", "\" leftmost-first match semantics.\"", "Sync", "if cur < end { cur = end . sub (V :: BYTES) ; prev0 = V :: splat (0xFF) ; prev1 = V :: splat (0xFF) ; prev2 = V :: splat (0xFF) ; if let Some (m) = self . find_one (cur , end , & mut prev0 , & mut prev1 , & mut prev2) { return Some (m) ; } }", "\"     .add(\\\"foobar\\\")\"", "& self . buckets [hash % NUM_BUCKETS]", "(self . by_id . len () <= u16 :: MAX as usize)", "0", "\" from.\"", "! (hash_len >= 1)", "rabinkarp", "{ :: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , \"Teddy\" , & __self_0 ,) }", "vgetq_lane_u64 (maxes , 0)", "\" # if cfg!(all(feature = \\\"std\\\", any(\"", "crate", "\" * The distance between `start` and `end` must not overflow `isize`.\"", "\" and the minimum length of the patterns being searched for.\"", "if ! (V :: BYTES <= self . lo . len ()) { :: core :: panicking :: panic (\"assertion failed: V::BYTES <= self.lo.len()\" ,) }", "(BITS <= 7)", "match * self { SearchKind :: Teddy (ref ted) => ted . memory_usage () , SearchKind :: RabinKarp => 0 , }", "\" possible. (And if you believe it's necessary, open an issue to discuss\"", "\" Returns the length, in bytes, of the smallest pattern.\"", "\" employed. This useful to disable for benchmarking where one wants to\"", ":: core :: fmt :: Formatter :: write_str (f , match self { ForceAlgorithm :: Teddy => \"Teddy\" , ForceAlgorithm :: RabinKarp => \"RabinKarp\" , } ,)", "\" This is useful for avoiding an additional import.\"", "if true { if ! (pid . as_usize () < self . patterns . len ()) { :: core :: panicking :: panic (\"assertion failed: pid.as_usize() < self.patterns.len()\" ,) } }", "Fat < V , 4 >", "\" All methods are not safe since they are intended to be implemented using\"", "indices", "\" default (leftmost-first).\"", "\" `None`.\"", "\" An implementation of the Rabin-Karp algorithm. The main idea of this\"", "while cur <= end . sub (V :: Half :: BYTES) { if let Some (m) = self . find_one (cur , end) { return Some (m) ; } cur = cur . add (V :: Half :: BYTES) ; }", "Arc :: clone (& patterns)", "\" if it's in the higher half.\"", "self . config . only_teddy_fat", "\" An undocumented method for forcing the use of the Teddy algorithm.\"", "\" time that \\\"selects\\\" the variant chosen at build time.\"", "\" Runs the verification routine for \\\"slim\\\" Teddy.\"", "self . hash (& haystack [at .. at + self . hash_len])", "FatMaskBuilder { lo : :: core :: default :: Default :: default () , hi : :: core :: default :: Default :: default () , }", "\" advantage of the fact that `_mm256_alignr_epi8` operates on each 128-bit\"", "for & (phash , pid) in bucket { if phash == hash { if let Some (c) = self . verify (pid , haystack , at) { return Some (c) ; } } }", "8", "\"Slim\"", "while cur <= end . sub (V :: BYTES) { if let Some (m) = self . find_one (cur , end , & mut prev0 , & mut prev1) { return Some (m) ; } cur = cur . add (V :: BYTES) ; }", "self . hi [byte_hi] |= 1 << bucket", "Some (m)", "if true { if ! (len >= self . minimum_len ()) { :: core :: panicking :: panic (\"assertion failed: len >= self.minimum_len()\" ,) } }", "span", "* const T", "generic :: Slim :: < uint8x16_t , 2 , > :: new", "\"only_teddy_256bit\"", "vpmaxq_u8", ":: core :: panicking :: panic (\"assertion failed: V::BYTES <= self.lo.len()\" ,)", "\"     .collect();\"", ":: core :: panicking :: panic_fmt (format_args ! (\"Teddy only supports 8 or 16 buckets\") ,)", "x . read () == y . read ()", "MatchKind :: default ()", "\" used to accumulate patterns and create a [`Searcher`] from them.\"", "match self { ForceAlgorithm :: Teddy => \"Teddy\" , ForceAlgorithm :: RabinKarp => \"RabinKarp\" , }", "self . i += 1", ":: core :: panicking :: panic (\"assertion failed: len >= self.minimum_len()\" ,)", "\" Set the match kind semantics for this collection of patterns.\"", "Pattern < '_ >", "Patterns :: new", ":: core :: clone :: AssertParamIsClone < PatternID >", "V :: load_unaligned (self . hi [..] . as_ptr ())", "if haystack [span] . len () < teddy . minimum_len () { return self . find_in_slow (haystack , span) ; }", "\" use the [`Config`] and/or [`Builder`] types for more fine grained control.\"", "\" The patterns provided by the caller.\"", "< [SlimMaskBuilder ; BYTES] > :: try_from (mask_builders) . unwrap ()", "\" Do an 8-bit pairwise equality check. If lane `i` is equal in this\"", "\" searcher will not be built.\"", "x", "Slim", "res2", "\" A knob for controlling the match semantics of a packed multiple string\"", "\" leftmost-longest, see the docs on the top-level `MatchKind` type.\"", "! (len >= self . minimum_len ())", "\" The match semantics determines the order of the iterator over patterns.\"", "f . debug_struct (\"FatMaskBuilder\") . field (\"lo\" , & parts_lo) . field (\"hi\" , & parts_hi) . finish ()", "(PatternID , Pattern < 'p >)", "self . force = Some (ForceAlgorithm :: Teddy)", "(& mut self . order , & mut self . by_id)", "\" https://www-igm.univ-mlv.fr/~lecroq/string/node5.html\"", "cur < end", "res0 . shift_in_three_bytes (* prev0)", "match self { SearchKind :: Teddy (__self_0) => { SearchKind :: Teddy (:: core :: clone :: Clone :: clone (__self_0)) } SearchKind :: RabinKarp => SearchKind :: RabinKarp , }", ":: core :: intrinsics :: discriminant_value (self)", "Searcher { imp : :: core :: clone :: Clone :: clone (& self . imp) , memory_usage : :: core :: clone :: Clone :: clone (& self . memory_usage) , minimum_len : :: core :: clone :: Clone :: clone (& self . minimum_len) , }", ":: core :: clone :: Clone :: clone (& self . imp)", "u8 :: try_from", "patlimit && patterns . len () > 64", "for (bucket_index , bucket) in teddy . buckets . iter () . enumerate () { for pid in bucket . iter () . copied () { let pat = teddy . patterns . get (pid) ; for (i , builder) in mask_builders . iter_mut () . enumerate () { builder . add (bucket_index , pat . bytes () [i]) ; } } }", "patlen", "masks [0]", "usize :: from ((byte >> 4) & 0xF)", "self . lo [..]", "\" This routine is marked `inline(always)`. If you want to call this function\"", "\" algorithm is to maintain a rolling hash as it moves through the input, and\"", "16", "\" `i`. Each candidate returned corresponds to the first, second and third\"", "vextq_u8 (vector2 , self , 13)", ":: core :: panicking :: panic (\"assertion failed: !bytes.is_empty()\")", "{ if patlimit && patterns . len () > 32 { } SlimNeon :: < 2 > :: new (& patterns) }", "self . teddy . verify (cur . sub (1) , end , c)", ":: core :: fmt :: Formatter", "Default", "if ! (hash_len >= 1) { :: core :: panicking :: panic (\"assertion failed: hash_len >= 1\") }", "SlimMaskBuilder :: from_teddy", "generic :: Slim :: < uint8x16_t , 1 , > :: new (Arc :: clone (patterns))", "self . patterns . len () * core :: mem :: size_of :: < (Hash , PatternID) > ()", "res2prev2", "V :: Half :: BYTES + (BYTES - 1)", "yes", "self . buckets . get_unchecked (bucket) . iter ()", "& & self . patterns", "& mut prev1", "byte_hi + 16", "\" slim Teddy is used (8 buckets) and `true` means fat Teddy is used\"", ":: core :: panicking :: panic_fmt", "\"Fat\"", "\" This uses a latency optimized variant of `memcmp` internally which *might*\"", "res0 . half_shift_in_three_bytes (* prev0)", "Pattern < 'a >", "\" This `Searcher` is essentially a wrapper for a `SearcherT` trait\"", "Slim < V , BYTES >", "match self . search_kind { SearchKind :: Teddy (ref teddy) => { if haystack [span] . len () < teddy . minimum_len () { return self . find_in_slow (haystack , span) ; } teddy . find (& haystack [.. span . end] , span . start) } SearchKind :: RabinKarp => { self . rabinkarp . find_at (& haystack [.. span . end] , span . start) } }", "AsRef < [u8] >", "{ SlimNeon :: < 4 > :: new (& patterns) }", ":: core :: panicking :: panic (\"assertion failed: pid.as_usize() < self.patterns.len()\" ,)", "Arc < Patterns >", "! (self . by_id . len () <= u16 :: MAX as usize)", "haystack [at + self . hash_len]", "1 <= BYTES && BYTES <= 4", "\" and instead only supports leftmost-first or leftmost-longest. Namely,\"", "\" and third bytes of all patterns that are being searched.\"", "\" ```\"", "mem :: size_of :: < PatternID > ()", "y . add (n . wrapping_sub (4))", "\" of the patterns being searched. If no candidate is found, then all of\"", "self . kind = MatchKind :: default ()", "\"end\"", "\" Wikipedia has a decent explanation, if a bit heavy on the theory:\"", ":: core :: cmp :: PartialEq", "\" identifiers. The order of `by_id` and `order` is always the same for\"", ".. span . end", "hayptr . add (haystack . len ())", "\" example, a `&[u8]`, they should automatically satisfy all of the safety\"", "usize :: MAX", "\" Return an iterator over all the patterns in this collection, in the\"", "self . bytes () . iter () . take (len) . enumerate ()", ":: core :: clone :: Clone :: clone (& self . slim128)", "\" Returns the length of this pattern, in bytes.\"", "\" Callers must ensure that a pattern with the given identifier exists\"", "\"assertion failed: len >= self.minimum_len()\"", "\"memory_usage\"", "x . cast :: < u16 > ()", "\" for N buckets.\"", "BTreeMap :: new ()", "* prev2", "masks [0] . hi", "[Mask < V > ; 4]", "\"FatMaskBuilder\"", "while candidate_chunk != 0 { let bit = candidate_chunk . trailing_zeros () . as_usize () ; candidate_chunk &= ! (1 << bit) ; let cur = cur . add (bit / BUCKETS) ; let bucket = bit % BUCKETS ; if let Some (m) = self . verify_bucket (cur , end , bucket) { return Some (m) ; } }", "\" For more information on the distinction between leftmost-first and\"", "RabinKarp :: new (& patterns)", "\" crate module in that it doesn't support \\\"standard\\\" match semantics,\"", "\" multiple patterns of varying size by fixing the number of bytes to hash\"", "order . sort_by (| & id1 , & id2 | { by_id [id1] . len () . cmp (& by_id [id2] . len ()) . reverse () })", "\" Callers must ensure that this is okay to call in the current target for\"", ":: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! (\"Teddy does not support zero-length patterns\") ,) ,)", "\" right by `Self::BYTES - 3` bytes.\"", "\" to a slower non-packed searcher (which is still generally faster than\"", "\" The Teddy variant we use. We use dynamic dispatch under the theory that\"", "14", "\" returned will include the identifier of the pattern that matched, which\"", ":: alloc :: fmt :: format", "core :: u16 :: MAX", "by_id [id1]", "V :: BYTES <= self . hi . len ()", "\"hash_2pow\"", "generic :: Slim :: < uint8x16_t , 4 , > :: new", "\" of this vector and then in the other vector. The given function is\"", "teddy :: Builder :: new () . only_256bit (self . config . only_teddy_256bit)", ":: core :: fmt :: Formatter :: write_str", "m", "prev . wrapping_sub ((old_byte as usize) . wrapping_mul (self . hash_2pow))", "end . sub (V :: Half :: BYTES)", "Mask :: members2", "Fat { teddy , masks }", "\" # Safety\"", "is_equal_raw (haystack . as_ptr () , needle . as_ptr () , needle . len ())", "self . patterns . memory_usage () + self . rabinkarp . memory_usage () + self . search_kind . memory_usage ()", "b as usize", "& self . only_fat", ":: core :: panicking :: panic (\"internal error: entered unreachable code\" ,)", "teddym . start ()", "< [FatMaskBuilder ; BYTES] > :: try_from (mask_builders)", "NUM_BUCKETS", "SlimNeon { slim128 }", "format_args ! (\"only 1, 2, 3 or 4 bytes are supported\")", "\" Compare `n` bytes at the given pointers for equality.\"", "res0prev0 . and (res1prev1) . and (res2prev2) . and (res3)", "\" The builder primarily permits fine grained configuration of the Teddy\"", "generic :: Slim :: < uint8x16_t , 4 , > :: new (Arc :: clone (patterns))", "p", "self . buckets . get_unchecked (bucket) . iter () . copied ()", "\" low and high masks together also results in 8-bit bitsets, but where bit\"", "\" Represents the low and high nybble masks that will be used during \\\"fat\\\"\"", "\" concatenated into a `2 * Self::BITS` temporary buffer and then shifted\"", "candidate_chunk . trailing_zeros ()", "\" masks, and 256-bit shuffles only operate on 128-bit lanes.)\"", "vld1q_u8 (data)", ":: core :: panicking :: AssertKind :: Eq", "\" Same as `ptr::offset_from` in addition to `self >= origin`.\"", "x . cast :: < u16 > () . read_unaligned () == y . cast :: < u16 > () . read_unaligned ()", "if at + self . hash_len >= haystack . len () { return None ; }", "self . patterns . len () >= PATTERN_LIMIT", "chunk . and (lomask)", "allow", "hlo", "\" match semantics (leftmost-first or leftmost-longest) of a searcher. In the\"", "\" * It must be the case that `start < end` and that the distance between\"", ":: core :: fmt :: Formatter :: debug_struct_field3_finish (f , \"Match\" , \"pid\" , & self . pid , \"start\" , & self . start , \"end\" , & & self . end ,)", "Teddy < 8 >", "coverage", "self . verify64 (cur , end , chunk)", "\" The masks should correspond to the masks computed for the first, second\"", "\" A trait for describing vector operations used by vectorized searchers.\"", "\"hi\"", "\" the lanes will be set to zero in at least one of the vectors returned.\"", "SlimNeon", "if let Some (m) = self . find_one (cur , end , & mut prev0 , & mut prev1) { return Some (m) ; }", "self . imp . find (hayptr . add (at) , hayptr . add (haystack . len ())) ?", "\" Create a new default configuration. A default configuration uses\"", "self . lo [byte_lo + 16] |= 1 << (bucket % 8)", "\"assertion failed: bucket < self.buckets.len()\"", "\" 256-bit vectors are requested and they aren't available, then a\"", "\" matcher. Most options are made only available for testing/benchmarking\"", ":: core :: option :: Option :: Some (format_args ! (\"Teddy does not support zero-length patterns\") ,)", "\"Pattern\"", "< [SlimMaskBuilder ; BYTES] > :: try_from (mask_builders)", "core :: mem :: size_of :: < (Hash , PatternID) >", "\" haystack. The candidate chunk given should correspond to 8-bit bitsets\"", ":: core :: fmt :: Result", "x . cast :: < [u8 ; 3] > () . read () == y . cast :: < [u8 ; 3] > () . read ()", ":: core :: intrinsics :: discriminant_value", "self . only_256bit = yes", "patterns . len ()", "\" The minimum haystack length this searcher can handle. It is intended\"", "core :: u16 :: MAX as usize", "pat . is_prefix (& haystack [at ..])", "\" Returns true if and only if this collection of patterns is empty.\"", "xend . cast :: < u32 > ()", "\" from. They must also point to a region of memory that is at least the\"", "t . buckets [bucket] . push (id)", "y", "bit % BUCKETS", "\" Each byte in the mask corresponds to a 8-bit bitset, where bit `i` is set\"", "unsafe { SlimNeon :: < 2 > :: new_unchecked (patterns) }", "res3", "\" Callers should not convert the `usize` back to a pointer if at all\"", "\" assert_eq!(vec![\"", ":: core :: clone :: Clone :: clone", "t . patterns", "& mut Builder", "\" the byte (0-15, inclusive) corresponds to the nybble.\"", "\" Teddy searcher.\"", "\" * Both `start` and `end` must be _derived from_ a pointer to the same\"", "\" the collection is itself empty.\"", "\" computing offsets or alignments.\"", "\"assertion failed: bucket < 16\"", ":: alloc :: vec :: from_elem (:: alloc :: vec :: Vec :: new () , BUCKETS)", "new_byte", "patlimit && patterns . len () > 48", "vy", "Slim < V , 2 >", "Mask", "Mask :: members1", "\" allocated objects.\"", "res2 . shift_in_one_byte (* prev2)", "\" to satisfy the correct match semantics. (Either leftmost-first or\"", "\"SlimNeon\"", "\" Fat Teddy.\"", "self . find_one (cur , end)", "Option < Match >", "slim128 . memory_usage ()", "if cur < end { cur = end . sub (V :: BYTES) ; prev0 = V :: splat (0xFF) ; if let Some (m) = self . find_one (cur , end , & mut prev0) { return Some (m) ; } }", "Fat", "\" byte.\"", "for pid in self . buckets . get_unchecked (bucket) . iter () . copied () { if true { if ! (pid . as_usize () < self . patterns . len ()) { :: core :: panicking :: panic (\"assertion failed: pid.as_usize() < self.patterns.len()\" ,) } } let pat = self . patterns . get_unchecked (pid) ; if pat . is_prefix_raw (cur , end) { let start = cur ; let end = start . add (pat . len ()) ; return Some (Match { pid , start , end }) ; } }", "for p in patterns { self . add (p) ; }", "\" the window repeated in each half of the vector.\"", "self . masks", "(bucket < self . buckets . len ())", "Mask :: members3", "teddy", "teddy :: Builder :: new", "& MatchKind", "& mut fmt :: Formatter < '_ >", "xend", "if pat . is_prefix (& haystack [at ..]) { Some (Match :: new (id , at .. at + pat . len ())) } else { None }", "self . candidate (cur , prev0 , prev1)", "{ if * left_val == * right_val { let kind = :: core :: panicking :: AssertKind :: Ne ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! (\"Teddy requires at least one pattern\") ,) ,) ; } }", "\" # fn example() -> Option<()> {\"", "Hash", "\" time. (Remember, the nybbles in the haystack are used as indices into these\"", "span . end", "parts_lo", "Arc :: new", "\" `0 <= i < n`.\"", "by_id [id1] . len () . cmp (& by_id [id2] . len ())", "vx == vy", "self . slim128", "! (pid . as_usize () < self . patterns . len ())", "\"Searcher\"", "PatternIter { patterns : self , i : 0 , }", "core :: mem :: size_of :: < PatternID >", "\" via a trait object. We basically implement this trait for each possible\"", "(patterns . len ())", "\"assertion failed: self.by_id.len() <= u16::MAX as usize\"", "\" candidate discovered.\"", "(byte >> 4) & 0xF", "{ :: core :: panicking :: panic_fmt (format_args ! (\"only 1, 2, 3 or 4 bytes are supported\") ,) ; }", "vshrq_n_u8 (self , BITS)", "\" one copy throughout all packed searchers.\"", "f (1 , lane)", ":: core :: fmt :: Formatter :: debug_tuple_field1_finish", "\" explore how Teddy performs on large number of patterns even if the\"", "* prev1 = res1", "\" We tag this function as `cold` because it helps improve codegen.\"", "& 'a Self", "self . patterns . match_kind ()", "\"Builder\"", "\" unsupported CPU or because there are too many patterns), then `None`\"", "\" leftmost-longest.)\"", "return match n { 0 => true , 1 => x . read () == y . read () , 2 => { x . cast :: < u16 > () . read_unaligned () == y . cast :: < u16 > () . read_unaligned () } 3 => x . cast :: < [u8 ; 3] > () . read () == y . cast :: < [u8 ; 3] > () . read () , _ => { :: core :: panicking :: panic (\"internal error: entered unreachable code\" ,) } }", "memory_usage", "self . find_one (cur , end , & mut prev0)", "self . by_id . len ()", "haystack [span]", ":: core :: clone :: Clone :: clone (& self . only_teddy_fat)", "[Vec < PatternID , > ; BUCKETS]", "\" This is slightly tweaked dependending on whether Slim or Fat Teddy is being\"", "& by_id [id2] . len ()", "\" bytes of the patterns being searched. If no candidate is found, then\"", "! (bucket < 16)", "maxes", "\" The length of the smallest pattern, in bytes.\"", "\" be used to construct a [`packed::Searcher`](Searcher) for searching.\"", "hash_2pow = hash_2pow . wrapping_shl (1)", "self . buckets [hash % NUM_BUCKETS]", "candidate . is_zero ()", "\" The extra number of buckets spreads the literals out more and reduces\"", "res1 . half_shift_in_one_byte (* prev1)", "self . hi [..] . as_ptr ()", "Vector", "\" be built, then `None` is returned.\"", "\" requires `alloc`, there's no real reason (AFAIK) to go down this path. (The\"", "self . order . len () * mem :: size_of :: < PatternID > () + self . by_id . len () * mem :: size_of :: < Vec < u8 > > () + self . total_pattern_bytes", "self . lo [..] . as_ptr ()", "Pattern (self . by_id . get_unchecked (id . as_usize ()))", "\" of things that can be converted to a `&[u8]`.\"", "usize :: try_from", "& self . buckets . len ()", "\" vectors returned.\"", "self . verify (pid , haystack , at)", "\"Mask\"", "& & self . i", "\" A searcher that dispatches to one of several possible Teddy variants.\"", ":: core :: marker :: Copy", "\"only_256bit\"", "mask_len", "len >= self . minimum_len ()", "rk . buckets [bucket]", "cur . sub (3)", "\" but Fat Teddy reads 16 bytes at a time.\"", "__self_0", "\" Read a half-vector-size number of bytes from the given pointer, and\"", "res0", "\" `i`. If no candidate is found, then the vector returned will have all\"", "builder . build ()", "self . lo . len ()", "self . verify_bucket (cur , end , bucket)", "& self . start", "FindIter { searcher : self , haystack , span , }", "\" # Motivation\"", "by_id", "\" `chunk` should correspond to a `V::BYTES` window of the haystack (where\"", "\" dispatch approach, but doesn't require any allocations. Since this crate\"", "{ self . force = None ; }", "let Some (m) = self . teddy . verify (cur . sub (3) , end , c)", "candidate_chunk &= ! (1 << bit)", "\"assertion failed: self.patterns.len() <= core::u16::MAX as usize\"", "& self . hash_2pow", "(V :: BYTES <= self . lo . len ())", "\" * Both `x` and `y` must each point to an allocated object and\"", "masks [1] . hi", "(bucket < 8)", "Builder :: from_config", "return Some (m)", "SlimMaskBuilder { lo : :: core :: clone :: Clone :: clone (& self . lo) , hi : :: core :: clone :: Clone :: clone (& self . hi) , }", "\" * Both `x` and `y` must be valid for reads of up to `n` bytes.\"", "\"lo\"", "FatMaskBuilder :: default", "\"by_id\"", "teddy :: Builder :: new () . only_256bit (self . config . only_teddy_256bit) . only_fat (self . config . only_teddy_fat) . heuristic_pattern_limits (self . config . heuristic_pattern_limits) . build (patterns)", "FatMaskBuilder :: default ()", "if ! c . is_zero () { if let Some (m) = self . teddy . verify (cur , end , c) { return Some (m) ; } }", "\" identified via the shuffle masks.\"", "< [Vec < PatternID , > ; BUCKETS] > :: try_from (:: alloc :: vec :: from_elem (:: alloc :: vec :: Vec :: new () , BUCKETS) ,) . unwrap ()", "lonybs", "loop { let bucket = & self . buckets [hash % NUM_BUCKETS] ; for & (phash , pid) in bucket { if phash == hash { if let Some (c) = self . verify (pid , haystack , at) { return Some (c) ; } } } if at + self . hash_len >= haystack . len () { return None ; } hash = self . update_hash (hash , haystack [at] , haystack [at + self . hash_len]) ; at += 1 ; }", ":: core :: panicking :: panic (\"assertion failed: !candidate.is_zero()\" ,)", "\" value is returned. Otherwise, this returns `None`.\"", "self . find_one (cur , end , & mut prev0 , & mut prev1 , & mut prev2)", "Patterns :: new ()", "x . cast :: < u32 > ()", ":: core :: fmt :: Formatter :: debug_struct_field2_finish (f , \"Slim\" , \"teddy\" , & self . teddy , \"masks\" , & & self . masks ,)", ":: core :: fmt :: Formatter :: debug_struct_field5_finish (f , \"Patterns\" , \"kind\" , & self . kind , \"by_id\" , & self . by_id , \"order\" , & self . order , \"minimum_len\" , & self . minimum_len , \"total_pattern_bytes\" , & & self . total_pattern_bytes ,)", "\"RabinKarp\"", "\" `i`. Each candidate returned corresponds to the first, second, third\"", "* const u8", "masks [0] . hi . shuffle_bytes (hhi)", "{ use self :: aarch64 :: SlimNeon ; let mask_len = core :: cmp :: min (4 , patterns . minimum_len ()) ; if self . only_256bit == Some (true) { return None ; } if self . only_fat == Some (true) { } match mask_len { 1 => { if patlimit && patterns . len () > 16 { } SlimNeon :: < 1 > :: new (& patterns) } 2 => { if patlimit && patterns . len () > 32 { } SlimNeon :: < 2 > :: new (& patterns) } 3 => { if patlimit && patterns . len () > 48 { } SlimNeon :: < 3 > :: new (& patterns) } 4 => { SlimNeon :: < 4 > :: new (& patterns) } _ => { None } } }", "\" Returns the approximate total amount of heap used by this searcher, in\"", "\" This is a limit placed on the total number of patterns we're willing to try\"", "Vec < PatternID , >", "\" to be the length of the smallest pattern. We also split the patterns into\"", "Slim < V , 4 >", "teddy . buckets", "\" An undocumented method for forcing the use of SSE (`Some(false)`) or\"", "locand2 . and (hicand2)", "\" before using this method.\"", "ForceAlgorithm", "# [inline (always)] | _ , chunk | { let result = self . verify64 (cur , end , chunk) ; cur = cur . add (8) ; result }", "(SearchKind :: Teddy (teddy) , minimum_len)", "* right_val", "\" searched.\"", "\" This is only exposed for more precise testing and benchmarks. Callers\"", "match self { MatchKind :: LeftmostFirst => \"LeftmostFirst\" , MatchKind :: LeftmostLongest => \"LeftmostLongest\" , }", "\" Create a new collection of patterns for the given match semantics. The\"", "{ SearchKind :: Teddy (:: core :: clone :: Clone :: clone (__self_0)) }", "& self . heuristic_pattern_limits", "if ! (BITS <= 7) { :: core :: panicking :: panic (\"assertion failed: BITS <= 7\") }", "Vec < u8 >", ":: core :: fmt :: Formatter :: debug_struct_field2_finish (f , \"PatternIter\" , \"patterns\" , & self . patterns , \"i\" , & & self . i ,)", "n . wrapping_sub (4)", "SlimNeon :: < 4 > :: new (& patterns)", "pattern . low_nybbles (t . mask_len ())", "\" Shuffles the bytes in this vector according to the indices in each of\"", "\" assert_eq!(0, mat.start());\"", "self . candidate (cur , prev0)", "if self . inert || self . patterns . is_empty () { return None ; }", "self . hash_2pow", "self . rabinkarp", "\" `None` is the default, which results in an automatic selection based on\"", "\"only_teddy_fat\"", "if yes { self . force = Some (ForceAlgorithm :: RabinKarp) ; } else { self . force = None ; }", "\"config\"", "if ! ! bytes . is_empty () { :: core :: panicking :: panic (\"assertion failed: !bytes.is_empty()\") }", ":: core :: option :: Option :: Some (format_args ! (\"Teddy requires at least one pattern\") ,)", "pat . is_prefix_raw (cur , end)", "masks [3] . hi . shuffle_bytes (hhi)", "cur . add (8)", "for (i , builder) in mask_builders . iter_mut () . enumerate () { builder . add (bucket_index , pat . bytes () [i]) ; }", "\" mostly to be generic over x86's __m128i and __m256i types. At time of\"", "\"   for p in patterns.iter():\"", "{ None }", "\" This is useful when a packed searcher could be constructed, but could\"", "* prev2 = res2", "\" * `end - start` must be greater than the minimum length for this\"", "\" were provided by the caller.\"", "self . by_id . len () <= u16 :: MAX as usize", "\"assertion failed: BITS <= 7\"", "\" second, third and fourth bytes of all patterns that are being searched.\"", "Builder { only_fat : None , only_256bit : None , heuristic_pattern_limits : true , }", "BYTES - 1", "self . lo [byte_lo] |= 1 << bucket", "V :: load_unaligned", "res0prev0 . and (res1prev1)", "\"Teddy\"", "if cur < end { cur = end . sub (V :: BYTES) ; prev0 = V :: splat (0xFF) ; prev1 = V :: splat (0xFF) ; if let Some (m) = self . find_one (cur , end , & mut prev0 , & mut prev1) { return Some (m) ; } }", "V :: load_half_unaligned (cur)", "by_id [id2]", "impl FnMut (usize , u64) -> Option < T >", "\" given haystack starting at the given position.\"", "& & self . hi", "SearchKind :: RabinKarp", "& & self . end", "& self . only_256bit", "\"patterns\"", "self . len () == 0", "& Self", "u64", "hhi", "! ! candidate . is_zero ()", "(byte >> 4)", "\" object. We just make `memory_usage` and `minimum_len` available without\"", "\" An iterator over the patterns in the `Patterns` collection.\"", "\" total to 16 instead of 8.) This permits spreading the patterns out a bit\"", "haystack [at ..] . len ()", ":: core :: fmt :: Formatter :: debug_struct_field5_finish", "n < 4", "(patterns . len () >= 1)", "\" * Both `x` and `y` must be _derived from_ a pointer to their respective\"", "self . patterns . len () <= core :: u16 :: MAX as usize", "(id , p)", "self . span", "\" It is generic over the number of buckets used. In general, the number of\"", "f (0 , lane)", ":: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: None ,)", "buckets", "\" The match semantics supported by this collection of patterns.\"", "teddym . start () . as_usize () . wrapping_sub (hayptr . as_usize ())", "15", "mem :: size_of :: < Vec < u8 > > ()", "\" Add the given iterator of patterns to this set to match.\"", "I", "Mask :: members2 (chunk , self . masks)", "\" position.\"", "parts_hi", "\" mask length is 4 since there are no Teddy searchers for more than 4\"", "\" pointers, and so this is a more natural return type based on how the\"", "x . cast :: < u16 > () . read_unaligned ()", "Searcher { imp , memory_usage , minimum_len , }", "\" to `0xFF`. Otherwise, it is set to `0x00`.\"", "cand3", ":: core :: panicking :: panic (\"assertion failed: bucket < self.buckets.len()\" ,)", "Builder", "\" it requires all of the patterns to be the same length, which in turn\"", "4", "if ! (bucket < 16) { :: core :: panicking :: panic (\"assertion failed: bucket < 16\") }", "\" If the number of patterns added exceeds the amount supported by packed\"", "vceqq_u8", "1 << bucket", "haystack [at ..]", "\" from the previous chunk (`vector2`) with the first `Self::BYTES - 1`\"", "\" let matches: Vec<PatternID> = searcher\"", "let Some (m) = self . find_one (cur , end , & mut prev0)", "\" A trait for adding some helper routines to pointers.\"", "V :: splat (0xF)", "\" Only 1, 2, 3 and 4 bytes are supported as minimum lengths.\"", "B", "imp", "& lonybs", "# [inline (always)] | _ , chunk | { let result = self . verify64 (cur , end , chunk) ; cur = cur . add (4) ; result }", "ted", "\" use aho_corasick::{packed::{Config, MatchKind}, PatternID};\"", "& self . searcher", "self as usize", "48", "Some (Searcher { patterns , rabinkarp , search_kind , minimum_len , })", "lomask", "& 'h [u8]", "self . hi [byte_hi + 16]", "Patterns { kind : :: core :: clone :: Clone :: clone (& self . kind) , by_id : :: core :: clone :: Clone :: clone (& self . by_id) , order : :: core :: clone :: Clone :: clone (& self . order) , minimum_len : :: core :: clone :: Clone :: clone (& self . minimum_len) , total_pattern_bytes : :: core :: clone :: Clone :: clone (& self . total_pattern_bytes ,) , }", "< [SlimMaskBuilder ; BYTES] > :: try_from", "let Some (m) = self . find_one (cur , end , & mut prev0 , & mut prev1)", "rk . hash (& pat . bytes () [.. rk . hash_len])", "vector2", "crate :: PatternID :: new_unchecked", ":: core :: clone :: Clone :: clone (& self . by_id)", "generic :: Slim < uint8x16_t , BYTES >", "\" Request that heuristic limitations on the number of patterns be\"", "PatternID :: new (self . by_id . len ())", "\" units of bytes.\"", "(* left_val == * right_val)", "f", "{ self . rabinkarp . find_at (& haystack [.. span . end] , span . start) }", ":: core :: option :: Option :: Some", "(haystack [at ..] . len () >= self . minimum_len)", "Builder :: from_config (self . clone ())", "\"heuristic_pattern_limits\"", "self . config . kind", "return false", "t . patterns . iter ()", "{ self . lo [byte_lo + 16] |= 1 << (bucket % 8) ; self . hi [byte_hi + 16] |= 1 << (bucket % 8) ; }", "\" for callers to use some other search routine (such as Rabin-Karp) in\"", "Box < [u8] >", "\" `unpack64(self) -> [u64; BITS / 64]` method, but defining that is\"", "(id . as_usize () % BUCKETS)", "start . add (pat . len ())", "match (& NUM_BUCKETS , & self . buckets . len ()) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: None ,) ; } } }", "crate :: Span", "\"     PatternID::must(1),\"", "& self . by_id [id]", "{ let teddy = match self . build_teddy (Arc :: clone (& patterns)) { None => return None , Some (teddy) => teddy , } ; let minimum_len = teddy . minimum_len () ; (SearchKind :: Teddy (teddy) , minimum_len) }", "candidate", "\" A vector generic mask for the low and high nybbles in a set of patterns.\"", "\" let searcher = Searcher::new([\\\"foobar\\\", \\\"foo\\\"].iter().cloned())?;\"", "(patterns . minimum_len ())", "\" # Example\"", "\" not exist, then this panics.\"", "self . teddy . memory_usage ()", "\" Build a matcher for the set of patterns given. If a matcher could not\"", "& self . i", "at + self . hash_len > haystack . len ()", "\" Add a pattern to this collection.\"", "\" Represents the low and high nybble masks that will be used during\"", "self . minimum_len", "self . rabinkarp . find_at (& haystack [.. span . end] , span . start)", "\" match semantics of the originating collection of patterns.\"", "vceqq_u8 (self , vector2)", "RabinKarp :: new", "\" If callers need more flexible construction, or if one wants to change the\"", "inline", "\" more and thus putting less pressure on verification to be fast.\"", "needle", "res2 . half_shift_in_one_byte (* prev2)", "(1 <= BYTES && BYTES <= 4)", "Builder :: from_config (Config :: new ())", "if ! (1 <= BYTES && BYTES <= 4) { { :: core :: panicking :: panic_fmt (format_args ! (\"only 1, 2, 3 or 4 bytes are supported\") ,) ; } }", "if patlen > haylen { return false ; }", "\" object.\"", "\" For example, if leftmost-longest semantics are used, then the patterns\"", "bucket < self . buckets . len ()", "self . by_id . len () * mem :: size_of :: < Vec < u8 > > ()", "\" The allocation of patterns in buckets. This only contains the IDs of\"", "& haystack [.. span . end]", "Sized", "if self . span . start > self . span . end { return None ; }", "\" Why not use slice equality instead? Well, slice equality usually results in\"", "{ :: alloc :: fmt :: format (format_args ! (\"{0:02}: {1:08b}\" , i , self . hi [i]) ,) }", "patlimit && patterns . len () > 16", "map . insert (lonybs , bucket)", "self . only_fat", "locand2", "masks [3] . hi", "\" The configuration is currently limited only to being able to select the\"", "haystack [span] . len ()", "\" ID of each pattern is the index of the pattern at which it occurs in\"", "\" use aho_corasick::packed::{MatchKind, Searcher};\"", "\" A convenience function for constructing a searcher from an iterator\"", "self . haystack", "self . bytes () . as_ptr ()", "Mask :: members1 (chunk , self . masks)", "\" The type of the rolling hash used in the Rabin-Karp algorithm.\"", "\" raw pointers. This is because the implementations below operate on raw\"", "\" from the previous chunk (`vector2`) with the first `Self::BYTES - 2`\"", "\" The order of patterns defined for iteration, given by pattern\"", "SearchKind", "\"buckets\"", "\"searcher\"", "SlimNeon :: < 1 > :: new_unchecked", "while cur <= end . sub (V :: BYTES) { if let Some (m) = self . find_one (cur , end) { return Some (m) ; } cur = cur . add (V :: BYTES) ; }", "V :: load_half_unaligned", "\" Execute a search on the given haystack (identified by `start` and `end`\"", "\" according to its match semantics, in the given haystack. The `Match`\"", "if bucket < 8 { self . lo [byte_lo] |= 1 << bucket ; self . hi [byte_hi] |= 1 << bucket ; } else { self . lo [byte_lo + 16] |= 1 << (bucket % 8) ; self . hi [byte_hi + 16] |= 1 << (bucket % 8) ; }", "vx", "\" Set to true if the builder detects that a matcher cannot be built.\"", "__arg1_discr", "\" The configuration for a packed multiple pattern searcher.\"", "& & self . span", "\" might be in some cases.\"", "cur", "mask_builders . iter_mut () . enumerate ()", "self . span . start", ":: alloc :: vec :: from_elem (FatMaskBuilder :: default () , BYTES ,)", "\" # Inlining\"", "unsafe { SlimNeon :: < 3 > :: new_unchecked (patterns) }", "\" A pattern that is used in packed searching.\"", "\" Returns true if this pattern is a prefix of the haystack given by the\"", "& haystack [at .. at + self . hash_len]", "& & self . heuristic_pattern_limits", "\" the corresponding lanes in `indices`.\"", "\" 16 buckets where as Slim Teddy uses 8 buckets. More buckets are useful\"", "u8", ":: core :: clone :: Clone :: clone (& self . rabinkarp)", "& self . kind", "\" Teddy search.\"", "\" returned.\"", ":: try_from", "self . bytes () . iter () . take (len)", "is_equal_raw", "masks [2]", "\" Total heap memory used by the Teddy variant.\"", "\" Read a vector-size number of bytes from the given pointer. The pointer\"", "[Mask < V > ; 2]", "{ x . cast :: < u16 > () . read_unaligned () == y . cast :: < u16 > () . read_unaligned () }", "\" found, then all of the lanes will be set to zero in at least one of the\"", "\" to use it with this searcher.\"", "\" Essentially, this contains the patterns and the buckets. Namely, it\"", "hash_len", "prev", "hash_2pow", "bucket % 8", "\" descending order of length, with ties broken by the order in which they\"", ":: core :: intrinsics :: discriminant_value (other)", "self . span . start = m . end ()", "\" let searcher = Config::new()\"", "FindIter", "\" Turn this builder into a vector mask.\"", "MatchKind :: LeftmostFirst", "true", "self . minimum_len ()", "{ :: core :: panicking :: panic_fmt (format_args ! (\"Teddy only supports 8 or 16 buckets\") ,) ; }", "\" Return the pattern with the given identifier without performing bounds\""}
  [split-expanded-lib] DeclsVisitor: Visiting module 'util'. Required imports for module: {"\" never overflow `u32`.\"", "\"Anchored\"", "114", "\" Returns the value that could not be converted to a small index.\"", "10", "return self . range . take ()", "index << self . stride2", "MemmemBuilder :: default", "\" to ever observe a match of `B`.\"", "\" configuration [`Input::anchored`]. Namely, if one requests an unsupported\"", "rank < rarest . 1", "Memmem (memchr :: memmem :: Finder :: new (pattern) . into_owned ())", "self . as_u32 ()", "204", "167", "oldmap", "\" type implements `Copy` which makes it more ergonomic to use in the context\"", "\" The match kind given should be the match kind of the automaton. It\"", "Candidate :: Match (Match :: new (PatternID :: ZERO , start .. end))", "\" small index values instead. It requires `ExactSizeIterator`. At\"", "ByteSet { bits : * self }", "& self . finder", "\" # Support for anchored searches\"", ":: core :: fmt :: Formatter :: debug_struct_field4_finish", "\" packed searching does not support standard semantics.\"", "\" representation is always a `u32` and has `repr(transparent)` enabled. (So\"", "\" it acceptable to return an error if it would otherwise build an NFA that\"", "n as i64", "PatternID :: new (value)", "if ! (start <= end) { :: core :: panicking :: panic (\"assertion failed: start <= end\") }", "173", "\" A candidate is the result of running a prefilter on a haystack at a\"", "\" A type that wraps a packed searcher and implements the `Prefilter`\"", "192", "\" If an Aho-Corasick searcher does not support the anchored mode selected,\"", "RareByteOffsets", ":: alloc :: vec :: Vec :: new ()", "\" leftmost-first search will return `abc` as a match. But an \\\"earliest\\\"\"", "[0u8 ; 10]", "for off in self . set . iter () { if off . max > 0 { offsets . push (off) ; } }", "self . offsets . set [usize :: from (haystack [pos])]", "\"elements\"", "self . byteset", ":: core :: cmp :: PartialOrd", "\"rng\"", "\" where the transitions for `id1` were.\"", "\" the same search APIs.\"", "\" of the [`MatchKind`] that the searcher was built with. This is configured\"", "\" The number of bytes set to true in `byteset`.\"", "self . get_span ()", "\" let haystack = \\\"abc\\\";\"", "if self . ascii_case_insensitive { self . add_one_byte (opposite_ascii_case (byte)) ; }", "match self . range . take () { None => { self . range = Some ((element , element)) ; } Some ((start , end)) => { if usize :: from (end) + 1 != usize :: from (element) { self . range = Some ((element , element)) ; return Some ((start , end)) ; } self . range = Some ((start , element)) ; } }", "\" `abcd` match is never reported since it overlaps with the `b` match.\"", "\" Create a new set of byte classes where all bytes are part of the same\"", "\" There is a `From<&T> for Input` implementation for all `T: AsRef<[u8]>`.\"", "\" Returns true if and only if every byte in this class maps to its own\"", "\" This occurs precisely when the start position of this search is greater\"", "self . start", "PartialEq < Span >", "core :: ops :: Index < StateID >", "[& dyn :: core :: fmt :: Debug]", "self . iter () . enumerate ()", "(start , element)", ":: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , \"MatchError\" , & & self . 0 ,)", "\" minimum buffer amount.\"", "self . idx . to_index (id1)", "| sid | self . map [self . idx . to_index (sid)]", "96", "core :: ops :: RangeInclusive < u8 >", "[55 , 52 , 51 , 50 , 49 , 48 , 47 , 46 , 45 , 103 , 242 , 66 , 67 , 229 , 44 , 43 , 42 , 41 , 40 , 39 , 38 , 37 , 36 , 35 , 34 , 33 , 56 , 32 , 31 , 30 , 29 , 28 , 255 , 148 , 164 , 149 , 136 , 160 , 155 , 173 , 221 , 222 , 134 , 122 , 232 , 202 , 215 , 224 , 208 , 220 , 204 , 187 , 183 , 179 , 177 , 168 , 178 , 200 , 226 , 195 , 154 , 184 , 174 , 126 , 120 , 191 , 157 , 194 , 170 , 189 , 162 , 161 , 150 , 193 , 142 , 137 , 171 , 176 , 185 , 167 , 186 , 112 , 175 , 192 , 188 , 156 , 140 , 143 , 123 , 133 , 128 , 147 , 138 , 146 , 114 , 223 , 151 , 249 , 216 , 238 , 236 , 253 , 227 , 218 , 230 , 247 , 135 , 180 , 241 , 233 , 246 , 244 , 231 , 139 , 245 , 243 , 251 , 235 , 201 , 196 , 240 , 214 , 152 , 182 , 205 , 181 , 127 , 27 , 212 , 211 , 210 , 213 , 228 , 197 , 169 , 159 , 131 , 172 , 105 , 80 , 98 , 96 , 97 , 81 , 207 , 145 , 116 , 115 , 144 , 130 , 153 , 121 , 107 , 132 , 109 , 110 , 124 , 111 , 82 , 108 , 118 , 141 , 113 , 129 , 119 , 125 , 165 , 117 , 92 , 106 , 83 , 72 , 99 , 93 , 65 , 79 , 166 , 237 , 163 , 199 , 190 , 225 , 209 , 203 , 198 , 217 , 219 , 206 , 234 , 248 , 158 , 239 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 ,]", "prestart", ":: core :: cmp :: Ordering", "\" Get the equivalence class for the given byte.\"", "roll_start + self . min", "SmallIndex :: new_unchecked (0)", "StateID (SmallIndex :: from (value))", "StateID :: LIMIT", "251", "\" input.set_range(2..=4);\"", "\" input.set_anchored(Anchored::Yes);\"", "SmallIndex :: from_ne_bytes (bytes) . map (PatternID)", "Builder", "\"i8 overflowed usize\"", ":: core :: fmt :: Formatter :: debug_struct_field2_finish", "\" the caller may use this to stop what it's doing and report the match. In\"", "& __self_1", "u32 :: from (index)", "Span { start , .. self . get_span () }", "range . end", "self . min", "184", "& mut self . rng . start", "\" Swap two states. Once this is called, callers must follow through to\"", "b'a'", "\" All patterns added to an Aho-Corasick automaton should be added to this\"", "self . span () . end", "\"pattern\"", "crate :: packed :: MatchKind :: LeftmostLongest", "\"\"", "IteratorIndexExt", "\" `0`, `stride`, `2*stride`, `3*stride`, etc., instead of `0`, `1`, `2`, `3`,\"", "\" automaton.\"", "SmallIndex :: new_unchecked (value)", "\" assert_eq!(4, input.end());\"", "39", "193", "RareByteOffset :: new (pos)", "\" corresponds to a particular bytes (its index) and is only non-zero if\"", "MatchKind :: LeftmostFirst", "181", "\" the patterns `abc` and `b`, and a haystack of `abc`, a normal\"", "127", "self . rank_sum += freq_rank (byte) as u16", "\"one\"", ":: core :: clone :: Clone :: clone (& self . earliest)", "\" fallible or an infallible routine was called.\"", "MatchKind :: Standard", "match self { ErrorKind :: StateIDOverflow { max : __self_0 , requested_max : __self_1 , } => { ErrorKind :: StateIDOverflow { max : :: core :: clone :: Clone :: clone (__self_0) , requested_max : :: core :: clone :: Clone :: clone (__self_1) , } } ErrorKind :: PatternIDOverflow { max : __self_0 , requested_max : __self_1 , } => { ErrorKind :: PatternIDOverflow { max : :: core :: clone :: Clone :: clone (__self_0) , requested_max : :: core :: clone :: Clone :: clone (__self_1) , } } ErrorKind :: PatternTooLong { pattern : __self_0 , len : __self_1 } => { ErrorKind :: PatternTooLong { pattern : :: core :: clone :: Clone :: clone (__self_0) , len : :: core :: clone :: Clone :: clone (__self_1) , } } }", "\" report matches. The first way is the \\\"standard\\\" approach that results from\"", "\" one need only use the state ID as-is, instead of having to multiply it by\"", "SmallIndex :: new_unchecked (index . as_usize ())", "\" there's no direct analogy that can be made here. Standard match semantics\"", "p", "\" Add a literal string to this prefilter builder.\"", "{ f . write_fmt (format_args ! (\"matching with an empty pattern string is not supported for this operation\" ,) ,) }", "\" the aforementioned file in two chunks: `test test foo` and `bar test test`.\"", "format_args ! (\")\")", "haystack [pos]", "\" into \\\"non-match\\\" and \\\"match\\\" states means one can tell if a state is a\"", "\" The configuration and the haystack to use for an Aho-Corasick search.\"", "ErrorKind :: PatternTooLong", "SmallIndexError { attempted : u64 :: from (index) , }", "\" * [`PatternID`] is for representing the identifiers of patterns.\"", "256", ":: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , \"Packed\" , & & self . 0)", "f . debug_struct (\"RareByteOffsets\") . field (\"set\" , & offsets)", "\" A partitioning of bytes into equivalence classes.\"", "\" state machine should be mutated such that all of the transitions in\"", "\" * The haystack to search, provided to the [`Input::new`] constructor. This\"", "210", ":: core :: fmt :: Formatter :: debug_struct_field4_finish (f , \"RareBytesThree\" , \"offsets\" , & self . offsets , \"byte1\" , & self . byte1 , \"byte2\" , & self . byte2 , \"byte3\" , & & self . byte3 ,)", "(1 << bit)", "\" A prefilter for scanning for two starting bytes.\"", "131", "if true { if ! (start <= end) { :: core :: panicking :: panic (\"assertion failed: start <= end\") } }", "235", "137", "start == end", "\" an empty pattern string is not supported.\"", "\" Create a new builder for constructing the best possible prefilter.\"", "PatternID :: ZERO", "& & self . byte2", "\" panics or silent logical errors.\"", "\" Returns one more than this value as a usize.\"", "\" Create a new \\\"unsupported empty pattern\\\" error. This occurs when the\"", "& StateIDError", "(0 .. r . state_len ()) . map (| i | idx . to_state_id (i))", "if cur_id == new_id { continue ; }", "& StartBytesBuilder", "ErrorKind :: StateIDOverflow { max : :: core :: clone :: Clone :: clone (__self_0) , requested_max : :: core :: clone :: Clone :: clone (__self_1) , }", "185", "\"SmallIndexIter\"", "\" match, but this roll buffer allows us to do that. Namely, after the second\"", "\" This is a convenience routine for only mutating the end of a span\"", "& Span", ":: core :: cmp :: AssertParamIsEq < Span >", "\"requested_max\"", "self . rare_set . contains (byte)", "return Err (SmallIndexError { attempted : u64 :: from (id) , })", "! (span . start <= span . end)", "{ :: core :: fmt :: Formatter :: debug_struct_field1_finish (f , \"UnsupportedOverlapping\" , \"got\" , & __self_0 ,) }", "& self . ids", "__self_0 == __arg1_0", "memchr :: memchr2 (self . byte1 , self . byte2 , & haystack [span]) . map (| i | span . start + i)", "self . count += 1", "\"ByteSet\"", "& self . enabled", "self . byte_offsets", "self . available", "\" streaming matches, then you _must_ use the standard kind. The leftmost\"", "& dyn :: core :: fmt :: Debug", "\" matches, then all possible matches are reported. When searching for\"", "227", "{ usize :: try_from (self) . expect (\"u32 overflowed usize\") }", "pbuilder . add (bytes)", "self . rng . start + 1", "b' '", "if ! found { self . add_rare_byte (rarest . 0) ; }", "\" prefilter is not active. The idea here is that if there is no prefilter,\"", "if rank < rarest . 1 { rarest = (b , rank) ; }", "\" The maximum index value.\"", "Default", "\" requires a slice longer than what a 32-bit integer can index. In exchange,\"", "\" In order to \\\"fix\\\" the underlying inconsistent state, a `Remapper`\"", "Option < Prefilter >", "memory_usage", "packed :: Config :: new () . match_kind (kind)", "p . len ()", "if self . ascii_case_insensitive { self . byte_offsets . set (opposite_ascii_case (byte) , offset) ; }", "\" the byte occurred at an offset greater than 0 in at least one pattern.\"", "if ! self . byteset [byte as usize] { self . byteset [byte as usize] = true ; self . count += 1 ; self . rank_sum += freq_rank (byte) as u16 ; }", "\" If the given index exceeds [`SmallIndex::MAX`], then this returns\"", "Vec < T >", "\" Set the starting offset for the span for this search configuration.\"", "self . 0 . to_ne_bytes ()", "self . get_span () . start", "pos . saturating_sub (usize :: from (self . offset . max))", "\" position of the search and end before the end position of the search.\"", "\" such that only the longest matching words are reported.\"", "\" caller requests a stream search while using an Aho-Corasick automaton\"", "\"available\"", "self . bits", "| i | { let pos = span . start + i ; let offset = self . offsets . set [usize :: from (haystack [pos])] . max ; cmp :: max (span . start , pos . saturating_sub (usize :: from (offset))) }", "\" A lot of the logic for dealing with this is unfortunately split out between\"", "133", "SmallIndex :: from (value)", "self . anchored = mode", "\" If no anchored mode was set, then it defaults to [`Anchored::No`].\"", "match self { MatchKind :: Standard => \"Standard\" , MatchKind :: LeftmostFirst => \"LeftmostFirst\" , MatchKind :: LeftmostLongest => \"LeftmostLongest\" , }", "\" is `ab`. Conversely, if the patterns were given in reverse order, i.e.,\"", "\" report the correct offsets at which the match occurs, but also the matching\"", "n as i32", "MatchErrorKind :: UnsupportedStream { got : :: core :: clone :: Clone :: clone (__self_0) , }", "SmallIndex :: LIMIT", "\" Because of that, when leftmost-first matching is used, if a pattern `A`\"", "self . set_span (Span { end , .. self . get_span () })", "builder . rare_set", "{ self . one = None ; }", "\" is the only required parameter.\"", "\" searcher that was built without anchored support.\"", "(u8 , u8)", "\" index into `haystack`.\"", "\" * [`contiguous::NFA`](crate::nfa::contiguous::NFA) always supports both\"", "\" Return true if this input has been exhausted, which in turn means all\"", "\" trait.\"", "b <= b'z'", "start <= end", ":: core :: clone :: AssertParamIsClone < u32 >", "names", "self . map . clone ()", "self . set_anchored (mode)", "\" // A search using default parameters is unanchored. With standard\"", "\"max\"", "PatternID", "self . 0 . find_in (haystack , span)", ":: core :: fmt :: Formatter :: debug_struct_fields_finish (f , \"RareBytesBuilder\" , names , values ,)", "\" An iterator adapter that is like std::iter::Enumerate, but attaches\"", "match self { Candidate :: None => :: core :: fmt :: Formatter :: write_str (f , \"None\") , Candidate :: Match (__self_0) => { :: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , \"Match\" , & __self_0 ,) } Candidate :: PossibleStartOfMatch (__self_0) => { :: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , \"PossibleStartOfMatch\" , & __self_0 ,) } }", "__self_0", "usize :: try_from (self) . expect (\"i64 overflowed usize\")", "\" The number of patterns that have been added.\"", "\" occurrence of this byte is found, the candidate position reported by\"", "\"ids\"", "\" `std::ops::Range<usize>`.\"", ":: core :: fmt :: Formatter :: debug_struct_fields_finish", "\" case, we set the stride of the index mapped to be `0`, which acts as an\"", "Memmem (:: core :: clone :: Clone :: clone (& self . 0))", ":: core :: fmt :: Formatter :: debug_struct_field2_finish (f , \"ByteClassElementRanges\" , \"elements\" , & self . elements , \"range\" , & & self . range ,)", "\" To avoid accidentally quadratic behavior, a prefilter is considered\"", "let Some (ref mut pbuilder) = self . packed", "245", "format_args ! (\"match kind {0:?} does not support overlapping searches\" , got ,)", "cmp :: max", ":: core :: clone :: AssertParamIsClone < BitSet >", "u16 :: try_from", "Some ((element , element))", "builder . one . as_ref ()", "& & self . attempted", "0 .. self . alphabet_len ()", "SmallIndexError { attempted : u64 :: from (id) , }", "\" Returns a reference to the underlying error kind.\"", "\" returns an error.\"", "self . elements", "ByteClassIter { it : 0 .. self . alphabet_len () , }", "Builder { count : 0 , ascii_case_insensitive : false , start_bytes : StartBytesBuilder :: new () , rare_bytes : RareBytesBuilder :: new () , memmem : MemmemBuilder :: default () , packed : pbuilder , enabled : true , }", "StartBytesOne { byte1 : bytes [0] }", "SmallIndex :: try_from (value) . map (PatternID) . map_err (PatternIDError)", "& [u8]", "\" `id1` are now in the memory region where the transitions for `id2`\"", "\" This must remap every single state ID in the underlying value according\"", "noncontiguous :: NFA :: states (self)", "\" Whether to execute an \\\"earliest\\\" search or not.\"", "\" to a valid [`Range`]. For example, this would panic when given\"", "\" non-overlapping matches, the first match seen is reported. For example, for\"", "\" DFA. That is, in order to get to the transitions for a particular state,\"", "\" Use leftmost-longest match semantics, which reports leftmost matches.\"", "\"u64 overflowed usize\"", "(& 1 , & builder . count)", "\" use aho_corasick::{Match, PatternID};\"", "max", "\"invalid small index\"", "\" things like `&str` and `&[u8]` to search APIs when the defaults are\"", "\" always start_unanchored_id+1.\"", "MatchError :: new (MatchErrorKind :: UnsupportedEmpty)", "u32 :: try_from", "patlen", "\" The identifier of a pattern in an Aho-Corasick automaton.\"", "\" input.set_span(2..4);\"", "u64 :: try_from (self)", "\" transitions that need to be visited/set.\"", "u8 :: try_from (self)", "\" offset as less than or equal to its end offset.\"", "if self . 0 == b' ' { return f . write_fmt (format_args ! (\"\\' \\'\")) ; }", "(self >> 16)", "MatchError :: new", "self . finder", "\" No match was found. Since false negatives are not possible, this means\"", "MatchError :: new (MatchErrorKind :: UnsupportedStream { got , })", "{ b }", "\" An error indicating that an anchored search was requested, but from a\"", "SmallIndex :: from", "\" Currently, prefilters cannot be constructed by\"", "min * 8", "32", "\"byte3\"", "\" generally only takes affect when there are at most 3 distinct possible\"", "inline", "Err (SmallIndexError { attempted : u64 :: from (id) , })", "self . it . next () ?", "s . memory_usage ()", "span . start + i", "\" for memory safety.\"", ":: core :: clone :: Clone :: clone (& self . rng)", "if cur_id == id { self . map [i] = new_id ; break ; }", "98", "\"rare_bytes\"", "\" Note that an empty span contains no offsets and will always return\"", "\"No\"", "if b == 255 { break ; }", "ErrorKind :: PatternIDOverflow", "self . start ()", "\" range of the haystack.\"", "ByteClassElements < 'a >", "return Some ((start , end))", "\" use aho_corasick::{\"", "\" When no match is returned, the prefilter is guaranteeing that no possible\"", "| p | p . len ()", "Some (crate :: packed :: MatchKind :: LeftmostFirst)", ":: core :: fmt :: Formatter :: debug_struct_field2_finish (f , \"MemmemBuilder\" , \"count\" , & self . count , \"one\" , & & self . one ,)", "\" Create a new rare byte offset. If the given offset is too big, then\"", "self . map [self . idx . to_index (sid)]", "core :: i32 :: MAX as usize - 1", "\" let input = Input::new(\\\"foobar\\\").span(2..4);\"", "SmallIndex :: new_unchecked (id . as_usize ())", "\" Set the ending offset for the span for this search configuration.\"", "SmallIndex :: new_unchecked (id)", "PatternID :: must (pattern)", "\" will match `Samwise` because it is the longest possible match, but a\"", "\" faster than integer division. The \\\"stride2\\\" is the exponent. i.e.,\"", ":: core :: fmt :: Formatter :: debug_struct_field2_finish (f , \"RareBytesOne\" , \"byte1\" , & self . byte1 , \"offset\" , & & self . offset ,)", "\" semantics in an effort to match the behavior of dominant backtracking\"", "PatternID :: must", "StartBytesBuilder { ascii_case_insensitive : :: core :: clone :: Clone :: clone (& self . ascii_case_insensitive ,) , byteset : :: core :: clone :: Clone :: clone (& self . byteset) , count : :: core :: clone :: Clone :: clone (& self . count) , rank_sum : :: core :: clone :: Clone :: clone (& self . rank_sum) , }", "self . buf [self . end ..]", "if patlen <= 16 && minlen >= 2 && self . start_bytes . count >= 3 { return packed ; }", "\" much else. If you have a use case for more APIs, please submit an issue.\"", "\" Create a new small index.\"", "& & self . one", "Arc :: new", "\"usize overflowed u8\"", "& & self . max", "\" transition for the state at that ID and re-mapping the transition from\"", "(ByteSet { bits : * self })", "* * self", "RareByteOffset :: default", "\" convey which region of a haystack should be searched via routines like\"", "\" [`Input::span`].\"", "\" A prefilter for accelerating a search.\"", "& self . stride2", "\" The end offset of the span, exclusive.\"", "\" can be used to configure whether your searcher supports unanchored,\"", "self . class == self . classes . get (byte)", "198", "\" all pertinent transitions to updated state IDs. Neglecting to call `remap`\"", "\" Support both anchored and unanchored searches.\"", "(StateID , I :: Item)", "\" then there is no point in treating start states as special.\"", "RareBytesThree { offsets : :: core :: clone :: Clone :: clone (& self . offsets) , byte1 : :: core :: clone :: Clone :: clone (& self . byte1) , byte2 : :: core :: clone :: Clone :: clone (& self . byte2) , byte3 : :: core :: clone :: Clone :: clone (& self . byte3) , }", "\" [`MatchErrorKind::InvalidInputAnchored`] kind.\"", "return Err (SmallIndexError { attempted : index . as_u64 () , })", "& self . map", "builder . count > 3", "\" let input = Input::new(haystack).range(1..).anchored(Anchored::Yes);\"", "allow", "self . bits . 0 [usize :: from (bucket)] & (1 << bit) > 0", "Bound :: Excluded", "PatternIDError", "& 'static _", "\" common the byte (heuristically speaking).\"", "\" a [`Span`] may be given directly, one may also provide a\"", "\" Currently, this prefilter is only active for Aho-Corasick searchers with\"", "\" also that this has no effect in overlapping searches, since overlapping\"", "Bound :: Included", ":: core :: fmt :: Formatter :: debug_struct_field4_finish (f , \"StartBytesBuilder\" , \"ascii_case_insensitive\" , & self . ascii_case_insensitive , \"byteset\" , & self . byteset , \"count\" , & self . count , \"rank_sum\" , & & self . rank_sum ,)", "\" intended to give a heuristic notion of how rare the bytes are.\"", "\" ineffective when it is asked to start scanning from a position that it\"", "& SmallIndex", "Option < SmallIndex >", "f . debug_tuple (\"StateID\") . field (& self . as_u32 ())", "\" `Input::range` APIs are never necessary. Instead, callers can slice the\"", "! self . available", "{ :: core :: fmt :: Formatter :: write_str (f , \"InvalidInputAnchored\") }", "i", "packed :: Config :: new ()", "\" A rare byte prefilter attempts to pick out a small set of rare bytes that\"", "len <= PatternID :: LIMIT", "\" Create a new small index from a `u32` without checking whether the\"", "non_exhaustive", "rdr . read (self . free_buffer ())", "120", "self . span = span", "\" Returns true when the given offset is contained within this span.\"", "\" matches, and the [`Span`] of the match in a haystack.\"", "bytes [1]", "\" A builder for constructing a prefilter that uses memmem.\"", "# [allow (non_exhaustive_omitted_patterns)] match * self { Anchored :: Yes => true , _ => false , }", "(roll_end <= self . end)", "\" An error indicating that an overlapping search was attempted on an\"", "\" use aho_corasick::Anchored;\"", "\"count\"", "Span", "self . range = Some ((start , element))", "\" this case, prefilter implementations must never report a false positive.\"", ":: alloc :: vec :: from_elem (false , 256)", "\" # Safety\"", "111", "self . pattern == other . pattern", ":: core :: clone :: Clone :: clone (& self . start_anchored_id ,)", "BuildError { kind : ErrorKind :: PatternIDOverflow { max , requested_max , } , }", "\" mode, and so APIs like Finder::into_owned aren't available when 'std' is\"", "self . rare_set", ":: core :: cmp :: AssertParamIsEq < [u128 ; 2] >", "len <= StateID :: LIMIT", "& self . anchored", "bytes [len]", "\" syntax, use the [`Input::range`] method.\"", "\" to infallible search methods, a panic will result.\"", ":: core :: clone :: Clone :: clone (& self . finder)", "(self >> 8) as u8", "SmallIndex :: try_from (value)", "\" turns out that regular expression engines have two different ways of\"", "\"Memmem\"", "RareByteOffset :: default ()", "match len { 0 => return None , 1 => Arc :: new (StartBytesOne { byte1 : bytes [0] }) , 2 => { Arc :: new (StartBytesTwo { byte1 : bytes [0] , byte2 : bytes [1] , }) } 3 => { Arc :: new (StartBytesThree { byte1 : bytes [0] , byte2 : bytes [1] , byte3 : bytes [2] , }) } _ => { :: core :: panicking :: panic (\"internal error: entered unreachable code\" ,) } }", "\" This crate uses prefilters in the core search implementations to accelerate\"", "\" * [`noncontiguous::NFA`](crate::nfa::noncontiguous::NFA) always\"", "\" that is too long.\"", "StartKind", "246", "match range . start_bound () { Bound :: Included (& i) => i , Bound :: Excluded (& i) => i . checked_add (1) . unwrap () , Bound :: Unbounded => 0 , }", "\"i32 overflowed usize\"", "147", "return Some (pre)", "\"rank_sum\"", "\" This is basically equivalent to a `std::ops::Range<usize>`, except this\"", "off . max > 0", "\" an error.\"", "end", "\" a `Into<Input>`. These two things combined together mean you can provide\"", "\" false during construction if a condition is seen that invalidates the\"", "{ f . write_fmt (format_args ! (\"ByteClasses(\")) ? ; for (i , class) in self . iter () . enumerate () { if i > 0 { f . write_fmt (format_args ! (\", \")) ? ; } f . write_fmt (format_args ! (\"{0:?} => [\" , class)) ? ; for (start , end) in self . element_ranges (class) { if start == end { f . write_fmt (format_args ! (\"{0:?}\" , start)) ? ; } else { f . write_fmt (format_args ! (\"{0:?}-{1:?}\" , start , end)) ? ; } } f . write_fmt (format_args ! (\"]\")) ? ; } f . write_fmt (format_args ! (\")\")) }", "! builder . available", "SmallIndex :: new (index)", "u8 :: MAX as usize", "self . start_bytes . ascii_case_insensitive (yes)", "self . set_offset (pos , b)", "& self . kind", "u64 :: from (id)", "{ :: core :: panicking :: panic_fmt (format_args ! (\"cannot create iterator for {0} when number of elements exceed {1:?}\" , \"PatternID\" , PatternID :: LIMIT ,) ,) ; }", "self . class", "| b | b . build ()", "crate :: packed :: MatchKind :: LeftmostFirst", "1 << 10", "{ }", "220", "state", "MatchErrorKind :: InvalidInputAnchored", "\" interface.\"", "\" input.set_start(5);\"", "\" Support only anchored searches. Requesting an unanchored search will\"", "let Some (& byte) = bytes . first ()", "Arc :: new (StartBytesTwo { byte1 : bytes [0] , byte2 : bytes [1] , })", "(1 << 10)", "self . available = false", "\" This should only be called when the entire contents of this buffer have\"", "([0 ; 3] , 0)", "StartBytesThree { byte1 : :: core :: clone :: Clone :: clone (& self . byte1) , byte2 : :: core :: clone :: Clone :: clone (& self . byte2) , byte3 : :: core :: clone :: Clone :: clone (& self . byte3) , }", "TryFrom < u32 >", "\" A set of byte offsets associated with bytes in a pattern. An entry\"", "PatternIDIter :: new (len)", "\" This is like the [`Input::span`] method, except this mutates the\"", "for i in 0 .. r . state_len () { let cur_id = self . idx . to_state_id (i) ; let mut new_id = oldmap [i] ; if cur_id == new_id { continue ; } loop { let id = oldmap [self . idx . to_index (new_id)] ; if cur_id == id { self . map [i] = new_id ; break ; } new_id = id ; } }", ":: core :: clone :: Clone", "\" stride2' pre-multiplies an index to an ID.\"", "\" This is a convenience routine for `search.get_span().start()`.\"", "16", "(span . start <= span . end)", "idx", "\" Return the total number of states.\"", "self . one = None", "__self_1", "\" which means it will never overflow a `i16` even though its internal\"", "\" returns false. Otherwise, this reads until it has filled the buffer\"", "156", "\" * Requested an anchored or an unanchored search on a searcher that doesn't\"", "index . as_u64 ()", ":: core :: cmp :: AssertParamIsEq < SmallIndexError >", "\" different positions in the machine.\"", ":: core :: cmp :: AssertParamIsEq < usize >", "f . write_fmt (format_args ! (\"{0}\" , core :: str :: from_utf8 (& bytes [.. len]) . unwrap ()) ,)", "\"len\"", ":: core :: fmt :: Formatter :: write_str (f , \"None\")", ":: core :: cmp :: Ord", "118", "151", "(start , end)", "\" This is like the [`Input::range`] method, except this mutates the\"", "self . 0 as i32", "self . start_anchored_id", "ByteClassElements { classes : self , class , bytes : 0 ..= 255 , }", "\" Convert a state ID to a state index.\"", "\" an unanchored search. Notice that we build our `AhoCorasick` searcher\"", "\" memchr), but it's not clear if it's worth it or not.\"", "StateID :: new_unchecked (index << self . stride2)", "& mut Self", "(* * self)", "self . rare_bytes = self . rare_bytes . ascii_case_insensitive (yes)", "builder . byteset [b]", "\" that the index will overflow a 32-bit integer. A good example of this is\"", "\" unanchored and anchored searches.\"", "\" );\"", "207", "\" The underlying match span.\"", "self . end ()", "\" is in turn split into two different ways of resolving ambiguous matches:\"", "& self . idx", "self . classes", "next_id", "return f . write_fmt (format_args ! (\"\\' \\'\"))", "ErrorKind", "\"start_bytes\"", "223", "b == 255", "\" Create a new \\\"invalid unanchored search\\\" error. This occurs when the\"", "builder . one . as_ref () ?", "PatternIDIter (SmallIndexIter { rng : 0 .. len })", ":: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: None ,)", "\" If you try to execute a search using a `try_` (\\\"fallible\\\") method with\"", "\" equivalence class identifier (which is never bigger than 255).\"", "StateID (SmallIndex :: new_unchecked (value))", "\" do not distinguish between true positives and false positives (i.e.,\"", ":: core :: panicking :: panic", "match * self . kind () { MatchErrorKind :: InvalidInputAnchored => { f . write_fmt (format_args ! (\"anchored searches are not supported or enabled\" ,) ,) } MatchErrorKind :: InvalidInputUnanchored => { f . write_fmt (format_args ! (\"unanchored searches are not supported or enabled\" ,) ,) } MatchErrorKind :: UnsupportedStream { got } => { f . write_fmt (format_args ! (\"match kind {0:?} does not support stream searching\" , got ,) ,) } MatchErrorKind :: UnsupportedOverlapping { got } => { f . write_fmt (format_args ! (\"match kind {0:?} does not support overlapping searches\" , got ,) ,) } MatchErrorKind :: UnsupportedEmpty => { f . write_fmt (format_args ! (\"matching with an empty pattern string is not supported for this operation\" ,) ,) } }", "Candidate :: PossibleStartOfMatch (:: core :: clone :: Clone :: clone (__self_0) ,)", "values", "134", "\" Using this routine with an invalid index value will result in\"", "fmtd . finish ()", "150", "& & self . byte1", ":: core :: cmp :: Ord :: cmp", "\" iterator is representable in the corresponding small index type.\"", "& self . haystack", "format_args ! (\"{0:?}\" , start)", "! (len <= PatternID :: LIMIT)", "(element , element)", "107", "self . 0 . next ()", "\" Remappable is a tightly coupled abstraction that facilitates remapping\"", "alloc :: boxed :: Box < MatchErrorKind >", "\" Create a new \\\"invalid anchored search\\\" error. This occurs when the\"", "format_args ! (\"match kind {0:?} does not support stream searching\" , got ,)", "usize :: from (haystack [pos])", "self . elements (class)", "Ok (readany)", "0", "ByteClassSet (:: core :: clone :: Clone :: clone (& self . 0))", "29", "164", "116", "Option < usize >", ":: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , \"Memmem\" , & & self . 0)", "\" Return the underlying small index integer as raw bytes in native endian\"", "SmallIndexError { attempted : index , }", "left_val", "\" if a certain state is a \\\"special\\\" state of some kind (like a match state)\"", "loop { let id = oldmap [self . idx . to_index (new_id)] ; if cur_id == id { self . map [i] = new_id ; break ; } new_id = id ; }", ":: core :: hash :: Hash :: hash (& self . end , state)", "\" Create a new value from a `u32` without checking whether the\"", "freq_rank", "Memmem", "MatchError :: new (MatchErrorKind :: InvalidInputUnanchored)", ":: core :: clone :: Clone :: clone (& self . it)", "haystack . as_ref () . len ()", "\" # Example\"", "\" has no effect since standard semantics are already \\\"earliest.\\\" Note\"", "WithStateIDIter", "\" Every match reported by a searcher guarantees that its span has its start\"", "\" key optimization and the implementation is a bit subtle. So the abstraction\"", "& self . earliest", "\" stream matches will fail.\"", "\" more data from the stream. For example, let's say we are trying to match\"", "ByteClassSet (ByteSet :: empty ())", "97", "self . end . saturating_sub (self . start)", "\" are generally useful for overlapping matches, or if you just want to see\"", "self . 0 . as_usize ()", "self . is_empty ()", "& mut core :: fmt :: Formatter < '_ >", "\" // because it is the correct leftmost-first match.\"", "\"Unanchored\"", "found = true", "SmallIndex :: new", "\" A span corresponds to the starting and ending _byte offsets_ of a\"", "offset <= self . end", "self . count", "self . rare_bytes . rank_sum", "ErrorKind :: StateIDOverflow { max , requested_max , }", "f", "Iterator", "{ :: core :: fmt :: Formatter :: write_str (f , \"InvalidInputUnanchored\") }", "id > SmallIndex :: MAX . as_u32 ()", "\" add `start` to any match position returned in order for it to be a correct\"", "f . write_fmt (format_args ! (\"failed to create {0} from {1:?}, which exceeds {2:?}\" , \"PatternID\" , self . attempted () , PatternID :: MAX ,) ,)", "\" Returns an iterator of byte ranges in the given equivalence class.\"", "\"RareBytesTwo\"", "kind . as_packed ()", "\" A representation of a range in a haystack.\"", "self . span == other . span", "\" The length that was too long.\"", "\" use aho_corasick::Match;\"", "(PatternID , I :: Item)", "f . write_fmt (format_args ! (\"ByteClasses(\")) ?", "\"UnsupportedEmpty\"", "{ let memory_usage = s . memory_usage () ; Prefilter { finder : Arc :: new (Packed (s)) , memory_usage , } }", "RareByteOffset { max : 0 }", "StateIDError", "{ :: core :: fmt :: Formatter :: debug_struct_field2_finish (f , \"StateIDOverflow\" , \"max\" , __self_0 , \"requested_max\" , & __self_1 ,) }", "\" its own equivalence class.\"", "__self_discr == __arg1_discr && match (self , other) { (MatchErrorKind :: UnsupportedStream { got : __self_0 } , MatchErrorKind :: UnsupportedStream { got : __arg1_0 } ,) => __self_0 == __arg1_0 , (MatchErrorKind :: UnsupportedOverlapping { got : __self_0 } , MatchErrorKind :: UnsupportedOverlapping { got : __arg1_0 } ,) => __self_0 == __arg1_0 , _ => true , }", "requested_max", "& self . packed", ":: core :: clone :: AssertParamIsClone < SmallIndex >", "171", "& & self . rank_sum", "\" value.\"", "| i | { let pos = span . start + i ; cmp :: max (span . start , pos . saturating_sub (usize :: from (self . offset . max)) ,) }", "177", "242", "loop { let element = match self . elements . next () { None => return self . range . take () , Some (element) => element , } ; match self . range . take () { None => { self . range = Some ((element , element)) ; } Some ((start , end)) => { if usize :: from (end) + 1 != usize :: from (element) { self . range = Some ((element , element)) ; return Some ((start , end)) ; } self . range = Some ((start , element)) ; } } }", "\"enabled\"", "RangeBounds < usize >", "PatternIDIter (:: core :: clone :: Clone :: clone (& self . 0))", "self . start == range . start && self . end == range . end", "42", ":: core :: fmt :: Formatter :: debug_struct_field1_finish (f , \"SmallIndexError\" , \"attempted\" , & & self . attempted ,)", "StateID (SmallIndex :: ZERO)", "\" * Executing a stream or overlapping search on a searcher that was built was\"", "0 .. len", "\" input.set_end(5);\"", "170", "cmp :: max (self . set [byte as usize] . max , off . max ,)", "self . end ..", "\" use aho_corasick::{AhoCorasick, Anchored, Input, Match, StartKind};\"", "\" assert_eq!(\\\"bcd\\\", &haystack[mat.span()]);\"", "bytes . iter () . enumerate ()", "153", "StartBytesBuilder :: new", "Arc :: new (RareBytesOne { byte1 : bytes [0] , offset : builder . byte_offsets . set [bytes [0] as usize] , })", "f . write_fmt (format_args ! (\"{0:?}-{1:?}\" , start , end))", "\" Build the starting bytes prefilter.\"", "StateIDIter (SmallIndexIter { rng : 0 .. len })", "\" If you're not sure which match kind to pick, then stick with the standard\"", "self . byte_offsets . set (opposite_ascii_case (byte) , offset)", "& & self . it", "| i | span . start + i", ":: core :: fmt :: Formatter :: debug_struct_field1_finish (f , \"UnsupportedStream\" , \"got\" , & __self_0 ,)", "\" assert!(Anchored::Yes.is_anchored());\"", "f . write_fmt (format_args ! (\"{0:?} => [\" , class))", "\" Each entry corresponds to the maximum offset of the corresponding\"", "other . 0", "self . max_match_id", ":: core :: intrinsics :: discriminant_value", "std :: io :: Read", "& & self . memory_usage", "! (* left_val == * right_val)", "b as u8", "Option < packed :: Builder >", "self . memory_usage", "match self { MatchErrorKind :: InvalidInputAnchored => { :: core :: fmt :: Formatter :: write_str (f , \"InvalidInputAnchored\") } MatchErrorKind :: InvalidInputUnanchored => { :: core :: fmt :: Formatter :: write_str (f , \"InvalidInputUnanchored\") } MatchErrorKind :: UnsupportedStream { got : __self_0 } => { :: core :: fmt :: Formatter :: debug_struct_field1_finish (f , \"UnsupportedStream\" , \"got\" , & __self_0 ,) } MatchErrorKind :: UnsupportedOverlapping { got : __self_0 } => { :: core :: fmt :: Formatter :: debug_struct_field1_finish (f , \"UnsupportedOverlapping\" , \"got\" , & __self_0 ,) } MatchErrorKind :: UnsupportedEmpty => { :: core :: fmt :: Formatter :: write_str (f , \"UnsupportedEmpty\") } }", "& self . rare_set", "format_args ! (\"pattern {0} with length {1} exceeds the maximum pattern length of {2}\" , pattern . as_usize () , len , SmallIndex :: MAX . as_usize () ,)", "\" unspecified behavior, but *not* undefined behavior. In particular, an\"", "218", "if u32 :: from (index) > SmallIndex :: MAX . as_u32 () { return Err (SmallIndexError { attempted : u64 :: from (index) , }) ; }", "\"PatternIDError\"", "b'A' <= b", "\" the prefilter is `position_of_byte - max`, such that the automaton\"", "\" kind, which is the default. In particular, if you need overlapping or\"", "\" The maximum ID of all the match states. Any state ID bigger than this\"", "{ Arc :: new (RareBytesThree { offsets : builder . byte_offsets , byte1 : bytes [0] , byte2 : bytes [1] , byte3 : bytes [2] , }) }", "SmallIndex :: new (value) . map (StateID)", "RareByteOffsets { set : [RareByteOffset :: default () ; 256] , }", "152", "& * left_val", "Option < RareByteOffset >", "self as u32", "\" Aho-Corasick searcher using convenient range syntax.\"", "bytes . to_vec ()", "self . set", "self . stride2 ()", "\" Callers must never rely on this type to be within a certain\"", "self . range", "\" Other than representing \\\"search is complete,\\\" the `Input::span` and\"", "BYTE_FREQUENCIES [b as usize]", "\" Note that [`Input::span`] overrides this method and vice versa.\"", "\" are dead, matches or start states. Namely, by arranging states in a\"", ":: core :: fmt :: Formatter :: debug_struct_field4_finish (f , \"Special\" , \"max_special_id\" , & self . max_special_id , \"max_match_id\" , & self . max_match_id , \"start_unanchored_id\" , & self . start_unanchored_id , \"start_anchored_id\" , & & self . start_anchored_id ,)", "self . start == other . start", "\" Returns true if and only if this anchor mode corresponds to an anchored\"", "\" configure:\"", "93", "209", "{ :: core :: fmt :: Formatter :: debug_struct_field2_finish (f , \"PatternIDOverflow\" , \"max\" , __self_0 , \"requested_max\" , & __self_1 ,) }", "\" via [`Input::earliest`].\"", "\" sets it and returns true.\"", "\" suffix corresponds precisely to the minimum buffer length.\"", "u64 :: try_from", "\" order in which the patterns were given to the Aho-Corasick automaton.\"", "self . start == span . start", "\" * The bounds represent a valid range into the input's haystack.\"", "Vec < StateID >", "f . write_fmt (format_args ! (\"unanchored searches are not supported or enabled\" ,) ,)", "\" Normally, for such little code, I would just duplicate it. But this is a\"", "\" An error indicating that an unanchored search was requested, but from a\"", "ExactSizeIterator", "\" The kind of error that occurred.\"", "{ None }", "for (pos , & b) in bytes . iter () . enumerate () { self . set_offset (pos , b) ; if found { continue ; } if self . rare_set . contains (b) { found = true ; continue ; } let rank = freq_rank (b) ; if rank < rarest . 1 { rarest = (b , rank) ; } }", "{ Arc :: new (StartBytesTwo { byte1 : bytes [0] , byte2 : bytes [1] , }) }", "\" `usize`, `u32` and a `i32`.\"", "SmallIndex :: from_ne_bytes", "\" range for memory safety.\"", "std :: io :: Result < bool >", ":: core :: cmp :: AssertParamIsEq < MatchKind >", "& & self . range", "self . bits == other . bits", "\" Execute a search in the haystack within the span given. If a match or\"", "i >= 2", "\"start_anchored_id\"", "\" automaton with a match kind other than [`MatchKind::Standard`].\"", "\"usize overflowed u16\"", "\"PatternID\"", "SmallIndex :: from_ne_bytes (bytes) . map (StateID) . map_err (StateIDError)", "ByteClasses ([0 ; 256])", "| kind | packed :: Config :: new () . match_kind (kind) . builder ()", "self . map [i] = new_id", "* self", "33", "self . buf . copy_within (roll_start .. roll_end , 0)", "\" An error indicating that a stream search was attempted on an\"", "\" Perl-like regex will match `Sam` since it appears earlier in the\"", "self . map . swap (self . idx . to_index (id1) , self . idx . to_index (id2))", "f . write_fmt (format_args ! (\"match kind {0:?} does not support overlapping searches\" , got ,) ,)", "if off . max > 0 { offsets . push (off) ; }", "core :: cmp :: max (min * 8 , DEFAULT_BUFFER_CAPACITY)", "U8", "\" A prefilter describes the behavior of fast literal scanners for quickly\"", "rank", "PatternID :: new (value) . expect (\"invalid PatternID value\")", "index > SmallIndex :: MAX . as_u64 ()", "\" Using this routine with an invalid value will result in\"", "| i | idx . to_state_id (i)", "MatchErrorKind", "\" not.\"", "\" search should ultimately resume immediately after `foo`. (The prefix `st `\"", "\" on their maximum value, adding `1` to it will always fit in a\"", "StateID :: new (value) . expect (\"invalid StateID value\")", "\" Creates a new set of equivalence classes where each byte belongs to\"", "match len { 0 => return None , 1 => { Arc :: new (RareBytesOne { byte1 : bytes [0] , offset : builder . byte_offsets . set [bytes [0] as usize] , }) } 2 => { Arc :: new (RareBytesTwo { offsets : builder . byte_offsets , byte1 : bytes [0] , byte2 : bytes [1] , }) } 3 => { Arc :: new (RareBytesThree { offsets : builder . byte_offsets , byte1 : bytes [0] , byte2 : bytes [1] , byte3 : bytes [2] , }) } _ => { :: core :: panicking :: panic (\"internal error: entered unreachable code\" ,) } }", "ByteClassSet :: empty", "Arc < dyn PrefilterI >", "self . ids . next () . unwrap ()", "StateIDIter", "& T", "self . start_bytes . build ()", "\"map\"", "Some ((start , element))", "self . 0 . add (start - 1)", "\"InvalidInputUnanchored\"", "rdr . read (self . free_buffer ()) ?", "format_args ! (\"{0}..{1}\" , self . start , self . end)", "return Some (byte)", "\" Build errors occur when some kind of limit has been exceeded, either in the\"", "id2", "{ usize :: try_from (self) . expect (\"i32 overflowed usize\") }", "b <= b'Z'", "RareBytesThree", "memchr :: memchr (self . byte1 , & haystack [span]) . map (| i | span . start + i) . map_or (Candidate :: None , Candidate :: PossibleStartOfMatch)", "(0 .. r . state_len ()) . map (| i | idx . to_state_id (i)) . collect ()", "187", "u8 :: MAX", "\" Returns the match span as a range.\"", "& * right_val", "\" The maximum ID requested.\"", "ids", "214", "\" match.\"", "\" `DFA`. Namely, it only supports unanchored searches by default, but\"", "Sized", "kind", "StartBytesTwo { byte1 : :: core :: clone :: Clone :: clone (& self . byte1) , byte2 : :: core :: clone :: Clone :: clone (& self . byte2) , }", "\"rare_set\"", "max > u8 :: MAX as usize", "\" The main idea of this type is to provide something that can index memory,\"", "\"stride2\"", ":: core :: clone :: Clone :: clone (& self . haystack)", "format_args ! (\"failed to create {0} from {1:?}, which exceeds {2:?}\" , \"PatternID\" , self . attempted () , PatternID :: MAX ,)", "usize :: from (self)", "Match", "{ MatchErrorKind :: InvalidInputAnchored }", "4", ":: core :: fmt :: Formatter :: debug_struct_field2_finish (f , \"StateIDOverflow\" , \"max\" , __self_0 , \"requested_max\" , & __self_1 ,)", "RareByteOffset :: new (pos) . unwrap ()", "& & self . rng", "\" Return the underlying integer as raw bytes in native endian\"", "self . add_one_rare_byte (byte)", "! (start <= end)", "Packed (:: core :: clone :: Clone :: clone (& self . 0))", "\" See also src/dfa/special.rs for a more detailed explanation of how dense\"", "\" call `remap`, or else it's possible for the underlying remappable\"", "\" input.set_earliest(true);\"", "* const T", "\" For most cases, the defaults for all optional parameters are appropriate.\"", "Span { start : 0 , end : haystack . as_ref () . len () , }", "span . end", "\" if its argument cannot fit into the type. This makes it much easier to\"", "& mut self . buf [self . end ..]", "if let Some (pre) = self . memmem . build () { return Some (pre) ; }", "\" indices.\"", "other . pattern", "\" searcher.\"", "& b", "MatchError (alloc :: boxed :: Box :: new (kind))", "\"Yes\"", "\" without having to set the entire span.\"", "\" The kind of anchored starting configurations to support in an Aho-Corasick\"", "f . write_fmt (format_args ! (\"{0:?}\" , start))", "I", "& & self . idx", "core :: ops :: IndexMut < PatternID >", "\"bits\"", "\" A prefilter for scanning for a single \\\"rare\\\" byte.\"", "self . start_bytes = self . start_bytes . ascii_case_insensitive (yes)", "\" Like `new`, but panics if the given value is not valid.\"", "\" depending on the type of searcher used and its configuration:\"", "\" bytes.\"", "\" POSIX regex alternations.\"", "opposite_ascii_case (byte)", "\" The pattern ID.\"", "haystack", "\"offset\"", "\" distinct starting bytes (`f` and `b`), and this prefilter returns all\"", "\"span\"", "self [index . range ()]", "\" The ID of the pattern that was too long.\"", "\" can be more convenient than slicing because the match positions reported\"", "0 .. 256", "& & self . ids", "SmallIndex :: from_u32_unchecked (index)", "& self . rank_sum", "if found { continue ; }", "oldmap [i]", "\" Since our state IDs are premultiplied, we can convert back-and-forth\"", "\" Return the internal `u32` of this small index. This is guaranteed to\"", "\" assert_eq!(Anchored::No, input.get_anchored());\"", "\" bytes themselves. So let's say our stream is a file with the following\"", "core :: cmp :: max (1 , min_buffer_len)", "! builder . byteset [b]", "\" input.set_start(7);\"", "44", "i . checked_add (1)", "u8 :: try_from (self) . expect (\"usize overflowed u8\")", "\" were, and all of the transitions in `id2` are now in the memory region\"", "__arg1_0", "\" The number of bytes that a single value uses in memory.\"", "Ok (SmallIndex :: new_unchecked (index . as_usize ()))", "\" The total number of values that can be represented.\"", "\" `AhoCorasick` by default only supports unanchored searches.\"", "b <= b'f'", "self . start_unanchored_id", "Some (start)", "! self . ascii_case_insensitive", "(len <= PatternID :: LIMIT)", "[u128 ; 2]", "\" When a state is swapped with another, then their corresponding\"", "Candidate :: PossibleStartOfMatch", "\" [`Input::span`] or [`Input::range`]. The bounds set must be valid, or\"", "& self . start_unanchored_id", "std :: error :: Error", "sid", "format_args ! (\"ByteClasses(\")", "\" corresponding equivalence class. The last mapping indicates the largest\"", "\" invalid value can be done in entirely safe code. This may in turn result in\"", "\" or even just anchored searches.\"", "packed :: Builder", "match self { Candidate :: None => Candidate :: None , Candidate :: Match (__self_0) => { Candidate :: Match (:: core :: clone :: Clone :: clone (__self_0)) } Candidate :: PossibleStartOfMatch (__self_0) => { Candidate :: PossibleStartOfMatch (:: core :: clone :: Clone :: clone (__self_0) ,) } }", "\" will automatically be treated as its own equivalence class. All other\"", "\" targets, for example, this type's maximum value will never overflow an\"", "\" Since values represented by a \\\"small index\\\" have constraints\"", "PatternID :: iter", "\" during a search. Since this is extremely perf critical code, we want this\"", "Span { start : self . start () + offset , end : self . end () + offset , }", "\" A collection of sentinel state IDs for Aho-Corasick automata.\"", "right_val", "\" Create a new remapper from the given remappable implementation. The\"", "break", "\" number of patterns (less than 100 or so), but when they do, thoughput can\"", "self . end . checked_sub (self . min) . expect (\"buffer capacity should be bigger than minimum amount\")", "\" Finder::into_owned but doesn't use std-only features like runtime CPU\"", "115", "\" assert_eq!(0..6, input.get_range());\"", "SmallIndex :: new_unchecked (usize :: from (index))", "\" space. Namely, on all targets, this type guarantees that its value will\"", "! self . is_empty ()", "\"UnsupportedStream\"", "Option < u8 >", "format_args ! (\"invalid match span\")", ":: alloc :: vec :: from_elem", "148", "146", "\" When a search is anchored (via [`Anchored::Yes`]), a match must begin\"", "\" The ending position of the match.\"", "& self . bits", "if ! self . enabled { return ; }", "()", "self . alphabet_len () . next_power_of_two () . trailing_zeros ()", "\" A small index is typically useful in cases where there is no practical way\"", "& self . classes", "\"u32 overflowed usize\"", "231", "self . rare_bytes . rank_sum + 50", "\" we can use 32-bit indices instead of 64-bit indices in various places.\"", "core :: fmt :: Display", "\" automatons that contain an empty pattern string.\"", "b", "& Anchored", "\" let input = Input::new(haystack).anchored(Anchored::Yes);\"", "PatternIDError (:: core :: clone :: Clone :: clone (& self . 0))", "\"LeftmostFirst\"", "{ Some (crate :: packed :: MatchKind :: LeftmostFirst) }", "229", "index . range ()", "\" to often just do a pass over all of the states and shuffle them into their\"", "RareByteOffsets :: empty", "loop { classes . set (b , class) ; if b == 255 { break ; } if self . 0 . contains (b) { class = class . checked_add (1) . unwrap () ; } b = b . checked_add (1) . unwrap () ; }", "\" returned. This, however, must never produce false negatives. That is,\"", "\" escapes the byte.\"", "self . start == span . start && self . end == span . end", "if self . count > 3 { return ; }", "38", "memchr :: memchr (self . byte1 , & haystack [span]) . map (| i | span . start + i)", "& self . 0", "StartKind :: Both", "\" pointing to, e.g., `id1` need to be updated to point to `id2`, since\"", ":: core :: fmt :: Formatter :: debug_tuple_field1_finish", ":: core :: fmt :: Formatter :: debug_struct_field1_finish (f , \"RareByteOffset\" , \"max\" , & & self . max ,)", "\" A span is used to report the offsets of a match, but it is also used to\"", "203", "\" let patterns = &[\\\"b\\\", \\\"abcd\\\", \\\"abc\\\"];\"", "\" assert_eq!(0, m.pattern().as_usize());\"", "\" The default range is the entire haystack.\"", "161", "\" in this map where `old_id` *started*, and set it to where it ended up\"", "ErrorKind :: StateIDOverflow", "SmallIndex :: new_unchecked (index)", "self . ascii_case_insensitive = yes", "start + self . 0 . needle () . len ()", "self . earliest", "if patlen <= 16 && minlen >= 2 && self . start_bytes . count >= 3 && self . rare_bytes . count >= 3 { return packed ; }", "\"ByteClassSet\"", "bytes [len] = b", "\" A prefilter for scanning for a single starting byte.\"", "\" property for correctness however. For example, creating a `StateID` with an\"", "StateID (:: core :: default :: Default :: default ())", "{ let start = span . start + i ; let end = start + self . 0 . needle () . len () ; Candidate :: Match (Match :: new (PatternID :: ZERO , start .. end)) }", "\" Complete the remapping process by rewriting all state IDs in the\"", ":: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , \"StateIDError\" , & & self . 0 ,)", "{ f . write_fmt (format_args ! (\"anchored searches are not supported or enabled\" ,) ,) }", "idx . to_state_id (i)", "\" // The normal leftmost-first match.\"", "\" This is analogous to [`SmallIndex::new_unchecked`] in that is does not\"", "usize :: try_from (self)", "\" An `Input` permits setting the bounds of a search via either\"", ":: core :: clone :: Clone :: clone (__self_1)", "\" match can be found in the haystack, and the caller may trust this. That is,\"", "PatternID (index)", "\" aren't supported.\"", "\" ```\"", "IndexMapper", "bytes [2]", "\" the same class.\"", "DEFAULT_BUFFER_CAPACITY", "usize :: from (element)", "usize :: from (end) + 1", "i >= 2 && b'a' <= b", "{ u16 :: try_from (self) . expect (\"usize overflowed u16\") }", "\" will almost certainly result in a corrupt machine.\"", "\" This is a convenience routine for `Match::span().end`.\"", "memchr :: memchr (self . byte1 , & haystack [span]) . map (| i | { let pos = span . start + i ; cmp :: max (span . start , pos . saturating_sub (usize :: from (self . offset . max)) ,) }) . map_or (Candidate :: None , Candidate :: PossibleStartOfMatch)", "self . start_bytes . rank_sum", "self . 0 . find_in (haystack , span) . map_or (Candidate :: None , Candidate :: Match)", "StateID :: new", "{ MatchErrorKind :: UnsupportedStream { got : :: core :: clone :: Clone :: clone (__self_0) , } }", "! (len <= StateID :: LIMIT)", ":: core :: fmt :: Formatter :: debug_struct_field1_finish (f , \"ByteClassIter\" , \"it\" , & & self . it ,)", "\"end\"", "\" let m = Match::must(3, 5..10);\"", "\" Set the equivalence class for the given byte.\"", ":: core :: clone :: AssertParamIsClone < [u8 ; 256] >", "[0 ; 2]", "\" after the start position of the search up until the end position of the\"", "\" a possible match is returned, then it is guaranteed to occur within\"", "\" Enable ASCII case insensitivity. When set, byte strings added to this\"", "self . rare_bytes . count >= 3", "min_buffer_len", "core :: ops :: IndexMut < SmallIndex >", "140", "usize :: try_from (self) . expect (\"i8 overflowed usize\")", "Some (bytes . to_vec ())", "return Ok (true)", "self . map", "\" A set of rare bytes, indexed by byte value.\"", "self . get_span () . end", "self . 0 . add (end)", ":: core :: fmt :: Formatter :: write_str (f , match self { StartKind :: Both => \"Both\" , StartKind :: Unanchored => \"Unanchored\" , StartKind :: Anchored => \"Anchored\" , } ,)", "\" This is a convenience routine for `search.get_span().end()`.\"", "\"Both\"", "\" feature detection.\"", "MatchErrorKind :: UnsupportedStream { got , }", "Usize", "28", "& self . ascii_case_insensitive", "self . set [byte as usize] . max", "199", "! found", "self . add_one_byte (byte)", "patlen <= 16", "* left_val == * right_val", "finder", "core :: ascii :: escape_default (self . 0) . enumerate ()", "145", "range . start_bound ()", "138", "self . 0 . needle ()", "other . start", "\" This is like [`Input::anchored`], except it mutates the search\"", "\" matches as they are detected.\"", "noncontiguous :: NFA :: remap", "105", "\" moved to the front and all other contents are dropped. The size of the\"", "\" whether an error occurs is not dependent on the specific bytes in the\"", "255", "usize :: from (offset)", "oldmap [self . idx . to_index (new_id)]", ":: core :: clone :: AssertParamIsClone < usize >", "& self . span", "\" Occurs when a pattern string is given to the Aho-Corasick constructor\"", "format_args ! (\"matching with an empty pattern string is not supported for this operation\" ,)", "\" PHP.)\"", "\" // Using the same 'find' routine, we can provide an 'Input' explicitly\"", "self . rare_set . add (byte)", "\" choose from. Leftmost-first always chooses the pattern that was provided\"", ":: core :: cmp :: AssertParamIsEq < BitSet >", "& self . attempted", "\" kind will report matches as they are seen. When searching for overlapping\"", "u16 :: try_from (self)", "From < StateID >", "roll_end <= self . end", ":: core :: cmp :: AssertParamIsEq < alloc :: boxed :: Box < MatchErrorKind > >", "self [index . as_usize ()]", "Span { start : self . start + offset , end : self . end + offset , }", "& self . rng", "has_rarer_bytes", ":: core :: clone :: Clone :: clone (& self . count)", "format_args ! (\"anchored searches are not supported or enabled\" ,)", "\"PossibleStartOfMatch\"", "\" of equivalence classes.\"", "WithStateIDIter :: new (self)", "PartialEq < Range < usize > >", "StateID (index)", "H", "fmtd", "if i >= 2 && b'a' <= b && b <= b'f' { b -= 32 ; }", "b . build ()", "\"buf\"", "82", "self . kind ()", "packed", "Arc :: new (RareBytesTwo { offsets : builder . byte_offsets , byte1 : bytes [0] , byte2 : bytes [1] , })", "self . rare_set . contains (b)", "\" memory usage would be exorbitant and its runtime execution would be so\"", "self . set_span (span)", "\"haystack\"", "\" assert_eq!(5, m.start());\"", "\" Return the internal value as a `u32`. This is guaranteed to\"", "\" contiguous ranges of bytes as an equivalence class. So the number of\"", "builder . one", "\"byte2\"", "\"Prefilter\"", "got", "__self_discr", "& mut __H", "format_args ! (\"failed to create small index from {0:?}, which exceeds {1:?}\" , self . attempted () , SmallIndex :: MAX ,)", "usize :: try_from (zeros)", ":: core :: fmt :: Formatter", "i >= 2 && b'a' <= b && b <= b'f'", "239", "b -= 32", "self >> 8", "\" Create a new search configuration for the given haystack.\"", "\" normal leftmost searching.\"", "\" If the given index exceeds the maximum allowed value, then this\"", ":: alloc :: vec :: from_elem (0 , capacity)", "126", ":: core :: fmt :: Result", "self . 0 . needle () . len ()", "memchr :: memchr (self . byte1 , & haystack [span]) . map (| i | { let pos = span . start + i ; cmp :: max (span . start , pos . saturating_sub (usize :: from (self . offset . max)) ,) })", "WithPatternIDIter < Self >", "\" class maps to a single contiguous range.\"", "159", "\" whether the decoded integer is representable as a small index.\"", "\" // Without the span stopping the search early, 'abcd' would be reported\"", "\" let input = Input::new(haystack).earliest(true);\"", "(* * self) . find_in (haystack , span)", "\" Returns true when the span in this match is empty.\"", "\" This example shows how the span of the search can impact whether a\"", "141", "{ MatchErrorKind :: UnsupportedOverlapping { got : :: core :: clone :: Clone :: clone (__self_0) , } }", "\" check whether the decoded integer is representable as a small index.\"", ":: core :: hash :: Hash :: hash (& self . 0 , state)", "self . range . take ()", "\"     Some(Match::must(1, 1..2)),\"", "byte / 128", ":: core :: clone :: Clone :: clone (& self . anchored)", "\" match state via a simple comparison of the state ID.\"", "\" assert_eq!(Anchored::Yes, input.get_anchored());\"", "\"got\"", "{ prerare }", "bytes [0]", "match core :: str :: from_utf8 (self . haystack ()) { Ok (nice) => fmter . field (\"haystack\" , & nice) , Err (_) => fmter . field (\"haystack\" , & self . haystack ()) , } . field (\"span\" , & self . span) . field (\"anchored\" , & self . anchored) . field (\"earliest\" , & self . earliest)", "\"RareBytesBuilder\"", "\" // While 'bcd' occurs in the haystack, it does not begin where our\"", "if i > 0 { f . write_fmt (format_args ! (\", \")) ? ; }", "\" this must, at minimum, return the starting position of the next match\"", ":: core :: fmt :: Formatter :: write_str (f , \"InvalidInputUnanchored\")", "f . write_fmt (format_args ! (\"failed to create small index from {0:?}, which exceeds {1:?}\" , self . attempted () , SmallIndex :: MAX ,) ,)", ":: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , \"PossibleStartOfMatch\" , & __self_0 ,)", "if has_rarer_bytes { prestart } else { prerare }", "From < Span >", "self . pattern == other . pattern && self . span == other . span", "self . span () . start", "u16 :: try_from (self) . expect (\"usize overflowed u16\")", "self . add_rare_byte (rarest . 0)", "RareBytesBuilder { ascii_case_insensitive : :: core :: clone :: Clone :: clone (& self . ascii_case_insensitive ,) , rare_set : :: core :: clone :: Clone :: clone (& self . rare_set) , byte_offsets : :: core :: clone :: Clone :: clone (& self . byte_offsets) , available : :: core :: clone :: Clone :: clone (& self . available) , count : :: core :: clone :: Clone :: clone (& self . count) , rank_sum : :: core :: clone :: Clone :: clone (& self . rank_sum) , }", "\" since it overlaps with the `abcd` match.\"", "Option < crate :: packed :: MatchKind >", "& mut :: core :: fmt :: Formatter", "\" but uses less memory than `usize` on 64-bit systems. Specifically, its\"", "SmallIndex :: try_from (value) . map (PatternID)", "\" used to optimize your own search implementation if necessary, but cannot do\"", "\" use aho_corasick::Input;\"", "\" This panics if `end < start` or if `pattern > PatternID::MAX`.\"", "\" Add a byte string to this builder.\"", "ByteSet { bits : BitSet ([0 ; 2]) }", "\" not rely on this property for safety. Callers may choose to rely on this\"", "Anchored", "classes . set (b , b)", "usize", "self . 0 as usize", "\" automaton would result in an identifier that exceeds the capacity of a\"", "core :: ops :: Range < usize >", "\"Builder\"", "\" let patterns = &[\\\"bcd\\\"];\"", ":: core :: fmt :: Formatter :: write_str (f , \"InvalidInputAnchored\")", "\" `isize` is to guarantee that the difference between any two small indices\"", "self . haystack . len ()", "self . buffer ()", "\" Naively, it would not be possible to report a single contiguous `foobar`\"", "memchr :: memchr2", "if ! self . rare_set . contains (byte) { self . rare_set . add (byte) ; self . count += 1 ; self . rank_sum += freq_rank (byte) as u16 ; }", "\" assert_eq!(\\\"b\\\", &haystack[mat.span()]);\"", "MatchErrorKind :: UnsupportedEmpty", "match (self , other) { (MatchErrorKind :: UnsupportedStream { got : __self_0 } , MatchErrorKind :: UnsupportedStream { got : __arg1_0 } ,) => __self_0 == __arg1_0 , (MatchErrorKind :: UnsupportedOverlapping { got : __self_0 } , MatchErrorKind :: UnsupportedOverlapping { got : __arg1_0 } ,) => __self_0 == __arg1_0 , _ => true , }", "\"     .build(patterns)\"", "\" Build the rare bytes prefilter.\"", "\" exceeds [`SmallIndex::MAX`].\"", "StateIDIter :: new (len)", "\" `From<Range>`, which means things like `Span::from(5..10)` work.\"", "self as u16", "\" assert!(!Anchored::No.is_anchored());\"", "freq_rank (byte) as u16", "\" seen.\"", "\"kind\"", "freq_rank (b)", "\" supports both unanchored and anchored searches.\"", "\" never overflow `usize`.\"", "\"invalid StateID value\"", "\" This is like [`Input::earliest`], except it mutates the search\"", "{ f . write_fmt (format_args ! (\"match kind {0:?} does not support overlapping searches\" , got ,) ,) }", "MemmemBuilder :: default ()", "if readlen == 0 { return Ok (readany) ; }", "(0 .. r . state_len ())", "247", "classes . set (b , class)", "f . write_fmt (format_args ! (\"state identifier overflow: failed to create state ID from {0}, which exceeds the max of {1}\" , requested_max , max ,) ,)", "\" One of the key complexities this manages is the ability to correctly move\"", "& self . start_bytes", "\" will never match `Samwise` since `Sam` will always have higher priority.\"", "{ if patlen <= 16 && minlen >= 2 && self . start_bytes . count >= 3 { return packed ; } prestart }", "\" internal representation is still a `u32`.\"", ":: core :: fmt :: Formatter :: debug_struct_field1_finish (f , \"StartBytesOne\" , \"byte1\" , & & self . byte1 ,)", "\" is basically a ham-fisted attempt at DRY. The only place we use this is in\"", "self . alphabet_len ()", "\" Return the span for this search configuration.\"", "Anchored :: Yes", "I32", "\" regex engine do not use backtracking, but still implement leftmost-first\"", "self . start <= offset", "self . ascii_case_insensitive", "self . memmem", "patlen <= 16 && minlen >= 2", "RareByteOffset :: new", "\" support unanchored or anchored searches, respectively.\"", "[u8 ; 256]", "rarest", "self . offset . max", "1 << bit", "self . as_usize () + 1", "160", "\" A utility trait that defines a couple of adapters for making it convenient\"", "usize :: from (end)", "\" the dense and one-pass DFAs.\"", "self . set_span (Span { start , end })", "f . write_fmt (format_args ! (\", \"))", "\" found in POSIX compatible implementations of regular expressions (such as\"", "\" `2^stride2 = stride`.\"", "\"max_special_id\"", "ByteClasses", "self . one = Some (bytes . to_vec ())", "self . get_span () . start > self . get_span () . end", "\" be boosted considerably, perhaps by an order of magnitude. When a prefilter\"", "self . max", "self . element_ranges (class)", "\" // that is configured to do an anchored search. Since 'b' doesn't start\"", "\" greater than the existing offset, then it overwrites the previous\"", "WithPatternIDIter { it : :: core :: clone :: Clone :: clone (& self . it) , ids : :: core :: clone :: Clone :: clone (& self . ids) , }", "196", "& [\"ascii_case_insensitive\" , \"rare_set\" , \"byte_offsets\" , \"available\" , \"count\" , \"rank_sum\" ,]", "\" Add the given offset for the given byte to this set. If the offset is\"", "& StateID", "crate", "cur_id", ":: core :: cmp :: AssertParamIsEq < PatternID >", "\" This is like [`Match::new`], but accepts a `usize` instead of a\"", "match self . elements . next () { None => return self . range . take () , Some (element) => element , }", "ByteClassElementRanges < 'a >", "readany = true", "\"     ac.find(haystack),\"", "core :: fmt :: Debug", "{ :: core :: fmt :: Formatter :: debug_struct_field2_finish (f , \"PatternTooLong\" , \"pattern\" , __self_0 , \"len\" , & __self_1 ,) }", "\" of bytes during NFA construction. That is, every byte in an equivalence\"", "83", "\" non-overlapping matches, given the patterns `abcd` and `b` and the haystack\"", "\" by iterating over every ID in this map, then iterating over each\"", "RareByteOffset", "\" This demonstrates the differences between an anchored search and\"", "f . debug_set ()", "\" // The \\\"earliest\\\" possible match, even if it isn't leftmost-first.\"", "\" The starting position of the match.\"", "\" A simple type for mapping between state indices and state IDs.\"", "ByteClasses :: empty", "b . to_ascii_uppercase ()", "\" [`AhoCorasickBuilder::start_kind`](crate::AhoCorasickBuilder::start_kind)\"", "\" In contrast, the leftmost match kind always prefers the leftmost match\"", "self . offsets . set [usize :: from (haystack [pos])] . max", "\" this match kind is used, attempting to find overlapping matches or\"", "self >> 16", "RareBytesTwo { offsets : builder . byte_offsets , byte1 : bytes [0] , byte2 : bytes [1] , }", "for b in 0 ..= 255 { classes . set (b , b) ; }", "u128", "\" to report only the leftmost non-overlapping matches. The leftmost approach\"", "\" Return true if and only if the given byte is in this set.\"", "Range { start : span . start , end : span . end , }", "let Some (pre) = self . memmem . build ()", "\" suffix of the data to the beginning of the buffer before refilling it with\"", "Option < Vec < u8 > >", "\" If the decoded integer is not representable as a small index for the\"", "self . idx . to_index (id2)", ":: core :: panicking :: panic_fmt (format_args ! (\"cannot create iterator for {0} when number of elements exceed {1:?}\" , \"PatternID\" , PatternID :: LIMIT ,) ,)", "& [& self . count , & self . ascii_case_insensitive , & self . start_bytes , & self . rare_bytes , & self . memmem , & self . packed , & & self . enabled ,]", "format_args ! (\"\\' \\'\")", "packed . is_some ()", "builder . byte_offsets", "usize :: from (index)", "& PatternIDError", ":: core :: clone :: Clone :: clone (& self . rank_sum)", "\" anchored searches simultaneously.\"", "\" has identifier `0`, and each subsequent pattern is `1`, `2` and so on.\"", "Match { pattern : self . pattern , span : Span { start : self . start () + offset , end : self . end () + offset , } , }", "\" Using a `u8` here means that if we ever see a pattern that's longer\"", "\" On all targets, this type guarantees that its value will fit in a `u32`,\"", "Option < PatternID >", "self . enabled = false", "\" here must the same one given to `swap` and `remap`.\"", "span . end <= self . haystack . len () && span . start <= span . end . wrapping_add (1)", "\" The maximum ID of all the \\\"special\\\" states. This corresponds either to\"", "& self . rare_bytes", "182", "b'f'", "\" assert!(!input.is_done());\"", "\" A map from the index of a state to its pre-multiplied identifier.\"", "__arg1_discr", "noncontiguous :: NFA :: states", "if index > SmallIndex :: MAX . as_u64 () { return Err (SmallIndexError { attempted : index , }) ; }", "31", "byte as usize", "Some (Prefilter { finder , memory_usage : 0 , })", "\" without using as much space as a `usize` on all targets, callers must\"", "\"StateID\"", "\" A knob for controlling the match semantics of an Aho-Corasick automaton.\"", "\" patterns given and leftmost-longest can be useful for dictionary searching\"", "self . 0 as u64", "\" depending on whether you're using infallible or fallibe APIs, respectively.\"", "if (ByteSet { bits : * self }) . contains (b) { fmtd . entry (& b) ; }", "\" * [`AhoCorasick`](crate::AhoCorasick) inherits the same setup as a\"", "\" Create a new \\\"unsupported overlapping search\\\" error. This occurs when\"", "\" an unsupported anchor mode, then an error will be returned. For calls\"", "f . debug_tuple (\"PatternID\")", "StateID (SmallIndex :: from_ne_bytes_unchecked (bytes))", "& self . memmem", "\" convenient Debug impl for it while keeping \\\"ByteSet\\\" in the output.\"", "225", "id", "min", "117", "RareBytesTwo { offsets : :: core :: clone :: Clone :: clone (& self . offsets) , byte1 : :: core :: clone :: Clone :: clone (& self . byte1) , byte2 : :: core :: clone :: Clone :: clone (& self . byte2) , }", ":: alloc :: vec :: Vec :: new", "\" Return a borrow of the underlying haystack as a slice of bytes.\"", "u64", "f . write_fmt (format_args ! (\"pattern identifier overflow: failed to create pattern ID from {0}, which exceeds the max of {1}\" , requested_max , max ,) ,)", "& PatternID", "b'z'", "\" when using `Input::span` or `Input::range` are in terms of the original\"", "\" The default match kind is `MatchKind::Standard`.\"", "\" classes computed may be bigger than necessary. This usually doesn't make\"", "self . span ()", "& self . min", ":: core :: fmt :: Formatter :: write_str (f , \"UnsupportedEmpty\")", "(packed , patlen , minlen)", "\" be enabled. That's because memchr doesn't have a no-std-but-with-alloc\"", "SmallIndex (index)", "\" let input = Input::new(\\\"foobar\\\").range(2..=4);\"", "\" The maximum offset at which a particular byte occurs from the start\"", ":: core :: clone :: AssertParamIsClone < Span >", "if ! (len <= StateID :: LIMIT) { { :: core :: panicking :: panic_fmt (format_args ! (\"cannot create iterator for {0} when number of elements exceed {1:?}\" , \"StateID\" , StateID :: LIMIT ,) ,) ; } }", "for (i , class) in self . iter () . enumerate () { if i > 0 { f . write_fmt (format_args ! (\", \")) ? ; } f . write_fmt (format_args ! (\"{0:?} => [\" , class)) ? ; for (start , end) in self . element_ranges (class) { if start == end { f . write_fmt (format_args ! (\"{0:?}\" , start)) ? ; } else { f . write_fmt (format_args ! (\"{0:?}-{1:?}\" , start , end)) ? ; } } f . write_fmt (format_args ! (\"]\")) ? ; }", "match core :: str :: from_utf8 (self . haystack ()) { Ok (nice) => fmter . field (\"haystack\" , & nice) , Err (_) => fmter . field (\"haystack\" , & self . haystack ()) , } . field (\"span\" , & self . span)", "237", "haystack [span]", "b'A'", ":: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , \"SmallIndex\" , & & self . 0 ,)", "\" the caller must always confirm the match).\"", "m", ":: core :: clone :: AssertParamIsClone < u8 >", "243", "\" A type that wraps a SIMD accelerated single substring search from the\"", "238", "U32", "P", "noncontiguous :: NFA :: states (self) . len ()", "\" # Example: `&str` and `&[u8]` automatically convert to an `Input`\"", "27", "self . bits . 0 [usize :: from (bucket)] |= 1 << bit", "! (span . end <= self . haystack . len () && span . start <= span . end . wrapping_add (1))", "\" use aho_corasick::{Anchored, Input};\"", "& nice", ":: core :: clone :: Clone :: clone", "& Range < usize >", "\"Special\"", ":: core :: fmt :: Formatter :: write_str", "i64", "f . debug_tuple (\"PatternID\") . field (& self . as_u32 ())", "SmallIndex :: new_unchecked", "\" alternation. Indeed, the regex `Sam|Samwise` in a Perl-like regex engine\"", "\" A builder for constructing a rare byte prefilter.\"", "\" This does **not** support overlapping matches or stream searching. If\"", "other . attempted", ":: core :: default :: Default", "\" this builder will heuristically select the best prefilter it can build,\"", "builder . byteset", "From < u8 >", "self . 0 . as_i32 ()", "if id1 == id2 { return ; }", "start - 1", "u32 :: try_from (self) . expect (\"usize overflowed u32\")", ":: core :: clone :: Clone :: clone (& self . 0)", "roll_start .. roll_end", "usize :: try_from (self) . expect (\"u64 overflowed usize\")", "imp (self)", "f . write_fmt (format_args ! (\"{0:?}-{1:?}\" , start , end)) ?", "builder", "self . start_bytes . rank_sum <= self . rare_bytes . rank_sum + 50", ":: core :: default :: Default :: default ()", "[RareByteOffset :: default () ; 256]", ":: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , \"PatternIDError\" , & & self . 0 ,)", "u32 :: from", "& mut impl Remappable", "& self . buf", "ByteClassElements", "format_args ! (\", \")", "\" much of a difference, and keeps the implementation simple.\"", "232", "packed :: Config :: new () . match_kind (kind) . builder ()", "self . set [byte as usize] . max = cmp :: max (self . set [byte as usize] . max , off . max ,)", "\" While a `StateID` is meant to guarantee that its value fits into `usize`\"", "b'a' <= b", "self . end += readlen", "MatchError", "if self . rare_set . contains (b) { found = true ; continue ; }", "\" The given stride should be the stride of the transition table expressed\"", "& builder . count", "\" # Ok::<(), Box<dyn std::error::Error>>(())\"", "Span { start : range . start , end : range . end , }", "freq_rank (byte)", "\" will begin its search at a position that is guaranteed to observe a\"", "\" given value exceeds the maximum.\"", "self . 0 . one_more ()", "None", "\" Callers must never rely on a `SmallIndex` to be within a certain range\"", "match core :: str :: from_utf8 (self . haystack ()) { Ok (nice) => fmter . field (\"haystack\" , & nice) , Err (_) => fmter . field (\"haystack\" , & self . haystack ()) , } . field (\"span\" , & self . span) . field (\"anchored\" , & self . anchored)", "! builder . available || builder . count > 3", "\" Set the span for this search configuration given any range.\"", "\" Run an unanchored search. This means a match may occur anywhere at or\"", "\" Run an anchored search. This means that a match must begin at the start\"", "packed :: Searcher", "51", "\" transition and every starting state ID.\"", "\" match is reported or not.\"", "\" Create a new value that is represented by a \\\"small index.\\\"\"", "\" to the smallest power of 2 greater than or equal to the number of\"", "self . span () . is_empty ()", "continue", "\"idx\"", "\"StateIDError\"", "Arc :: new (StartBytesOne { byte1 : bytes [0] })", "self . 0 . next () . map (StateID)", "\" let input = Input::new(haystack).span(0..3);\"", "\" The utility of this type is that it keeps the default or common case simple\"", "\" Return the internal value as a `u64`. This is guaranteed to\"", "222", "\" search.\"", "core :: ops :: Index < SmallIndex >", "StartBytesBuilder { ascii_case_insensitive : false , byteset : :: alloc :: vec :: from_elem (false , 256) , count : 0 , rank_sum : 0 , }", "\"\\nLower level primitive types that are useful in a variety of circumstances.\\n\\n# Overview\\n\\nThis list represents the principle types in this module and briefly describes\\nwhen you might want to use them.\\n\\n* [`PatternID`] - A type that represents the identifier of a regex pattern.\\nThis is probably the most widely used type in this module (which is why it's\\nalso re-exported in the crate root).\\n* [`StateID`] - A type the represents the identifier of a finite automaton\\nstate. This is used for both NFAs and DFAs, with the notable exception of\\nthe hybrid NFA/DFA. (The hybrid NFA/DFA uses a special purpose \\\"lazy\\\" state\\nidentifier.)\\n* [`SmallIndex`] - The internal representation of both a `PatternID` and a\\n`StateID`. Its purpose is to serve as a type that can index memory without\\nbeing as big as a `usize` on 64-bit targets. The main idea behind this type\\nis that there are many things in regex engines that will, in practice, never\\noverflow a 32-bit integer. (For example, like the number of patterns in a regex\\nor the number of states in an NFA.) Thus, a `SmallIndex` can be used to index\\nmemory without peppering `as` casts everywhere. Moreover, it forces callers\\nto handle errors in the case where, somehow, the value would otherwise overflow\\neither a 32-bit integer or a `usize` (e.g., on 16-bit targets).\\n\"", "if id > SmallIndex :: MAX . as_u32 () { return Err (SmallIndexError { attempted : u64 :: from (id) , }) ; }", "\" // be explicitly specified here.\"", "123", "self . haystack", "\" This is a convenience routine for `Match::span().range()`.\"", ":: core :: hash :: Hash :: hash", "& StartKind", ":: core :: clone :: Clone :: clone (& self . available)", "Match { pattern , span }", "PatternID (SmallIndex :: from (value))", "\" It is possible and legal for max_match_id to be equal to\"", ":: core :: hash :: Hash :: hash (& self . start , state)", "\" let m = Match::new(PatternID::ZERO, 5..10);\"", "From < & 'h H >", "\" assert_eq!(b\\\"foobar\\\", input.haystack());\"", "self . ids", ":: core :: clone :: Clone :: clone (& self . attempted)", "noncontiguous :: NFA :: swap_states", "\" Returns the span for this match.\"", "\" This type ensures this by providing a constructor that will return an error\"", "\" string is a pattern that was added to the underlying automaton.\"", "& self . end", "[RareByteOffset ; 256]", "return", "\"internal error: entered unreachable code\"", "\" state IDs and indices can be done with shifts alone, which is much\"", "\" it is safe to transmute between a `u32` and a `SmallIndex`.)\"", "\" number of states, the number of patterns of the length of a pattern. These\"", "SmallIndex :: try_from (value) . map (StateID)", "\" A fairly simple roll buffer for supporting stream searches.\"", "\" format.\"", "Option < StateID >", "has_fewer_bytes", "& self . offset", "\" value to be in a corrupt state.\"", "\" Support only unanchored searches. Requesting an anchored search will\"", "[& self . ascii_case_insensitive , & self . rare_set , & self . byte_offsets , & self . available , & self . count , & & self . rank_sum ,]", "self . it", "\" `MatchError::unsupported_stream`.\"", "self . range = Some ((element , element))", "{ if packed . is_some () { } else { } packed }", "\" Hence, this abstraction.\"", "\" # Panics\"", "\" representation is still a `u32`.\"", "{ :: core :: panicking :: panic_fmt (format_args ! (\"invalid span {0:?} for haystack of length {1}\" , span , self . haystack . len () ,) ,) ; }", "195", "WithStateIDIter { it , ids }", "\" otherwise determine that this prefilter should not be used, then `None`\"", "0x7F", "memchr :: memchr3 (self . byte1 , self . byte2 , self . byte3 , & haystack [span]) . map (| i | { let pos = span . start + i ; let offset = self . offsets . set [usize :: from (haystack [pos])] . max ; cmp :: max (span . start , pos . saturating_sub (usize :: from (offset))) }) . map_or (Candidate :: None , Candidate :: PossibleStartOfMatch)", "memchr :: memchr3 (self . byte1 , self . byte2 , self . byte3 , & haystack [span]) . map (| i | span . start + i) . map_or (Candidate :: None , Candidate :: PossibleStartOfMatch)", "\"ByteClassIter\"", "u32 :: from_ne_bytes (bytes) . as_usize ()", "readlen", "\" A prefilter for scanning for three \\\"rare\\\" bytes.\"", "\" The maximum possible id.\"", "{ :: core :: fmt :: Formatter :: write_str (f , \"UnsupportedEmpty\") }", "return None", "return Err (SmallIndexError { attempted : u64 :: from (index) , })", "\" [`Anchored::No`]), searchers will look for a match anywhere in the\"", "\" // However, if we start our search where 'bcd' starts, then we will\"", "\" string `ab`, the leftmost-first match is `a` but the leftmost-longest match\"", "& & self . byte3", "{ usize :: try_from (self) . expect (\"u64 overflowed usize\") }", "\" would be `ab`. Stated differently, the leftmost-first match depends on the\"", "80", "\" something other than [`MatchKind::Standard`](crate::MatchKind::Standard)\"", ":: core :: marker :: Copy", "\" of this crate. Indeed, `Span` exists only because `Range<usize>` does\"", "self . add_one_rare_byte (opposite_ascii_case (byte))", "rarest = (b , rank)", "\" `grep`). The second way, leftmost-first, is commonly found in backtracking\"", "self . is_singleton ()", "Prefilter", "let Some (byte) = self . bytes . next ()", "\"RareByteOffset\"", "sid . 0", "StateID (SmallIndex :: MAX)", "for (i , mut b) in core :: ascii :: escape_default (self . 0) . enumerate () { if i >= 2 && b'a' <= b && b <= b'f' { b -= 32 ; } bytes [len] = b ; len += 1 ; }", "index", "\" // Note that 'Anchored::No' is the default, so it doesn't need to\"", "\" Returns this span as a range.\"", "{ Some (crate :: packed :: MatchKind :: LeftmostLongest) }", "& self . one", "memchr :: memchr3 (self . byte1 , self . byte2 , self . byte3 , & haystack [span])", "start .. end", "StateID :: new (value)", "\" Returns true when this span is empty. That is, when `start >= end`.\"", "minlen", "\" When the `std` feature is enabled, this implements the `std::error::Error`\"", "\" including the given length.\"", "\" searches by default.\"", "& self . count", ":: core :: fmt :: Formatter :: debug_struct_field2_finish (f , \"Remapper\" , \"map\" , & self . map , \"idx\" , & & self . idx ,)", "\"Packed\"", "\" A match has two essential pieces of information: the [`PatternID`] that\"", "\" resolve ambiguous matches when there are multiple leftmost matches to\"", "\" this buffer's free capacity. If no more bytes could be read, then this\"", "\" Since a small index has constraints on its maximum value, adding `1` to\"", "\"invalid PatternID value\"", "\" case the callers must attempt to confirm the match. In this case, prefilter\"", "id1", "\"RareBytesThree\"", "\" of an FSM, but also on FSM build times because it reduces the number of\"", "roll_end", "core :: ascii :: escape_default (self . 0)", "ErrorKind :: PatternIDOverflow { max : :: core :: clone :: Clone :: clone (__self_0) , requested_max : :: core :: clone :: Clone :: clone (__self_1) , }", "self . start_bytes . count < self . rare_bytes . count", ":: core :: clone :: Clone :: clone (& self . byte3)", "PatternIDIter :: new", "\"     ac.find(Input::new(haystack).anchored(Anchored::Yes)),\"", "201", "{ let pos = span . start + i ; let offset = self . offsets . set [usize :: from (haystack [pos])] . max ; cmp :: max (span . start , pos . saturating_sub (usize :: from (offset))) }", "\" The purpose for making the type fit into even signed integer types like\"", "213", ":: core :: fmt :: Formatter :: debug_struct_field2_finish (f , \"StartBytesTwo\" , \"byte1\" , & self . byte1 , \"byte2\" , & & self . byte2 ,)", "\" state identifiers in DFAs.\"", "197", "66", "& [& self . ascii_case_insensitive , & self . rare_set , & self . byte_offsets , & self . available , & self . count , & & self . rank_sum ,]", "186", "self . end", "\" If there are more than 3 distinct rare bytes found, or if heuristics\"", "(len <= StateID :: LIMIT)", "span . start <= span . end . wrapping_add (1)", "\" assert_eq!(0, input.start());\"", "u64 :: try_from (self) . expect (\"usize overflowed u64\")", "self . map [i]", "\" This is disabled by default.\"", "format_args ! (\"ByteClasses(<one-class-per-byte>)\")", "Pointer", "match self . kind { ErrorKind :: StateIDOverflow { max , requested_max } => { f . write_fmt (format_args ! (\"state identifier overflow: failed to create state ID from {0}, which exceeds the max of {1}\" , requested_max , max ,) ,) } ErrorKind :: PatternIDOverflow { max , requested_max } => { f . write_fmt (format_args ! (\"pattern identifier overflow: failed to create pattern ID from {0}, which exceeds the max of {1}\" , requested_max , max ,) ,) } ErrorKind :: PatternTooLong { pattern , len } => { f . write_fmt (format_args ! (\"pattern {0} with length {1} exceeds the maximum pattern length of {2}\" , pattern . as_usize () , len , SmallIndex :: MAX . as_usize () ,) ,) } }", "U16", "pattern . len ()", "\" Return the span as a range for this search configuration.\"", "\"Input\"", "self . end == span . end", "\"\\nThis module provides several integer oriented traits for converting between\\nboth fixed size integers and integers whose size varies based on the target\\n(like `usize`).\\n\\nThe main design principle for this module is to centralize all uses of `as`.\\nThe thinking here is that `as` makes it very easy to perform accidental lossy\\nconversions, and if we centralize all its uses here under more descriptive\\nhigher level operations, its use and correctness becomes easier to audit.\\n\\nThis was copied mostly wholesale from `regex-automata`.\\n\\nNOTE: for simplicity, we don't take target pointer width into account here for\\n`usize` conversions. Since we currently only panic in debug mode, skipping the\\ncheck when it can be proven it isn't needed at compile time doesn't really\\nmatter. Now, if we wind up wanting to do as many checks as possible in release\\nmode, then we would want to skip those when we know the conversions are always\\nnon-lossy.\\n\"", "self as usize", "self . start == other . start && self . end == other . end", "139", "MatchKind :: LeftmostLongest", "\" The main conclusion to draw from this section is that the match semantics\"", "alloc :: boxed :: Box :: new (kind)", "self . rng . start >= self . rng . end", "From < SmallIndex >", "{ :: core :: panicking :: panic_fmt (format_args ! (\"invalid match span\")) ; }", "\" sequence of contiguous ranges.\"", "\"None\"", "\" Aho-Corasick searcher.\"", "self . memmem . add (bytes)", "\" values.\"", "# [allow (non_exhaustive_omitted_patterns)] match * self { MatchKind :: Standard => true , _ => false , }", "Special", "\" haystack. If you instead use `&haystack[start..end]`, then you'll need to\"", "\" The ID of a pattern is derived from the position in which it was\"", "r . state_len ()", "155", "\" zero. The general idea here is that they will be updated and set to\"", "f . debug_struct (\"RareByteOffsets\") . field (\"set\" , & offsets) . finish ()", "self . end == other . end", "\" The issue is that during the DFA construction process, it's not\"", "core :: i32 :: MAX", "From < PatternID >", "format_args ! (\"unanchored searches are not supported or enabled\" ,)", "132", ":: core :: fmt :: Formatter :: debug_struct_field2_finish (f , \"Prefilter\" , \"finder\" , & self . finder , \"memory_usage\" , & & self . memory_usage ,)", "if ! self . enabled { return None ; }", "\"PatternTooLong\"", "\"set\"", "& mut [u8]", "\" originally inserted into the corresponding searcher. The first pattern\"", "\" and each class contains exactly one byte (plus the special EOI class).\"", "MatchErrorKind :: InvalidInputUnanchored", "TryFrom < u64 >", "index as u32", "pid . 0", "\" `PatternID`.\"", ":: core :: cmp :: AssertParamIsEq < SmallIndex >", "\" haystack.\"", "& mut core :: fmt :: Formatter", "\" to the function given. For example, in a DFA, this should remap every\"", "{ ErrorKind :: StateIDOverflow { max : :: core :: clone :: Clone :: clone (__self_0) , requested_max : :: core :: clone :: Clone :: clone (__self_1) , } }", "RareBytesOne { byte1 : bytes [0] , offset : builder . byte_offsets . set [bytes [0] as usize] , }", "SmallIndex", "\" The number of bytes that a single small index uses in memory.\"", "\" If the given length exceeds this type's limit, then this\"", "new_id = id", "0u8 ..= 255", "{ f . write_fmt (format_args ! (\"{0:?}-{1:?}\" , start , end)) ? ; }", "Range :: from", "if ! (roll_end <= self . end) { :: core :: panicking :: panic (\"assertion failed: roll_end <= self.end\") }", "& impl Remappable", "Match :: new (PatternID :: ZERO , start .. end)", "\" This constructor is generic over how a span is provided. While\"", "\" current target, then this returns an error.\"", "self . rare_bytes . ascii_case_insensitive (yes)", "\" invalid index value is likely to cause panics or possibly even silent\"", "\" a match of `Samwise` in both POSIX and Perl-like regexes since `Samwise` is\"", ":: core :: clone :: Clone :: clone (& self . rare_set)", "\" The result is either no match, a confirmed match or a possible match.\"", "if patlen <= 16 && minlen >= 2 && self . rare_bytes . count >= 3 { return packed ; }", ":: core :: fmt :: Formatter :: debug_struct_field3_finish", "Vec < u8 >", "\" The underlying kind of a [`MatchError`].\"", "& & self . offset", "i > 0", "& self . buf [.. self . end]", ":: core :: clone :: AssertParamIsClone < [u128 ; 2] >", "& self . memory_usage", "Ok (true)", "Some (pre)", "usize :: try_from (self) . expect (\"u32 overflowed usize\")", "\" Return the internal `u32` of this small index represented as an `i32`.\"", ":: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , \"ByteClassSet\" , & & self . 0 ,)", "index > SmallIndex :: MAX . as_u32 ()", "\" overlapping matches and stream searching. (Trying to find overlapping or\"", "BitSet (:: core :: default :: Default :: default ())", "\" An error indicating that the operation requested doesn't support\"", "& [\"count\" , \"ascii_case_insensitive\" , \"start_bytes\" , \"rare_bytes\" , \"memmem\" , \"packed\" , \"enabled\" ,]", "\" is chosen.\"", "SmallIndex :: new_unchecked (core :: i32 :: MAX as usize - 1 ,)", "\" when a match occurs across two `read` calls, *something* needs to retain\"", "\" than 255 bytes, then the entire rare byte prefilter is disabled.\"", "SmallIndex :: from_ne_bytes_unchecked (bytes)", "{ :: core :: panicking :: panic_fmt (format_args ! (\"cannot create iterator for {0} when number of elements exceed {1:?}\" , \"StateID\" , StateID :: LIMIT ,) ,) ; }", "{ :: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , \"Match\" , & __self_0 ,) }", "if bytes . is_empty () { self . enabled = false ; }", "& mut T", "\" that's where `id1` moved to.\"", "Send", "alloc :: boxed :: Box :: new", "SmallIndex :: from_u32_unchecked", "\" Returns an iterator over all values from 0 up to and not\"", "self . finder . find_in (haystack , span)", "if self . ascii_case_insensitive { self . add_one_rare_byte (opposite_ascii_case (byte)) ; }", "\" method and used to execute a search. In other words, a prefilter can be\"", "& mut self [index . as_usize ()]", "id1 == id2", "\" In the latter case, [`Input::is_done`] will return true and indicates any\"", "span . end . wrapping_add (1)", "\" input.set_start(6);\"", "self . bytes", "self . bytes . next ()", "\" for delta encoding.\"", "str", "Some (byte)", "memchr :: memchr2 (self . byte1 , self . byte2 , & haystack [span]) . map (| i | { let pos = span . start + i ; let offset = self . offsets . set [usize :: from (haystack [pos])] . max ; cmp :: max (span . start , pos . saturating_sub (usize :: from (offset))) })", "return Err (SmallIndexError { attempted : index , })", "self . rare_bytes . count", "\"StartBytesThree\"", "core :: i32 :: MAX as usize", "index . as_usize ()", "format_args ! (\"failed to create {0} from {1:?}, which exceeds {2:?}\" , \"StateID\" , self . attempted () , StateID :: MAX ,)", "PatternID (SmallIndex :: from_u32_unchecked (index))", "\" This routine will panic if the given range could not be converted\"", "\" of any pattern. This is used as a shift amount. That is, when an\"", "impl Remappable", "f . debug_struct (\"Input\")", "\" Use leftmost-first match semantics, which reports leftmost matches.\"", "\" transition table's stride.\"", "\" If one was not explicitly set, then the span corresponds to the entire\"", "\" a semver-compatible release.\"", "\" An error that occurs when allocating a new state would result in an\"", "\" the caller requests an overlapping search while using an Aho-Corasick\"", "if builder . count > 3 { return None ; }", "\" In some cases, a prefilter can confirm a match very quickly, in which case,\"", "{ f . write_fmt (format_args ! (\"pattern {0} with length {1} exceeds the maximum pattern length of {2}\" , pattern . as_usize () , len , SmallIndex :: MAX . as_usize () ,) ,) }", "PatternIDIter", "self . end = self . min", "self . 0 . next () . map (PatternID)", "WithPatternIDIter < I >", "\" assert_eq!(3, m.pattern().as_usize());\"", "\" If the decoded integer is not representable as a small index\"", "other", "\" haystack instead, e.g., with `&haystack[start..end]`. With that said, they\"", "\" construction, it ensures that the index of each element in the\"", "\" then the search will return an error or panic, depending on whether a\"", ":: core :: cmp :: AssertParamIsEq < u32 >", "\" be part of a single equivalence class, but in practice, we only treat\"", "\" Returns the value that could not be converted to an ID.\"", "format_args ! (\"{0:?} => [\" , class)", "return Ok (readany)", "if self . class == self . classes . get (byte) { return Some (byte) ; }", "MatchKind", "if self . is_singleton () { f . write_fmt (format_args ! (\"ByteClasses(<one-class-per-byte>)\")) } else { f . write_fmt (format_args ! (\"ByteClasses(\")) ? ; for (i , class) in self . iter () . enumerate () { if i > 0 { f . write_fmt (format_args ! (\", \")) ? ; } f . write_fmt (format_args ! (\"{0:?} => [\" , class)) ? ; for (start , end) in self . element_ranges (class) { if start == end { f . write_fmt (format_args ! (\"{0:?}\" , start)) ? ; } else { f . write_fmt (format_args ! (\"{0:?}-{1:?}\" , start , end)) ? ; } } f . write_fmt (format_args ! (\"]\")) ? ; } f . write_fmt (format_args ! (\")\")) }", "\" occurr in the patterns, and then quickly scan to matches of those rare\"", "WithPatternIDIter { it , ids }", ":: core :: fmt :: Formatter :: debug_struct_field1_finish (f , \"BuildError\" , \"kind\" , & & self . kind ,)", "BuildError { kind : ErrorKind :: StateIDOverflow { max , requested_max , } , }", "226", "Option < (u8 , u8) >", "\" Create a new set of \\\"special\\\" state IDs with all IDs initialized to\"", "49", "! (roll_end <= self . end)", "n", "self . ids . next ()", "\" earliest, where as leftmost-longest always chooses the longest matching\"", "\" This error occurs when an ID could not be constructed.\"", "244", "\" pattern. For example, given the patterns `a` and `ab` and the subject\"", "classes", "bytes [0] as usize", "if bytes . len () >= 256 { self . available = false ; return ; }", ":: core :: clone :: Clone :: clone (& self . byte2)", "175", "\" can be tweaked to precisely match either Perl-like regex alternations or\"", "f . write_fmt (format_args ! (\"ByteClasses(<one-class-per-byte>)\"))", "0u8", "\"PatternIDIter\"", "\" DFAs are partitioned.\"", "self . attempted == other . attempted", "map", ":: core :: panicking :: panic_fmt (format_args ! (\"invalid match span\"))", "self . span () . len ()", "b as usize", "45", "\" a `stride2` of `0`, which acts as an identity.\"", "67", "\" None is returned. In that case, callers should render the rare bytes\"", "noncontiguous :: NFA :: remap (self , map)", "& self . range", "\" The difference between leftmost-first and leftmost-longest is in how they\"", "self . it . next ()", "\" If the span provided is invalid for the given haystack, then behavior\"", "\" patterns used to construct a single Aho-Corasick automaton.\"", "self . set [byte as usize]", "Span { start , end }", "[0 ; 256]", "self . iter ()", "135", "& & self . kind", "U64", "(self . start_bytes . build () , self . rare_bytes . build ())", "\" is returned.\"", "\" When the `std` feature is enabled, this implements the `Error`\"", "Remapper { map , idx }", "\" Returns the length of this match.\"", "\"Standard\"", "class", "cmp :: max (span . start , pos . saturating_sub (usize :: from (offset)))", "\" The main idea behind remapping state IDs is that DFAs often need to check\"", "zeros", "241", "\" Return the contents of this buffer.\"", "\" Add a byte to this set.\"", "self . count == 1", "\"SmallIndex\"", "BuildError", "PatternID (SmallIndex :: from_ne_bytes_unchecked (bytes))", "Packed (s)", "\" This occurs when given an integer exceeding the maximum allowed\"", "Arc :: new (StartBytesThree { byte1 : bytes [0] , byte2 : bytes [1] , byte3 : bytes [2] , })", "\" Returns the stride for these equivalence classes, which corresponds\"", "\" should be used to guarantee that `remap` is called at the appropriate\"", "176", "& & self . bytes", "SmallIndex :: ZERO", "\" The number of bytes set to an active value in `byte_offsets`.\"", "Input { haystack : :: core :: clone :: Clone :: clone (& self . haystack) , span : :: core :: clone :: Clone :: clone (& self . span) , anchored : :: core :: clone :: Clone :: clone (& self . anchored) , earliest : :: core :: clone :: Clone :: clone (& self . earliest) , }", "\" callers. A `Prefilter` can only be accessed via the\"", "188", "i8", "SmallIndex :: from_ne_bytes_unchecked", "\" Like `Input::span`, but accepts any range instead.\"", "Ok", "yes", "DebugByte", "1", "\"packed\"", "\" use aho_corasick::{AhoCorasick, Anchored, Input, MatchKind, StartKind};\"", "\" If a byte's offset is not representable in 8 bits, then the rare bytes\"", "& self . offsets", "\" An error that occurred during the construction of an Aho-Corasick\"", "\" etc.\"", ":: core :: fmt :: Formatter :: write_str (f , match self { Anchored :: No => \"No\" , Anchored :: Yes => \"Yes\" , } ,)", "if max > u8 :: MAX as usize { None } else { Some (RareByteOffset { max : max as u8 }) }", "\" span in place.\"", "\" leftmost-first and leftmost-longest.\"", "self . count > 3", "loop { let readlen = rdr . read (self . free_buffer ()) ? ; if readlen == 0 { return Ok (readany) ; } readany = true ; self . end += readlen ; if self . buffer () . len () >= self . min { return Ok (true) ; } }", "S", "b'A' <= b && b <= b'Z'", "\" [`dfa::Builder::start_kind`](crate::dfa::Builder::start_kind) can\"", "r . swap_states (id1 , id2)", "self . rare_bytes . add (bytes)", "\" The raw buffer contents. This has a fixed size and never increases.\"", "Prefilter { finder , memory_usage }", "\" This buffer acts as a temporary place to store a fixed amount of data when\"", "[& self . count , & self . ascii_case_insensitive , & self . start_bytes , & self . rare_bytes , & self . memmem , & self . packed , & & self . enabled ,]", "& self . start", "MatchErrorKind :: UnsupportedOverlapping { got , }", "self . end == range . end", "cmp :: max (span . start , pos . saturating_sub (usize :: from (self . offset . max)) ,)", "\" Returns one more than this small index as a usize.\"", "self . end () + offset", "{ ErrorKind :: PatternTooLong { pattern : :: core :: clone :: Clone :: clone (__self_0) , len : :: core :: clone :: Clone :: clone (__self_1) , } }", "format_args ! (\"{0}\" , core :: str :: from_utf8 (& bytes [.. len]) . unwrap ())", "SmallIndex :: new (value)", "\" has already scanned past.\"", "{ u8 :: try_from (self) . expect (\"usize overflowed u8\") }", "\" given value exceeds [`SmallIndex::MAX`].\"", "format_args ! (\"cannot create iterator for {0} when number of elements exceed {1:?}\" , \"StateID\" , StateID :: LIMIT ,)", "Some ((start , end))", "off", "\" equivalence class. Equivalently, there are 257 equivalence classes\"", "230", "core :: ops :: Index < PatternID >", "\" the start of the search) search. Unanchored search is the default. This is\"", "bit", "span . into ()", "48", "\"WithPatternIDIter\"", "u32 :: from_ne_bytes (bytes)", "fmter . field (\"haystack\" , & nice)", "\" as a `PatternID`.\"", "Match :: new (PatternID :: must (pattern) , span)", "self . alphabet_len () == 256", "it . len ()", "\" A confirmed match was found. Callers do not need to confirm it.\"", "\" that iterator construction can do a single check to make sure the index of\"", "self . idx", "\" Whether this prefilter should account for ASCII case insensitivity or\"", "\"usize overflowed u32\"", "it", "240", "Option < (StateID , I :: Item) >", "usize :: MAX", "BitSet ([0 ; 2])", ":: core :: clone :: Clone :: clone (& self . offset)", "f . write_fmt (format_args ! (\"{0:?} => [\" , class)) ?", ":: core :: fmt :: Formatter :: debug_struct_field2_finish (f , \"WithStateIDIter\" , \"it\" , & self . it , \"ids\" , & & self . ids ,)", "memchr :: memmem :: Finder :: new (pattern) . into_owned ()", "\" is to think about them as a simple alternation of literals in a regular\"", "memchr :: memchr3 (self . byte1 , self . byte2 , self . byte3 , & haystack [span]) . map (| i | span . start + i)", "\" is the entire haystack.) This is configured via [`Input::span`] or\"", "& MatchError", "PatternID :: new", "30", "element", "\" A starting byte prefilter is a simplistic prefilter that looks for possible\"", "u32 :: from_ne_bytes", "SmallIndex :: new (value) . map (StateID) . map_err (StateIDError)", "self . start >= self . end", "{ self . range = Some ((element , element)) ; }", "& 'h H", "self . as_usize ()", "& & self . bits", "52", ":: core :: fmt :: Formatter :: debug_struct_field3_finish (f , \"StartBytesThree\" , \"byte1\" , & self . byte1 , \"byte2\" , & self . byte2 , \"byte3\" , & & self . byte3 ,)", "Arc :: new (Packed (s))", "36", "\" Return the start position of this search.\"", "self . bits . 0", "core :: ascii :: escape_default", "* right_val", "\"     .start_kind(StartKind::Both)\"", "112", "(self >> 32)", "self . 0 [usize :: from (byte)] = class", "if index > SmallIndex :: MAX . as_usize () { return Err (SmallIndexError { attempted : index . as_u64 () , }) ; }", "{ :: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , \"PossibleStartOfMatch\" , & __self_0 ,) }", "\"     AhoCorasick, Anchored, Input, MatchKind, StartKind,\"", "f . write_fmt (format_args ! (\"{0}..{1}\" , self . start , self . end))", "rarest . 0", "\"byte1\"", "Candidate :: Match (:: core :: clone :: Clone :: clone (__self_0))", "if has_fewer_bytes { prestart } else if has_rarer_bytes { prestart } else { prerare }", ":: core :: fmt :: Formatter :: debug_struct_field2_finish (f , \"Match\" , \"pattern\" , & self . pattern , \"span\" , & & self . span ,)", "\" This is a convenience routine for `Match::span().start`.\"", "if ! self . ascii_case_insensitive { if let Some (pre) = self . memmem . build () { return Some (pre) ; } }", "Buffer", "236", "self . add_one_byte (opposite_ascii_case (byte))", "PatternID (:: core :: default :: Default :: default ())", "memchr :: memchr2 (self . byte1 , self . byte2 , & haystack [span]) . map (| i | span . start + i) . map_or (Candidate :: None , Candidate :: PossibleStartOfMatch)", "\" return the match location as early as possible. For example, given\"", "I64", "StateIDError (:: core :: clone :: Clone :: clone (& self . 0))", "\" be better not to use this prefilter even when there are 3 or fewer distinct\"", ":: core :: panicking :: AssertKind :: Eq", "b . checked_add (1)", "\" A byte class set keeps track of an *approximation* of equivalence classes\"", "\" Basically, any byte in a pattern given to the noncontiguous NFA builder\"", "for b in 0 .. 256 { if ! builder . byteset [b] { continue ; } if b > 0x7F { return None ; } bytes [len] = b as u8 ; len += 1 ; }", "\" `repr(transparent)`. Thus, this type always has the same representation as\"", "match core :: str :: from_utf8 (self . haystack ()) { Ok (nice) => fmter . field (\"haystack\" , & nice) , Err (_) => fmter . field (\"haystack\" , & self . haystack ()) , }", "usize :: try_from", "& mut self [index . range ()]", "\" `Sam` and `Samwise`, which would turn into the regex `Sam|Samwise`. It\"", ":: core :: panicking :: panic (\"assertion failed: start <= end\")", "\" Returns the next possible match candidate. This may yield false\"", "range . end_bound ()", "core :: mem :: replace", "\" particularly easy to partition the states. Instead, the simplest thing is\"", "\" This is the same as calling `MatchError::new` with a\"", "bytes . len () >= 256", "if start == end { f . write_fmt (format_args ! (\"{0:?}\" , start)) ? ; } else { f . write_fmt (format_args ! (\"{0:?}-{1:?}\" , start , end)) ? ; }", "\" Whether this is available as a prefilter or not. This can be set to\"", "Arc :: new (Memmem (memchr :: memmem :: Finder :: new (pattern) . into_owned ()) ,)", "\" (starting from `0`) relative to other patterns used to construct the\"", "\"MatchError\"", "\" This returns `0` in precisely the cases that `is_empty` returns `true`.\"", "228", "{ f . write_fmt (format_args ! (\"state identifier overflow: failed to create state ID from {0}, which exceeds the max of {1}\" , requested_max , max ,) ,) }", "\"IndexMapper\"", "178", "81", "47", "\" This is guaranteed to never overflow an `i32`.\"", "class . checked_add (1) . unwrap ()", "& haystack [span]", "\"     Some(Match::must(0, 0..4)),\"", "\"InvalidInputAnchored\"", "& & self . start_anchored_id", "106", "& self . as_u32 ()", "i . checked_add (1) . unwrap ()", "\"offsets\"", "b'Z'", "SmallIndex :: try_from (index)", "SmallIndex :: try_from (value) . map (StateID) . map_err (StateIDError)", "189", "self . buffer () . len ()", "& SmallIndexError", "(self >> 32) as u32", "MatchError (:: core :: clone :: Clone :: clone (& self . 0))", "s", "self . start + offset", "& self [index . range ()]", "_", "\" never overflow an `i32`.\"", "& __self_0", "BYTE_FREQUENCIES", ":: core :: panicking :: panic_fmt (format_args ! (\"cannot create iterator for {0} when number of elements exceed {1:?}\" , \"StateID\" , StateID :: LIMIT ,) ,)", "\" The maximum value.\"", "\" Additionally, the [`AhoCorasick`](crate::AhoCorasick) search APIs accept\"", "\" There are two generally different ways that Aho-Corasick automatons can\"", "\" implementations are permitted to return false positives.\"", "ByteSet", "\" is active, it is used whenever a search enters an automaton's start state.\"", "usize :: from", "MemmemBuilder { count : :: core :: default :: Default :: default () , one : :: core :: default :: Default :: default () , }", "\"class\"", "Vec < bool >", "\"byteset\"", "\"     .match_kind(MatchKind::LeftmostFirst)\"", "\" When executing a search, there are a few parameters one might want to\"", "\" [`AhoCorasick`](crate::AhoCorasick), supporting both unanchored\"", "core :: mem :: size_of :: < SmallIndex > ()", "\"byte_offsets\"", "\" The set of starting bytes observed.\"", "value", "\" When running a non-overlapping search, an \\\"earliest\\\" search will\"", "\" reading from a stream. Its central purpose is to allow \\\"rolling\\\" some\"", "impl Fn (StateID) -> StateID", "& self . start_anchored_id", "for (start , end) in self . element_ranges (class) { if start == end { f . write_fmt (format_args ! (\"{0:?}\" , start)) ? ; } else { f . write_fmt (format_args ! (\"{0:?}-{1:?}\" , start , end)) ? ; } }", "\" match between it and all other bytes outside of the range.\"", "RareBytesOne", "core :: cmp :: max", "b'a' <= b && b <= b'z'", "builder . available", ":: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , \"Match\" , & __self_0 ,)", "\" A set of byte offsets, keyed by byte.\"", "Special { max_special_id : StateID :: ZERO , max_match_id : StateID :: ZERO , start_unanchored_id : StateID :: ZERO , start_anchored_id : StateID :: ZERO , }", "core :: fmt :: Formatter", "! self . rare_set . contains (byte)", "__H", "\" is unspecified.\"", "\" will be left in an inconsistent state, since any other transitions\"", "& 'a ByteClasses", "Err", "SmallIndex :: new (value) . map (PatternID) . map_err (PatternIDError)", "self . 0 . attempted ()", ":: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , \"StateIDIter\" , & & self . 0 ,)", "\" to create a span where `start > end`.\"", "& MemmemBuilder", "builder . byte_offsets . set", "Ok (SmallIndex :: new_unchecked (id . as_usize ()))", "{ f . write_fmt (format_args ! (\"pattern identifier overflow: failed to create pattern ID from {0}, which exceeds the max of {1}\" , requested_max , max ,) ,) }", "\" after all swaps have been completed.\"", "readlen == 0", "Some (Prefilter { finder , memory_usage })", "\" and anchored searches can be quite costly. For this reason,\"", "StartKind :: Unanchored", "\" Returns a new match with `offset` added to its span's `start` and `end`\"", "kind . as_packed () . map (| kind | packed :: Config :: new () . match_kind (kind) . builder ())", "off . max", "Err (SmallIndexError { attempted : index . as_u64 () , })", "[\"count\" , \"ascii_case_insensitive\" , \"start_bytes\" , \"rare_bytes\" , \"memmem\" , \"packed\" , \"enabled\" ,]", "\" `old_id` to `map[dfa.to_index(old_id)]`. That is, we find the position\"", "match self { Anchored :: No => \"No\" , Anchored :: Yes => \"Yes\" , }", "\" The state ID of the start state used for unanchored searches.\"", "f . debug_struct (\"RareByteOffsets\")", "& self . byteset", "119", "if ! (len <= PatternID :: LIMIT) { { :: core :: panicking :: panic_fmt (format_args ! (\"cannot create iterator for {0} when number of elements exceed {1:?}\" , \"PatternID\" , PatternID :: LIMIT ,) ,) ; } }", "\" equivalence classes. In theory, all bytes not in any pattern should\"", "\" // Build a searcher that supports both unanchored and anchored modes.\"", "\" regex engines such as those found in Perl, Ruby, Python, Javascript and\"", ":: core :: fmt :: Formatter :: debug_struct_field3_finish (f , \"Buffer\" , \"buf\" , & self . buf , \"min\" , & self . min , \"end\" , & & self . end ,)", "Arc :: new (RareBytesThree { offsets : builder . byte_offsets , byte1 : bytes [0] , byte2 : bytes [1] , byte3 : bytes [2] , })", "\" Create a new small index without checking whether the given value\"", "\" these equivalence classes. Equivalently, this returns the total number\"", "\" The default span is the entire haystack.\"", "\" equivalence class.\"", "\" This type is always represented internally by a `u32` and is marked as\"", "\" assert_eq!(2..5, input.get_range());\"", "StartBytesThree", "cur_id == new_id", "u8", "core :: ops :: IndexMut < Span >", "\"ByteClassElements\"", "WithStateIDIter { it : :: core :: clone :: Clone :: clone (& self . it) , ids : :: core :: clone :: Clone :: clone (& self . ids) , }", "217", "class . checked_add (1)", "\"StartBytesTwo\"", "if b'A' <= b && b <= b'Z' { b . to_ascii_lowercase () } else if b'a' <= b && b <= b'z' { b . to_ascii_uppercase () } else { b }", "& self . available", "\" to the match semantics of any large group of regex implementations, so\"", "\" start_anchored_id, which occurs precisely in the case where the empty\"", "\"i64 overflowed usize\"", "noncontiguous :: NFA", "RareBytesOne { byte1 : :: core :: clone :: Clone :: clone (& self . byte1) , offset : :: core :: clone :: Clone :: clone (& self . offset) , }", "34", "& self . max", "\" This error occurs when a small index could not be constructed.\"", "match core :: str :: from_utf8 (self . haystack ()) { Ok (nice) => fmter . field (\"haystack\" , & nice) , Err (_) => fmter . field (\"haystack\" , & self . haystack ()) , } . field (\"span\" , & self . span) . field (\"anchored\" , & self . anchored) . field (\"earliest\" , & self . earliest) . finish ()", "! self . is_empty () && self . start <= offset", "self . packed . as_ref () . and_then (| b | b . build ())", "\" assert_eq!(\"", "\" use aho_corasick::{AhoCorasick, Input, MatchKind};\"", "self . attempted", "core :: mem :: size_of :: < SmallIndex >", "\" anchored or both kinds of searches.\"", "46", "usize :: from (byte)", "match (& 1 , & builder . count) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: None ,) ; } } }", "\" Return this small index as a `usize`. This is guaranteed to never\"", "u32", "\" * Whether to run an unanchored (matches can occur anywhere after the\"", "108", "\" The singular pattern to search for. This is only set when count==1.\"", "{ if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: None ,) ; } }", ":: core :: hash :: Hash :: hash (& self . pattern , state)", "\" bytes---any byte not in any pattern---will be treated as their own\"", "\" # Indexing\"", "if self . buffer () . len () >= self . min { return Ok (true) ; }", "99", "f . write_fmt (format_args ! (\")\"))", "{ usize :: try_from (self) . expect (\"i64 overflowed usize\") }", "SmallIndex :: MAX . as_usize ()", "\"StateIDOverflow\"", "& & self . 0", "\" indices. If state IDs and state indices are equivalent, then provide\"", "{ ErrorKind :: PatternIDOverflow { max : :: core :: clone :: Clone :: clone (__self_0) , requested_max : :: core :: clone :: Clone :: clone (__self_1) , } }", "SmallIndex :: MAX", "Candidate :: None", "\" `ab` and `a`, then both the leftmost-first and leftmost-longest matches\"", "\" subsequent searches will return no matches.\"", "patlen <= 16 && minlen >= 2 && self . start_bytes . count >= 3 && self . rare_bytes . count >= 3", "121", "\" been searched.\"", "\" A builder for constructing a starting byte prefilter.\"", "f . write_fmt (format_args ! (\", \")) ?", "StartBytesBuilder :: new ()", "\" It is represented by a `u32` even on 64-bit systems in order to conserve\"", "\" while permitting tweaking parameters in more niche use cases while reusing\"", "Range", "self . start () + offset", "self . packed", "\" For convenience, callers may use a `SmallIndex` to index slices.\"", "core :: ops :: IndexMut < StateID >", "\" remappable value according to the swaps performed.\"", "[\"ascii_case_insensitive\" , \"rare_set\" , \"byte_offsets\" , \"available\" , \"count\" , \"rank_sum\" ,]", "self . 0 == other . 0", "SmallIndex :: from_ne_bytes (bytes) . map (PatternID) . map_err (PatternIDError)", "Anchored :: No", "self . pattern", "168", "self . set_span (Span { start , .. self . get_span () })", "\"RareByteOffsets\"", "\" The \\\"standard\\\" match semantics of Aho-Corasick generally don't correspond\"", "& & self . enabled", "\" A simple set of bytes that is reasonably cheap to copy and allocation free.\"", "core :: str :: from_utf8", "253", "memchr :: memchr2 (self . byte1 , self . byte2 , & haystack [span])", "ByteClassSet :: empty ()", "\"usize overflowed u64\"", "Span { end , .. self . get_span () }", "\" one state multiple times.\"", "match self { ErrorKind :: StateIDOverflow { max : __self_0 , requested_max : __self_1 , } => { :: core :: fmt :: Formatter :: debug_struct_field2_finish (f , \"StateIDOverflow\" , \"max\" , __self_0 , \"requested_max\" , & __self_1 ,) } ErrorKind :: PatternIDOverflow { max : __self_0 , requested_max : __self_1 , } => { :: core :: fmt :: Formatter :: debug_struct_field2_finish (f , \"PatternIDOverflow\" , \"max\" , __self_0 , \"requested_max\" , & __self_1 ,) } ErrorKind :: PatternTooLong { pattern : __self_0 , len : __self_1 } => { :: core :: fmt :: Formatter :: debug_struct_field2_finish (f , \"PatternTooLong\" , \"pattern\" , __self_0 , \"len\" , & __self_1 ,) } }", "\" This is a more verbose version of the kind-specific constructors, e.g.,\"", "self as u8", "\" Note that when using [`MatchKind::Standard`], the \\\"earliest\\\" option\"", "\" implementing most textbook explanations of Aho-Corasick. The second way is\"", ".. self . end", "\" A type that wraps a single byte with a convenient fmt::Debug impl that\"", "format_args ! (\"cannot create iterator for {0} when number of elements exceed {1:?}\" , \"PatternID\" , PatternID :: LIMIT ,)", "\" be used to change the default to supporting both kinds of searches\"", "match self { Candidate :: None => None , Candidate :: Match (ref m) => Some (m . start ()) , Candidate :: PossibleStartOfMatch (start) => Some (start) , }", "Some (SmallIndex :: new_unchecked (id))", "\" The identifier of a finite automaton state.\"", ":: core :: clone :: Clone :: clone (& self . kind)", "self . set . iter ()", "\" identifier that exceeds the capacity of a `StateID`.\"", ":: core :: option :: Option < :: core :: cmp :: Ordering >", "SmallIndex :: try_from", "item", "f . debug_tuple (\"StateID\")", "self . start_bytes . count", "Result < PatternID , PatternIDError >", "pre", "172", "\" Set the span for this search.\"", "\" assert!(input.is_done());\"", "| i | { let start = span . start + i ; let end = start + self . 0 . needle () . len () ; Candidate :: Match (Match :: new (PatternID :: ZERO , start .. end)) }", "bucket", "if ! self . available { return ; }", "\"memory_usage\"", "SmallIndex :: from_u32_unchecked (index as u32)", "self . 0 . as_u32 ()", "ByteClasses :: empty ()", "154", "Some (crate :: packed :: MatchKind :: LeftmostLongest)", "\" `i32`, `usize` and an `isize`. This means that on 16-bit targets, for\"", "\" to access indices as \\\"small index\\\" types. We require ExactSizeIterator so\"", "\" Because a `Match` is just some offsets. But it *is* required for supporting\"", "136", "0 .. r . state_len ()", "self . rank_sum", "& self . max_special_id", "SmallIndexIter", "* self . kind ()", "self . earliest = yes", "From < Range < usize > >", "\" corresponding searcher. If only a single pattern is provided, then all\"", "\" While a `SmallIndex` is meant to guarantee that its value fits into `usize`\"", "\" Return the frequency rank of the given byte. The higher the rank, the more\"", "{ MatchErrorKind :: InvalidInputUnanchored }", ":: core :: clone :: Clone :: clone (& self . byte_offsets)", "\" The zero value.\"", "\" let input = Input::new(haystack);\"", "\"start_unanchored_id\"", "UnwindSafe", "memchr :: memchr3 (self . byte1 , self . byte2 , self . byte3 , & haystack [span]) . map (| i | { let pos = span . start + i ; let offset = self . offsets . set [usize :: from (haystack [pos])] . max ; cmp :: max (span . start , pos . saturating_sub (usize :: from (offset))) })", "\"RareBytesOne\"", "! self . byteset [byte as usize]", "\" happens once `b` is seen.\"", "found", "SmallIndex :: from_ne_bytes (bytes) . map (StateID)", "\" overflow `usize`.\"", ":: core :: panicking :: assert_failed", "f . write_fmt (format_args ! (\"failed to create {0} from {1:?}, which exceeds {2:?}\" , \"StateID\" , self . attempted () , StateID :: MAX ,) ,)", "\" A builder for constructing the best possible prefilter. When constructed,\"", "\" this roll buffer and the `StreamChunkIter`.\"", "\" semantics.\"", ":: core :: clone :: Clone :: clone (& self . byteset)", "\" A prefilter for scanning for three starting bytes.\"", "\" time.\"", "match bytes . first () { None => return , Some (& b) => (b , freq_rank (b)) , }", "new_id", "55", "pos . saturating_sub (usize :: from (offset))", "\" in panics or silent logical errors.\"", "f . write_fmt (format_args ! (\"pattern {0} with length {1} exceeds the maximum pattern length of {2}\" , pattern . as_usize () , len , SmallIndex :: MAX . as_usize () ,) ,)", "\" a single pattern. In theory, this could be extended to support searchers\"", "PatternID :: iter (it . len ())", "self . idx . to_index (new_id)", "\" let haystack = \\\"abcd\\\";\"", "128", "Match :: new", "max as u8", "index > SmallIndex :: MAX . as_usize ()", "\" This routine is generic over how a span is provided. While\"", "\" Return the anchored mode for this search configuration.\"", "\" Create a new match from a pattern ID and a span.\"", "40", "\"     .build(&[\\\"abcd\\\", \\\"b\\\"])\"", "if self . ascii_case_insensitive { (None , usize :: MAX , 0) } else { let patlen = self . packed . as_ref () . map_or (usize :: MAX , | p | p . len ()) ; let minlen = self . packed . as_ref () . map_or (0 , | p | p . minimum_len ()) ; let packed = self . packed . as_ref () . and_then (| b | b . build ()) . map (| s | { let memory_usage = s . memory_usage () ; Prefilter { finder : Arc :: new (Packed (s)) , memory_usage , } }) ; (packed , patlen , minlen) }", "\" let input = Input::new(\\\"foobar\\\");\"", "\" reporting it as a match.\"", "\" A way to map indices to state IDs (and back).\"", "\" searches also use standard semantics and report all possible matches.\"", "\" Return all free capacity in this buffer.\"", "n as i8", "start > 0", "[0 ; 3]", "while let Some (byte) = self . bytes . next () { if self . class == self . classes . get (byte) { return Some (byte) ; } }", "\" fit in a `u32`, `i32`, `usize` and an `isize`. This means that on 16-bit\"", "\" starting bytes.\"", "\"     .unwrap();\"", "\" Note also that this buffer is not actually required to just report matches.\"", "fmter", "f . write_fmt (format_args ! (\"]\"))", "\" The power of 2 corresponding to the stride of the corresponding\"", "\" When there are multiple possible leftmost matches, the longest match\"", "{ Arc :: new (RareBytesOne { byte1 : bytes [0] , offset : builder . byte_offsets . set [bytes [0] as usize] , }) }", "\"max_match_id\"", "memchr :: memmem :: Finder :: new", ":: core :: clone :: Clone :: clone (__self_0)", "\" desired partitionings. To do that, we need a mechanism for swapping states.\"", "\"Buffer\"", "Some", "{ :: core :: panicking :: panic (\"internal error: entered unreachable code\" ,) }", "self . buf [.. self . end]", "\" Create a new buffer for stream searching. The minimum buffer length\"", "\" with a match kind other than [`MatchKind::Standard`].\"", "self . byte1", "\" locations in this map are also swapped. Thus, its new position will\"", "\" Return whether this search should execute in \\\"earliest\\\" mode.\"", "i32", "\" Returns the stride, as a base-2 exponent, required for these\"", "\" Returns the length of this span.\"", "self . haystack () . len ()", "37", "self . 0 == b' '", "StateIDIter :: new", "\" Decode this value from the bytes given using the native endian\"", "\" its ID.\"", "& self . elements", "format_args ! (\"pattern identifier overflow: failed to create pattern ID from {0}, which exceeds the max of {1}\" , requested_max , max ,)", "pos", "& self . byte2", "& offsets", "SmallIndexIter { rng : 0 .. len }", "StartBytesBuilder", "\" correct values later.\"", "SmallIndex :: new (value) . map (PatternID)", "span", ":: core :: cmp :: PartialOrd :: partial_cmp (& self . 0 , & other . 0)", "\" assert_eq!(None, ac.try_find(input)?);\"", "\" Create a new match from a pattern ID and a byte offset span.\"", "\" This shows how to create a match for the third pattern in an\"", "206", "pbuilder", "self . 0 [usize :: from (byte)]", "f . write_fmt (format_args ! (\"{0:?}\" , start)) ?", "\" anchored mode, then the search will either panic or return an error,\"", "\" Examples of misconfiguration:\"", "65", "if ! builder . available || builder . count > 3 { return None ; }", "builder . rare_set . contains (b)", "SmallIndex :: new_unchecked (u32 :: from_ne_bytes (bytes) . as_usize ())", "180", "109", "format_args ! (\"]\")", ":: core :: marker :: StructuralPartialEq", "129", "f . write_fmt (format_args ! (\"\\' \\'\"))", "\" caller requests a search for which matching an automaton that contains\"", "ByteClassElementRanges", "{ usize :: try_from (self) . expect (\"i8 overflowed usize\") }", "prerare", "cur_id == id", "self . 0", "\" When the `std` feature is enabled, this implements the `Error` trait.\"", "\" past the minimum amount.\"", "\" This routine also panics if the given range does not correspond to\"", "if ! builder . byteset [b] { continue ; }", "\" * [`dfa::DFA`](crate::dfa::DFA) supports only unanchored\"", "\"LeftmostLongest\"", "WithStateIDIter :: new", "\" While there is a bit more to it, this then allows us to rewrite the\"", "r . remap (| sid | self . map [self . idx . to_index (sid)])", "Sync", "self . bits . 0 [usize :: from (bucket)] & (1 << bit)", "f . write_fmt (format_args ! (\"match kind {0:?} does not support stream searching\" , got ,) ,)", "\" occurrences of either `f` or `b`.\"", "\" This is analogous to `new_unchecked` in that is does not check\"", "Some ((id , item))", "\" check to be as fast as possible. Partitioning state IDs into, for example,\"", "\" # Valid bounds and search termination\"", "BuildError { kind : :: core :: clone :: Clone :: clone (& self . kind) , }", "\" Returns a new span with `offset` added to this span's `start` and `end`\"", "79", ":: core :: clone :: Clone :: clone (& self . offsets)", "readany", "\" Return the end position of this search.\"", "self . rng . start", "WithStateIDIter < Self >", "memchr :: memchr2 (self . byte1 , self . byte2 , & haystack [span]) . map (| i | { let pos = span . start + i ; let offset = self . offsets . set [usize :: from (haystack [pos])] . max ; cmp :: max (span . start , pos . saturating_sub (usize :: from (offset))) }) . map_or (Candidate :: None , Candidate :: PossibleStartOfMatch)", "\" If the given byte is an ASCII letter, then return it in the opposite case.\"", "SmallIndex :: MAX . as_u64 ()", "\" An iterator over all elements in a specific equivalence class.\"", "\"SmallIndexError\"", "* left_val", "\" transition table. 'id >> stride2' de-multiplies an ID while 'index <<\"", "\" Returns the ID of the pattern that matched.\"", "fmtd . entry (& b)", "Buffer { buf : :: alloc :: vec :: from_elem (0 , capacity) , min , end : 0 , }", "234", "MemmemBuilder", ":: core :: cmp :: AssertParamIsEq < u64 >", "self . rng", "SmallIndex :: SIZE", "\" Create a new empty set of rare byte offsets.\"", "WithPatternIDIter :: new", "MatchError :: new (MatchErrorKind :: UnsupportedOverlapping { got , })", "\" search receiving such an input should immediately return with no match.\"", "! self . is_empty () && self . start <= offset && offset <= self . end", "\" // search begins, so no match is found.\"", "\" // semantics, this finds `b` first.\"", "\" Indicate the the range of byte given (inclusive) can discriminate a\"", "\" This is a **non-exhaustive** enum. That means new variants may be added in\"", "\" An iterator over all elements in an equivalence class expressed as a\"", ":: core :: clone :: AssertParamIsClone < PatternID >", "if usize :: from (end) + 1 != usize :: from (element) { self . range = Some ((element , element)) ; return Some ((start , end)) ; }", "\" This specifically enables the technique by which we determine which states\"", "__self_discr == __arg1_discr", "\" An error that occurs during a search is limited to some kind of\"", "opposite_ascii_case", "179", "StateIDIter (:: core :: clone :: Clone :: clone (& self . 0))", "\" identity.\"", "RareBytesBuilder", "\" second read call whether a match exists or not.\"", "& BitSet", "\" the start bound is exactly one greater than the end bound.\"", "\" contiguous region of bytes. The starting offset is inclusive while the\"", "bytes", "\" let ac = AhoCorasick::builder()\"", "\" The `Standard` match kind is the default and is the only one that supports\"", "RareByteOffset { max : max as u8 }", "[u8 ; 4]", "self . rare_bytes . build ()", "\" use of the rare-byte prefilter.\"", "\"ByteClassElementRanges\"", "190", "PatternID (SmallIndex :: new_unchecked (value))", "Result < StateID , StateIDError >", "StateID :: iter (it . len ())", "format_args ! (\"invalid span {0:?} for haystack of length {1}\" , span , self . haystack . len () ,)", "\" assert_eq!(0..5, input.get_range());\"", "\" This occurs when given an integer exceeding the maximum small index value.\"", "Candidate :: Match", "\" is itself also a small index. This is useful in certain contexts, e.g.,\"", "\" In some cases, a heuristic frequency analysis may determine that it would\"", "StartBytesTwo", "249", "self . offset", "[T]", "\" assert!(input.get_earliest());\"", "\" This is used in finite state machines to reduce the size of the transition\"", "\" Understanding match semantics can be a little tricky, and one easy way\"", ":: core :: clone :: Clone :: clone (& self . start_unanchored_id ,)", "\" searcher that was built without unanchored support.\"", "\" caller requests an anchored search but where anchored searches aren't\"", "\"StartBytesBuilder\"", "\" [`Input::range`].\"", "self . idx . to_state_id (i)", "\" `std::ops::Range<usize>`. To provide anything supported by range\"", "\" This is a convenience routine for only mutating the start of a span\"", "\" contents: `test test foobar test test`. Now assume that we happen to read\"", "! self . enabled", ":: core :: panicking :: panic_fmt", "WithPatternIDIter :: new (self)", "span . end <= self . haystack . len ()", "range . start", "| s | { let memory_usage = s . memory_usage () ; Prefilter { finder : Arc :: new (Packed (s)) , memory_usage , } }", "if self . rng . start >= self . rng . end { return None ; }", "166", "\" prefilter becomes inert.\"", "self . 0 . as_u64 ()", "\" kinds are useful in specific circumstances. For example, leftmost-first can\"", "\" and `str`, and `IndexMut` for `[u8]`. For convenience, this also impls\"", "2", "\" There are no constraints on the values of a span. It is, for example, legal\"", "{ Candidate :: Match (:: core :: clone :: Clone :: clone (__self_0)) }", "self . offsets", "\"PatternIDOverflow\"", "format_args ! (\"{0:?}-{1:?}\" , start , end)", "u32 :: try_from (self)", "usize :: from (self . 0 [255])", "span . start", "self . end . checked_sub (self . min)", "\" never overflow.\"", "(id , item)", "\"bytes\"", "Self", "\" if any, and discard the rest.\"", "\" let mat = ac.try_find(input)?.expect(\\\"should have a match\\\");\"", "\" corresponds to standard semantics, then this returns None, since\"", "StartKind :: Anchored", "(start <= end)", "b . to_ascii_lowercase ()", "usize :: try_from (zeros) . unwrap ()", "8", "f . write_fmt (format_args ! (\"matching with an empty pattern string is not supported for this operation\" ,) ,)", "usize :: try_from (self) . expect (\"i32 overflowed usize\")", "class = class . checked_add (1) . unwrap ()", "self . packed . as_ref () . map_or (usize :: MAX , | p | p . len ())", "other . end", "\" streaming matches using leftmost match semantics will result in an error in\"", "219", "205", "\" Aho-Corasick automaton with an unsupported `MatchKind`.\"", "Input < 'h >", "\" The stride is always the smallest power of 2 that is greater than or\"", "113", "\" That is, a sequence of contiguous ranges are returned. Typically, every\"", "Arc < P >", "imp", "Packed", "\" start of the search) or anchored (matches can only occur beginning at\"", "match * self { MatchKind :: Standard => None , MatchKind :: LeftmostFirst => { Some (crate :: packed :: MatchKind :: LeftmostFirst) } MatchKind :: LeftmostLongest => { Some (crate :: packed :: MatchKind :: LeftmostLongest) } }", "\" A type that represents a \\\"small\\\" index.\"", "\" Returns an iterator of the bytes in the given equivalence class.\"", "if let Some (& byte) = bytes . first () { self . add_one_byte (byte) ; if self . ascii_case_insensitive { self . add_one_byte (opposite_ascii_case (byte)) ; } }", "\" assert_eq!(2, input.start());\"", "& self . max_match_id", "self . byte3", "\" Return the minimum size of the buffer. The only way a buffer may be\"", "PatternID (SmallIndex :: ZERO)", "\" suitable, but also an `Input` when they're not. For example:\"", "\"assertion failed: roll_end <= self.end\"", "mode", "\" byte order for the current target.\"", "WithStateIDIter < I >", ":: core :: fmt :: Formatter :: debug_struct_field3_finish (f , \"ByteClassElements\" , \"classes\" , & self . classes , \"class\" , & self . class , \"bytes\" , & & self . bytes ,)", "other . bits", "& & self . end", "if ! (span . start <= span . end) { { :: core :: panicking :: panic_fmt (format_args ! (\"invalid match span\")) ; } }", "TryFrom < usize >", "Remapper", "\" The end of the contents of this buffer.\"", "StartBytesThree { byte1 : bytes [0] , byte2 : bytes [1] , byte3 : bytes [2] , }", "AsRef < [u8] >", "ByteSet :: empty", "format_args", "byte % 128", "\" The downside of this is that it's inconvenient to map between state IDs\"", ":: core :: fmt :: Formatter :: debug_struct_fields_finish (f , \"Builder\" , names , values ,)", "SmallIndexError { attempted : index . as_u64 () , }", "\" valid bounds in the haystack or the termination of a search.\"", "\" This shows how to create a match for the first pattern in an\"", "\" It is expected that, after calling this, the underlying state machine\"", "IndexMapper { stride2 }", "\" state IDs in a DFA's transition table in a single pass. This is done\"", "\" The reason why this exists is because state IDs are \\\"premultiplied\\\" in a\"", "StateID :: new_unchecked", "b = b . checked_add (1) . unwrap ()", "\" The representation of a byte set. Split out so that we can define a\"", "core :: mem :: replace (& mut self . rng . start , next_id)", "Range < usize >", "\"UnsupportedOverlapping\"", "\" remapper can then be used to swap states. The remappable value given\"", "\" as a power of 2. This stride is used to map between state IDs and state\"", "92", "StartBytesOne", "other . span", "len", "& Self", "124", "Prefilter { finder , memory_usage : 0 , }", "self . 0 [255]", "212", ":: core :: cmp :: PartialOrd :: partial_cmp", "\" particular, an invalid ID value is likely to cause panics or\"", "\" given should be the size of the maximum possible match length.\"", "\" between IDs and indices by simply unmultiplying the IDs and multiplying the\"", "span . start <= span . end", "packed :: Config :: new", "{ :: core :: fmt :: Formatter :: debug_struct_field1_finish (f , \"UnsupportedStream\" , \"got\" , & __self_0 ,) }", "f . debug_tuple (\"PatternID\") . field (& self . as_u32 ()) . finish ()", "\" starting bytes. e.g., the patterns `foo`, `bar`, and `baz` have two\"", "\" the haystack or the termination of a search.\"", "self . byteset [byte as usize]", "& self . pattern", "\" interval in terms of `usize`.\"", "\" Convert this boolean set to a map that maps all byte values to their\"", "\" roll\"", "ErrorKind :: PatternIDOverflow { max , requested_max , }", "RareBytesThree { offsets : builder . byte_offsets , byte1 : bytes [0] , byte2 : bytes [1] , byte3 : bytes [2] , }", "core :: str :: from_utf8 (self . haystack ())", ":: core :: fmt :: Formatter :: debug_struct_field1_finish (f , \"UnsupportedOverlapping\" , \"got\" , & __self_0 ,)", "offsets . push (off)", "41", "202", "builder . byte_offsets . set [bytes [0] as usize]", "core :: fmt :: Formatter < '_ >", "\" An iterator over each equivalence class.\"", "\" enough to handle most use cases.\"", "StartBytesOne { byte1 : :: core :: clone :: Clone :: clone (& self . byte1) , }", "& RareBytesBuilder", "StateID", "\" // at the beginning of the search, it is not reported as a match.\"", "self . start == range . start", "\" The pattern is identified by an ID, which corresponds to its position\"", "rdr", "I :: Item", "\" configured via [`Input::anchored`].\"", "142", "core :: ops :: Index < Span >", "(ByteSet { bits : * self }) . contains (b)", "bytes . is_empty ()", "130", "\" };\"", "{ Candidate :: PossibleStartOfMatch (:: core :: clone :: Clone :: clone (__self_0) ,) }", ":: core :: clone :: Clone :: clone (& self . span)", "\" This example shows the difference between \\\"earliest\\\" searching and\"", "pid", "\" * [`StateID`] is for representing the identifiers of states in finite\"", "233", "\" in the given haystack after or at the given position.\"", "\" matches are guaranteed to have a pattern ID of `0`.\"", "\" Create a new error value with the given kind.\"", "{ f . write_fmt (format_args ! (\"match kind {0:?} does not support stream searching\" , got ,) ,) }", "\" An empty match can only be returned when empty pattern is in the\"", ":: core :: clone :: Clone :: clone (& self . memory_usage)", "\" `abcdef`, only a match for `b` is reported since it is detected first. The\"", "Fn (StateID) -> StateID", ":: core :: fmt :: Formatter :: write_str (f , match self { MatchKind :: Standard => \"Standard\" , MatchKind :: LeftmostFirst => \"LeftmostFirst\" , MatchKind :: LeftmostLongest => \"LeftmostLongest\" , } ,)", "\" Creates a new set of equivalence classes where all bytes are mapped to\"", "\" Set the anchor mode of a search.\"", "\" * The span _within_ the haystack to limit a search to. (The default\"", "for b in 0 ..= 255 { if builder . rare_set . contains (b) { bytes [len] = b ; len += 1 ; } }", "(self >> 8)", "\" This panics if `end < start`.\"", "self . memmem . build ()", "\" `b'A'`. If a non-ASCII letter is given, then the given byte is returned.\"", "\" assert_eq!(2..4, input.get_range());\"", "SmallIndexIter { rng : :: core :: clone :: Clone :: clone (& self . rng) , }", "\" matching this alternation. The first way, leftmost-longest, is commonly\"", "StateID :: ZERO", "163", ":: core :: clone :: Clone :: clone (& self . max_special_id)", "if self . 0 . contains (b) { class = class . checked_add (1) . unwrap () ; }", "match (self . start_bytes . build () , self . rare_bytes . build ()) { (prestart @ Some (_) , prerare @ Some (_)) => { if patlen <= 16 && minlen >= 2 && self . start_bytes . count >= 3 && self . rare_bytes . count >= 3 { return packed ; } let has_fewer_bytes = self . start_bytes . count < self . rare_bytes . count ; let has_rarer_bytes = self . start_bytes . rank_sum <= self . rare_bytes . rank_sum + 50 ; if has_fewer_bytes { prestart } else if has_rarer_bytes { prestart } else { prerare } } (prestart @ Some (_) , None) => { if patlen <= 16 && minlen >= 2 && self . start_bytes . count >= 3 { return packed ; } prestart } (None , prerare @ Some (_)) => { if patlen <= 16 && minlen >= 2 && self . rare_bytes . count >= 3 { return packed ; } prerare } (None , None) if self . ascii_case_insensitive => { None } (None , None) => { if packed . is_some () { } else { } packed } }", "\" than the end position of the search.\"", "\" that have a common prefix of more than one byte (for one byte, we would use\"", "\" example, this type's maximum value will never overflow an `isize`,\"", "self", "MatchError :: new (MatchErrorKind :: InvalidInputAnchored)", "\" The zero index value.\"", "\" assert_eq!(\\\"abc\\\", &haystack[mat.span()]);\"", "& self . bytes", "\" By default, the anchored mode is [`Anchored::No`].\"", ":: core :: cmp :: Ord :: cmp (& self . 0 , & other . 0)", "BuildError { kind : ErrorKind :: PatternTooLong { pattern , len , } , }", "if ! (span . end <= self . haystack . len () && span . start <= span . end . wrapping_add (1)) { { :: core :: panicking :: panic_fmt (format_args ! (\"invalid span {0:?} for haystack of length {1}\" , span , self . haystack . len () ,) ,) ; } }", ":: core :: clone :: Clone :: clone (& self . max_match_id)", "memchr :: memchr", "(span . end <= self . haystack . len () && span . start <= span . end . wrapping_add (1))", "\" skipping past bytes in the haystack that we know cannot possibly\"", "\" Convert a state index to a state ID.\"", "# [allow (non_exhaustive_omitted_patterns)] match * self { MatchKind :: LeftmostFirst => true , _ => false , }", "\" Anchored or unanchored searches might not always be available,\"", "stride2", "memchr :: memmem :: Finder < 'static >", ":: core :: panicking :: panic (\"internal error: entered unreachable code\" ,)", "216", "{ let patlen = self . packed . as_ref () . map_or (usize :: MAX , | p | p . len ()) ; let minlen = self . packed . as_ref () . map_or (0 , | p | p . minimum_len ()) ; let packed = self . packed . as_ref () . and_then (| b | b . build ()) . map (| s | { let memory_usage = s . memory_usage () ; Prefilter { finder : Arc :: new (Packed (s)) , memory_usage , } }) ; (packed , patlen , minlen) }", "RareBytesBuilder { ascii_case_insensitive : false , rare_set : ByteSet :: empty () , byte_offsets : RareByteOffsets :: empty () , available : true , count : 0 , rank_sum : 0 , }", "\" The start of a possible match was found. Callers must confirm it before\"", "\" Like [`SmallIndex::new`], but panics if the given index is not valid.\"", "\" Create a new builder for constructing a start byte prefilter.\"", "\" it will always fit in a `usize`, `isize`, `u32` and a `i32`.\"", "f . write_fmt (format_args ! (\"ByteClasses(\"))", ":: core :: cmp :: PartialEq", ":: core :: panicking :: panic (\"assertion failed: roll_end <= self.end\")", "{ Arc :: new (RareBytesTwo { offsets : builder . byte_offsets , byte1 : bytes [0] , byte2 : bytes [1] , }) }", "bytes . len ()", "\" While a `PatternID` is meant to guarantee that its value fits into `usize`\"", "\" Return the internal value as a `i32`. This is guaranteed to\"", "\" \\\"foobar\\\" on a stream. When we report the match, we'd like to not only\"", "if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: None ,) ; }", "len += 1", "\" Decode this small index from the bytes given using the native endian\"", "PatternID (SmallIndex :: MAX)", "\" * Whether to quit the search as soon as a match has been found, regardless\"", "T", "I8", "bytes [len] = b as u8", "R", "if start > 0 { self . 0 . add (start - 1) ; }", "id . as_usize ()", ":: core :: fmt :: Formatter :: debug_struct_field1_finish (f , \"IndexMapper\" , \"stride2\" , & & self . stride2 ,)", "Input :: new (haystack)", "& MatchKind", "\" [`MatchErrorKind::InvalidInputUnanchored`] kind.\"", "self . rng . end", "\" Use standard match semantics, which support overlapping matches. When\"", "\" supported.\"", ":: core :: fmt :: Debug", "Ok (SmallIndex :: new_unchecked (index))", "\" possibly even silent logical errors.\"", "\" limits aren't part of the public API, but they should generally be large\"", "StateID (SmallIndex :: from_u32_unchecked (index))", "automatically_derived", "& 'h [u8]", "194", "Err (SmallIndexError { attempted : index , })", "self . offsets . set", "\" all correct prefilters must never report false negatives.\"", "m . start ()", "\" Return the internal value as a `usize`. This is guaranteed to\"", "usize :: from (self . 0 [255]) + 1", "\" assert_eq!(10, m.end());\"", "\" an NFA state. If you could somehow build an NFA with `2^30` states, its\"", "SmallIndex :: MAX . as_usize () + 1", "self . packed . as_ref () . map_or (0 , | p | p . minimum_len ())", "215", "& [& dyn :: core :: fmt :: Debug]", "self . start_bytes . add (bytes)", "\" false.\"", "\" is guaranteed to be a non-match ID.\"", "b . checked_add (1) . unwrap ()", "\" [`Automaton::prefilter`](crate::automaton::Automaton::prefilter)\"", "\"StateIDIter\"", "self . anchored", "\" slow as to be completely worthless. Therefore, this crate generally deems\"", "\" the bytes from the previous `read` call because you don't know before the\"", "TryFrom < u16 >", "\" e.g., Given `b'A'`, this returns `b'a'`, and given `b'a'`, this returns\"", "self . set_range (range)", "self . stride2", "match range . end_bound () { Bound :: Included (& i) => i . checked_add (1) . unwrap () , Bound :: Excluded (& i) => i , Bound :: Unbounded => self . haystack () . len () , }", "\" When there are multiple possible leftmost matches, the match\"", "1 << self . stride2 ()", "& self . byte1", "\" particular order, we can determine the type of a state simply by looking at\"", "r", "221", "self . 0 . find (& haystack [span])", ":: core :: hash :: Hash :: hash (& self . span , state)", "offset", "{ u64 :: try_from (self) . expect (\"usize overflowed u64\") }", "\"range\"", "169", "\"anchored\"", "\" The start offset of the span, inclusive.\"", "Range :: from (* self)", "\" implementations such as Perl. (Some regex engines, such as RE2 and Rust's\"", "\" assert_eq!(5..6, input.get_range());\"", "\" Create a new value without checking whether the given argument\"", "ByteClassIter", "\" In other cases, the prefilter can only report a potential match, in which\"", "\" Note that for a sparse NFA, state IDs and indices are equivalent. In this\"", ":: core :: panicking :: panic_fmt (format_args ! (\"invalid span {0:?} for haystack of length {1}\" , span , self . haystack . len () ,) ,)", "50", "\" for the current target, then this returns an error.\"", "self . get_span () . range ()", "RefUnwindSafe", "bytes . iter ()", "self . classes . get (byte)", "if b'a' <= b && b <= b'z' { b . to_ascii_uppercase () } else { b }", "MatchErrorKind :: UnsupportedOverlapping { got : :: core :: clone :: Clone :: clone (__self_0) , }", "haystack . as_ref ()", "\" be very useful as a way to implement match priority based on the order of\"", "\" corresponding to the pattern that appeared earlier when constructing\"", "ErrorKind :: PatternTooLong { pattern : :: core :: clone :: Clone :: clone (__self_0) , len : :: core :: clone :: Clone :: clone (__self_1) , }", "191", "\" Remapper is an abstraction the manages the remapping of state IDs in a\"", "\" assert_eq!(6, input.end());\"", "ByteClassSet", "\" Conversely, matching the regex `Samwise|Sam` against `Samwise` will lead to\"", "\" A representation of a match reported by an Aho-Corasick searcher.\"", "MatchErrorKind :: UnsupportedStream", "\" Return the total number of elements in the alphabet represented by\"", "\" # Other types\"", ":: core :: fmt :: Formatter :: debug_struct_field3_finish (f , \"RareBytesTwo\" , \"offsets\" , & self . offsets , \"byte1\" , & self . byte1 , \"byte2\" , & & self . byte2 ,)", ":: core :: fmt :: Formatter :: debug_struct_field2_finish (f , \"PatternIDOverflow\" , \"max\" , __self_0 , \"requested_max\" , & __self_1 ,)", "pattern", "memchr :: memchr3", ":: core :: default :: Default :: default", "self . byteset [byte as usize] = true", "\" let mut input = Input::new(\\\"foobar\\\");\"", "\" # Relationship with regular expression alternations\"", "| p | p . minimum_len ()", "true", "(b , freq_rank (b))", "\"it\"", "SmallIndexError { attempted : :: core :: clone :: Clone :: clone (& self . attempted) , }", "dyn :: core :: fmt :: Debug", "self . bits . 0 [usize :: from (bucket)]", ":: core :: clone :: AssertParamIsClone < [RareByteOffset ; 256] >", "\" The match semantics for the automaton that was used.\"", "\"min\"", "\" builder before attempting to construct the prefilter.\"", "& ByteSet", "u16", "byte", "| class | class . as_u8 ()", "Some (RareByteOffset { max : max as u8 })", "self . byte2", "\" The minimum size of the buffer, which is equivalent to the maximum\"", "\" # Representation\"", "\" The following types wrap `SmallIndex` to provide a more focused use case:\"", "SmallIndex :: new (index) . expect (\"invalid small index\")", "if b > 0x7F { return None ; }", ":: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , \"PatternIDIter\" , & & self . 0 ,)", "\" Return this small index as a `u64`. This is guaranteed to never\"", "\" caller requests an unanchored search but where unanchored searches\"", "\" positives, so callers must confirm a match starting at the position\"", "\" property for correctness however. For example, creating a `SmallIndex` with\"", "\" Set the span for this search configuration.\"", "Bound :: Unbounded", "\" use aho_corasick::{Input, Span};\"", "& & self . span", "\" that appears before a pattern `B` is a prefix of `B`, then it is impossible\"", "110", "\"Match\"", "\" unspecified behavior, but *not* undefined behavior. In\"", "match self { MatchErrorKind :: InvalidInputAnchored => { MatchErrorKind :: InvalidInputAnchored } MatchErrorKind :: InvalidInputUnanchored => { MatchErrorKind :: InvalidInputUnanchored } MatchErrorKind :: UnsupportedStream { got : __self_0 } => { MatchErrorKind :: UnsupportedStream { got : :: core :: clone :: Clone :: clone (__self_0) , } } MatchErrorKind :: UnsupportedOverlapping { got : __self_0 } => { MatchErrorKind :: UnsupportedOverlapping { got : :: core :: clone :: Clone :: clone (__self_0) , } } MatchErrorKind :: UnsupportedEmpty => MatchErrorKind :: UnsupportedEmpty , }", "WithPatternIDIter", "Remappable", "id . as_usize () >> self . stride2", "PrefilterI", "\"classes\"", "211", "PatternID :: LIMIT", "Input", "\" The total number of values that can be represented as a small index.\"", "\" That is, when matching `Sam|Samwise` against `Samwise`, a POSIX regex\"", "\" let patterns = &[\\\"abc\\\", \\\"b\\\"];\"", ":: core :: fmt :: Formatter :: debug_struct_field2_finish (f , \"WithPatternIDIter\" , \"it\" , & self . it , \"ids\" , & & self . ids ,)", "ErrorKind :: PatternTooLong { pattern , len , }", "if index > SmallIndex :: MAX . as_u32 () { return Err (SmallIndexError { attempted : u64 :: from (index) , }) ; }", "ByteSet :: empty ()", "\" The state ID of the start state used for anchored searches. This is\"", "\" still longest match, but it also appears earlier than `Sam`.\"", "self . max_special_id", "174", "self . span", "\" not implement `Copy`. Like a range, this implements `Index` for `[u8]`\"", "format_args ! (\"state identifier overflow: failed to create state ID from {0}, which exceeds the max of {1}\" , requested_max , max ,)", "Prefilter { finder : :: core :: clone :: Clone :: clone (& self . finder) , memory_usage : :: core :: clone :: Clone :: clone (& self . memory_usage) , }", "\" matches by reporting all positions corresponding to a particular byte. This\"", "doc", ":: core :: intrinsics :: discriminant_value (other)", "\" Create a new builder for constructing a rare byte prefilter.\"", "\" `memchr` crate for use as a prefilter.\"", "{ let pos = span . start + i ; cmp :: max (span . start , pos . saturating_sub (usize :: from (self . offset . max)) ,) }", "self . buffer () . len () >= self . min", "157", "\" a `u32`. It is thus safe to transmute between a `u32` and a `SmallIndex`.\"", "# [allow (non_exhaustive_omitted_patterns)] match * self { MatchKind :: LeftmostFirst | MatchKind :: LeftmostLongest => true , _ => false , }", "{ if patlen <= 16 && minlen >= 2 && self . start_bytes . count >= 3 && self . rare_bytes . count >= 3 { return packed ; } let has_fewer_bytes = self . start_bytes . count < self . rare_bytes . count ; let has_rarer_bytes = self . start_bytes . rank_sum <= self . rare_bytes . rank_sum + 50 ; if has_fewer_bytes { prestart } else if has_rarer_bytes { prestart } else { prerare } }", "\" possible length of a match. This corresponds to the amount that we\"", "64 * (1 << 10)", "\" overflow.\"", "\" exceeds the maximum.\"", "\" A representation of byte oriented equivalence classes.\"", "RareByteOffsets :: empty ()", "\" Note that [`Input::range`] overrides this method and vice versa.\"", "Some (m . start ())", "roll_start", "Candidate", ":: core :: cmp :: Eq", "3", "\" An error that occurs when adding a pattern to an Aho-Corasick\"", "{ u32 :: try_from (self) . expect (\"usize overflowed u32\") }", "\" particular position.\"", "self . start_bytes", "\" Returns an iterator over all equivalence classes in this set.\"", "(None , usize :: MAX , 0)", "self . alphabet_len () . next_power_of_two ()", "\" Create a new \\\"unsupported stream search\\\" error. This occurs when the\"", "self . packed . as_ref ()", "\" common cases. They typically only apply to cases where there are a small\"", "\" else a panic will occur. Bounds are valid if and only if:\"", "\"MemmemBuilder\"", "\" ending offset is exclusive. That is, a span is a half-open interval.\"", "\" The sum of frequency ranks for the rare bytes detected. This is\"", "\" class cannot discriminate between a match and a non-match.\"", "if self . count > 3 { self . available = false ; return ; }", "Option < (PatternID , I :: Item) >", "\" `b` as patterns and `abcdef` as the haystack, the leftmost match is `abcd`\"", "\" things like `try_stream_replace_all` because that needs some mechanism for\"", ":: core :: fmt :: Formatter :: debug_struct_field1_finish (f , \"SmallIndexIter\" , \"rng\" , & & self . rng ,)", "\" before the `abcd` match. In this case, the `b` match is not reported at all\"", "patlen <= 16 && minlen >= 2 && self . start_bytes . count >= 3", "f . write_fmt (format_args ! (\"anchored searches are not supported or enabled\" ,) ,)", "Input :: new", "rarest . 1", "149", "self . elements . next ()", "\"StartBytesOne\"", "\" Offsets associated with an occurrence of a \\\"rare\\\" byte in any of the\"", "\" configuration in place.\"", "\" Depending on which searcher is used internally by\"", "& self . byte_offsets", "\" using a dense map, e.g., Vec<StateID>. That's because state IDs look like\"", "143", "class . as_u8 ()", "72", "bytes . first ()", "& & self . stride2", "\" `isize`, which means it will never overflow a `i16` even though its\"", "self . haystack ()", "& str", "\" handle these sorts of boundary cases that are otherwise extremely subtle.\"", "\" equal to the alphabet length. This is done so that converting between\"", "\" each element is representable by its small index type.\"", "Input { haystack : haystack . as_ref () , span : Span { start : 0 , end : haystack . as_ref () . len () , } , anchored : Anchored :: No , earliest : false , }", "Err (SmallIndexError { attempted : u64 :: from (index) , })", "capacity", "\" used with non-overlapping matches, matches are reported as they are\"", "\" * **or** the end bound is a valid ending bound for the haystack *and*\"", "\" table. This can have a particularly large impact not only on the total size\"", "p . minimum_len ()", "if packed . is_some () { } else { }", "\" at the start of a search. When a search is not anchored (that's\"", "\"assertion failed: start <= end\"", "\" disabled. But there should be an 'alloc' feature that brings in APIs like\"", "noncontiguous :: NFA :: swap_states (self , id1 , id2)", "\" byte across all patterns seen.\"", "if self . count == 1 { self . one = Some (bytes . to_vec ()) ; } else { self . one = None ; }", "nice", "56", "125", "\"ascii_case_insensitive\"", "self . idx . to_index (sid)", "range", "\" misconfiguration that resulted in an illegal call. Stated differently,\"", "& self . haystack ()", "\" Essentially, this \\\"moves\\\" `id1` to `id2` and `id2` to `id1`.\"", "[u8]", "SmallIndex :: from_ne_bytes (bytes)", "\" The default buffer capacity that we use for the stream buffer.\"", "\" participate in a match.\"", "\" [`PatternID`]. This panics if the given `usize` is not representable\"", "\" still point to its old pre-multiplied StateID.\"", "\" A prefilter for scanning for two \\\"rare\\\" bytes.\"", "158", "200", "Prefilter { finder : Arc :: new (Packed (s)) , memory_usage , }", "u8 :: try_from", "\" logical errors.\"", "\"buffer capacity should be bigger than minimum amount\"", "183", "{ Arc :: new (StartBytesThree { byte1 : bytes [0] , byte2 : bytes [1] , byte3 : bytes [2] , }) }", "\" knowing which bytes in the stream correspond to a match and which don't. So\"", "StartBytesTwo { byte1 : bytes [0] , byte2 : bytes [1] , }", "\" If there are more than 3 distinct starting bytes, or if heuristics\"", "\" Refill the contents of this buffer by reading as much as possible into\"", "SmallIndex (:: core :: default :: Default :: default ())", "\" the search can quit as it is guaranteed not to find another match.\"", "\" assert!(!input.get_earliest());\"", "\" search will return as soon as it is known that a match occurs, which\"", "\" since it begins before the `b` match, even though the `b` match is detected\"", "\" Convert this candidate into an option. This is useful when callers\"", "(b , rank)", ":: core :: intrinsics :: discriminant_value (self)", "self . one", "\"Remapper\"", "StateID :: iter", "248", "\" `0..=usize::MAX` since it cannot be represented using a half-open\"", "(self , other)", "\" fallible APIs and a panic when using infallibe APIs.) The `Standard` match\"", "\" return an error in fallible APIs and panic in infallible APIs.\"", "match self { StartKind :: Both => \"Both\" , StartKind :: Unanchored => \"Unanchored\" , StartKind :: Anchored => \"Anchored\" , }", "Special { max_special_id : :: core :: clone :: Clone :: clone (& self . max_special_id) , max_match_id : :: core :: clone :: Clone :: clone (& self . max_match_id) , start_unanchored_id : :: core :: clone :: Clone :: clone (& self . start_unanchored_id ,) , start_anchored_id : :: core :: clone :: Clone :: clone (& self . start_anchored_id ,) , }", "b > 0x7F", "RareBytesBuilder :: new", ":: core :: clone :: Clone :: clone (& self . ascii_case_insensitive ,)", "35", "patlen <= 16 && minlen >= 2 && self . rare_bytes . count >= 3", "\" Return a prefilter suitable for quickly finding potential matches.\"", "\" Once shuffling is complete, `remap` must be called, which will rewrite\"", "fmter . field (\"haystack\" , & self . haystack ())", "u32 :: from (index) > SmallIndex :: MAX . as_u32 ()", ":: core :: hash :: Hash", "208", "{ f . write_fmt (format_args ! (\"unanchored searches are not supported or enabled\" ,) ,) }", "\" // find a match.\"", "self . kind", "\" Convert this match kind into a packed match kind. If this match kind\"", "self . enabled", "f . debug_tuple (\"StateID\") . field (& self . as_u32 ()) . finish ()", "\" assert_eq!(Span { start: 0, end: 6 }, input.get_span());\"", "\"memmem\"", "self . rare_bytes", "\" read, the contents of the buffer should be `st foobar test test`, where the\"", "{ if usize :: from (end) + 1 != usize :: from (element) { self . range = Some ((element , element)) ; return Some ((start , end)) ; } self . range = Some ((start , element)) ; }", "\" smaller than this is if the stream itself contains less than the\"", "\" Also, unfortunately, this currently also requires the 'std' feature to\"", "& self . it", "self . 0 . find (& haystack [span]) . map_or (Candidate :: None , | i | { let start = span . start + i ; let end = start + self . 0 . needle () . len () ; Candidate :: Match (Match :: new (PatternID :: ZERO , start .. end)) } ,)", "Result < SmallIndex , SmallIndexError >", "64", "165", "self as u64", "\"WithStateIDIter\"", "\" to conceptualize non-overlapping matches from an Aho-Corasick automaton\"", "162", "\" Set whether the search should execute in \\\"earliest\\\" mode or not.\"", "crate :: packed :: MatchKind", "& MatchErrorKind", "\" an invalid value can be done in entirely safe code. This may in turn result\"", "\" This searcher configuration knob works in concert with the search time\"", "\" The type of anchored search to perform.\"", "ByteSet { bits : :: core :: default :: Default :: default () , }", "self . it . next () . map (| class | class . as_u8 ())", "103", "\"finder\"", ":: core :: clone :: Clone :: clone (& self . ids)", "144", "core :: fmt :: Result", "self . 0 . contains (b)", "for b in 0u8 ..= 255 { if (ByteSet { bits : * self }) . contains (b) { fmtd . entry (& b) ; } }", "minlen >= 2", "& self . byte3", "(* left_val == * right_val)", "(self >> 16) as u16", "memchr :: memmem :: Finder :: new (pattern)", "start", "coverage", "\" expression. For example, let's say we wanted to match the strings\"", "\"earliest\"", "& self . class", "122", "u64 :: from", "BitSet", "Debug", "usize :: from (bucket)", "RareBytesBuilder :: new ()", "if builder . rare_set . contains (b) { bytes [len] = b ; len += 1 ; }", "self . byte_offsets . set (byte , offset)", ":: core :: clone :: Clone :: clone (& self . byte1)", "\" Note that this may not compute the minimal set of equivalence classes.\"", "\" finite state machine. This is useful when one wants to shuffle states into\"", "\" can change this.\"", "\" among all possible matches. Given the same example as above with `abcd` and\"", "\" where N is the maximum possible length of a match.)\"", "& self [index . as_usize ()]", "\" should never be `MatchKind::Standard`.\"", "{ if patlen <= 16 && minlen >= 2 && self . rare_bytes . count >= 3 { return packed ; } prerare }", "\" the automaton is reported.\"", "\"BuildError\"", "\" An error that occurred during an Aho-Corasick search.\"", "\" equivalence classes.\"", "\" is included because the roll buffer saves N bytes at the end of the buffer,\"", "\" builder will be interpreted without respect to ASCII case.\"", "\"attempted\"", "Into < Span >", "offsets", ":: core :: fmt :: Formatter :: debug_struct_field1_finish", "{ Some (RareByteOffset { max : max as u8 }) }", "bool", "usize :: from (self . offset . max)", "SmallIndexError", "false", "usize :: from (end) + 1 != usize :: from (element)", "43", "\" value and returns false. If there is no previous value set, then this\"", "\" start_anchored_id when a prefilter is active and max_match_id when a\"", "self . packed . as_ref () . and_then (| b | b . build ()) . map (| s | { let memory_usage = s . memory_usage () ; Prefilter { finder : Arc :: new (Packed (s)) , memory_usage , } })", "\" This panics if the given span does not correspond to valid bounds in\"", "self . set_earliest (yes)", "return packed", "& Match", "& other . 0", "self . free_buffer ()", "RareBytesTwo", "SmallIndex :: MAX . as_u32 ()", ":: core :: option :: Option :: None", "self . start_bytes . count >= 3", "\" Create an empty set of bytes.\"", "self . buf", "\" the bounds of the span.\"", "f . write_fmt (format_args ! (\"]\")) ?", "\" automata. It is used for both NFAs and DFAs.\"", "\" Sets the anchor mode of a search.\"", "if let Some (ref mut pbuilder) = self . packed { pbuilder . add (bytes) ; }", "ByteClassElementRanges { elements : self . elements (class) , range : None , }", "builder . count", ":: core :: fmt :: Formatter :: debug_struct_field1_finish (f , \"ByteSet\" , \"bits\" , & & self . bits ,)", "dyn PrefilterI", "\" prefilter inert.\"", "\" Swap the states pointed to by the given IDs. The underlying finite\"", "MatchErrorKind :: UnsupportedOverlapping", "self >> 32", ":: core :: hash :: Hasher", "224", "\" with [`StartKind::Both`] so that it supports both unanchored and\"", "\" panics.\"", "memchr :: memchr (self . byte1 , & haystack [span])", "\" Roll the contents of the buffer so that the suffix of this buffer is\"", "u64 :: from (index)", ":: core :: fmt :: Formatter :: debug_struct_field2_finish (f , \"PatternTooLong\" , \"pattern\" , __self_0 , \"len\" , & __self_1 ,)", "self . span () . range ()", "repr", "0 ..= 255", "\" If the given byte already belongs to this set, then this is a no-op.\"", "& 1", "self . end + offset"}
Starting first pass of dependency resolution.
Starting second pass of dependency resolution.
Starting layering algorithm.
  Layering algorithm iteration: 1
Max dependency level found: 0
Collecting external dependencies per level.
External dependencies written to: /data/data/com.termux.nix/files/home/pick-up-nix2/rust-bootstrap-core/dependencies.json
Starting declaration writing phase.
GENERATED_MODULE_NAMES: 
HAS_PROC_MACROS: false
