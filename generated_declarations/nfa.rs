pub mod nfa { # ! [doc = "\nProvides direct access to NFA implementations of Aho-Corasick.\n\nThe principle characteristic of an NFA in this crate is that it may\ntransition through multiple states per byte of haystack. In Aho-Corasick\nparlance, NFAs follow failure transitions during a search. In contrast,\na [`DFA`](crate::dfa::DFA) pre-computes all failure transitions during\ncompilation at the expense of a much bigger memory footprint.\n\nCurrently, there are two NFA implementations provided: noncontiguous and\ncontiguous. The names reflect their internal representation, and consequently,\nthe trade offs associated with them:\n\n* A [`noncontiguous::NFA`] uses a separate allocation for every NFA state to\nrepresent its transitions in a sparse format. This is ideal for building an\nNFA, since it cheaply permits different states to have a different number of\ntransitions. A noncontiguous NFA is where the main Aho-Corasick construction\nalgorithm is implemented. All other Aho-Corasick implementations are built by\nfirst constructing a noncontiguous NFA.\n* A [`contiguous::NFA`] is uses a single allocation to represent all states,\nwhile still encoding most states as sparse states but permitting states near\nthe starting state to have a dense representation. The dense representation\nuses more memory, but permits computing transitions during a search more\nquickly. By only making the most active states dense (the states near the\nstarting state), a contiguous NFA better balances memory usage with search\nspeed. The single contiguous allocation also uses less overhead per state and\nenables compression tricks where most states only use 8 bytes of heap memory.\n\nWhen given the choice between these two, you almost always want to pick a\ncontiguous NFA. It takes only a little longer to build, but both its memory\nusage and search speed are typically much better than a noncontiguous NFA. A\nnoncontiguous NFA is useful when prioritizing build times, or when there are\nso many patterns that a contiguous NFA could not be built. (Currently, because\nof both memory and search speed improvements, a contiguous NFA has a smaller\ninternal limit on the total number of NFA states it can represent. But you\nwould likely need to have hundreds of thousands or even millions of patterns\nbefore you hit this limit.)\n"] pub mod contiguous { # ! [doc = "\nProvides a contiguous NFA implementation of Aho-Corasick.\n\nThis is a low-level API that generally only needs to be used in niche\ncircumstances. When possible, prefer using [`AhoCorasick`](crate::AhoCorasick)\ninstead of a contiguous NFA directly. Using an `NFA` directly is typically only\nnecessary when one needs access to the [`Automaton`] trait implementation.\n"] use alloc :: { vec , vec :: Vec } ; use crate :: { automaton :: Automaton , nfa :: noncontiguous , util :: { alphabet :: ByteClasses , error :: { BuildError , MatchError } , int :: { Usize , U16 , U32 } , prefilter :: Prefilter , primitives :: { IteratorIndexExt , PatternID , SmallIndex , StateID } , search :: { Anchored , MatchKind } , special :: Special , } , } ; # [doc = " A contiguous NFA implementation of Aho-Corasick."] # [doc = ""] # [doc = " When possible, prefer using [`AhoCorasick`](crate::AhoCorasick) instead of"] # [doc = " this type directly. Using an `NFA` directly is typically only necessary"] # [doc = " when one needs access to the [`Automaton`] trait implementation."] # [doc = ""] # [doc = " This NFA can only be built by first constructing a [`noncontiguous::NFA`]."] # [doc = " Both [`NFA::new`] and [`Builder::build`] do this for you automatically, but"] # [doc = " [`Builder::build_from_noncontiguous`] permits doing it explicitly."] # [doc = ""] # [doc = " The main difference between a noncontiguous NFA and a contiguous NFA is"] # [doc = " that the latter represents all of its states and transitions in a single"] # [doc = " allocation, where as the former uses a separate allocation for each state."] # [doc = " Doing this at construction time while keeping a low memory footprint isn't"] # [doc = " feasible, which is primarily why there are two different NFA types: one"] # [doc = " that does the least amount of work possible to build itself, and another"] # [doc = " that does a little extra work to compact itself and make state transitions"] # [doc = " faster by making some states use a dense representation."] # [doc = ""] # [doc = " Because a contiguous NFA uses a single allocation, there is a lot more"] # [doc = " opportunity for compression tricks to reduce the heap memory used. Indeed,"] # [doc = " it is not uncommon for a contiguous NFA to use an order of magnitude less"] # [doc = " heap memory than a noncontiguous NFA. Since building a contiguous NFA"] # [doc = " usually only takes a fraction of the time it takes to build a noncontiguous"] # [doc = " NFA, the overall build time is not much slower. Thus, in most cases, a"] # [doc = " contiguous NFA is the best choice."] # [doc = ""] # [doc = " Since a contiguous NFA uses various tricks for compression and to achieve"] # [doc = " faster state transitions, currently, its limit on the number of states"] # [doc = " is somewhat smaller than what a noncontiguous NFA can achieve. Generally"] # [doc = " speaking, you shouldn't expect to run into this limit if the number of"] # [doc = " patterns is under 1 million. It is plausible that this limit will be"] # [doc = " increased in the future. If the limit is reached, building a contiguous NFA"] # [doc = " will return an error. Often, since building a contiguous NFA is relatively"] # [doc = " cheap, it can make sense to always try it even if you aren't sure if it"] # [doc = " will fail or not. If it does, you can always fall back to a noncontiguous"] # [doc = " NFA. (Indeed, the main [`AhoCorasick`](crate::AhoCorasick) type employs a"] # [doc = " strategy similar to this at construction time.)"] # [doc = ""] # [doc = " # Example"] # [doc = ""] # [doc = " This example shows how to build an `NFA` directly and use it to execute"] # [doc = " [`Automaton::try_find`]:"] # [doc = ""] # [doc = " ```"] # [doc = " use aho_corasick::{"] # [doc = "     automaton::Automaton,"] # [doc = "     nfa::contiguous::NFA,"] # [doc = "     Input, Match,"] # [doc = " };"] # [doc = ""] # [doc = " let patterns = &[\"b\", \"abc\", \"abcd\"];"] # [doc = " let haystack = \"abcd\";"] # [doc = ""] # [doc = " let nfa = NFA::new(patterns).unwrap();"] # [doc = " assert_eq!("] # [doc = "     Some(Match::must(0, 1..2)),"] # [doc = "     nfa.try_find(&Input::new(haystack))?,"] # [doc = " );"] # [doc = " # Ok::<(), Box<dyn std::error::Error>>(())"] # [doc = " ```"] # [doc = ""] # [doc = " It is also possible to implement your own version of `try_find`. See the"] # [doc = " [`Automaton`] documentation for an example."] pub struct NFA { # [doc = " The raw NFA representation. Each state is packed with a header"] # [doc = " (containing the format of the state, the failure transition and, for"] # [doc = " a sparse state, the number of transitions), its transitions and any"] # [doc = " matching pattern IDs for match states."] repr : Vec < u32 > , # [doc = " The length of each pattern. This is used to compute the start offset"] # [doc = " of a match."] pattern_lens : Vec < SmallIndex > , # [doc = " The total number of states in this NFA."] state_len : usize , # [doc = " A prefilter for accelerating searches, if one exists."] prefilter : Option < Prefilter > , # [doc = " The match semantics built into this NFA."] match_kind : MatchKind , # [doc = " The alphabet size, or total number of equivalence classes, for this"] # [doc = " NFA. Dense states always have this many transitions."] alphabet_len : usize , # [doc = " The equivalence classes for this NFA. All transitions, dense and"] # [doc = " sparse, are defined on equivalence classes and not on the 256 distinct"] # [doc = " byte values."] byte_classes : ByteClasses , # [doc = " The length of the shortest pattern in this automaton."] min_pattern_len : usize , # [doc = " The length of the longest pattern in this automaton."] max_pattern_len : usize , # [doc = " The information required to deduce which states are \"special\" in this"] # [doc = " NFA."] special : Special , } # [automatically_derived] impl :: core :: clone :: Clone for NFA { # [inline] fn clone (& self) -> NFA { NFA { repr : :: core :: clone :: Clone :: clone (& self . repr) , pattern_lens : :: core :: clone :: Clone :: clone (& self . pattern_lens) , state_len : :: core :: clone :: Clone :: clone (& self . state_len) , prefilter : :: core :: clone :: Clone :: clone (& self . prefilter) , match_kind : :: core :: clone :: Clone :: clone (& self . match_kind) , alphabet_len : :: core :: clone :: Clone :: clone (& self . alphabet_len) , byte_classes : :: core :: clone :: Clone :: clone (& self . byte_classes) , min_pattern_len : :: core :: clone :: Clone :: clone (& self . min_pattern_len) , max_pattern_len : :: core :: clone :: Clone :: clone (& self . max_pattern_len) , special : :: core :: clone :: Clone :: clone (& self . special) , } } } impl NFA { # [doc = " Create a new Aho-Corasick contiguous NFA using the default"] # [doc = " configuration."] # [doc = ""] # [doc = " Use a [`Builder`] if you want to change the configuration."] pub fn new < I , P > (patterns : I) -> Result < NFA , BuildError > where I : IntoIterator < Item = P > , P : AsRef < [u8] > , { NFA :: builder () . build (patterns) } # [doc = " A convenience method for returning a new Aho-Corasick contiguous NFA"] # [doc = " builder."] # [doc = ""] # [doc = " This usually permits one to just import the `NFA` type."] pub fn builder () -> Builder { Builder :: new () } } impl NFA { # [doc = " A sentinel state ID indicating that a search should stop once it has"] # [doc = " entered this state. When a search stops, it returns a match if one"] # [doc = " has been found, otherwise no match. A contiguous NFA always has an"] # [doc = " actual dead state at this ID."] const DEAD : StateID = StateID :: new_unchecked (0) ; # [doc = " Another sentinel state ID indicating that a search should move through"] # [doc = " current state's failure transition."] # [doc = ""] # [doc = " Note that unlike DEAD, this does not actually point to a valid state"] # [doc = " in a contiguous NFA. (noncontiguous::NFA::FAIL does point to a valid"] # [doc = " state.) Instead, this points to the position that is guaranteed to"] # [doc = " never be a valid state ID (by making sure it points to a place in the"] # [doc = " middle of the encoding of the DEAD state). Since we never need to"] # [doc = " actually look at the FAIL state itself, this works out."] # [doc = ""] # [doc = " By why do it this way? So that FAIL is a constant. I don't have any"] # [doc = " concrete evidence that this materially helps matters, but it's easy to"] # [doc = " do. The alternative would be making the FAIL ID point to the second"] # [doc = " state, which could be made a constant but is a little trickier to do."] # [doc = " The easiest path is to just make the FAIL state a runtime value, but"] # [doc = " since comparisons with FAIL occur in perf critical parts of the search,"] # [doc = " we want it to be as tight as possible and not waste any registers."] # [doc = ""] # [doc = " Very hand wavy... But the code complexity that results from this is"] # [doc = " very mild."] const FAIL : StateID = StateID :: new_unchecked (1) ; } unsafe impl Automaton for NFA { # [inline (always)] fn start_state (& self , anchored : Anchored) -> Result < StateID , MatchError > { match anchored { Anchored :: No => Ok (self . special . start_unanchored_id) , Anchored :: Yes => Ok (self . special . start_anchored_id) , } } # [inline (always)] fn next_state (& self , anchored : Anchored , mut sid : StateID , byte : u8 ,) -> StateID { let repr = & self . repr ; let class = self . byte_classes . get (byte) ; let u32tosid = StateID :: from_u32_unchecked ; loop { let o = sid . as_usize () ; let kind = repr [o] & 0xFF ; if kind == State :: KIND_DENSE { let next = u32tosid (repr [o + 2 + usize :: from (class)]) ; if next != NFA :: FAIL { return next ; } } else if kind == State :: KIND_ONE { if class == repr [o] . low_u16 () . high_u8 () { return u32tosid (repr [o + 2]) ; } } else { let trans_len = kind . as_usize () ; let classes_len = u32_len (trans_len) ; let trans_offset = o + 2 + classes_len ; for (i , & chunk) in repr [o + 2 ..] [.. classes_len] . iter () . enumerate () { let classes = chunk . to_ne_bytes () ; if classes [0] == class { return u32tosid (repr [trans_offset + i * 4]) ; } if classes [1] == class { return u32tosid (repr [trans_offset + i * 4 + 1]) ; } if classes [2] == class { return u32tosid (repr [trans_offset + i * 4 + 2]) ; } if classes [3] == class { return u32tosid (repr [trans_offset + i * 4 + 3]) ; } } } if anchored . is_anchored () { return NFA :: DEAD ; } sid = u32tosid (repr [o + 1]) ; } } # [inline (always)] fn is_special (& self , sid : StateID) -> bool { sid <= self . special . max_special_id } # [inline (always)] fn is_dead (& self , sid : StateID) -> bool { sid == NFA :: DEAD } # [inline (always)] fn is_match (& self , sid : StateID) -> bool { ! self . is_dead (sid) && sid <= self . special . max_match_id } # [inline (always)] fn is_start (& self , sid : StateID) -> bool { sid == self . special . start_unanchored_id || sid == self . special . start_anchored_id } # [inline (always)] fn match_kind (& self) -> MatchKind { self . match_kind } # [inline (always)] fn patterns_len (& self) -> usize { self . pattern_lens . len () } # [inline (always)] fn pattern_len (& self , pid : PatternID) -> usize { self . pattern_lens [pid] . as_usize () } # [inline (always)] fn min_pattern_len (& self) -> usize { self . min_pattern_len } # [inline (always)] fn max_pattern_len (& self) -> usize { self . max_pattern_len } # [inline (always)] fn match_len (& self , sid : StateID) -> usize { State :: match_len (self . alphabet_len , & self . repr [sid . as_usize () ..]) } # [inline (always)] fn match_pattern (& self , sid : StateID , index : usize) -> PatternID { State :: match_pattern (self . alphabet_len , & self . repr [sid . as_usize () ..] , index ,) } # [inline (always)] fn memory_usage (& self) -> usize { use core :: mem :: size_of ; (self . repr . len () * size_of :: < u32 > ()) + (self . pattern_lens . len () * size_of :: < SmallIndex > ()) + self . prefilter . as_ref () . map_or (0 , | p | p . memory_usage ()) } # [inline (always)] fn prefilter (& self) -> Option < & Prefilter > { self . prefilter . as_ref () } } impl core :: fmt :: Debug for NFA { fn fmt (& self , f : & mut core :: fmt :: Formatter) -> core :: fmt :: Result { use crate :: automaton :: fmt_state_indicator ; f . write_fmt (format_args ! ("contiguous::NFA(\n")) ? ; let mut sid = NFA :: DEAD ; loop { let raw = & self . repr [sid . as_usize () ..] ; if raw . is_empty () { break ; } let is_match = self . is_match (sid) ; let state = State :: read (self . alphabet_len , is_match , raw) ; fmt_state_indicator (f , self , sid) ? ; f . write_fmt (format_args ! ("{0:06}({1:06}): " , sid . as_usize () , state . fail . as_usize () ,) ,) ? ; state . fmt (f) ? ; f . write_fmt (format_args ! ("\n")) ? ; if self . is_match (sid) { f . write_fmt (format_args ! ("         matches: ")) ? ; for i in 0 .. state . match_len { let pid = State :: match_pattern (self . alphabet_len , raw , i) ; if i > 0 { f . write_fmt (format_args ! (", ")) ? ; } f . write_fmt (format_args ! ("{0}" , pid . as_usize ())) ? ; } f . write_fmt (format_args ! ("\n")) ? ; } if sid == NFA :: DEAD { f . write_fmt (format_args ! ("F {0:06}:\n" , NFA :: FAIL . as_usize ())) ? ; } let len = State :: len (self . alphabet_len , is_match , raw) ; sid = StateID :: new (sid . as_usize () . checked_add (len) . unwrap ()) . unwrap () ; } f . write_fmt (format_args ! ("match kind: {0:?}\n" , self . match_kind)) ? ; f . write_fmt (format_args ! ("prefilter: {0:?}\n" , self . prefilter . is_some ()) ,) ? ; f . write_fmt (format_args ! ("state length: {0:?}\n" , self . state_len)) ? ; f . write_fmt (format_args ! ("pattern length: {0:?}\n" , self . patterns_len ()) ,) ? ; f . write_fmt (format_args ! ("shortest pattern length: {0:?}\n" , self . min_pattern_len ,) ,) ? ; f . write_fmt (format_args ! ("longest pattern length: {0:?}\n" , self . max_pattern_len) ,) ? ; f . write_fmt (format_args ! ("alphabet length: {0:?}\n" , self . alphabet_len) ,) ? ; f . write_fmt (format_args ! ("byte classes: {0:?}\n" , self . byte_classes)) ? ; f . write_fmt (format_args ! ("memory usage: {0:?}\n" , self . memory_usage ())) ? ; f . write_fmt (format_args ! (")\n")) ? ; Ok (()) } } # [doc = " The \"in memory\" representation a single dense or sparse state."] # [doc = ""] # [doc = " A `State`'s in memory representation is not ever actually materialized"] # [doc = " during a search with a contiguous NFA. Doing so would be too slow. (Indeed,"] # [doc = " the only time a `State` is actually constructed is in `Debug` impls.)"] # [doc = " Instead, a `State` exposes a number of static methods for reading certain"] # [doc = " things from the raw binary encoding of the state."] struct State < 'a > { # [doc = " The state to transition to when 'class_to_next' yields a transition"] # [doc = " to the FAIL state."] fail : StateID , # [doc = " The number of pattern IDs in this state. For a non-match state, this is"] # [doc = " always zero. Otherwise it is always bigger than zero."] match_len : usize , # [doc = " The sparse or dense representation of the transitions for this state."] trans : StateTrans < 'a > , } # [automatically_derived] impl < 'a > :: core :: clone :: Clone for State < 'a > { # [inline] fn clone (& self) -> State < 'a > { State { fail : :: core :: clone :: Clone :: clone (& self . fail) , match_len : :: core :: clone :: Clone :: clone (& self . match_len) , trans : :: core :: clone :: Clone :: clone (& self . trans) , } } } # [doc = " The underlying representation of sparse or dense transitions for a state."] # [doc = ""] # [doc = " Note that like `State`, we don't typically construct values of this type"] # [doc = " during a search since we don't always need all values and thus would"] # [doc = " represent a lot of wasteful work."] enum StateTrans < 'a > { # [doc = " A sparse representation of transitions for a state, where only non-FAIL"] # [doc = " transitions are explicitly represented."] Sparse { classes : & 'a [u32] , # [doc = " The transitions for this state, where each transition is packed"] # [doc = " into a u32. The low 8 bits correspond to the byte class for the"] # [doc = " transition, and the high 24 bits correspond to the next state ID."] # [doc = ""] # [doc = " This packing is why the max state ID allowed for a contiguous"] # [doc = " NFA is 2^24-1."] nexts : & 'a [u32] , } , # [doc = " A \"one transition\" state that is never a match state."] # [doc = ""] # [doc = " These are by far the most common state, so we use a specialized and"] # [doc = " very compact representation for them."] One { # [doc = " The element of this NFA's alphabet that this transition is"] # [doc = " defined for."] class : u8 , # [doc = " The state this should transition to if the current symbol is"] # [doc = " equal to 'class'."] next : u32 , } , # [doc = " A dense representation of transitions for a state, where all"] # [doc = " transitions are explicitly represented, including transitions to the"] # [doc = " FAIL state."] Dense { # [doc = " A dense set of transitions to other states. The transitions may"] # [doc = " point to a FAIL state, in which case, the search should try the"] # [doc = " same transition lookup at 'fail'."] # [doc = ""] # [doc = " Note that this is indexed by byte equivalence classes and not"] # [doc = " byte values. That means 'class_to_next[byte]' is wrong and"] # [doc = " 'class_to_next[classes.get(byte)]' is correct. The number of"] # [doc = " transitions is always equivalent to 'classes.alphabet_len()'."] class_to_next : & 'a [u32] , } , } # [automatically_derived] impl < 'a > :: core :: clone :: Clone for StateTrans < 'a > { # [inline] fn clone (& self) -> StateTrans < 'a > { match self { StateTrans :: Sparse { classes : __self_0 , nexts : __self_1 } => { StateTrans :: Sparse { classes : :: core :: clone :: Clone :: clone (__self_0) , nexts : :: core :: clone :: Clone :: clone (__self_1) , } } StateTrans :: One { class : __self_0 , next : __self_1 } => { StateTrans :: One { class : :: core :: clone :: Clone :: clone (__self_0) , next : :: core :: clone :: Clone :: clone (__self_1) , } } StateTrans :: Dense { class_to_next : __self_0 } => { StateTrans :: Dense { class_to_next : :: core :: clone :: Clone :: clone (__self_0) , } } } } } impl < 'a > State < 'a > { # [doc = " The offset of where the \"kind\" of a state is stored. If it isn't one"] # [doc = " of the sentinel values below, then it's a sparse state and the kind"] # [doc = " corresponds to the number of transitions in the state."] const KIND : usize = 0 ; # [doc = " A sentinel value indicating that the state uses a dense representation."] const KIND_DENSE : u32 = 0xFF ; # [doc = " A sentinel value indicating that the state uses a special \"one"] # [doc = " transition\" encoding. In practice, non-match states with one transition"] # [doc = " make up the overwhelming majority of all states in any given"] # [doc = " Aho-Corasick automaton, so we can specialize them using a very compact"] # [doc = " representation."] const KIND_ONE : u32 = 0xFE ; # [doc = " The maximum number of transitions to encode as a sparse state. Usually"] # [doc = " states with a lot of transitions are either very rare, or occur near"] # [doc = " the start state. In the latter case, they are probably dense already"] # [doc = " anyway. In the former case, making them dense is fine because they're"] # [doc = " rare."] # [doc = ""] # [doc = " This needs to be small enough to permit each of the sentinel values for"] # [doc = " 'KIND' above. Namely, a sparse state embeds the number of transitions"] # [doc = " into the 'KIND'. Basically, \"sparse\" is a state kind too, but it's the"] # [doc = " \"else\" branch."] # [doc = ""] # [doc = " N.B. There isn't anything particularly magical about 127 here. I"] # [doc = " just picked it because I figured any sparse state with this many"] # [doc = " transitions is going to be exceptionally rare, and if it did have this"] # [doc = " many transitions, then it would be quite slow to do a linear scan on"] # [doc = " the transitions during a search anyway."] const MAX_SPARSE_TRANSITIONS : usize = 127 ; # [doc = " Remap state IDs in-place."] # [doc = ""] # [doc = " `state` should be the the raw binary encoding of a state. (The start"] # [doc = " of the slice must correspond to the start of the state, but the slice"] # [doc = " may extend past the end of the encoding of the state.)"] fn remap (alphabet_len : usize , old_to_new : & [StateID] , state : & mut [u32] ,) -> Result < () , BuildError > { let kind = State :: kind (state) ; if kind == State :: KIND_DENSE { state [1] = old_to_new [state [1] . as_usize ()] . as_u32 () ; for next in state [2 ..] [.. alphabet_len] . iter_mut () { * next = old_to_new [next . as_usize ()] . as_u32 () ; } } else if kind == State :: KIND_ONE { state [1] = old_to_new [state [1] . as_usize ()] . as_u32 () ; state [2] = old_to_new [state [2] . as_usize ()] . as_u32 () ; } else { let trans_len = State :: sparse_trans_len (state) ; let classes_len = u32_len (trans_len) ; state [1] = old_to_new [state [1] . as_usize ()] . as_u32 () ; for next in state [2 + classes_len ..] [.. trans_len] . iter_mut () { * next = old_to_new [next . as_usize ()] . as_u32 () ; } } Ok (()) } # [doc = " Returns the length, in number of u32s, of this state."] # [doc = ""] # [doc = " This is useful for reading states consecutively, e.g., in the Debug"] # [doc = " impl without needing to store a separate map from state index to state"] # [doc = " identifier."] # [doc = ""] # [doc = " `state` should be the the raw binary encoding of a state. (The start"] # [doc = " of the slice must correspond to the start of the state, but the slice"] # [doc = " may extend past the end of the encoding of the state.)"] fn len (alphabet_len : usize , is_match : bool , state : & [u32]) -> usize { let kind_len = 1 ; let fail_len = 1 ; let kind = State :: kind (state) ; let (classes_len , trans_len) = if kind == State :: KIND_DENSE { (0 , alphabet_len) } else if kind == State :: KIND_ONE { (0 , 1) } else { let trans_len = State :: sparse_trans_len (state) ; let classes_len = u32_len (trans_len) ; (classes_len , trans_len) } ; let match_len = if ! is_match { 0 } else if State :: match_len (alphabet_len , state) == 1 { 1 } else { 1 + State :: match_len (alphabet_len , state) } ; kind_len + fail_len + classes_len + trans_len + match_len } # [doc = " Returns the kind of this state."] # [doc = ""] # [doc = " This only includes the low byte."] # [inline (always)] fn kind (state : & [u32]) -> u32 { state [State :: KIND] & 0xFF } # [doc = " Get the number of sparse transitions in this state. This can never"] # [doc = " be more than State::MAX_SPARSE_TRANSITIONS, as all states with more"] # [doc = " transitions are encoded as dense states."] # [doc = ""] # [doc = " `state` should be the the raw binary encoding of a sparse state. (The"] # [doc = " start of the slice must correspond to the start of the state, but the"] # [doc = " slice may extend past the end of the encoding of the state.) If this"] # [doc = " isn't a sparse state, then the return value is unspecified."] # [doc = ""] # [doc = " Do note that this is only legal to call on a sparse state. So for"] # [doc = " example, \"one transition\" state is not a sparse state, so it would not"] # [doc = " be legal to call this method on such a state."] # [inline (always)] fn sparse_trans_len (state : & [u32]) -> usize { (state [State :: KIND] & 0xFF) . as_usize () } # [doc = " Returns the total number of matching pattern IDs in this state. Calling"] # [doc = " this on a state that isn't a match results in unspecified behavior."] # [doc = " Thus, the returned number is never 0 for all correct calls."] # [doc = ""] # [doc = " `state` should be the the raw binary encoding of a state. (The start"] # [doc = " of the slice must correspond to the start of the state, but the slice"] # [doc = " may extend past the end of the encoding of the state.)"] # [inline (always)] fn match_len (alphabet_len : usize , state : & [u32]) -> usize { let packed = if State :: kind (state) == State :: KIND_DENSE { let start = 2 + alphabet_len ; state [start] . as_usize () } else { let trans_len = State :: sparse_trans_len (state) ; let classes_len = u32_len (trans_len) ; let start = 2 + classes_len + trans_len ; state [start] . as_usize () } ; if packed & (1 << 31) == 0 { packed } else { 1 } } # [doc = " Returns the pattern ID corresponding to the given index for the state"] # [doc = " given. The `index` provided must be less than the number of pattern IDs"] # [doc = " in this state."] # [doc = ""] # [doc = " `state` should be the the raw binary encoding of a state. (The start of"] # [doc = " the slice must correspond to the start of the state, but the slice may"] # [doc = " extend past the end of the encoding of the state.)"] # [doc = ""] # [doc = " If the given state is not a match state or if the index is out of"] # [doc = " bounds, then this has unspecified behavior."] # [inline (always)] fn match_pattern (alphabet_len : usize , state : & [u32] , index : usize ,) -> PatternID { let start = if State :: kind (state) == State :: KIND_DENSE { 2 + alphabet_len } else { let trans_len = State :: sparse_trans_len (state) ; let classes_len = u32_len (trans_len) ; 2 + classes_len + trans_len } ; let packed = state [start] ; let pid = if packed & (1 << 31) == 0 { state [start + 1 + index] } else { match (& 0 , & index) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: None ,) ; } } } ; packed & ! (1 << 31) } ; PatternID :: from_u32_unchecked (pid) } # [doc = " Read a state's binary encoding to its in-memory representation."] # [doc = ""] # [doc = " `alphabet_len` should be the total number of transitions defined for"] # [doc = " dense states."] # [doc = ""] # [doc = " `is_match` should be true if this state is a match state and false"] # [doc = " otherwise."] # [doc = ""] # [doc = " `state` should be the the raw binary encoding of a state. (The start"] # [doc = " of the slice must correspond to the start of the state, but the slice"] # [doc = " may extend past the end of the encoding of the state.)"] fn read (alphabet_len : usize , is_match : bool , state : & 'a [u32]) -> State < 'a > { let kind = State :: kind (state) ; let match_len = if ! is_match { 0 } else { State :: match_len (alphabet_len , state) } ; let (trans , fail) = if kind == State :: KIND_DENSE { let fail = StateID :: from_u32_unchecked (state [1]) ; let class_to_next = & state [2 ..] [.. alphabet_len] ; (StateTrans :: Dense { class_to_next } , fail) } else if kind == State :: KIND_ONE { let fail = StateID :: from_u32_unchecked (state [1]) ; let class = state [State :: KIND] . low_u16 () . high_u8 () ; let next = state [2] ; (StateTrans :: One { class , next } , fail) } else { let fail = StateID :: from_u32_unchecked (state [1]) ; let trans_len = State :: sparse_trans_len (state) ; let classes_len = u32_len (trans_len) ; let classes = & state [2 ..] [.. classes_len] ; let nexts = & state [2 + classes_len ..] [.. trans_len] ; (StateTrans :: Sparse { classes , nexts , } , fail ,) } ; State { fail , match_len , trans } } # [doc = " Encode the \"old\" state from a noncontiguous NFA to its binary"] # [doc = " representation to the given `dst` slice. `classes` should be the byte"] # [doc = " classes computed for the noncontiguous NFA that the given state came"] # [doc = " from."] # [doc = ""] # [doc = " This returns an error if `dst` became so big that `StateID`s can no"] # [doc = " longer be created for new states. Otherwise, it returns the state ID of"] # [doc = " the new state created."] # [doc = ""] # [doc = " When `force_dense` is true, then the encoded state will always use a"] # [doc = " dense format. Otherwise, the choice between dense and sparse will be"] # [doc = " automatically chosen based on the old state."] fn write (nnfa : & noncontiguous :: NFA , oldsid : StateID , old : & noncontiguous :: State , classes : & ByteClasses , dst : & mut Vec < u32 > , force_dense : bool ,) -> Result < StateID , BuildError > { let sid = StateID :: new (dst . len ()) . map_err (| e | { BuildError :: state_id_overflow (StateID :: MAX . as_u64 () , e . attempted () ,) }) ? ; let old_len = nnfa . iter_trans (oldsid) . count () ; let kind = if force_dense || old_len > State :: MAX_SPARSE_TRANSITIONS { State :: KIND_DENSE } else if old_len == 1 && ! old . is_match () { State :: KIND_ONE } else { u32 :: try_from (old_len) . unwrap () } ; if kind == State :: KIND_DENSE { dst . push (kind) ; dst . push (old . fail () . as_u32 ()) ; State :: write_dense_trans (nnfa , oldsid , classes , dst) ? ; } else if kind == State :: KIND_ONE { let t = nnfa . iter_trans (oldsid) . next () . unwrap () ; let class = u32 :: from (classes . get (t . byte ())) ; dst . push (kind | (class << 8)) ; dst . push (old . fail () . as_u32 ()) ; dst . push (t . next () . as_u32 ()) ; } else { dst . push (kind) ; dst . push (old . fail () . as_u32 ()) ; State :: write_sparse_trans (nnfa , oldsid , classes , dst) ? ; } if old . is_match () { let matches_len = nnfa . iter_matches (oldsid) . count () ; if matches_len == 1 { let pid = nnfa . iter_matches (oldsid) . next () . unwrap () . as_u32 () ; match (& 0 , & (pid & (1 << 31))) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: None ,) ; } } } ; dst . push ((1 << 31) | pid) ; } else { match (& 0 , & (matches_len & (1 << 31))) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: None ,) ; } } } ; dst . push (matches_len . as_u32 ()) ; dst . extend (nnfa . iter_matches (oldsid) . map (| pid | pid . as_u32 ())) ; } } Ok (sid) } # [doc = " Encode the \"old\" state transitions from a noncontiguous NFA to its"] # [doc = " binary sparse representation to the given `dst` slice. `classes` should"] # [doc = " be the byte classes computed for the noncontiguous NFA that the given"] # [doc = " state came from."] # [doc = ""] # [doc = " This returns an error if `dst` became so big that `StateID`s can no"] # [doc = " longer be created for new states."] fn write_sparse_trans (nnfa : & noncontiguous :: NFA , oldsid : StateID , classes : & ByteClasses , dst : & mut Vec < u32 > ,) -> Result < () , BuildError > { let (mut chunk , mut len) = ([0 ; 4] , 0) ; for t in nnfa . iter_trans (oldsid) { chunk [len] = classes . get (t . byte ()) ; len += 1 ; if len == 4 { dst . push (u32 :: from_ne_bytes (chunk)) ; chunk = [0 ; 4] ; len = 0 ; } } if len > 0 { let repeat = chunk [len - 1] ; while len < 4 { chunk [len] = repeat ; len += 1 ; } dst . push (u32 :: from_ne_bytes (chunk)) ; } for t in nnfa . iter_trans (oldsid) { dst . push (t . next () . as_u32 ()) ; } Ok (()) } # [doc = " Encode the \"old\" state transitions from a noncontiguous NFA to its"] # [doc = " binary dense representation to the given `dst` slice. `classes` should"] # [doc = " be the byte classes computed for the noncontiguous NFA that the given"] # [doc = " state came from."] # [doc = ""] # [doc = " This returns an error if `dst` became so big that `StateID`s can no"] # [doc = " longer be created for new states."] fn write_dense_trans (nnfa : & noncontiguous :: NFA , oldsid : StateID , classes : & ByteClasses , dst : & mut Vec < u32 > ,) -> Result < () , BuildError > { let start = dst . len () ; dst . extend (core :: iter :: repeat (noncontiguous :: NFA :: FAIL . as_u32 ()) . take (classes . alphabet_len ()) ,) ; if ! (start < dst . len ()) { { :: core :: panicking :: panic_fmt (format_args ! ("equivalence classes are never empty") ,) ; } } for t in nnfa . iter_trans (oldsid) { dst [start + usize :: from (classes . get (t . byte ()))] = t . next () . as_u32 () ; } Ok (()) } # [doc = " Return an iterator over every explicitly defined transition in this"] # [doc = " state."] fn transitions (& self) -> impl Iterator < Item = (u8 , StateID) > + '_ { let mut i = 0 ; core :: iter :: from_fn (move | | match self . trans { StateTrans :: Sparse { classes , nexts } => { if i >= nexts . len () { return None ; } let chunk = classes [i / 4] ; let class = chunk . to_ne_bytes () [i % 4] ; let next = StateID :: from_u32_unchecked (nexts [i]) ; i += 1 ; Some ((class , next)) } StateTrans :: One { class , next } => { if i == 0 { i += 1 ; Some ((class , StateID :: from_u32_unchecked (next))) } else { None } } StateTrans :: Dense { class_to_next } => { if i >= class_to_next . len () { return None ; } let class = i . as_u8 () ; let next = StateID :: from_u32_unchecked (class_to_next [i]) ; i += 1 ; Some ((class , next)) } }) } } impl < 'a > core :: fmt :: Debug for State < 'a > { fn fmt (& self , f : & mut core :: fmt :: Formatter < '_ >) -> core :: fmt :: Result { use crate :: { automaton :: sparse_transitions , util :: debug :: DebugByte } ; let it = sparse_transitions (self . transitions ()) . filter (| & (_ , _ , sid) | sid != NFA :: FAIL) . enumerate () ; for (i , (start , end , sid)) in it { if i > 0 { f . write_fmt (format_args ! (", ")) ? ; } if start == end { f . write_fmt (format_args ! ("{0:?} => {1:?}" , DebugByte (start) , sid . as_usize () ,) ,) ? ; } else { f . write_fmt (format_args ! ("{0:?}-{1:?} => {2:?}" , DebugByte (start) , DebugByte (end) , sid . as_usize () ,) ,) ? ; } } Ok (()) } } # [doc = " A builder for configuring an Aho-Corasick contiguous NFA."] # [doc = ""] # [doc = " This builder has a subset of the options available to a"] # [doc = " [`AhoCorasickBuilder`](crate::AhoCorasickBuilder). Of the shared options,"] # [doc = " their behavior is identical."] pub struct Builder { noncontiguous : noncontiguous :: Builder , dense_depth : usize , byte_classes : bool , } # [automatically_derived] impl :: core :: clone :: Clone for Builder { # [inline] fn clone (& self) -> Builder { Builder { noncontiguous : :: core :: clone :: Clone :: clone (& self . noncontiguous) , dense_depth : :: core :: clone :: Clone :: clone (& self . dense_depth) , byte_classes : :: core :: clone :: Clone :: clone (& self . byte_classes) , } } } # [automatically_derived] impl :: core :: fmt :: Debug for Builder { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field3_finish (f , "Builder" , "noncontiguous" , & self . noncontiguous , "dense_depth" , & self . dense_depth , "byte_classes" , & & self . byte_classes ,) } } impl Default for Builder { fn default () -> Builder { Builder { noncontiguous : noncontiguous :: Builder :: new () , dense_depth : 2 , byte_classes : true , } } } impl Builder { # [doc = " Create a new builder for configuring an Aho-Corasick contiguous NFA."] pub fn new () -> Builder { Builder :: default () } # [doc = " Build an Aho-Corasick contiguous NFA from the given iterator of"] # [doc = " patterns."] # [doc = ""] # [doc = " A builder may be reused to create more NFAs."] pub fn build < I , P > (& self , patterns : I) -> Result < NFA , BuildError > where I : IntoIterator < Item = P > , P : AsRef < [u8] > , { let nnfa = self . noncontiguous . build (patterns) ? ; self . build_from_noncontiguous (& nnfa) } # [doc = " Build an Aho-Corasick contiguous NFA from the given noncontiguous NFA."] # [doc = ""] # [doc = " Note that when this method is used, only the `dense_depth` and"] # [doc = " `byte_classes` settings on this builder are respected. The other"] # [doc = " settings only apply to the initial construction of the Aho-Corasick"] # [doc = " automaton. Since using this method requires that initial construction"] # [doc = " has already completed, all settings impacting only initial construction"] # [doc = " are no longer relevant."] pub fn build_from_noncontiguous (& self , nnfa : & noncontiguous :: NFA ,) -> Result < NFA , BuildError > { let byte_classes = if self . byte_classes { nnfa . byte_classes () . clone () } else { ByteClasses :: singletons () } ; let mut index_to_state_id = :: alloc :: vec :: from_elem (NFA :: DEAD , nnfa . states () . len () ,) ; let mut nfa = NFA { repr : :: alloc :: vec :: Vec :: new () , pattern_lens : nnfa . pattern_lens_raw () . to_vec () , state_len : nnfa . states () . len () , prefilter : nnfa . prefilter () . map (| p | p . clone ()) , match_kind : nnfa . match_kind () , alphabet_len : byte_classes . alphabet_len () , byte_classes , min_pattern_len : nnfa . min_pattern_len () , max_pattern_len : nnfa . max_pattern_len () , special : Special :: zero () , } ; for (oldsid , state) in nnfa . states () . iter () . with_state_ids () { if oldsid == noncontiguous :: NFA :: FAIL { index_to_state_id [oldsid] = NFA :: FAIL ; continue ; } let force_dense = state . depth () . as_usize () < self . dense_depth ; let newsid = State :: write (nnfa , oldsid , state , & nfa . byte_classes , & mut nfa . repr , force_dense ,) ? ; index_to_state_id [oldsid] = newsid ; } for & newsid in index_to_state_id . iter () { if newsid == NFA :: FAIL { continue ; } let state = & mut nfa . repr [newsid . as_usize () ..] ; State :: remap (nfa . alphabet_len , & index_to_state_id , state) ? ; } let remap = & index_to_state_id ; let old = nnfa . special () ; let new = & mut nfa . special ; new . max_special_id = remap [old . max_special_id] ; new . max_match_id = remap [old . max_match_id] ; new . start_unanchored_id = remap [old . start_unanchored_id] ; new . start_anchored_id = remap [old . start_anchored_id] ; nfa . repr . shrink_to_fit () ; nfa . pattern_lens . shrink_to_fit () ; Ok (nfa) } # [doc = " Set the desired match semantics."] # [doc = ""] # [doc = " This only applies when using [`Builder::build`] and not"] # [doc = " [`Builder::build_from_noncontiguous`]."] # [doc = ""] # [doc = " See"] # [doc = " [`AhoCorasickBuilder::match_kind`](crate::AhoCorasickBuilder::match_kind)"] # [doc = " for more documentation and examples."] pub fn match_kind (& mut self , kind : MatchKind) -> & mut Builder { self . noncontiguous . match_kind (kind) ; self } # [doc = " Enable ASCII-aware case insensitive matching."] # [doc = ""] # [doc = " This only applies when using [`Builder::build`] and not"] # [doc = " [`Builder::build_from_noncontiguous`]."] # [doc = ""] # [doc = " See"] # [doc = " [`AhoCorasickBuilder::ascii_case_insensitive`](crate::AhoCorasickBuilder::ascii_case_insensitive)"] # [doc = " for more documentation and examples."] pub fn ascii_case_insensitive (& mut self , yes : bool) -> & mut Builder { self . noncontiguous . ascii_case_insensitive (yes) ; self } # [doc = " Enable heuristic prefilter optimizations."] # [doc = ""] # [doc = " This only applies when using [`Builder::build`] and not"] # [doc = " [`Builder::build_from_noncontiguous`]."] # [doc = ""] # [doc = " See"] # [doc = " [`AhoCorasickBuilder::prefilter`](crate::AhoCorasickBuilder::prefilter)"] # [doc = " for more documentation and examples."] pub fn prefilter (& mut self , yes : bool) -> & mut Builder { self . noncontiguous . prefilter (yes) ; self } # [doc = " Set the limit on how many states use a dense representation for their"] # [doc = " transitions. Other states will generally use a sparse representation."] # [doc = ""] # [doc = " See"] # [doc = " [`AhoCorasickBuilder::dense_depth`](crate::AhoCorasickBuilder::dense_depth)"] # [doc = " for more documentation and examples."] pub fn dense_depth (& mut self , depth : usize) -> & mut Builder { self . dense_depth = depth ; self } # [doc = " A debug setting for whether to attempt to shrink the size of the"] # [doc = " automaton's alphabet or not."] # [doc = ""] # [doc = " This should never be enabled unless you're debugging an automaton."] # [doc = " Namely, disabling byte classes makes transitions easier to reason"] # [doc = " about, since they use the actual bytes instead of equivalence classes."] # [doc = " Disabling this confers no performance benefit at search time."] # [doc = ""] # [doc = " See"] # [doc = " [`AhoCorasickBuilder::byte_classes`](crate::AhoCorasickBuilder::byte_classes)"] # [doc = " for more documentation and examples."] pub fn byte_classes (& mut self , yes : bool) -> & mut Builder { self . byte_classes = yes ; self } } # [doc = " Computes the number of u32 values needed to represent one byte per the"] # [doc = " number of transitions given."] fn u32_len (ntrans : usize) -> usize { if ntrans % 4 == 0 { ntrans >> 2 } else { (ntrans >> 2) + 1 } } } pub mod noncontiguous { # ! [doc = "\nProvides a noncontiguous NFA implementation of Aho-Corasick.\n\nThis is a low-level API that generally only needs to be used in niche\ncircumstances. When possible, prefer using [`AhoCorasick`](crate::AhoCorasick)\ninstead of a noncontiguous NFA directly. Using an `NFA` directly is typically\nonly necessary when one needs access to the [`Automaton`] trait implementation.\n"] use alloc :: { collections :: { BTreeSet , VecDeque } , vec , vec :: Vec , } ; use crate :: { automaton :: Automaton , util :: { alphabet :: { ByteClassSet , ByteClasses } , error :: { BuildError , MatchError } , prefilter :: { self , opposite_ascii_case , Prefilter } , primitives :: { IteratorIndexExt , PatternID , SmallIndex , StateID } , remapper :: Remapper , search :: { Anchored , MatchKind } , special :: Special , } , } ; # [doc = " A noncontiguous NFA implementation of Aho-Corasick."] # [doc = ""] # [doc = " When possible, prefer using [`AhoCorasick`](crate::AhoCorasick) instead of"] # [doc = " this type directly. Using an `NFA` directly is typically only necessary"] # [doc = " when one needs access to the [`Automaton`] trait implementation."] # [doc = ""] # [doc = " This NFA represents the \"core\" implementation of Aho-Corasick in this"] # [doc = " crate. Namely, constructing this NFA involving building a trie and then"] # [doc = " filling in the failure transitions between states, similar to what is"] # [doc = " described in any standard textbook description of Aho-Corasick."] # [doc = ""] # [doc = " In order to minimize heap usage and to avoid additional construction costs,"] # [doc = " this implementation represents the transitions of all states as distinct"] # [doc = " sparse memory allocations. This is where it gets its name from. That is,"] # [doc = " this NFA has no contiguous memory allocation for its transition table. Each"] # [doc = " state gets its own allocation."] # [doc = ""] # [doc = " While the sparse representation keeps memory usage to somewhat reasonable"] # [doc = " levels, it is still quite large and also results in somewhat mediocre"] # [doc = " search performance. For this reason, it is almost always a good idea to"] # [doc = " use a [`contiguous::NFA`](crate::nfa::contiguous::NFA) instead. It is"] # [doc = " marginally slower to build, but has higher throughput and can sometimes use"] # [doc = " an order of magnitude less memory. The main reason to use a noncontiguous"] # [doc = " NFA is when you need the fastest possible construction time, or when a"] # [doc = " contiguous NFA does not have the desired capacity. (The total number of NFA"] # [doc = " states it can have is fewer than a noncontiguous NFA.)"] # [doc = ""] # [doc = " # Example"] # [doc = ""] # [doc = " This example shows how to build an `NFA` directly and use it to execute"] # [doc = " [`Automaton::try_find`]:"] # [doc = ""] # [doc = " ```"] # [doc = " use aho_corasick::{"] # [doc = "     automaton::Automaton,"] # [doc = "     nfa::noncontiguous::NFA,"] # [doc = "     Input, Match,"] # [doc = " };"] # [doc = ""] # [doc = " let patterns = &[\"b\", \"abc\", \"abcd\"];"] # [doc = " let haystack = \"abcd\";"] # [doc = ""] # [doc = " let nfa = NFA::new(patterns).unwrap();"] # [doc = " assert_eq!("] # [doc = "     Some(Match::must(0, 1..2)),"] # [doc = "     nfa.try_find(&Input::new(haystack))?,"] # [doc = " );"] # [doc = " # Ok::<(), Box<dyn std::error::Error>>(())"] # [doc = " ```"] # [doc = ""] # [doc = " It is also possible to implement your own version of `try_find`. See the"] # [doc = " [`Automaton`] documentation for an example."] pub struct NFA { # [doc = " The match semantics built into this NFA."] match_kind : MatchKind , # [doc = " A set of states. Each state defines its own transitions, a fail"] # [doc = " transition and a set of indices corresponding to matches."] # [doc = ""] # [doc = " The first state is always the fail state, which is used only as a"] # [doc = " sentinel. Namely, in the final NFA, no transition into the fail state"] # [doc = " exists. (Well, they do, but they aren't followed. Instead, the state's"] # [doc = " failure transition is followed.)"] # [doc = ""] # [doc = " The second state (index 1) is always the dead state. Dead states are"] # [doc = " in every automaton, but only used when leftmost-{first,longest} match"] # [doc = " semantics are enabled. Specifically, they instruct search to stop"] # [doc = " at specific points in order to report the correct match location. In"] # [doc = " the standard Aho-Corasick construction, there are no transitions to"] # [doc = " the dead state."] # [doc = ""] # [doc = " The third state (index 2) is generally intended to be the starting or"] # [doc = " \"root\" state."] states : Vec < State > , # [doc = " Transitions stored in a sparse representation via a linked list."] # [doc = ""] # [doc = " Each transition contains three pieces of information: the byte it"] # [doc = " is defined for, the state it transitions to and a link to the next"] # [doc = " transition in the same state (or `StateID::ZERO` if it is the last"] # [doc = " transition)."] # [doc = ""] # [doc = " The first transition for each state is determined by `State::sparse`."] # [doc = ""] # [doc = " Note that this contains a complete set of all transitions in this NFA,"] # [doc = " including states that have a dense representation for transitions."] # [doc = " (Adding dense transitions for a state doesn't remove its sparse"] # [doc = " transitions, since deleting transitions from this particular sparse"] # [doc = " representation would be fairly expensive.)"] sparse : Vec < Transition > , # [doc = " Transitions stored in a dense representation."] # [doc = ""] # [doc = " A state has a row in this table if and only if `State::dense` is"] # [doc = " not equal to `StateID::ZERO`. When not zero, there are precisely"] # [doc = " `NFA::byte_classes::alphabet_len()` entries beginning at `State::dense`"] # [doc = " in this table."] # [doc = ""] # [doc = " Generally a very small minority of states have a dense representation"] # [doc = " since it uses so much memory."] dense : Vec < StateID > , # [doc = " Matches stored in linked list for each state."] # [doc = ""] # [doc = " Like sparse transitions, each match has a link to the next match in the"] # [doc = " state."] # [doc = ""] # [doc = " The first match for each state is determined by `State::matches`."] matches : Vec < Match > , # [doc = " The length, in bytes, of each pattern in this NFA. This slice is"] # [doc = " indexed by `PatternID`."] # [doc = ""] # [doc = " The number of entries in this vector corresponds to the total number of"] # [doc = " patterns in this automaton."] pattern_lens : Vec < SmallIndex > , # [doc = " A prefilter for quickly skipping to candidate matches, if pertinent."] prefilter : Option < Prefilter > , # [doc = " A set of equivalence classes in terms of bytes. We compute this while"] # [doc = " building the NFA, but don't use it in the NFA's states. Instead, we"] # [doc = " use this for building the DFA. We store it on the NFA since it's easy"] # [doc = " to compute while visiting the patterns."] byte_classes : ByteClasses , # [doc = " The length, in bytes, of the shortest pattern in this automaton. This"] # [doc = " information is useful for detecting whether an automaton matches the"] # [doc = " empty string or not."] min_pattern_len : usize , # [doc = " The length, in bytes, of the longest pattern in this automaton. This"] # [doc = " information is useful for keeping correct buffer sizes when searching"] # [doc = " on streams."] max_pattern_len : usize , # [doc = " The information required to deduce which states are \"special\" in this"] # [doc = " NFA."] # [doc = ""] # [doc = " Since the DEAD and FAIL states are always the first two states and"] # [doc = " there are only ever two start states (which follow all of the match"] # [doc = " states), it follows that we can determine whether a state is a fail,"] # [doc = " dead, match or start with just a few comparisons on the ID itself:"] # [doc = ""] # [doc = "    is_dead(sid): sid == NFA::DEAD"] # [doc = "    is_fail(sid): sid == NFA::FAIL"] # [doc = "   is_match(sid): NFA::FAIL < sid && sid <= max_match_id"] # [doc = "   is_start(sid): sid == start_unanchored_id || sid == start_anchored_id"] # [doc = ""] # [doc = " Note that this only applies to the NFA after it has been constructed."] # [doc = " During construction, the start states are the first ones added and the"] # [doc = " match states are inter-leaved with non-match states. Once all of the"] # [doc = " states have been added, the states are shuffled such that the above"] # [doc = " predicates hold."] special : Special , } # [automatically_derived] impl :: core :: clone :: Clone for NFA { # [inline] fn clone (& self) -> NFA { NFA { match_kind : :: core :: clone :: Clone :: clone (& self . match_kind) , states : :: core :: clone :: Clone :: clone (& self . states) , sparse : :: core :: clone :: Clone :: clone (& self . sparse) , dense : :: core :: clone :: Clone :: clone (& self . dense) , matches : :: core :: clone :: Clone :: clone (& self . matches) , pattern_lens : :: core :: clone :: Clone :: clone (& self . pattern_lens) , prefilter : :: core :: clone :: Clone :: clone (& self . prefilter) , byte_classes : :: core :: clone :: Clone :: clone (& self . byte_classes) , min_pattern_len : :: core :: clone :: Clone :: clone (& self . min_pattern_len) , max_pattern_len : :: core :: clone :: Clone :: clone (& self . max_pattern_len) , special : :: core :: clone :: Clone :: clone (& self . special) , } } } impl NFA { # [doc = " Create a new Aho-Corasick noncontiguous NFA using the default"] # [doc = " configuration."] # [doc = ""] # [doc = " Use a [`Builder`] if you want to change the configuration."] pub fn new < I , P > (patterns : I) -> Result < NFA , BuildError > where I : IntoIterator < Item = P > , P : AsRef < [u8] > , { NFA :: builder () . build (patterns) } # [doc = " A convenience method for returning a new Aho-Corasick noncontiguous NFA"] # [doc = " builder."] # [doc = ""] # [doc = " This usually permits one to just import the `NFA` type."] pub fn builder () -> Builder { Builder :: new () } } impl NFA { # [doc = " The DEAD state is a sentinel state like the FAIL state. The DEAD state"] # [doc = " instructs any search to stop and return any currently recorded match,"] # [doc = " or no match otherwise. Generally speaking, it is impossible for an"] # [doc = " unanchored standard search to enter a DEAD state. But an anchored"] # [doc = " search can, and so to can a leftmost search."] # [doc = ""] # [doc = " We put DEAD before FAIL so that DEAD is always 0. We repeat this"] # [doc = " decision across the other Aho-Corasicm automata, so that DEAD"] # [doc = " states there are always 0 too. It's not that we need all of the"] # [doc = " implementations to agree, but rather, the contiguous NFA and the DFA"] # [doc = " use a sort of \"premultiplied\" state identifier where the only state"] # [doc = " whose ID is always known and constant is the first state. Subsequent"] # [doc = " state IDs depend on how much space has already been used in the"] # [doc = " transition table."] pub (crate) const DEAD : StateID = StateID :: new_unchecked (0) ; # [doc = " The FAIL state mostly just corresponds to the ID of any transition on a"] # [doc = " state that isn't explicitly defined. When one transitions into the FAIL"] # [doc = " state, one must follow the previous state's failure transition before"] # [doc = " doing the next state lookup. In this way, FAIL is more of a sentinel"] # [doc = " than a state that one actually transitions into. In particular, it is"] # [doc = " never exposed in the `Automaton` interface."] pub (crate) const FAIL : StateID = StateID :: new_unchecked (1) ; # [doc = " Returns the equivalence classes of bytes found while constructing"] # [doc = " this NFA."] # [doc = ""] # [doc = " Note that the NFA doesn't actually make use of these equivalence"] # [doc = " classes. Instead, these are useful for building the DFA when desired."] pub (crate) fn byte_classes (& self) -> & ByteClasses { & self . byte_classes } # [doc = " Returns a slice containing the length of each pattern in this searcher."] # [doc = " It is indexed by `PatternID` and has length `NFA::patterns_len`."] # [doc = ""] # [doc = " This is exposed for convenience when building a contiguous NFA. But it"] # [doc = " can be reconstructed from the `Automaton` API if necessary."] pub (crate) fn pattern_lens_raw (& self) -> & [SmallIndex] { & self . pattern_lens } # [doc = " Returns a slice of all states in this non-contiguous NFA."] pub (crate) fn states (& self) -> & [State] { & self . states } # [doc = " Returns the underlying \"special\" state information for this NFA."] pub (crate) fn special (& self) -> & Special { & self . special } # [doc = " Swaps the states at `id1` and `id2`."] # [doc = ""] # [doc = " This does not update the transitions of any state to account for the"] # [doc = " state swap."] pub (crate) fn swap_states (& mut self , id1 : StateID , id2 : StateID) { self . states . swap (id1 . as_usize () , id2 . as_usize ()) ; } # [doc = " Re-maps all state IDs in this NFA according to the `map` function"] # [doc = " given."] pub (crate) fn remap (& mut self , map : impl Fn (StateID) -> StateID) { let alphabet_len = self . byte_classes . alphabet_len () ; for state in self . states . iter_mut () { state . fail = map (state . fail) ; let mut link = state . sparse ; while link != StateID :: ZERO { let t = & mut self . sparse [link] ; t . next = map (t . next) ; link = t . link ; } if state . dense != StateID :: ZERO { let start = state . dense . as_usize () ; for next in self . dense [start ..] [.. alphabet_len] . iter_mut () { * next = map (* next) ; } } } } # [doc = " Iterate over all of the transitions for the given state ID."] pub (crate) fn iter_trans (& self , sid : StateID ,) -> impl Iterator < Item = Transition > + '_ { let mut link = self . states [sid] . sparse ; core :: iter :: from_fn (move | | { if link == StateID :: ZERO { return None ; } let t = self . sparse [link] ; link = t . link ; Some (t) }) } # [doc = " Iterate over all of the matches for the given state ID."] pub (crate) fn iter_matches (& self , sid : StateID ,) -> impl Iterator < Item = PatternID > + '_ { let mut link = self . states [sid] . matches ; core :: iter :: from_fn (move | | { if link == StateID :: ZERO { return None ; } let m = self . matches [link] ; link = m . link ; Some (m . pid) }) } # [doc = " Return the link following the one given. If the one given is the last"] # [doc = " link for the given state, then return `None`."] # [doc = ""] # [doc = " If no previous link is given, then this returns the first link in the"] # [doc = " state, if one exists."] # [doc = ""] # [doc = " This is useful for manually iterating over the transitions in a single"] # [doc = " state without borrowing the NFA. This permits mutating other parts of"] # [doc = " the NFA during iteration. Namely, one can access the transition pointed"] # [doc = " to by the link via `self.sparse[link]`."] fn next_link (& self , sid : StateID , prev : Option < StateID >) -> Option < StateID > { let link = prev . map_or (self . states [sid] . sparse , | p | self . sparse [p] . link) ; if link == StateID :: ZERO { None } else { Some (link) } } # [doc = " Follow the transition for the given byte in the given state. If no such"] # [doc = " transition exists, then the FAIL state ID is returned."] # [inline (always)] fn follow_transition (& self , sid : StateID , byte : u8) -> StateID { let s = & self . states [sid] ; if s . dense == StateID :: ZERO { self . follow_transition_sparse (sid , byte) } else { let class = usize :: from (self . byte_classes . get (byte)) ; self . dense [s . dense . as_usize () + class] } } # [doc = " Like `follow_transition`, but always uses the sparse representation."] # [inline (always)] fn follow_transition_sparse (& self , sid : StateID , byte : u8) -> StateID { for t in self . iter_trans (sid) { if byte <= t . byte { if byte == t . byte { return t . next ; } break ; } } NFA :: FAIL } # [doc = " Set the transition for the given byte to the state ID given."] # [doc = ""] # [doc = " Note that one should not set transitions to the FAIL state. It is not"] # [doc = " technically incorrect, but it wastes space. If a transition is not"] # [doc = " defined, then it is automatically assumed to lead to the FAIL state."] fn add_transition (& mut self , prev : StateID , byte : u8 , next : StateID ,) -> Result < () , BuildError > { if self . states [prev] . dense != StateID :: ZERO { let dense = self . states [prev] . dense ; let class = usize :: from (self . byte_classes . get (byte)) ; self . dense [dense . as_usize () + class] = next ; } let head = self . states [prev] . sparse ; if head == StateID :: ZERO || byte < self . sparse [head] . byte { let new_link = self . alloc_transition () ? ; self . sparse [new_link] = Transition { byte , next , link : head , } ; self . states [prev] . sparse = new_link ; return Ok (()) ; } else if byte == self . sparse [head] . byte { self . sparse [head] . next = next ; return Ok (()) ; } let (mut link_prev , mut link_next) = (head , self . sparse [head] . link) ; while link_next != StateID :: ZERO && byte > self . sparse [link_next] . byte { link_prev = link_next ; link_next = self . sparse [link_next] . link ; } if link_next == StateID :: ZERO || byte < self . sparse [link_next] . byte { let link = self . alloc_transition () ? ; self . sparse [link] = Transition { byte , next , link : link_next , } ; self . sparse [link_prev] . link = link ; } else { match (& byte , & self . sparse [link_next] . byte) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: None ,) ; } } } ; self . sparse [link_next] . next = next ; } Ok (()) } # [doc = " This sets every possible transition (all 255 of them) for the given"] # [doc = " state to the name `next` value."] # [doc = ""] # [doc = " This is useful for efficiently initializing start/dead states."] # [doc = ""] # [doc = " # Panics"] # [doc = ""] # [doc = " This requires that the state has no transitions added to it already."] # [doc = " If it has any transitions, then this panics. It will also panic if"] # [doc = " the state has been densified prior to calling this."] fn init_full_state (& mut self , prev : StateID , next : StateID ,) -> Result < () , BuildError > { match (& StateID :: ZERO , & self . states [prev] . dense) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! ("state must not be dense yet") ,) ,) ; } } } ; match (& StateID :: ZERO , & self . states [prev] . sparse) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! ("state must have zero transitions") ,) ,) ; } } } ; let mut prev_link = StateID :: ZERO ; for byte in 0 ..= 255 { let new_link = self . alloc_transition () ? ; self . sparse [new_link] = Transition { byte , next , link : StateID :: ZERO , } ; if prev_link == StateID :: ZERO { self . states [prev] . sparse = new_link ; } else { self . sparse [prev_link] . link = new_link ; } prev_link = new_link ; } Ok (()) } # [doc = " Add a match for the given pattern ID to the state for the given ID."] fn add_match (& mut self , sid : StateID , pid : PatternID ,) -> Result < () , BuildError > { let head = self . states [sid] . matches ; let mut link = head ; while self . matches [link] . link != StateID :: ZERO { link = self . matches [link] . link ; } let new_match_link = self . alloc_match () ? ; self . matches [new_match_link] . pid = pid ; if link == StateID :: ZERO { self . states [sid] . matches = new_match_link ; } else { self . matches [link] . link = new_match_link ; } Ok (()) } # [doc = " Copy matches from the `src` state to the `dst` state. This is useful"] # [doc = " when a match state can be reached via a failure transition. In which"] # [doc = " case, you'll want to copy the matches (if any) from the state reached"] # [doc = " by the failure transition to the original state you were at."] fn copy_matches (& mut self , src : StateID , dst : StateID ,) -> Result < () , BuildError > { let head_dst = self . states [dst] . matches ; let mut link_dst = head_dst ; while self . matches [link_dst] . link != StateID :: ZERO { link_dst = self . matches [link_dst] . link ; } let mut link_src = self . states [src] . matches ; while link_src != StateID :: ZERO { let new_match_link = StateID :: new (self . matches . len ()) . map_err (| e | { BuildError :: state_id_overflow (StateID :: MAX . as_u64 () , e . attempted () ,) }) ? ; self . matches . push (Match { pid : self . matches [link_src] . pid , link : StateID :: ZERO , }) ; if link_dst == StateID :: ZERO { self . states [dst] . matches = new_match_link ; } else { self . matches [link_dst] . link = new_match_link ; } link_dst = new_match_link ; link_src = self . matches [link_src] . link ; } Ok (()) } # [doc = " Create a new entry in `NFA::trans`, if there's room, and return that"] # [doc = " entry's ID. If there's no room, then an error is returned."] fn alloc_transition (& mut self) -> Result < StateID , BuildError > { let id = StateID :: new (self . sparse . len ()) . map_err (| e | { BuildError :: state_id_overflow (StateID :: MAX . as_u64 () , e . attempted () ,) }) ? ; self . sparse . push (Transition :: default ()) ; Ok (id) } # [doc = " Create a new entry in `NFA::matches`, if there's room, and return that"] # [doc = " entry's ID. If there's no room, then an error is returned."] fn alloc_match (& mut self) -> Result < StateID , BuildError > { let id = StateID :: new (self . matches . len ()) . map_err (| e | { BuildError :: state_id_overflow (StateID :: MAX . as_u64 () , e . attempted () ,) }) ? ; self . matches . push (Match :: default ()) ; Ok (id) } # [doc = " Create a new set of `N` transitions in this NFA's dense transition"] # [doc = " table. The ID return corresponds to the index at which the `N`"] # [doc = " transitions begin. So `id+0` is the first transition and `id+(N-1)` is"] # [doc = " the last."] # [doc = ""] # [doc = " `N` is determined via `NFA::byte_classes::alphabet_len`."] fn alloc_dense_state (& mut self) -> Result < StateID , BuildError > { let id = StateID :: new (self . dense . len ()) . map_err (| e | { BuildError :: state_id_overflow (StateID :: MAX . as_u64 () , e . attempted () ,) }) ? ; self . dense . extend (core :: iter :: repeat (NFA :: FAIL) . take (self . byte_classes . alphabet_len ()) ,) ; Ok (id) } # [doc = " Allocate and add a fresh state to the underlying NFA and return its"] # [doc = " ID (guaranteed to be one more than the ID of the previously allocated"] # [doc = " state). If the ID would overflow `StateID`, then this returns an error."] fn alloc_state (& mut self , depth : usize) -> Result < StateID , BuildError > { let depth = SmallIndex :: new (depth) . expect ("patterns longer than SmallIndex::MAX are not allowed") ; let id = StateID :: new (self . states . len ()) . map_err (| e | { BuildError :: state_id_overflow (StateID :: MAX . as_u64 () , e . attempted () ,) }) ? ; self . states . push (State { sparse : StateID :: ZERO , dense : StateID :: ZERO , matches : StateID :: ZERO , fail : self . special . start_unanchored_id , depth , }) ; Ok (id) } } unsafe impl Automaton for NFA { # [inline (always)] fn start_state (& self , anchored : Anchored) -> Result < StateID , MatchError > { match anchored { Anchored :: No => Ok (self . special . start_unanchored_id) , Anchored :: Yes => Ok (self . special . start_anchored_id) , } } # [inline (always)] fn next_state (& self , anchored : Anchored , mut sid : StateID , byte : u8 ,) -> StateID { loop { let next = self . follow_transition (sid , byte) ; if next != NFA :: FAIL { return next ; } if anchored . is_anchored () { return NFA :: DEAD ; } sid = self . states [sid] . fail () ; } } # [inline (always)] fn is_special (& self , sid : StateID) -> bool { sid <= self . special . max_special_id } # [inline (always)] fn is_dead (& self , sid : StateID) -> bool { sid == NFA :: DEAD } # [inline (always)] fn is_match (& self , sid : StateID) -> bool { ! self . is_dead (sid) && sid <= self . special . max_match_id } # [inline (always)] fn is_start (& self , sid : StateID) -> bool { sid == self . special . start_unanchored_id || sid == self . special . start_anchored_id } # [inline (always)] fn match_kind (& self) -> MatchKind { self . match_kind } # [inline (always)] fn patterns_len (& self) -> usize { self . pattern_lens . len () } # [inline (always)] fn pattern_len (& self , pid : PatternID) -> usize { self . pattern_lens [pid] . as_usize () } # [inline (always)] fn min_pattern_len (& self) -> usize { self . min_pattern_len } # [inline (always)] fn max_pattern_len (& self) -> usize { self . max_pattern_len } # [inline (always)] fn match_len (& self , sid : StateID) -> usize { self . iter_matches (sid) . count () } # [inline (always)] fn match_pattern (& self , sid : StateID , index : usize) -> PatternID { self . iter_matches (sid) . nth (index) . unwrap () } # [inline (always)] fn memory_usage (& self) -> usize { self . states . len () * core :: mem :: size_of :: < State > () + self . sparse . len () * core :: mem :: size_of :: < Transition > () + self . matches . len () * core :: mem :: size_of :: < Match > () + self . dense . len () * StateID :: SIZE + self . pattern_lens . len () * SmallIndex :: SIZE + self . prefilter . as_ref () . map_or (0 , | p | p . memory_usage ()) } # [inline (always)] fn prefilter (& self) -> Option < & Prefilter > { self . prefilter . as_ref () } } # [doc = " A representation of a sparse NFA state for an Aho-Corasick automaton."] # [doc = ""] # [doc = " It contains the transitions to the next state, a failure transition for"] # [doc = " cases where there exists no other transition for the current input byte"] # [doc = " and the matches implied by visiting this state (if any)."] pub (crate) struct State { # [doc = " A pointer to `NFA::trans` corresponding to the head of a linked list"] # [doc = " containing all of the transitions for this state."] # [doc = ""] # [doc = " This is `StateID::ZERO` if and only if this state has zero transitions."] sparse : StateID , # [doc = " A pointer to a row of `N` transitions in `NFA::dense`. These"] # [doc = " transitions correspond precisely to what is obtained by traversing"] # [doc = " `sparse`, but permits constant time lookup."] # [doc = ""] # [doc = " When this is zero (which is true for most states in the default"] # [doc = " configuration), then this state has no dense representation."] # [doc = ""] # [doc = " Note that `N` is equal to `NFA::byte_classes::alphabet_len()`. This is"] # [doc = " typically much less than 256 (the maximum value)."] dense : StateID , # [doc = " A pointer to `NFA::matches` corresponding to the head of a linked list"] # [doc = " containing all of the matches for this state."] # [doc = ""] # [doc = " This is `StateID::ZERO` if and only if this state is not a match state."] matches : StateID , # [doc = " The state that should be transitioned to if the current byte in the"] # [doc = " haystack does not have a corresponding transition defined in this"] # [doc = " state."] fail : StateID , # [doc = " The depth of this state. Specifically, this is the distance from this"] # [doc = " state to the starting state. (For the special sentinel states DEAD and"] # [doc = " FAIL, their depth is always 0.) The depth of a starting state is 0."] # [doc = ""] # [doc = " Note that depth is currently not used in this non-contiguous NFA. It"] # [doc = " may in the future, but it is used in the contiguous NFA. Namely, it"] # [doc = " permits an optimization where states near the starting state have their"] # [doc = " transitions stored in a dense fashion, but all other states have their"] # [doc = " transitions stored in a sparse fashion. (This non-contiguous NFA uses"] # [doc = " a sparse representation for all states unconditionally.) In any case,"] # [doc = " this is really the only convenient place to compute and store this"] # [doc = " information, which we need when building the contiguous NFA."] depth : SmallIndex , } # [automatically_derived] impl :: core :: clone :: Clone for State { # [inline] fn clone (& self) -> State { State { sparse : :: core :: clone :: Clone :: clone (& self . sparse) , dense : :: core :: clone :: Clone :: clone (& self . dense) , matches : :: core :: clone :: Clone :: clone (& self . matches) , fail : :: core :: clone :: Clone :: clone (& self . fail) , depth : :: core :: clone :: Clone :: clone (& self . depth) , } } } # [automatically_derived] impl :: core :: fmt :: Debug for State { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field5_finish (f , "State" , "sparse" , & self . sparse , "dense" , & self . dense , "matches" , & self . matches , "fail" , & self . fail , "depth" , & & self . depth ,) } } impl State { # [doc = " Return true if and only if this state is a match state."] pub (crate) fn is_match (& self) -> bool { self . matches != StateID :: ZERO } # [doc = " Returns the failure transition for this state."] pub (crate) fn fail (& self) -> StateID { self . fail } # [doc = " Returns the depth of this state. That is, the number of transitions"] # [doc = " this state is from the start state of the NFA."] pub (crate) fn depth (& self) -> SmallIndex { self . depth } } # [doc = " A single transition in a non-contiguous NFA."] # [repr (packed)] pub (crate) struct Transition { byte : u8 , next : StateID , link : StateID , } # [automatically_derived] impl :: core :: clone :: Clone for Transition { # [inline] fn clone (& self) -> Transition { let _ : :: core :: clone :: AssertParamIsClone < u8 > ; let _ : :: core :: clone :: AssertParamIsClone < StateID > ; * self } } # [automatically_derived] impl :: core :: marker :: Copy for Transition { } # [automatically_derived] impl :: core :: default :: Default for Transition { # [inline] fn default () -> Transition { Transition { byte : :: core :: default :: Default :: default () , next : :: core :: default :: Default :: default () , link : :: core :: default :: Default :: default () , } } } impl Transition { # [doc = " Return the byte for which this transition is defined."] pub (crate) fn byte (& self) -> u8 { self . byte } # [doc = " Return the ID of the state that this transition points to."] pub (crate) fn next (& self) -> StateID { self . next } # [doc = " Return the ID of the next transition."] fn link (& self) -> StateID { self . link } } impl core :: fmt :: Debug for Transition { fn fmt (& self , f : & mut core :: fmt :: Formatter) -> core :: fmt :: Result { f . write_fmt (format_args ! ("Transition(byte: {0:X?}, next: {1:?}, link: {2:?})" , self . byte , self . next () . as_usize () , self . link () . as_usize () ,) ,) } } # [doc = " A single match in a non-contiguous NFA."] struct Match { pid : PatternID , link : StateID , } # [automatically_derived] impl :: core :: clone :: Clone for Match { # [inline] fn clone (& self) -> Match { let _ : :: core :: clone :: AssertParamIsClone < PatternID > ; let _ : :: core :: clone :: AssertParamIsClone < StateID > ; * self } } # [automatically_derived] impl :: core :: marker :: Copy for Match { } # [automatically_derived] impl :: core :: default :: Default for Match { # [inline] fn default () -> Match { Match { pid : :: core :: default :: Default :: default () , link : :: core :: default :: Default :: default () , } } } impl Match { # [doc = " Return the pattern ID for this match."] pub (crate) fn pattern (& self) -> PatternID { self . pid } # [doc = " Return the ID of the next match."] fn link (& self) -> StateID { self . link } } impl core :: fmt :: Debug for Match { fn fmt (& self , f : & mut core :: fmt :: Formatter) -> core :: fmt :: Result { f . write_fmt (format_args ! ("Match(pid: {0:?}, link: {1:?})" , self . pattern () . as_usize () , self . link () . as_usize () ,) ,) } } # [doc = " A builder for configuring an Aho-Corasick noncontiguous NFA."] # [doc = ""] # [doc = " This builder has a subset of the options available to a"] # [doc = " [`AhoCorasickBuilder`](crate::AhoCorasickBuilder). Of the shared options,"] # [doc = " their behavior is identical."] pub struct Builder { match_kind : MatchKind , prefilter : bool , ascii_case_insensitive : bool , dense_depth : usize , } # [automatically_derived] impl :: core :: clone :: Clone for Builder { # [inline] fn clone (& self) -> Builder { Builder { match_kind : :: core :: clone :: Clone :: clone (& self . match_kind) , prefilter : :: core :: clone :: Clone :: clone (& self . prefilter) , ascii_case_insensitive : :: core :: clone :: Clone :: clone (& self . ascii_case_insensitive ,) , dense_depth : :: core :: clone :: Clone :: clone (& self . dense_depth) , } } } # [automatically_derived] impl :: core :: fmt :: Debug for Builder { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field4_finish (f , "Builder" , "match_kind" , & self . match_kind , "prefilter" , & self . prefilter , "ascii_case_insensitive" , & self . ascii_case_insensitive , "dense_depth" , & & self . dense_depth ,) } } impl Default for Builder { fn default () -> Builder { Builder { match_kind : MatchKind :: default () , prefilter : true , ascii_case_insensitive : false , dense_depth : 3 , } } } impl Builder { # [doc = " Create a new builder for configuring an Aho-Corasick noncontiguous NFA."] pub fn new () -> Builder { Builder :: default () } # [doc = " Build an Aho-Corasick noncontiguous NFA from the given iterator of"] # [doc = " patterns."] # [doc = ""] # [doc = " A builder may be reused to create more NFAs."] pub fn build < I , P > (& self , patterns : I) -> Result < NFA , BuildError > where I : IntoIterator < Item = P > , P : AsRef < [u8] > , { let nfa = Compiler :: new (self) ? . compile (patterns) ? ; Ok (nfa) } # [doc = " Set the desired match semantics."] # [doc = ""] # [doc = " See"] # [doc = " [`AhoCorasickBuilder::match_kind`](crate::AhoCorasickBuilder::match_kind)"] # [doc = " for more documentation and examples."] pub fn match_kind (& mut self , kind : MatchKind) -> & mut Builder { self . match_kind = kind ; self } # [doc = " Enable ASCII-aware case insensitive matching."] # [doc = ""] # [doc = " See"] # [doc = " [`AhoCorasickBuilder::ascii_case_insensitive`](crate::AhoCorasickBuilder::ascii_case_insensitive)"] # [doc = " for more documentation and examples."] pub fn ascii_case_insensitive (& mut self , yes : bool) -> & mut Builder { self . ascii_case_insensitive = yes ; self } # [doc = " Set the limit on how many states use a dense representation for their"] # [doc = " transitions. Other states will generally use a sparse representation."] # [doc = ""] # [doc = " See"] # [doc = " [`AhoCorasickBuilder::dense_depth`](crate::AhoCorasickBuilder::dense_depth)"] # [doc = " for more documentation and examples."] pub fn dense_depth (& mut self , depth : usize) -> & mut Builder { self . dense_depth = depth ; self } # [doc = " Enable heuristic prefilter optimizations."] # [doc = ""] # [doc = " See"] # [doc = " [`AhoCorasickBuilder::prefilter`](crate::AhoCorasickBuilder::prefilter)"] # [doc = " for more documentation and examples."] pub fn prefilter (& mut self , yes : bool) -> & mut Builder { self . prefilter = yes ; self } } # [doc = " A compiler uses a builder configuration and builds up the NFA formulation"] # [doc = " of an Aho-Corasick automaton. This roughly corresponds to the standard"] # [doc = " formulation described in textbooks, with some tweaks to support leftmost"] # [doc = " searching."] struct Compiler < 'a > { builder : & 'a Builder , prefilter : prefilter :: Builder , nfa : NFA , byteset : ByteClassSet , } # [automatically_derived] impl < 'a > :: core :: fmt :: Debug for Compiler < 'a > { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field4_finish (f , "Compiler" , "builder" , & self . builder , "prefilter" , & self . prefilter , "nfa" , & self . nfa , "byteset" , & & self . byteset ,) } } impl < 'a > Compiler < 'a > { fn new (builder : & 'a Builder) -> Result < Compiler < 'a > , BuildError > { let prefilter = prefilter :: Builder :: new (builder . match_kind) . ascii_case_insensitive (builder . ascii_case_insensitive) ; Ok (Compiler { builder , prefilter , nfa : NFA { match_kind : builder . match_kind , states : :: alloc :: vec :: Vec :: new () , sparse : :: alloc :: vec :: Vec :: new () , dense : :: alloc :: vec :: Vec :: new () , matches : :: alloc :: vec :: Vec :: new () , pattern_lens : :: alloc :: vec :: Vec :: new () , prefilter : None , byte_classes : ByteClasses :: singletons () , min_pattern_len : usize :: MAX , max_pattern_len : 0 , special : Special :: zero () , } , byteset : ByteClassSet :: empty () , }) } fn compile < I , P > (mut self , patterns : I) -> Result < NFA , BuildError > where I : IntoIterator < Item = P > , P : AsRef < [u8] > , { self . nfa . sparse . push (Transition :: default ()) ; self . nfa . matches . push (Match :: default ()) ; self . nfa . dense . push (NFA :: DEAD) ; self . nfa . alloc_state (0) ? ; self . nfa . alloc_state (0) ? ; self . nfa . special . start_unanchored_id = self . nfa . alloc_state (0) ? ; self . nfa . special . start_anchored_id = self . nfa . alloc_state (0) ? ; self . init_unanchored_start_state () ? ; self . add_dead_state_loop () ? ; self . build_trie (patterns) ? ; self . nfa . states . shrink_to_fit () ; self . nfa . byte_classes = self . byteset . byte_classes () ; self . set_anchored_start_state () ? ; self . add_unanchored_start_state_loop () ; self . densify () ? ; self . fill_failure_transitions () ? ; self . close_start_state_loop_for_leftmost () ; self . shuffle () ; self . nfa . prefilter = self . prefilter . build () ; self . nfa . special . max_special_id = if self . nfa . prefilter . is_some () { self . nfa . special . start_anchored_id } else { self . nfa . special . max_match_id } ; self . nfa . sparse . shrink_to_fit () ; self . nfa . dense . shrink_to_fit () ; self . nfa . matches . shrink_to_fit () ; self . nfa . pattern_lens . shrink_to_fit () ; Ok (self . nfa) } # [doc = " This sets up the initial prefix trie that makes up the Aho-Corasick"] # [doc = " automaton. Effectively, it creates the basic structure of the"] # [doc = " automaton, where every pattern given has a path from the start state to"] # [doc = " the end of the pattern."] fn build_trie < I , P > (& mut self , patterns : I) -> Result < () , BuildError > where I : IntoIterator < Item = P > , P : AsRef < [u8] > , { 'PATTERNS : for (i , pat) in patterns . into_iter () . enumerate () { let pid = PatternID :: new (i) . map_err (| e | { BuildError :: pattern_id_overflow (PatternID :: MAX . as_u64 () , e . attempted () ,) }) ? ; let pat = pat . as_ref () ; let patlen = SmallIndex :: new (pat . len ()) . map_err (| _ | BuildError :: pattern_too_long (pid , pat . len ())) ? ; self . nfa . min_pattern_len = core :: cmp :: min (self . nfa . min_pattern_len , pat . len () ,) ; self . nfa . max_pattern_len = core :: cmp :: max (self . nfa . max_pattern_len , pat . len () ,) ; match (& i , & self . nfa . pattern_lens . len ()) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! ("expected number of patterns to match pattern ID" ,) ,) ,) ; } } } ; self . nfa . pattern_lens . push (patlen) ; if self . builder . prefilter { self . prefilter . add (pat) ; } let mut prev = self . nfa . special . start_unanchored_id ; let mut saw_match = false ; for (depth , & b) in pat . iter () . enumerate () { saw_match = saw_match || self . nfa . states [prev] . is_match () ; if self . builder . match_kind . is_leftmost_first () && saw_match { continue 'PATTERNS ; } self . byteset . set_range (b , b) ; if self . builder . ascii_case_insensitive { let b = opposite_ascii_case (b) ; self . byteset . set_range (b , b) ; } let next = self . nfa . follow_transition (prev , b) ; if next != NFA :: FAIL { prev = next ; } else { let next = self . nfa . alloc_state (depth) ? ; self . nfa . add_transition (prev , b , next) ? ; if self . builder . ascii_case_insensitive { let b = opposite_ascii_case (b) ; self . nfa . add_transition (prev , b , next) ? ; } prev = next ; } } self . nfa . add_match (prev , pid) ? ; } Ok (()) } # [doc = " This routine creates failure transitions according to the standard"] # [doc = " textbook formulation of the Aho-Corasick algorithm, with a couple small"] # [doc = " tweaks to support \"leftmost\" semantics."] # [doc = ""] # [doc = " Building failure transitions is the most interesting part of building"] # [doc = " the Aho-Corasick automaton, because they are what allow searches to"] # [doc = " be performed in linear time. Specifically, a failure transition is"] # [doc = " a single transition associated with each state that points back to"] # [doc = " the longest proper suffix of the pattern being searched. The failure"] # [doc = " transition is followed whenever there exists no transition on the"] # [doc = " current state for the current input byte. If there is no other proper"] # [doc = " suffix, then the failure transition points back to the starting state."] # [doc = ""] # [doc = " For example, let's say we built an Aho-Corasick automaton with the"] # [doc = " following patterns: 'abcd' and 'cef'. The trie looks like this:"] # [doc = ""] # [doc = " ```ignore"] # [doc = "          a - S1 - b - S2 - c - S3 - d - S4*"] # [doc = "         /"] # [doc = "     S0 - c - S5 - e - S6 - f - S7*"] # [doc = " ```"] # [doc = ""] # [doc = " At this point, it should be fairly straight-forward to see how this"] # [doc = " trie can be used in a simplistic way. At any given position in the"] # [doc = " text we're searching (called the \"subject\" string), all we need to do"] # [doc = " is follow the transitions in the trie by consuming one transition for"] # [doc = " each byte in the subject string. If we reach a match state, then we can"] # [doc = " report that location as a match."] # [doc = ""] # [doc = " The trick comes when searching a subject string like 'abcef'. We'll"] # [doc = " initially follow the transition from S0 to S1 and wind up in S3 after"] # [doc = " observng the 'c' byte. At this point, the next byte is 'e' but state"] # [doc = " S3 has no transition for 'e', so the search fails. We then would need"] # [doc = " to restart the search at the next position in 'abcef', which"] # [doc = " corresponds to 'b'. The match would fail, but the next search starting"] # [doc = " at 'c' would finally succeed. The problem with this approach is that"] # [doc = " we wind up searching the subject string potentially many times. In"] # [doc = " effect, this makes the algorithm have worst case `O(n * m)` complexity,"] # [doc = " where `n ~ len(subject)` and `m ~ len(all patterns)`. We would instead"] # [doc = " like to achieve a `O(n + m)` worst case complexity."] # [doc = ""] # [doc = " This is where failure transitions come in. Instead of dying at S3 in"] # [doc = " the first search, the automaton can instruct the search to move to"] # [doc = " another part of the automaton that corresponds to a suffix of what"] # [doc = " we've seen so far. Recall that we've seen 'abc' in the subject string,"] # [doc = " and the automaton does indeed have a non-empty suffix, 'c', that could"] # [doc = " potentially lead to another match. Thus, the actual Aho-Corasick"] # [doc = " automaton for our patterns in this case looks like this:"] # [doc = ""] # [doc = " ```ignore"] # [doc = "          a - S1 - b - S2 - c - S3 - d - S4*"] # [doc = "         /                      /"] # [doc = "        /       ----------------"] # [doc = "       /       /"] # [doc = "     S0 - c - S5 - e - S6 - f - S7*"] # [doc = " ```"] # [doc = ""] # [doc = " That is, we have a failure transition from S3 to S5, which is followed"] # [doc = " exactly in cases when we are in state S3 but see any byte other than"] # [doc = " 'd' (that is, we've \"failed\" to find a match in this portion of our"] # [doc = " trie). We know we can transition back to S5 because we've already seen"] # [doc = " a 'c' byte, so we don't need to re-scan it. We can then pick back up"] # [doc = " with the search starting at S5 and complete our match."] # [doc = ""] # [doc = " Adding failure transitions to a trie is fairly simple, but subtle. The"] # [doc = " key issue is that you might have multiple failure transition that you"] # [doc = " need to follow. For example, look at the trie for the patterns"] # [doc = " 'abcd', 'b', 'bcd' and 'cd':"] # [doc = ""] # [doc = " ```ignore"] # [doc = "          - a - S1 - b - S2* - c - S3 - d - S4*"] # [doc = "         /               /         /"] # [doc = "        /         -------   -------"] # [doc = "       /         /         /"] # [doc = "     S0 --- b - S5* - c - S6 - d - S7*"] # [doc = "       \\                  /"] # [doc = "        \\         --------"] # [doc = "         \\       /"] # [doc = "          - c - S8 - d - S9*"] # [doc = " ```"] # [doc = ""] # [doc = " The failure transitions for this trie are defined from S2 to S5,"] # [doc = " S3 to S6 and S6 to S8. Moreover, state S2 needs to track that it"] # [doc = " corresponds to a match, since its failure transition to S5 is itself"] # [doc = " a match state."] # [doc = ""] # [doc = " Perhaps simplest way to think about adding these failure transitions"] # [doc = " is recursively. That is, if you know the failure transitions for every"] # [doc = " possible previous state that could be visited (e.g., when computing the"] # [doc = " failure transition for S3, you already know the failure transitions"] # [doc = " for S0, S1 and S2), then you can simply follow the failure transition"] # [doc = " of the previous state and check whether the incoming transition is"] # [doc = " defined after following the failure transition."] # [doc = ""] # [doc = " For example, when determining the failure state for S3, by our"] # [doc = " assumptions, we already know that there is a failure transition from"] # [doc = " S2 (the previous state) to S5. So we follow that transition and check"] # [doc = " whether the transition connecting S2 to S3 is defined. Indeed, it is,"] # [doc = " as there is a transition from S5 to S6 for the byte 'c'. If no such"] # [doc = " transition existed, we could keep following the failure transitions"] # [doc = " until we reach the start state, which is the failure transition for"] # [doc = " every state that has no corresponding proper suffix."] # [doc = ""] # [doc = " We don't actually use recursion to implement this, but instead, use a"] # [doc = " breadth first search of the automaton. Our base case is the start"] # [doc = " state, whose failure transition is just a transition to itself."] # [doc = ""] # [doc = " When building a leftmost automaton, we proceed as above, but only"] # [doc = " include a subset of failure transitions. Namely, we omit any failure"] # [doc = " transitions that appear after a match state in the trie. This is"] # [doc = " because failure transitions always point back to a proper suffix of"] # [doc = " what has been seen so far. Thus, following a failure transition after"] # [doc = " a match implies looking for a match that starts after the one that has"] # [doc = " already been seen, which is of course therefore not the leftmost match."] # [doc = ""] # [doc = " N.B. I came up with this algorithm on my own, and after scouring all of"] # [doc = " the other AC implementations I know of (Perl, Snort, many on GitHub)."] # [doc = " I couldn't find any that implement leftmost semantics like this."] # [doc = " Perl of course needs leftmost-first semantics, but they implement it"] # [doc = " with a seeming hack at *search* time instead of encoding it into the"] # [doc = " automaton. There are also a couple Java libraries that support leftmost"] # [doc = " longest semantics, but they do it by building a queue of matches at"] # [doc = " search time, which is even worse than what Perl is doing. ---AG"] fn fill_failure_transitions (& mut self) -> Result < () , BuildError > { let is_leftmost = self . builder . match_kind . is_leftmost () ; let start_uid = self . nfa . special . start_unanchored_id ; let mut queue = VecDeque :: new () ; let mut seen = self . queued_set () ; let mut prev_link = None ; while let Some (link) = self . nfa . next_link (start_uid , prev_link) { prev_link = Some (link) ; let t = self . nfa . sparse [link] ; if start_uid == t . next () || seen . contains (t . next) { continue ; } queue . push_back (t . next) ; seen . insert (t . next) ; if is_leftmost && self . nfa . states [t . next] . is_match () { self . nfa . states [t . next] . fail = NFA :: DEAD ; } } while let Some (id) = queue . pop_front () { let mut prev_link = None ; while let Some (link) = self . nfa . next_link (id , prev_link) { prev_link = Some (link) ; let t = self . nfa . sparse [link] ; if seen . contains (t . next) { continue ; } queue . push_back (t . next) ; seen . insert (t . next) ; if is_leftmost && self . nfa . states [t . next] . is_match () { self . nfa . states [t . next] . fail = NFA :: DEAD ; continue ; } let mut fail = self . nfa . states [id] . fail ; while self . nfa . follow_transition (fail , t . byte) == NFA :: FAIL { fail = self . nfa . states [fail] . fail ; } fail = self . nfa . follow_transition (fail , t . byte) ; self . nfa . states [t . next] . fail = fail ; self . nfa . copy_matches (fail , t . next) ? ; } if ! is_leftmost { self . nfa . copy_matches (self . nfa . special . start_unanchored_id , id) ? ; } } Ok (()) } # [doc = " Shuffle the states so that they appear in this sequence:"] # [doc = ""] # [doc = "   DEAD, FAIL, MATCH..., START, START, NON-MATCH..."] # [doc = ""] # [doc = " The idea here is that if we know how special states are laid out in our"] # [doc = " transition table, then we can determine what \"kind\" of state we're in"] # [doc = " just by comparing our current state ID with a particular value. In this"] # [doc = " way, we avoid doing extra memory lookups."] # [doc = ""] # [doc = " Before shuffling begins, our states look something like this:"] # [doc = ""] # [doc = "   DEAD, FAIL, START, START, (MATCH | NON-MATCH)..."] # [doc = ""] # [doc = " So all we need to do is move all of the MATCH states so that they"] # [doc = " all appear before any NON-MATCH state, like so:"] # [doc = ""] # [doc = "   DEAD, FAIL, START, START, MATCH... NON-MATCH..."] # [doc = ""] # [doc = " Then it's just a simple matter of swapping the two START states with"] # [doc = " the last two MATCH states."] # [doc = ""] # [doc = " (This is the same technique used for fully compiled DFAs in"] # [doc = " regex-automata.)"] fn shuffle (& mut self) { let old_start_uid = self . nfa . special . start_unanchored_id ; let old_start_aid = self . nfa . special . start_anchored_id ; if ! (old_start_uid < old_start_aid) { :: core :: panicking :: panic ("assertion failed: old_start_uid < old_start_aid" ,) } match (& 3 , & old_start_aid . as_usize ()) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! ("anchored start state should be at index 3") ,) ,) ; } } } ; let mut remapper = Remapper :: new (& self . nfa , 0) ; let mut next_avail = StateID :: from (4u8) ; for i in next_avail . as_usize () .. self . nfa . states . len () { let sid = StateID :: new (i) . unwrap () ; if ! self . nfa . states [sid] . is_match () { continue ; } remapper . swap (& mut self . nfa , sid , next_avail) ; next_avail = StateID :: new (next_avail . one_more ()) . unwrap () ; } let new_start_aid = StateID :: new (next_avail . as_usize () . checked_sub (1) . unwrap () ,) . unwrap () ; remapper . swap (& mut self . nfa , old_start_aid , new_start_aid) ; let new_start_uid = StateID :: new (next_avail . as_usize () . checked_sub (2) . unwrap () ,) . unwrap () ; remapper . swap (& mut self . nfa , old_start_uid , new_start_uid) ; let new_max_match_id = StateID :: new (next_avail . as_usize () . checked_sub (3) . unwrap () ,) . unwrap () ; self . nfa . special . max_match_id = new_max_match_id ; self . nfa . special . start_unanchored_id = new_start_uid ; self . nfa . special . start_anchored_id = new_start_aid ; if self . nfa . states [self . nfa . special . start_anchored_id] . is_match () { self . nfa . special . max_match_id = self . nfa . special . start_anchored_id ; } remapper . remap (& mut self . nfa) ; } # [doc = " Attempts to convert the transition representation of a subset of states"] # [doc = " in this NFA from sparse to dense. This can greatly improve search"] # [doc = " performance since states with a higher number of transitions tend to"] # [doc = " correlate with very active states."] # [doc = ""] # [doc = " We generally only densify states that are close to the start state."] # [doc = " These tend to be the most active states and thus benefit from a dense"] # [doc = " representation more than other states."] # [doc = ""] # [doc = " This tends to best balance between memory usage and performance. In"] # [doc = " particular, the *vast majority* of all states in a typical Aho-Corasick"] # [doc = " automaton have only 1 transition and are usually farther from the start"] # [doc = " state and thus don't get densified."] # [doc = ""] # [doc = " Note that this doesn't remove the sparse representation of transitions"] # [doc = " for states that are densified. It could be done, but actually removing"] # [doc = " entries from `NFA::sparse` is likely more expensive than it's worth."] fn densify (& mut self) -> Result < () , BuildError > { for i in 0 .. self . nfa . states . len () { let sid = StateID :: new (i) . unwrap () ; if sid == NFA :: DEAD || sid == NFA :: FAIL { continue ; } if self . nfa . states [sid] . depth . as_usize () >= self . builder . dense_depth { continue ; } let dense = self . nfa . alloc_dense_state () ? ; let mut prev_link = None ; while let Some (link) = self . nfa . next_link (sid , prev_link) { prev_link = Some (link) ; let t = self . nfa . sparse [link] ; let class = usize :: from (self . nfa . byte_classes . get (t . byte)) ; let index = dense . as_usize () + class ; self . nfa . dense [index] = t . next ; } self . nfa . states [sid] . dense = dense ; } Ok (()) } # [doc = " Returns a set that tracked queued states."] # [doc = ""] # [doc = " This is only necessary when ASCII case insensitivity is enabled, since"] # [doc = " it is the only way to visit the same state twice. Otherwise, this"] # [doc = " returns an inert set that nevers adds anything and always reports"] # [doc = " `false` for every member test."] fn queued_set (& self) -> QueuedSet { if self . builder . ascii_case_insensitive { QueuedSet :: active () } else { QueuedSet :: inert () } } # [doc = " Initializes the unanchored start state by making it dense. This is"] # [doc = " achieved by explicitly setting every transition to the FAIL state."] # [doc = " This isn't necessary for correctness, since any missing transition is"] # [doc = " automatically assumed to be mapped to the FAIL state. We do this to"] # [doc = " make the unanchored starting state dense, and thus in turn make"] # [doc = " transition lookups on it faster. (Which is worth doing because it's"] # [doc = " the most active state.)"] fn init_unanchored_start_state (& mut self) -> Result < () , BuildError > { let start_uid = self . nfa . special . start_unanchored_id ; let start_aid = self . nfa . special . start_anchored_id ; self . nfa . init_full_state (start_uid , NFA :: FAIL) ? ; self . nfa . init_full_state (start_aid , NFA :: FAIL) ? ; Ok (()) } # [doc = " Setup the anchored start state by copying all of the transitions and"] # [doc = " matches from the unanchored starting state with one change: the failure"] # [doc = " transition is changed to the DEAD state, so that for any undefined"] # [doc = " transitions, the search will stop."] fn set_anchored_start_state (& mut self) -> Result < () , BuildError > { let start_uid = self . nfa . special . start_unanchored_id ; let start_aid = self . nfa . special . start_anchored_id ; let (mut uprev_link , mut aprev_link) = (None , None) ; loop { let unext = self . nfa . next_link (start_uid , uprev_link) ; let anext = self . nfa . next_link (start_aid , aprev_link) ; let (ulink , alink) = match (unext , anext) { (Some (ulink) , Some (alink)) => (ulink , alink) , (None , None) => break , _ => { :: core :: panicking :: panic ("internal error: entered unreachable code" ,) } } ; uprev_link = Some (ulink) ; aprev_link = Some (alink) ; self . nfa . sparse [alink] . next = self . nfa . sparse [ulink] . next ; } self . nfa . copy_matches (start_uid , start_aid) ? ; self . nfa . states [start_aid] . fail = NFA :: DEAD ; Ok (()) } # [doc = " Set the failure transitions on the start state to loop back to the"] # [doc = " start state. This effectively permits the Aho-Corasick automaton to"] # [doc = " match at any position. This is also required for finding the next"] # [doc = " state to terminate, namely, finding the next state should never return"] # [doc = " a fail_id."] # [doc = ""] # [doc = " This must be done after building the initial trie, since trie"] # [doc = " construction depends on transitions to `fail_id` to determine whether a"] # [doc = " state already exists or not."] fn add_unanchored_start_state_loop (& mut self) { let start_uid = self . nfa . special . start_unanchored_id ; let mut prev_link = None ; while let Some (link) = self . nfa . next_link (start_uid , prev_link) { prev_link = Some (link) ; if self . nfa . sparse [link] . next () == NFA :: FAIL { self . nfa . sparse [link] . next = start_uid ; } } } # [doc = " Remove the start state loop by rewriting any transitions on the start"] # [doc = " state back to the start state with transitions to the dead state."] # [doc = ""] # [doc = " The loop is only closed when two conditions are met: the start state"] # [doc = " is a match state and the match kind is leftmost-first or"] # [doc = " leftmost-longest."] # [doc = ""] # [doc = " The reason for this is that under leftmost semantics, a start state"] # [doc = " that is also a match implies that we should never restart the search"] # [doc = " process. We allow normal transitions out of the start state, but if"] # [doc = " none exist, we transition to the dead state, which signals that"] # [doc = " searching should stop."] fn close_start_state_loop_for_leftmost (& mut self) { let start_uid = self . nfa . special . start_unanchored_id ; let start = & mut self . nfa . states [start_uid] ; let dense = start . dense ; if self . builder . match_kind . is_leftmost () && start . is_match () { let mut prev_link = None ; while let Some (link) = self . nfa . next_link (start_uid , prev_link) { prev_link = Some (link) ; if self . nfa . sparse [link] . next () == start_uid { self . nfa . sparse [link] . next = NFA :: DEAD ; if dense != StateID :: ZERO { let b = self . nfa . sparse [link] . byte ; let class = usize :: from (self . nfa . byte_classes . get (b)) ; self . nfa . dense [dense . as_usize () + class] = NFA :: DEAD ; } } } } } # [doc = " Sets all transitions on the dead state to point back to the dead state."] # [doc = " Normally, missing transitions map back to the failure state, but the"] # [doc = " point of the dead state is to act as a sink that can never be escaped."] fn add_dead_state_loop (& mut self) -> Result < () , BuildError > { self . nfa . init_full_state (NFA :: DEAD , NFA :: DEAD) ? ; Ok (()) } } # [doc = " A set of state identifiers used to avoid revisiting the same state multiple"] # [doc = " times when filling in failure transitions."] # [doc = ""] # [doc = " This set has an \"inert\" and an \"active\" mode. When inert, the set never"] # [doc = " stores anything and always returns `false` for every member test. This is"] # [doc = " useful to avoid the performance and memory overhead of maintaining this"] # [doc = " set when it is not needed."] struct QueuedSet { set : Option < BTreeSet < StateID > > , } # [automatically_derived] impl :: core :: fmt :: Debug for QueuedSet { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field1_finish (f , "QueuedSet" , "set" , & & self . set ,) } } impl QueuedSet { # [doc = " Return an inert set that returns `false` for every state ID membership"] # [doc = " test."] fn inert () -> QueuedSet { QueuedSet { set : None } } # [doc = " Return an active set that tracks state ID membership."] fn active () -> QueuedSet { QueuedSet { set : Some (BTreeSet :: new ()) , } } # [doc = " Inserts the given state ID into this set. (If the set is inert, then"] # [doc = " this is a no-op.)"] fn insert (& mut self , state_id : StateID) { if let Some (ref mut set) = self . set { set . insert (state_id) ; } } # [doc = " Returns true if and only if the given state ID is in this set. If the"] # [doc = " set is inert, this always returns false."] fn contains (& self , state_id : StateID) -> bool { match self . set { None => false , Some (ref set) => set . contains (& state_id) , } } } impl core :: fmt :: Debug for NFA { fn fmt (& self , f : & mut core :: fmt :: Formatter < '_ >) -> core :: fmt :: Result { use crate :: { automaton :: { fmt_state_indicator , sparse_transitions } , util :: debug :: DebugByte , } ; f . write_fmt (format_args ! ("noncontiguous::NFA(\n")) ? ; for (sid , state) in self . states . iter () . with_state_ids () { if sid == NFA :: FAIL { f . write_fmt (format_args ! ("F {0:06}:\n" , sid . as_usize ())) ? ; continue ; } fmt_state_indicator (f , self , sid) ? ; f . write_fmt (format_args ! ("{0:06}({1:06}): " , sid . as_usize () , state . fail . as_usize () ,) ,) ? ; let it = sparse_transitions (self . iter_trans (sid) . map (| t | (t . byte , t . next)) ,) . enumerate () ; for (i , (start , end , sid)) in it { if i > 0 { f . write_fmt (format_args ! (", ")) ? ; } if start == end { f . write_fmt (format_args ! ("{0:?} => {1:?}" , DebugByte (start) , sid . as_usize () ,) ,) ? ; } else { f . write_fmt (format_args ! ("{0:?}-{1:?} => {2:?}" , DebugByte (start) , DebugByte (end) , sid . as_usize () ,) ,) ? ; } } f . write_fmt (format_args ! ("\n")) ? ; if self . is_match (sid) { f . write_fmt (format_args ! ("         matches: ")) ? ; for (i , pid) in self . iter_matches (sid) . enumerate () { if i > 0 { f . write_fmt (format_args ! (", ")) ? ; } f . write_fmt (format_args ! ("{0}" , pid . as_usize ())) ? ; } f . write_fmt (format_args ! ("\n")) ? ; } } f . write_fmt (format_args ! ("match kind: {0:?}\n" , self . match_kind)) ? ; f . write_fmt (format_args ! ("prefilter: {0:?}\n" , self . prefilter . is_some ()) ,) ? ; f . write_fmt (format_args ! ("state length: {0:?}\n" , self . states . len ())) ? ; f . write_fmt (format_args ! ("pattern length: {0:?}\n" , self . patterns_len ()) ,) ? ; f . write_fmt (format_args ! ("shortest pattern length: {0:?}\n" , self . min_pattern_len ,) ,) ? ; f . write_fmt (format_args ! ("longest pattern length: {0:?}\n" , self . max_pattern_len) ,) ? ; f . write_fmt (format_args ! ("memory usage: {0:?}\n" , self . memory_usage ())) ? ; f . write_fmt (format_args ! (")\n")) ? ; Ok (()) } } } }