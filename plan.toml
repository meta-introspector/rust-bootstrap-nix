# plan.toml
title = "Advanced Rust Project Analysis and Level 0 Knowledgebase Construction"
description = "A detailed plan to extract comprehensive data from Rust Cargo crates, instrument the compiler, build a Level 0 knowledgebase, and prepare data for a Minizinc solver."
status = "draft"
created_at = "2025-11-01T12:00:00Z" # Placeholder for current timestamp

[[stages]]
id = 1
name = "Project Discovery and Initial Data Collection"
description = "Identify all Cargo projects and extract initial metadata and dependency information."

    [[stages.steps]]
    id = "1.1"
    name = "Identify Cargo Projects in ~/nix/"
    description = "Locate all Cargo.toml files within the specified ~/nix/ directory."
    tool = "glob"
    command = "glob('**/Cargo.toml', path='/data/data/com.termux.nix/files/home/nix/')"
    output_variable = "nix_cargo_projects"
    expected_output = "List of absolute paths to Cargo.toml files in ~/nix/."

    [[stages.steps]]
    id = "1.2"
    name = "Build hf-dataset-validator (cargo2hf_extractor)"
    description = "Ensure the hf-dataset-validator binary is built and available for extracting Cargo information."
    tool = "run_shell_command"
    command = "cargo build --release --package hf-dataset-validator"
    directory = "/data/data/com.termux.nix/files/home/pick-up-nix2/vendor/rust/platform-tools-agave-rust-solana/vendor/rust-src/vendor/rust/rust-bootstrap-nix/vendor/rust/hugging-face-dataset-validator-rust"
    expected_output = "Successful build of the hf-dataset-validator crate."

    [[stages.steps]]
    id = "1.3"
    name = "Define Output Directory for Raw Data"
    description = "Specify the directory where the raw extracted data (Parquet files) will be stored."
    action = "define_variable"
    variable_name = "raw_data_output_dir"
    value = "/data/data/com.termux.nix/files/home/pick-up-nix2/generated_raw_cargo_data"
    expected_output = "Output directory path defined."

    [[stages.steps]]
    id = "1.4"
    name = "Create Output Directory for Raw Data"
    description = "Create the specified raw data output directory if it does not already exist."
    tool = "run_shell_command"
    command = "mkdir -p {{raw_data_output_dir}}"
    expected_output = "Output directory created."

    [[stages.steps]]
    id = "1.5"
    name = "Extract Initial Cargo Information for Each Project"
    description = "Iterate through each identified Cargo project and execute the hf-dataset-validator for ProjectMetadata and DependencyAnalysis phases."
    loop_over = "nix_cargo_projects"
    loop_variable = "project_manifest_path"
    sub_steps = [
        {
            id = "1.5.1"
            name = "Determine Project Root"
            description = "Extract the project root path from the Cargo.toml manifest path."
            action = "derive_variable"
            variable_name = "project_root"
            value = "{{dirname(project_manifest_path)}}" # Placeholder for dirname function
            expected_output = "Project root path derived."
        },
        {
            id = "1.5.2"
            name = "Execute hf-dataset-validator for Metadata and Dependencies"
            description = "Run the hf-dataset-validator for the current project, extracting ProjectMetadata and DependencyAnalysis."
            tool = "run_shell_command"
            command = '''
                nix develop --command bash -c "/data/data/com.termux.nix/files/home/pick-up-nix2/vendor/rust/platform-tools-agave-rust-solana/vendor/rust-src/vendor/rust/rust-bootstrap-nix/vendor/rust/hugging-face-dataset-validator-rust/target/release/hf-validator \
                --project-path \"{{project_root}}\" \
                --phases ProjectMetadata DependencyAnalysis \
                --output-dir \"{{raw_data_output_dir}}\" \
                --include-dependencies"
            '''
            directory = "/data/data/com.termux.nix/files/home/pick-up-nix2/vendor/rust/platform-tools-agave-rust-solana/vendor/rust-src/vendor/rust/rust-bootstrap-nix/vendor/rust/hugging-face-dataset-validator-rust"
            expected_output = "Parquet files generated for ProjectMetadata and DependencyAnalysis for the current project."
        }
    ]

[[stages]]
id = 2
name = "Compiler Instrumentation and Advanced Data Collection"
description = "Set up and execute compiler instrumentation to capture detailed build traces, ASTs, and other intermediate representations."
status = "TODO" # This stage requires significant development and is marked as TODO for now.

    [[stages.steps]]
    id = "2.1"
    name = "Develop Compiler Instrumentation Tool"
    description = "Create or adapt a tool to hook into rustc and LLVM to dump intermediate representations (AST, HIR, MIR, LLVM IR) and execution traces during compilation."
    status = "TODO"

    [[stages.steps]]
    id = "2.2"
    name = "Integrate Instrumentation with Cargo Build"
    description = "Modify Cargo's build process (e.g., via RUSTFLAGS, custom build scripts, or a Cargo subcommand) to use the instrumentation tool during compilation of each crate."
    status = "TODO"

    [[stages.steps]]
    id = "2.3"
    name = "Execute Instrumented Builds for All Projects"
    description = "Run instrumented builds for all identified Cargo projects, collecting all specified dumps and traces."
    status = "TODO"

    [[stages.steps]]
    id = "2.4"
    name = "Nixify Cargo Expand Output Capture"
    description = "For each package with non-zero cargo expand output, create a Nix flake to run the expansion and capture the expanded output in the Nix store. This ensures that the expanded code is versioned and reproducible within the Nix ecosystem."
    status = "TODO"

[[stages]]
id = 3
name = "Data Processing and Level 0 Knowledgebase Construction"
description = "Process the collected raw data, extract key information, and build the Level 0 knowledgebase."
status = "TODO"

    [[stages.steps]]
    id = "3.1"
    name = "Process Raw Dumps and Traces"
    description = "Develop parsers and processors for the various compiler dumps (ASTs, IRs) and execution traces to extract relevant data."
    status = "TODO"

    [[stages.steps]]
    id = "3.2"
    name = "Extract Constants, Names, and IDs"
    description = "From the processed data, identify and extract all constants, names, and unique identifiers."
    status = "TODO"

    [[stages.steps]]
    id = "3.3"
    name = "Build Level 0 Knowledgebase Index"
    description = "Organize the extracted constants, names, and IDs into a tree structure of 4KB blocks, forming the Level 0 knowledgebase index."
    status = "TODO"

[[stages]]
id = 4
name = "Crate Usage Analysis and Refactoring for Lattice Construction"
description = "Analyze declaration-level crate usage, refactor into client-X crates, and decouple API types using traits to build a lattice of crate dependencies."
status = "TODO"

    [[stages.steps]]
    id = "4.1"
    name = "Extract Declaration-Level Crate Usage"
    description = "Identify all declarations and the external crates they directly use."
    status = "TODO"

    [[stages.steps]]
    id = "4.2"
    name = "Group Declarations into Client Crates"
    description = "Group declarations into new 'client-X' or 'client-X-Y' crates based on their primary external crate dependencies, aiming for the 'one external crate per module' principle."
    status = "TODO"

    [[stages.steps]]
    id = "4.3"
    name = "Decouple API Types using Traits"
    description = "Refactor client crates to export functions via traits, decoupling them from concrete bound API types to enhance modularity and flexibility."
    status = "TODO"

[[stages]]
id = 5
name = "Minizinc Solver Integration"
description = "Prepare the Level 0 knowledgebase as input for a Minizinc solver and execute the solver."
status = "TODO"

    [[stages.steps]]
    id = "5.1"
    name = "Format Knowledgebase for Minizinc"
    description = "Convert the Level 0 knowledgebase into a format suitable for input to a Minizinc solver."
    status = "TODO"

    [[stages.steps]]
    id = "5.2"
    name = "Execute Minizinc Solver"
    description = "Run the Minizinc solver with the prepared input data."
    status = "TODO"
