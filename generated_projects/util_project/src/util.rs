use std::collections::HashSet;
use split_expanded_lib::{DeclarationItem};

pub (crate) mod util { pub (crate) mod alphabet { use crate :: util :: int :: Usize ; # [doc = " A representation of byte oriented equivalence classes."] # [doc = ""] # [doc = " This is used in finite state machines to reduce the size of the transition"] # [doc = " table. This can have a particularly large impact not only on the total size"] # [doc = " of an FSM, but also on FSM build times because it reduces the number of"] # [doc = " transitions that need to be visited/set."] pub (crate) struct ByteClasses ([u8 ; 256]) ; # [automatically_derived] impl :: core :: clone :: Clone for ByteClasses { # [inline] fn clone (& self) -> ByteClasses { let _ : :: core :: clone :: AssertParamIsClone < [u8 ; 256] > ; * self } } # [automatically_derived] impl :: core :: marker :: Copy for ByteClasses { } impl ByteClasses { # [doc = " Creates a new set of equivalence classes where all bytes are mapped to"] # [doc = " the same class."] pub (crate) fn empty () -> ByteClasses { ByteClasses ([0 ; 256]) } # [doc = " Creates a new set of equivalence classes where each byte belongs to"] # [doc = " its own equivalence class."] pub (crate) fn singletons () -> ByteClasses { let mut classes = ByteClasses :: empty () ; for b in 0 ..= 255 { classes . set (b , b) ; } classes } # [doc = " Set the equivalence class for the given byte."] # [inline] pub (crate) fn set (& mut self , byte : u8 , class : u8) { self . 0 [usize :: from (byte)] = class ; } # [doc = " Get the equivalence class for the given byte."] # [inline] pub (crate) fn get (& self , byte : u8) -> u8 { self . 0 [usize :: from (byte)] } # [doc = " Return the total number of elements in the alphabet represented by"] # [doc = " these equivalence classes. Equivalently, this returns the total number"] # [doc = " of equivalence classes."] # [inline] pub (crate) fn alphabet_len (& self) -> usize { usize :: from (self . 0 [255]) + 1 } # [doc = " Returns the stride, as a base-2 exponent, required for these"] # [doc = " equivalence classes."] # [doc = ""] # [doc = " The stride is always the smallest power of 2 that is greater than or"] # [doc = " equal to the alphabet length. This is done so that converting between"] # [doc = " state IDs and indices can be done with shifts alone, which is much"] # [doc = " faster than integer division. The \"stride2\" is the exponent. i.e.,"] # [doc = " `2^stride2 = stride`."] pub (crate) fn stride2 (& self) -> usize { let zeros = self . alphabet_len () . next_power_of_two () . trailing_zeros () ; usize :: try_from (zeros) . unwrap () } # [doc = " Returns the stride for these equivalence classes, which corresponds"] # [doc = " to the smallest power of 2 greater than or equal to the number of"] # [doc = " equivalence classes."] pub (crate) fn stride (& self) -> usize { 1 << self . stride2 () } # [doc = " Returns true if and only if every byte in this class maps to its own"] # [doc = " equivalence class. Equivalently, there are 257 equivalence classes"] # [doc = " and each class contains exactly one byte (plus the special EOI class)."] # [inline] pub (crate) fn is_singleton (& self) -> bool { self . alphabet_len () == 256 } # [doc = " Returns an iterator over all equivalence classes in this set."] pub (crate) fn iter (& self) -> ByteClassIter { ByteClassIter { it : 0 .. self . alphabet_len () , } } # [doc = " Returns an iterator of the bytes in the given equivalence class."] pub (crate) fn elements (& self , class : u8) -> ByteClassElements { ByteClassElements { classes : self , class , bytes : 0 ..= 255 , } } # [doc = " Returns an iterator of byte ranges in the given equivalence class."] # [doc = ""] # [doc = " That is, a sequence of contiguous ranges are returned. Typically, every"] # [doc = " class maps to a single contiguous range."] fn element_ranges (& self , class : u8) -> ByteClassElementRanges { ByteClassElementRanges { elements : self . elements (class) , range : None , } } } impl core :: fmt :: Debug for ByteClasses { fn fmt (& self , f : & mut core :: fmt :: Formatter < '_ >) -> core :: fmt :: Result { if self . is_singleton () { f . write_fmt (format_args ! ("ByteClasses(<one-class-per-byte>)")) } else { f . write_fmt (format_args ! ("ByteClasses(")) ? ; for (i , class) in self . iter () . enumerate () { if i > 0 { f . write_fmt (format_args ! (", ")) ? ; } f . write_fmt (format_args ! ("{0:?} => [" , class)) ? ; for (start , end) in self . element_ranges (class) { if start == end { f . write_fmt (format_args ! ("{0:?}" , start)) ? ; } else { f . write_fmt (format_args ! ("{0:?}-{1:?}" , start , end)) ? ; } } f . write_fmt (format_args ! ("]")) ? ; } f . write_fmt (format_args ! (")")) } } } # [doc = " An iterator over each equivalence class."] pub (crate) struct ByteClassIter { it : core :: ops :: Range < usize > , } # [automatically_derived] impl :: core :: fmt :: Debug for ByteClassIter { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field1_finish (f , "ByteClassIter" , "it" , & & self . it ,) } } impl Iterator for ByteClassIter { type Item = u8 ; fn next (& mut self) -> Option < u8 > { self . it . next () . map (| class | class . as_u8 ()) } } # [doc = " An iterator over all elements in a specific equivalence class."] pub (crate) struct ByteClassElements < 'a > { classes : & 'a ByteClasses , class : u8 , bytes : core :: ops :: RangeInclusive < u8 > , } # [automatically_derived] impl < 'a > :: core :: fmt :: Debug for ByteClassElements < 'a > { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field3_finish (f , "ByteClassElements" , "classes" , & self . classes , "class" , & self . class , "bytes" , & & self . bytes ,) } } impl < 'a > Iterator for ByteClassElements < 'a > { type Item = u8 ; fn next (& mut self) -> Option < u8 > { while let Some (byte) = self . bytes . next () { if self . class == self . classes . get (byte) { return Some (byte) ; } } None } } # [doc = " An iterator over all elements in an equivalence class expressed as a"] # [doc = " sequence of contiguous ranges."] pub (crate) struct ByteClassElementRanges < 'a > { elements : ByteClassElements < 'a > , range : Option < (u8 , u8) > , } # [automatically_derived] impl < 'a > :: core :: fmt :: Debug for ByteClassElementRanges < 'a > { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field2_finish (f , "ByteClassElementRanges" , "elements" , & self . elements , "range" , & & self . range ,) } } impl < 'a > Iterator for ByteClassElementRanges < 'a > { type Item = (u8 , u8) ; fn next (& mut self) -> Option < (u8 , u8) > { loop { let element = match self . elements . next () { None => return self . range . take () , Some (element) => element , } ; match self . range . take () { None => { self . range = Some ((element , element)) ; } Some ((start , end)) => { if usize :: from (end) + 1 != usize :: from (element) { self . range = Some ((element , element)) ; return Some ((start , end)) ; } self . range = Some ((start , element)) ; } } } } } # [doc = " A partitioning of bytes into equivalence classes."] # [doc = ""] # [doc = " A byte class set keeps track of an *approximation* of equivalence classes"] # [doc = " of bytes during NFA construction. That is, every byte in an equivalence"] # [doc = " class cannot discriminate between a match and a non-match."] # [doc = ""] # [doc = " Note that this may not compute the minimal set of equivalence classes."] # [doc = " Basically, any byte in a pattern given to the noncontiguous NFA builder"] # [doc = " will automatically be treated as its own equivalence class. All other"] # [doc = " bytes---any byte not in any pattern---will be treated as their own"] # [doc = " equivalence classes. In theory, all bytes not in any pattern should"] # [doc = " be part of a single equivalence class, but in practice, we only treat"] # [doc = " contiguous ranges of bytes as an equivalence class. So the number of"] # [doc = " classes computed may be bigger than necessary. This usually doesn't make"] # [doc = " much of a difference, and keeps the implementation simple."] pub (crate) struct ByteClassSet (ByteSet) ; # [automatically_derived] impl :: core :: clone :: Clone for ByteClassSet { # [inline] fn clone (& self) -> ByteClassSet { ByteClassSet (:: core :: clone :: Clone :: clone (& self . 0)) } } # [automatically_derived] impl :: core :: fmt :: Debug for ByteClassSet { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , "ByteClassSet" , & & self . 0 ,) } } impl Default for ByteClassSet { fn default () -> ByteClassSet { ByteClassSet :: empty () } } impl ByteClassSet { # [doc = " Create a new set of byte classes where all bytes are part of the same"] # [doc = " equivalence class."] pub (crate) fn empty () -> Self { ByteClassSet (ByteSet :: empty ()) } # [doc = " Indicate the the range of byte given (inclusive) can discriminate a"] # [doc = " match between it and all other bytes outside of the range."] pub (crate) fn set_range (& mut self , start : u8 , end : u8) { if true { if ! (start <= end) { :: core :: panicking :: panic ("assertion failed: start <= end") } } if start > 0 { self . 0 . add (start - 1) ; } self . 0 . add (end) ; } # [doc = " Convert this boolean set to a map that maps all byte values to their"] # [doc = " corresponding equivalence class. The last mapping indicates the largest"] # [doc = " equivalence class identifier (which is never bigger than 255)."] pub (crate) fn byte_classes (& self) -> ByteClasses { let mut classes = ByteClasses :: empty () ; let mut class = 0u8 ; let mut b = 0u8 ; loop { classes . set (b , class) ; if b == 255 { break ; } if self . 0 . contains (b) { class = class . checked_add (1) . unwrap () ; } b = b . checked_add (1) . unwrap () ; } classes } } # [doc = " A simple set of bytes that is reasonably cheap to copy and allocation free."] pub (crate) struct ByteSet { bits : BitSet , } # [automatically_derived] impl :: core :: clone :: Clone for ByteSet { # [inline] fn clone (& self) -> ByteSet { let _ : :: core :: clone :: AssertParamIsClone < BitSet > ; * self } } # [automatically_derived] impl :: core :: marker :: Copy for ByteSet { } # [automatically_derived] impl :: core :: fmt :: Debug for ByteSet { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field1_finish (f , "ByteSet" , "bits" , & & self . bits ,) } } # [automatically_derived] impl :: core :: default :: Default for ByteSet { # [inline] fn default () -> ByteSet { ByteSet { bits : :: core :: default :: Default :: default () , } } } # [automatically_derived] impl :: core :: cmp :: Eq for ByteSet { # [inline] # [doc (hidden)] # [coverage (off)] fn assert_receiver_is_total_eq (& self) -> () { let _ : :: core :: cmp :: AssertParamIsEq < BitSet > ; } } # [automatically_derived] impl :: core :: marker :: StructuralPartialEq for ByteSet { } # [automatically_derived] impl :: core :: cmp :: PartialEq for ByteSet { # [inline] fn eq (& self , other : & ByteSet) -> bool { self . bits == other . bits } } # [doc = " The representation of a byte set. Split out so that we can define a"] # [doc = " convenient Debug impl for it while keeping \"ByteSet\" in the output."] struct BitSet ([u128 ; 2]) ; # [automatically_derived] impl :: core :: clone :: Clone for BitSet { # [inline] fn clone (& self) -> BitSet { let _ : :: core :: clone :: AssertParamIsClone < [u128 ; 2] > ; * self } } # [automatically_derived] impl :: core :: marker :: Copy for BitSet { } # [automatically_derived] impl :: core :: default :: Default for BitSet { # [inline] fn default () -> BitSet { BitSet (:: core :: default :: Default :: default ()) } } # [automatically_derived] impl :: core :: cmp :: Eq for BitSet { # [inline] # [doc (hidden)] # [coverage (off)] fn assert_receiver_is_total_eq (& self) -> () { let _ : :: core :: cmp :: AssertParamIsEq < [u128 ; 2] > ; } } # [automatically_derived] impl :: core :: marker :: StructuralPartialEq for BitSet { } # [automatically_derived] impl :: core :: cmp :: PartialEq for BitSet { # [inline] fn eq (& self , other : & BitSet) -> bool { self . 0 == other . 0 } } impl ByteSet { # [doc = " Create an empty set of bytes."] pub (crate) fn empty () -> ByteSet { ByteSet { bits : BitSet ([0 ; 2]) } } # [doc = " Add a byte to this set."] # [doc = ""] # [doc = " If the given byte already belongs to this set, then this is a no-op."] pub (crate) fn add (& mut self , byte : u8) { let bucket = byte / 128 ; let bit = byte % 128 ; self . bits . 0 [usize :: from (bucket)] |= 1 << bit ; } # [doc = " Return true if and only if the given byte is in this set."] pub (crate) fn contains (& self , byte : u8) -> bool { let bucket = byte / 128 ; let bit = byte % 128 ; self . bits . 0 [usize :: from (bucket)] & (1 << bit) > 0 } } impl core :: fmt :: Debug for BitSet { fn fmt (& self , f : & mut core :: fmt :: Formatter) -> core :: fmt :: Result { let mut fmtd = f . debug_set () ; for b in 0u8 ..= 255 { if (ByteSet { bits : * self }) . contains (b) { fmtd . entry (& b) ; } } fmtd . finish () } } } pub (crate) mod buffer { use alloc :: { vec , vec :: Vec } ; # [doc = " The default buffer capacity that we use for the stream buffer."] const DEFAULT_BUFFER_CAPACITY : usize = 64 * (1 << 10) ; # [doc = " A fairly simple roll buffer for supporting stream searches."] # [doc = ""] # [doc = " This buffer acts as a temporary place to store a fixed amount of data when"] # [doc = " reading from a stream. Its central purpose is to allow \"rolling\" some"] # [doc = " suffix of the data to the beginning of the buffer before refilling it with"] # [doc = " more data from the stream. For example, let's say we are trying to match"] # [doc = " \"foobar\" on a stream. When we report the match, we'd like to not only"] # [doc = " report the correct offsets at which the match occurs, but also the matching"] # [doc = " bytes themselves. So let's say our stream is a file with the following"] # [doc = " contents: `test test foobar test test`. Now assume that we happen to read"] # [doc = " the aforementioned file in two chunks: `test test foo` and `bar test test`."] # [doc = " Naively, it would not be possible to report a single contiguous `foobar`"] # [doc = " match, but this roll buffer allows us to do that. Namely, after the second"] # [doc = " read, the contents of the buffer should be `st foobar test test`, where the"] # [doc = " search should ultimately resume immediately after `foo`. (The prefix `st `"] # [doc = " is included because the roll buffer saves N bytes at the end of the buffer,"] # [doc = " where N is the maximum possible length of a match.)"] # [doc = ""] # [doc = " A lot of the logic for dealing with this is unfortunately split out between"] # [doc = " this roll buffer and the `StreamChunkIter`."] # [doc = ""] # [doc = " Note also that this buffer is not actually required to just report matches."] # [doc = " Because a `Match` is just some offsets. But it *is* required for supporting"] # [doc = " things like `try_stream_replace_all` because that needs some mechanism for"] # [doc = " knowing which bytes in the stream correspond to a match and which don't. So"] # [doc = " when a match occurs across two `read` calls, *something* needs to retain"] # [doc = " the bytes from the previous `read` call because you don't know before the"] # [doc = " second read call whether a match exists or not."] pub (crate) struct Buffer { # [doc = " The raw buffer contents. This has a fixed size and never increases."] buf : Vec < u8 > , # [doc = " The minimum size of the buffer, which is equivalent to the maximum"] # [doc = " possible length of a match. This corresponds to the amount that we"] # [doc = " roll"] min : usize , # [doc = " The end of the contents of this buffer."] end : usize , } # [automatically_derived] impl :: core :: fmt :: Debug for Buffer { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field3_finish (f , "Buffer" , "buf" , & self . buf , "min" , & self . min , "end" , & & self . end ,) } } impl Buffer { # [doc = " Create a new buffer for stream searching. The minimum buffer length"] # [doc = " given should be the size of the maximum possible match length."] pub (crate) fn new (min_buffer_len : usize) -> Buffer { let min = core :: cmp :: max (1 , min_buffer_len) ; let capacity = core :: cmp :: max (min * 8 , DEFAULT_BUFFER_CAPACITY) ; Buffer { buf : :: alloc :: vec :: from_elem (0 , capacity) , min , end : 0 , } } # [doc = " Return the contents of this buffer."] # [inline] pub (crate) fn buffer (& self) -> & [u8] { & self . buf [.. self . end] } # [doc = " Return the minimum size of the buffer. The only way a buffer may be"] # [doc = " smaller than this is if the stream itself contains less than the"] # [doc = " minimum buffer amount."] # [inline] pub (crate) fn min_buffer_len (& self) -> usize { self . min } # [doc = " Return all free capacity in this buffer."] fn free_buffer (& mut self) -> & mut [u8] { & mut self . buf [self . end ..] } # [doc = " Refill the contents of this buffer by reading as much as possible into"] # [doc = " this buffer's free capacity. If no more bytes could be read, then this"] # [doc = " returns false. Otherwise, this reads until it has filled the buffer"] # [doc = " past the minimum amount."] pub (crate) fn fill < R : std :: io :: Read > (& mut self , mut rdr : R ,) -> std :: io :: Result < bool > { let mut readany = false ; loop { let readlen = rdr . read (self . free_buffer ()) ? ; if readlen == 0 { return Ok (readany) ; } readany = true ; self . end += readlen ; if self . buffer () . len () >= self . min { return Ok (true) ; } } } # [doc = " Roll the contents of the buffer so that the suffix of this buffer is"] # [doc = " moved to the front and all other contents are dropped. The size of the"] # [doc = " suffix corresponds precisely to the minimum buffer length."] # [doc = ""] # [doc = " This should only be called when the entire contents of this buffer have"] # [doc = " been searched."] pub (crate) fn roll (& mut self) { let roll_start = self . end . checked_sub (self . min) . expect ("buffer capacity should be bigger than minimum amount") ; let roll_end = roll_start + self . min ; if ! (roll_end <= self . end) { :: core :: panicking :: panic ("assertion failed: roll_end <= self.end") } self . buf . copy_within (roll_start .. roll_end , 0) ; self . end = self . min ; } } } pub (crate) mod byte_frequencies { pub const BYTE_FREQUENCIES : [u8 ; 256] = [55 , 52 , 51 , 50 , 49 , 48 , 47 , 46 , 45 , 103 , 242 , 66 , 67 , 229 , 44 , 43 , 42 , 41 , 40 , 39 , 38 , 37 , 36 , 35 , 34 , 33 , 56 , 32 , 31 , 30 , 29 , 28 , 255 , 148 , 164 , 149 , 136 , 160 , 155 , 173 , 221 , 222 , 134 , 122 , 232 , 202 , 215 , 224 , 208 , 220 , 204 , 187 , 183 , 179 , 177 , 168 , 178 , 200 , 226 , 195 , 154 , 184 , 174 , 126 , 120 , 191 , 157 , 194 , 170 , 189 , 162 , 161 , 150 , 193 , 142 , 137 , 171 , 176 , 185 , 167 , 186 , 112 , 175 , 192 , 188 , 156 , 140 , 143 , 123 , 133 , 128 , 147 , 138 , 146 , 114 , 223 , 151 , 249 , 216 , 238 , 236 , 253 , 227 , 218 , 230 , 247 , 135 , 180 , 241 , 233 , 246 , 244 , 231 , 139 , 245 , 243 , 251 , 235 , 201 , 196 , 240 , 214 , 152 , 182 , 205 , 181 , 127 , 27 , 212 , 211 , 210 , 213 , 228 , 197 , 169 , 159 , 131 , 172 , 105 , 80 , 98 , 96 , 97 , 81 , 207 , 145 , 116 , 115 , 144 , 130 , 153 , 121 , 107 , 132 , 109 , 110 , 124 , 111 , 82 , 108 , 118 , 141 , 113 , 129 , 119 , 125 , 165 , 117 , 92 , 106 , 83 , 72 , 99 , 93 , 65 , 79 , 166 , 237 , 163 , 199 , 190 , 225 , 209 , 203 , 198 , 217 , 219 , 206 , 234 , 248 , 158 , 239 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 ,] ; } pub (crate) mod debug { # [doc = " A type that wraps a single byte with a convenient fmt::Debug impl that"] # [doc = " escapes the byte."] pub (crate) struct DebugByte (pub (crate) u8) ; impl core :: fmt :: Debug for DebugByte { fn fmt (& self , f : & mut core :: fmt :: Formatter) -> core :: fmt :: Result { if self . 0 == b' ' { return f . write_fmt (format_args ! ("\' \'")) ; } let mut bytes = [0u8 ; 10] ; let mut len = 0 ; for (i , mut b) in core :: ascii :: escape_default (self . 0) . enumerate () { if i >= 2 && b'a' <= b && b <= b'f' { b -= 32 ; } bytes [len] = b ; len += 1 ; } f . write_fmt (format_args ! ("{0}" , core :: str :: from_utf8 (& bytes [.. len]) . unwrap ()) ,) } } } pub (crate) mod error { use crate :: util :: { primitives :: { PatternID , SmallIndex } , search :: MatchKind , } ; # [doc = " An error that occurred during the construction of an Aho-Corasick"] # [doc = " automaton."] # [doc = ""] # [doc = " Build errors occur when some kind of limit has been exceeded, either in the"] # [doc = " number of states, the number of patterns of the length of a pattern. These"] # [doc = " limits aren't part of the public API, but they should generally be large"] # [doc = " enough to handle most use cases."] # [doc = ""] # [doc = " When the `std` feature is enabled, this implements the `std::error::Error`"] # [doc = " trait."] pub struct BuildError { kind : ErrorKind , } # [automatically_derived] impl :: core :: clone :: Clone for BuildError { # [inline] fn clone (& self) -> BuildError { BuildError { kind : :: core :: clone :: Clone :: clone (& self . kind) , } } } # [automatically_derived] impl :: core :: fmt :: Debug for BuildError { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field1_finish (f , "BuildError" , "kind" , & & self . kind ,) } } # [doc = " The kind of error that occurred."] enum ErrorKind { # [doc = " An error that occurs when allocating a new state would result in an"] # [doc = " identifier that exceeds the capacity of a `StateID`."] StateIDOverflow { # [doc = " The maximum possible id."] max : u64 , # [doc = " The maximum ID requested."] requested_max : u64 , } , # [doc = " An error that occurs when adding a pattern to an Aho-Corasick"] # [doc = " automaton would result in an identifier that exceeds the capacity of a"] # [doc = " `PatternID`."] PatternIDOverflow { # [doc = " The maximum possible id."] max : u64 , # [doc = " The maximum ID requested."] requested_max : u64 , } , # [doc = " Occurs when a pattern string is given to the Aho-Corasick constructor"] # [doc = " that is too long."] PatternTooLong { # [doc = " The ID of the pattern that was too long."] pattern : PatternID , # [doc = " The length that was too long."] len : usize , } , } # [automatically_derived] impl :: core :: clone :: Clone for ErrorKind { # [inline] fn clone (& self) -> ErrorKind { match self { ErrorKind :: StateIDOverflow { max : __self_0 , requested_max : __self_1 , } => { ErrorKind :: StateIDOverflow { max : :: core :: clone :: Clone :: clone (__self_0) , requested_max : :: core :: clone :: Clone :: clone (__self_1) , } } ErrorKind :: PatternIDOverflow { max : __self_0 , requested_max : __self_1 , } => { ErrorKind :: PatternIDOverflow { max : :: core :: clone :: Clone :: clone (__self_0) , requested_max : :: core :: clone :: Clone :: clone (__self_1) , } } ErrorKind :: PatternTooLong { pattern : __self_0 , len : __self_1 } => { ErrorKind :: PatternTooLong { pattern : :: core :: clone :: Clone :: clone (__self_0) , len : :: core :: clone :: Clone :: clone (__self_1) , } } } } } # [automatically_derived] impl :: core :: fmt :: Debug for ErrorKind { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { match self { ErrorKind :: StateIDOverflow { max : __self_0 , requested_max : __self_1 , } => { :: core :: fmt :: Formatter :: debug_struct_field2_finish (f , "StateIDOverflow" , "max" , __self_0 , "requested_max" , & __self_1 ,) } ErrorKind :: PatternIDOverflow { max : __self_0 , requested_max : __self_1 , } => { :: core :: fmt :: Formatter :: debug_struct_field2_finish (f , "PatternIDOverflow" , "max" , __self_0 , "requested_max" , & __self_1 ,) } ErrorKind :: PatternTooLong { pattern : __self_0 , len : __self_1 } => { :: core :: fmt :: Formatter :: debug_struct_field2_finish (f , "PatternTooLong" , "pattern" , __self_0 , "len" , & __self_1 ,) } } } } impl BuildError { pub (crate) fn state_id_overflow (max : u64 , requested_max : u64) -> BuildError { BuildError { kind : ErrorKind :: StateIDOverflow { max , requested_max , } , } } pub (crate) fn pattern_id_overflow (max : u64 , requested_max : u64 ,) -> BuildError { BuildError { kind : ErrorKind :: PatternIDOverflow { max , requested_max , } , } } pub (crate) fn pattern_too_long (pattern : PatternID , len : usize ,) -> BuildError { BuildError { kind : ErrorKind :: PatternTooLong { pattern , len , } , } } } impl std :: error :: Error for BuildError { } impl core :: fmt :: Display for BuildError { fn fmt (& self , f : & mut core :: fmt :: Formatter < '_ >) -> core :: fmt :: Result { match self . kind { ErrorKind :: StateIDOverflow { max , requested_max } => { f . write_fmt (format_args ! ("state identifier overflow: failed to create state ID from {0}, which exceeds the max of {1}" , requested_max , max ,) ,) } ErrorKind :: PatternIDOverflow { max , requested_max } => { f . write_fmt (format_args ! ("pattern identifier overflow: failed to create pattern ID from {0}, which exceeds the max of {1}" , requested_max , max ,) ,) } ErrorKind :: PatternTooLong { pattern , len } => { f . write_fmt (format_args ! ("pattern {0} with length {1} exceeds the maximum pattern length of {2}" , pattern . as_usize () , len , SmallIndex :: MAX . as_usize () ,) ,) } } } } # [doc = " An error that occurred during an Aho-Corasick search."] # [doc = ""] # [doc = " An error that occurs during a search is limited to some kind of"] # [doc = " misconfiguration that resulted in an illegal call. Stated differently,"] # [doc = " whether an error occurs is not dependent on the specific bytes in the"] # [doc = " haystack."] # [doc = ""] # [doc = " Examples of misconfiguration:"] # [doc = ""] # [doc = " * Executing a stream or overlapping search on a searcher that was built was"] # [doc = " something other than [`MatchKind::Standard`](crate::MatchKind::Standard)"] # [doc = " semantics."] # [doc = " * Requested an anchored or an unanchored search on a searcher that doesn't"] # [doc = " support unanchored or anchored searches, respectively."] # [doc = ""] # [doc = " When the `std` feature is enabled, this implements the `std::error::Error`"] # [doc = " trait."] pub struct MatchError (alloc :: boxed :: Box < MatchErrorKind >) ; # [automatically_derived] impl :: core :: clone :: Clone for MatchError { # [inline] fn clone (& self) -> MatchError { MatchError (:: core :: clone :: Clone :: clone (& self . 0)) } } # [automatically_derived] impl :: core :: fmt :: Debug for MatchError { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , "MatchError" , & & self . 0 ,) } } # [automatically_derived] impl :: core :: cmp :: Eq for MatchError { # [inline] # [doc (hidden)] # [coverage (off)] fn assert_receiver_is_total_eq (& self) -> () { let _ : :: core :: cmp :: AssertParamIsEq < alloc :: boxed :: Box < MatchErrorKind > > ; } } # [automatically_derived] impl :: core :: marker :: StructuralPartialEq for MatchError { } # [automatically_derived] impl :: core :: cmp :: PartialEq for MatchError { # [inline] fn eq (& self , other : & MatchError) -> bool { self . 0 == other . 0 } } impl MatchError { # [doc = " Create a new error value with the given kind."] # [doc = ""] # [doc = " This is a more verbose version of the kind-specific constructors, e.g.,"] # [doc = " `MatchError::unsupported_stream`."] pub fn new (kind : MatchErrorKind) -> MatchError { MatchError (alloc :: boxed :: Box :: new (kind)) } # [doc = " Returns a reference to the underlying error kind."] pub fn kind (& self) -> & MatchErrorKind { & self . 0 } # [doc = " Create a new \"invalid anchored search\" error. This occurs when the"] # [doc = " caller requests an anchored search but where anchored searches aren't"] # [doc = " supported."] # [doc = ""] # [doc = " This is the same as calling `MatchError::new` with a"] # [doc = " [`MatchErrorKind::InvalidInputAnchored`] kind."] pub fn invalid_input_anchored () -> MatchError { MatchError :: new (MatchErrorKind :: InvalidInputAnchored) } # [doc = " Create a new \"invalid unanchored search\" error. This occurs when the"] # [doc = " caller requests an unanchored search but where unanchored searches"] # [doc = " aren't supported."] # [doc = ""] # [doc = " This is the same as calling `MatchError::new` with a"] # [doc = " [`MatchErrorKind::InvalidInputUnanchored`] kind."] pub fn invalid_input_unanchored () -> MatchError { MatchError :: new (MatchErrorKind :: InvalidInputUnanchored) } # [doc = " Create a new \"unsupported stream search\" error. This occurs when the"] # [doc = " caller requests a stream search while using an Aho-Corasick automaton"] # [doc = " with a match kind other than [`MatchKind::Standard`]."] # [doc = ""] # [doc = " The match kind given should be the match kind of the automaton. It"] # [doc = " should never be `MatchKind::Standard`."] pub fn unsupported_stream (got : MatchKind) -> MatchError { MatchError :: new (MatchErrorKind :: UnsupportedStream { got , }) } # [doc = " Create a new \"unsupported overlapping search\" error. This occurs when"] # [doc = " the caller requests an overlapping search while using an Aho-Corasick"] # [doc = " automaton with a match kind other than [`MatchKind::Standard`]."] # [doc = ""] # [doc = " The match kind given should be the match kind of the automaton. It"] # [doc = " should never be `MatchKind::Standard`."] pub fn unsupported_overlapping (got : MatchKind) -> MatchError { MatchError :: new (MatchErrorKind :: UnsupportedOverlapping { got , }) } # [doc = " Create a new \"unsupported empty pattern\" error. This occurs when the"] # [doc = " caller requests a search for which matching an automaton that contains"] # [doc = " an empty pattern string is not supported."] pub fn unsupported_empty () -> MatchError { MatchError :: new (MatchErrorKind :: UnsupportedEmpty) } } # [doc = " The underlying kind of a [`MatchError`]."] # [doc = ""] # [doc = " This is a **non-exhaustive** enum. That means new variants may be added in"] # [doc = " a semver-compatible release."] # [non_exhaustive] pub enum MatchErrorKind { # [doc = " An error indicating that an anchored search was requested, but from a"] # [doc = " searcher that was built without anchored support."] InvalidInputAnchored , # [doc = " An error indicating that an unanchored search was requested, but from a"] # [doc = " searcher that was built without unanchored support."] InvalidInputUnanchored , # [doc = " An error indicating that a stream search was attempted on an"] # [doc = " Aho-Corasick automaton with an unsupported `MatchKind`."] UnsupportedStream { # [doc = " The match semantics for the automaton that was used."] got : MatchKind , } , # [doc = " An error indicating that an overlapping search was attempted on an"] # [doc = " Aho-Corasick automaton with an unsupported `MatchKind`."] UnsupportedOverlapping { # [doc = " The match semantics for the automaton that was used."] got : MatchKind , } , # [doc = " An error indicating that the operation requested doesn't support"] # [doc = " automatons that contain an empty pattern string."] UnsupportedEmpty , } # [automatically_derived] impl :: core :: clone :: Clone for MatchErrorKind { # [inline] fn clone (& self) -> MatchErrorKind { match self { MatchErrorKind :: InvalidInputAnchored => { MatchErrorKind :: InvalidInputAnchored } MatchErrorKind :: InvalidInputUnanchored => { MatchErrorKind :: InvalidInputUnanchored } MatchErrorKind :: UnsupportedStream { got : __self_0 } => { MatchErrorKind :: UnsupportedStream { got : :: core :: clone :: Clone :: clone (__self_0) , } } MatchErrorKind :: UnsupportedOverlapping { got : __self_0 } => { MatchErrorKind :: UnsupportedOverlapping { got : :: core :: clone :: Clone :: clone (__self_0) , } } MatchErrorKind :: UnsupportedEmpty => MatchErrorKind :: UnsupportedEmpty , } } } # [automatically_derived] impl :: core :: fmt :: Debug for MatchErrorKind { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { match self { MatchErrorKind :: InvalidInputAnchored => { :: core :: fmt :: Formatter :: write_str (f , "InvalidInputAnchored") } MatchErrorKind :: InvalidInputUnanchored => { :: core :: fmt :: Formatter :: write_str (f , "InvalidInputUnanchored") } MatchErrorKind :: UnsupportedStream { got : __self_0 } => { :: core :: fmt :: Formatter :: debug_struct_field1_finish (f , "UnsupportedStream" , "got" , & __self_0 ,) } MatchErrorKind :: UnsupportedOverlapping { got : __self_0 } => { :: core :: fmt :: Formatter :: debug_struct_field1_finish (f , "UnsupportedOverlapping" , "got" , & __self_0 ,) } MatchErrorKind :: UnsupportedEmpty => { :: core :: fmt :: Formatter :: write_str (f , "UnsupportedEmpty") } } } } # [automatically_derived] impl :: core :: cmp :: Eq for MatchErrorKind { # [inline] # [doc (hidden)] # [coverage (off)] fn assert_receiver_is_total_eq (& self) -> () { let _ : :: core :: cmp :: AssertParamIsEq < MatchKind > ; } } # [automatically_derived] impl :: core :: marker :: StructuralPartialEq for MatchErrorKind { } # [automatically_derived] impl :: core :: cmp :: PartialEq for MatchErrorKind { # [inline] fn eq (& self , other : & MatchErrorKind) -> bool { let __self_discr = :: core :: intrinsics :: discriminant_value (self) ; let __arg1_discr = :: core :: intrinsics :: discriminant_value (other) ; __self_discr == __arg1_discr && match (self , other) { (MatchErrorKind :: UnsupportedStream { got : __self_0 } , MatchErrorKind :: UnsupportedStream { got : __arg1_0 } ,) => __self_0 == __arg1_0 , (MatchErrorKind :: UnsupportedOverlapping { got : __self_0 } , MatchErrorKind :: UnsupportedOverlapping { got : __arg1_0 } ,) => __self_0 == __arg1_0 , _ => true , } } } impl std :: error :: Error for MatchError { } impl core :: fmt :: Display for MatchError { fn fmt (& self , f : & mut core :: fmt :: Formatter) -> core :: fmt :: Result { match * self . kind () { MatchErrorKind :: InvalidInputAnchored => { f . write_fmt (format_args ! ("anchored searches are not supported or enabled" ,) ,) } MatchErrorKind :: InvalidInputUnanchored => { f . write_fmt (format_args ! ("unanchored searches are not supported or enabled" ,) ,) } MatchErrorKind :: UnsupportedStream { got } => { f . write_fmt (format_args ! ("match kind {0:?} does not support stream searching" , got ,) ,) } MatchErrorKind :: UnsupportedOverlapping { got } => { f . write_fmt (format_args ! ("match kind {0:?} does not support overlapping searches" , got ,) ,) } MatchErrorKind :: UnsupportedEmpty => { f . write_fmt (format_args ! ("matching with an empty pattern string is not supported for this operation" ,) ,) } } } } } pub (crate) mod int { # ! [doc = "\nThis module provides several integer oriented traits for converting between\nboth fixed size integers and integers whose size varies based on the target\n(like `usize`).\n\nThe main design principle for this module is to centralize all uses of `as`.\nThe thinking here is that `as` makes it very easy to perform accidental lossy\nconversions, and if we centralize all its uses here under more descriptive\nhigher level operations, its use and correctness becomes easier to audit.\n\nThis was copied mostly wholesale from `regex-automata`.\n\nNOTE: for simplicity, we don't take target pointer width into account here for\n`usize` conversions. Since we currently only panic in debug mode, skipping the\ncheck when it can be proven it isn't needed at compile time doesn't really\nmatter. Now, if we wind up wanting to do as many checks as possible in release\nmode, then we would want to skip those when we know the conversions are always\nnon-lossy.\n"] # ! [allow (dead_code)] pub (crate) trait U8 { fn as_usize (self) -> usize ; } impl U8 for u8 { fn as_usize (self) -> usize { usize :: from (self) } } pub (crate) trait U16 { fn as_usize (self) -> usize ; fn low_u8 (self) -> u8 ; fn high_u8 (self) -> u8 ; } impl U16 for u16 { fn as_usize (self) -> usize { usize :: from (self) } fn low_u8 (self) -> u8 { self as u8 } fn high_u8 (self) -> u8 { (self >> 8) as u8 } } pub (crate) trait U32 { fn as_usize (self) -> usize ; fn low_u8 (self) -> u8 ; fn low_u16 (self) -> u16 ; fn high_u16 (self) -> u16 ; } impl U32 for u32 { # [inline] fn as_usize (self) -> usize { { usize :: try_from (self) . expect ("u32 overflowed usize") } } fn low_u8 (self) -> u8 { self as u8 } fn low_u16 (self) -> u16 { self as u16 } fn high_u16 (self) -> u16 { (self >> 16) as u16 } } pub (crate) trait U64 { fn as_usize (self) -> usize ; fn low_u8 (self) -> u8 ; fn low_u16 (self) -> u16 ; fn low_u32 (self) -> u32 ; fn high_u32 (self) -> u32 ; } impl U64 for u64 { fn as_usize (self) -> usize { { usize :: try_from (self) . expect ("u64 overflowed usize") } } fn low_u8 (self) -> u8 { self as u8 } fn low_u16 (self) -> u16 { self as u16 } fn low_u32 (self) -> u32 { self as u32 } fn high_u32 (self) -> u32 { (self >> 32) as u32 } } pub (crate) trait I8 { fn as_usize (self) -> usize ; fn to_bits (self) -> u8 ; fn from_bits (n : u8) -> i8 ; } impl I8 for i8 { fn as_usize (self) -> usize { { usize :: try_from (self) . expect ("i8 overflowed usize") } } fn to_bits (self) -> u8 { self as u8 } fn from_bits (n : u8) -> i8 { n as i8 } } pub (crate) trait I32 { fn as_usize (self) -> usize ; fn to_bits (self) -> u32 ; fn from_bits (n : u32) -> i32 ; } impl I32 for i32 { fn as_usize (self) -> usize { { usize :: try_from (self) . expect ("i32 overflowed usize") } } fn to_bits (self) -> u32 { self as u32 } fn from_bits (n : u32) -> i32 { n as i32 } } pub (crate) trait I64 { fn as_usize (self) -> usize ; fn to_bits (self) -> u64 ; fn from_bits (n : u64) -> i64 ; } impl I64 for i64 { fn as_usize (self) -> usize { { usize :: try_from (self) . expect ("i64 overflowed usize") } } fn to_bits (self) -> u64 { self as u64 } fn from_bits (n : u64) -> i64 { n as i64 } } pub (crate) trait Usize { fn as_u8 (self) -> u8 ; fn as_u16 (self) -> u16 ; fn as_u32 (self) -> u32 ; fn as_u64 (self) -> u64 ; } impl Usize for usize { fn as_u8 (self) -> u8 { { u8 :: try_from (self) . expect ("usize overflowed u8") } } fn as_u16 (self) -> u16 { { u16 :: try_from (self) . expect ("usize overflowed u16") } } fn as_u32 (self) -> u32 { { u32 :: try_from (self) . expect ("usize overflowed u32") } } fn as_u64 (self) -> u64 { { u64 :: try_from (self) . expect ("usize overflowed u64") } } } pub (crate) trait Pointer { fn as_usize (self) -> usize ; } impl < T > Pointer for * const T { fn as_usize (self) -> usize { self as usize } } } pub (crate) mod prefilter { use core :: { cmp , fmt :: Debug , panic :: { RefUnwindSafe , UnwindSafe } , u8 , } ; use alloc :: { sync :: Arc , vec , vec :: Vec } ; use crate :: { packed , util :: { alphabet :: ByteSet , search :: { Match , MatchKind , Span } } } ; # [doc = " A prefilter for accelerating a search."] # [doc = ""] # [doc = " This crate uses prefilters in the core search implementations to accelerate"] # [doc = " common cases. They typically only apply to cases where there are a small"] # [doc = " number of patterns (less than 100 or so), but when they do, thoughput can"] # [doc = " be boosted considerably, perhaps by an order of magnitude. When a prefilter"] # [doc = " is active, it is used whenever a search enters an automaton's start state."] # [doc = ""] # [doc = " Currently, prefilters cannot be constructed by"] # [doc = " callers. A `Prefilter` can only be accessed via the"] # [doc = " [`Automaton::prefilter`](crate::automaton::Automaton::prefilter)"] # [doc = " method and used to execute a search. In other words, a prefilter can be"] # [doc = " used to optimize your own search implementation if necessary, but cannot do"] # [doc = " much else. If you have a use case for more APIs, please submit an issue."] pub struct Prefilter { finder : Arc < dyn PrefilterI > , memory_usage : usize , } # [automatically_derived] impl :: core :: clone :: Clone for Prefilter { # [inline] fn clone (& self) -> Prefilter { Prefilter { finder : :: core :: clone :: Clone :: clone (& self . finder) , memory_usage : :: core :: clone :: Clone :: clone (& self . memory_usage) , } } } # [automatically_derived] impl :: core :: fmt :: Debug for Prefilter { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field2_finish (f , "Prefilter" , "finder" , & self . finder , "memory_usage" , & & self . memory_usage ,) } } impl Prefilter { # [doc = " Execute a search in the haystack within the span given. If a match or"] # [doc = " a possible match is returned, then it is guaranteed to occur within"] # [doc = " the bounds of the span."] # [doc = ""] # [doc = " If the span provided is invalid for the given haystack, then behavior"] # [doc = " is unspecified."] # [inline] pub fn find_in (& self , haystack : & [u8] , span : Span) -> Candidate { self . finder . find_in (haystack , span) } # [inline] pub (crate) fn memory_usage (& self) -> usize { self . memory_usage } } # [doc = " A candidate is the result of running a prefilter on a haystack at a"] # [doc = " particular position."] # [doc = ""] # [doc = " The result is either no match, a confirmed match or a possible match."] # [doc = ""] # [doc = " When no match is returned, the prefilter is guaranteeing that no possible"] # [doc = " match can be found in the haystack, and the caller may trust this. That is,"] # [doc = " all correct prefilters must never report false negatives."] # [doc = ""] # [doc = " In some cases, a prefilter can confirm a match very quickly, in which case,"] # [doc = " the caller may use this to stop what it's doing and report the match. In"] # [doc = " this case, prefilter implementations must never report a false positive."] # [doc = " In other cases, the prefilter can only report a potential match, in which"] # [doc = " case the callers must attempt to confirm the match. In this case, prefilter"] # [doc = " implementations are permitted to return false positives."] pub enum Candidate { # [doc = " No match was found. Since false negatives are not possible, this means"] # [doc = " the search can quit as it is guaranteed not to find another match."] None , # [doc = " A confirmed match was found. Callers do not need to confirm it."] Match (Match) , # [doc = " The start of a possible match was found. Callers must confirm it before"] # [doc = " reporting it as a match."] PossibleStartOfMatch (usize) , } # [automatically_derived] impl :: core :: clone :: Clone for Candidate { # [inline] fn clone (& self) -> Candidate { match self { Candidate :: None => Candidate :: None , Candidate :: Match (__self_0) => { Candidate :: Match (:: core :: clone :: Clone :: clone (__self_0)) } Candidate :: PossibleStartOfMatch (__self_0) => { Candidate :: PossibleStartOfMatch (:: core :: clone :: Clone :: clone (__self_0) ,) } } } } # [automatically_derived] impl :: core :: fmt :: Debug for Candidate { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { match self { Candidate :: None => :: core :: fmt :: Formatter :: write_str (f , "None") , Candidate :: Match (__self_0) => { :: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , "Match" , & __self_0 ,) } Candidate :: PossibleStartOfMatch (__self_0) => { :: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , "PossibleStartOfMatch" , & __self_0 ,) } } } } impl Candidate { # [doc = " Convert this candidate into an option. This is useful when callers"] # [doc = " do not distinguish between true positives and false positives (i.e.,"] # [doc = " the caller must always confirm the match)."] pub fn into_option (self) -> Option < usize > { match self { Candidate :: None => None , Candidate :: Match (ref m) => Some (m . start ()) , Candidate :: PossibleStartOfMatch (start) => Some (start) , } } } # [doc = " A prefilter describes the behavior of fast literal scanners for quickly"] # [doc = " skipping past bytes in the haystack that we know cannot possibly"] # [doc = " participate in a match."] trait PrefilterI : Send + Sync + RefUnwindSafe + UnwindSafe + Debug + 'static { # [doc = " Returns the next possible match candidate. This may yield false"] # [doc = " positives, so callers must confirm a match starting at the position"] # [doc = " returned. This, however, must never produce false negatives. That is,"] # [doc = " this must, at minimum, return the starting position of the next match"] # [doc = " in the given haystack after or at the given position."] fn find_in (& self , haystack : & [u8] , span : Span) -> Candidate ; } impl < P : PrefilterI + ? Sized > PrefilterI for Arc < P > { # [inline (always)] fn find_in (& self , haystack : & [u8] , span : Span) -> Candidate { (* * self) . find_in (haystack , span) } } # [doc = " A builder for constructing the best possible prefilter. When constructed,"] # [doc = " this builder will heuristically select the best prefilter it can build,"] # [doc = " if any, and discard the rest."] pub (crate) struct Builder { count : usize , ascii_case_insensitive : bool , start_bytes : StartBytesBuilder , rare_bytes : RareBytesBuilder , memmem : MemmemBuilder , packed : Option < packed :: Builder > , enabled : bool , } # [automatically_derived] impl :: core :: fmt :: Debug for Builder { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { let names : & 'static _ = & ["count" , "ascii_case_insensitive" , "start_bytes" , "rare_bytes" , "memmem" , "packed" , "enabled" ,] ; let values : & [& dyn :: core :: fmt :: Debug] = & [& self . count , & self . ascii_case_insensitive , & self . start_bytes , & self . rare_bytes , & self . memmem , & self . packed , & & self . enabled ,] ; :: core :: fmt :: Formatter :: debug_struct_fields_finish (f , "Builder" , names , values ,) } } impl Builder { # [doc = " Create a new builder for constructing the best possible prefilter."] pub (crate) fn new (kind : MatchKind) -> Builder { let pbuilder = kind . as_packed () . map (| kind | packed :: Config :: new () . match_kind (kind) . builder ()) ; Builder { count : 0 , ascii_case_insensitive : false , start_bytes : StartBytesBuilder :: new () , rare_bytes : RareBytesBuilder :: new () , memmem : MemmemBuilder :: default () , packed : pbuilder , enabled : true , } } # [doc = " Enable ASCII case insensitivity. When set, byte strings added to this"] # [doc = " builder will be interpreted without respect to ASCII case."] pub (crate) fn ascii_case_insensitive (mut self , yes : bool) -> Builder { self . ascii_case_insensitive = yes ; self . start_bytes = self . start_bytes . ascii_case_insensitive (yes) ; self . rare_bytes = self . rare_bytes . ascii_case_insensitive (yes) ; self } # [doc = " Return a prefilter suitable for quickly finding potential matches."] # [doc = ""] # [doc = " All patterns added to an Aho-Corasick automaton should be added to this"] # [doc = " builder before attempting to construct the prefilter."] pub (crate) fn build (& self) -> Option < Prefilter > { if ! self . enabled { return None ; } if ! self . ascii_case_insensitive { if let Some (pre) = self . memmem . build () { return Some (pre) ; } } let (packed , patlen , minlen) = if self . ascii_case_insensitive { (None , usize :: MAX , 0) } else { let patlen = self . packed . as_ref () . map_or (usize :: MAX , | p | p . len ()) ; let minlen = self . packed . as_ref () . map_or (0 , | p | p . minimum_len ()) ; let packed = self . packed . as_ref () . and_then (| b | b . build ()) . map (| s | { let memory_usage = s . memory_usage () ; Prefilter { finder : Arc :: new (Packed (s)) , memory_usage , } }) ; (packed , patlen , minlen) } ; match (self . start_bytes . build () , self . rare_bytes . build ()) { (prestart @ Some (_) , prerare @ Some (_)) => { if patlen <= 16 && minlen >= 2 && self . start_bytes . count >= 3 && self . rare_bytes . count >= 3 { return packed ; } let has_fewer_bytes = self . start_bytes . count < self . rare_bytes . count ; let has_rarer_bytes = self . start_bytes . rank_sum <= self . rare_bytes . rank_sum + 50 ; if has_fewer_bytes { prestart } else if has_rarer_bytes { prestart } else { prerare } } (prestart @ Some (_) , None) => { if patlen <= 16 && minlen >= 2 && self . start_bytes . count >= 3 { return packed ; } prestart } (None , prerare @ Some (_)) => { if patlen <= 16 && minlen >= 2 && self . rare_bytes . count >= 3 { return packed ; } prerare } (None , None) if self . ascii_case_insensitive => { None } (None , None) => { if packed . is_some () { } else { } packed } } } # [doc = " Add a literal string to this prefilter builder."] pub (crate) fn add (& mut self , bytes : & [u8]) { if bytes . is_empty () { self . enabled = false ; } if ! self . enabled { return ; } self . count += 1 ; self . start_bytes . add (bytes) ; self . rare_bytes . add (bytes) ; self . memmem . add (bytes) ; if let Some (ref mut pbuilder) = self . packed { pbuilder . add (bytes) ; } } } # [doc = " A type that wraps a packed searcher and implements the `Prefilter`"] # [doc = " interface."] struct Packed (packed :: Searcher) ; # [automatically_derived] impl :: core :: clone :: Clone for Packed { # [inline] fn clone (& self) -> Packed { Packed (:: core :: clone :: Clone :: clone (& self . 0)) } } # [automatically_derived] impl :: core :: fmt :: Debug for Packed { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , "Packed" , & & self . 0) } } impl PrefilterI for Packed { fn find_in (& self , haystack : & [u8] , span : Span) -> Candidate { self . 0 . find_in (haystack , span) . map_or (Candidate :: None , Candidate :: Match) } } # [doc = " A builder for constructing a prefilter that uses memmem."] struct MemmemBuilder { # [doc = " The number of patterns that have been added."] count : usize , # [doc = " The singular pattern to search for. This is only set when count==1."] one : Option < Vec < u8 > > , } # [automatically_derived] impl :: core :: fmt :: Debug for MemmemBuilder { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field2_finish (f , "MemmemBuilder" , "count" , & self . count , "one" , & & self . one ,) } } # [automatically_derived] impl :: core :: default :: Default for MemmemBuilder { # [inline] fn default () -> MemmemBuilder { MemmemBuilder { count : :: core :: default :: Default :: default () , one : :: core :: default :: Default :: default () , } } } impl MemmemBuilder { fn build (& self) -> Option < Prefilter > { fn imp (builder : & MemmemBuilder) -> Option < Prefilter > { let pattern = builder . one . as_ref () ? ; match (& 1 , & builder . count) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: None ,) ; } } } ; let finder = Arc :: new (Memmem (memchr :: memmem :: Finder :: new (pattern) . into_owned ()) ,) ; let memory_usage = pattern . len () ; Some (Prefilter { finder , memory_usage }) } imp (self) } fn add (& mut self , bytes : & [u8]) { self . count += 1 ; if self . count == 1 { self . one = Some (bytes . to_vec ()) ; } else { self . one = None ; } } } # [doc = " A type that wraps a SIMD accelerated single substring search from the"] # [doc = " `memchr` crate for use as a prefilter."] # [doc = ""] # [doc = " Currently, this prefilter is only active for Aho-Corasick searchers with"] # [doc = " a single pattern. In theory, this could be extended to support searchers"] # [doc = " that have a common prefix of more than one byte (for one byte, we would use"] # [doc = " memchr), but it's not clear if it's worth it or not."] # [doc = ""] # [doc = " Also, unfortunately, this currently also requires the 'std' feature to"] # [doc = " be enabled. That's because memchr doesn't have a no-std-but-with-alloc"] # [doc = " mode, and so APIs like Finder::into_owned aren't available when 'std' is"] # [doc = " disabled. But there should be an 'alloc' feature that brings in APIs like"] # [doc = " Finder::into_owned but doesn't use std-only features like runtime CPU"] # [doc = " feature detection."] struct Memmem (memchr :: memmem :: Finder < 'static >) ; # [automatically_derived] impl :: core :: clone :: Clone for Memmem { # [inline] fn clone (& self) -> Memmem { Memmem (:: core :: clone :: Clone :: clone (& self . 0)) } } # [automatically_derived] impl :: core :: fmt :: Debug for Memmem { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , "Memmem" , & & self . 0) } } impl PrefilterI for Memmem { fn find_in (& self , haystack : & [u8] , span : Span) -> Candidate { use crate :: util :: primitives :: PatternID ; self . 0 . find (& haystack [span]) . map_or (Candidate :: None , | i | { let start = span . start + i ; let end = start + self . 0 . needle () . len () ; Candidate :: Match (Match :: new (PatternID :: ZERO , start .. end)) } ,) } } # [doc = " A builder for constructing a rare byte prefilter."] # [doc = ""] # [doc = " A rare byte prefilter attempts to pick out a small set of rare bytes that"] # [doc = " occurr in the patterns, and then quickly scan to matches of those rare"] # [doc = " bytes."] struct RareBytesBuilder { # [doc = " Whether this prefilter should account for ASCII case insensitivity or"] # [doc = " not."] ascii_case_insensitive : bool , # [doc = " A set of rare bytes, indexed by byte value."] rare_set : ByteSet , # [doc = " A set of byte offsets associated with bytes in a pattern. An entry"] # [doc = " corresponds to a particular bytes (its index) and is only non-zero if"] # [doc = " the byte occurred at an offset greater than 0 in at least one pattern."] # [doc = ""] # [doc = " If a byte's offset is not representable in 8 bits, then the rare bytes"] # [doc = " prefilter becomes inert."] byte_offsets : RareByteOffsets , # [doc = " Whether this is available as a prefilter or not. This can be set to"] # [doc = " false during construction if a condition is seen that invalidates the"] # [doc = " use of the rare-byte prefilter."] available : bool , # [doc = " The number of bytes set to an active value in `byte_offsets`."] count : usize , # [doc = " The sum of frequency ranks for the rare bytes detected. This is"] # [doc = " intended to give a heuristic notion of how rare the bytes are."] rank_sum : u16 , } # [automatically_derived] impl :: core :: clone :: Clone for RareBytesBuilder { # [inline] fn clone (& self) -> RareBytesBuilder { RareBytesBuilder { ascii_case_insensitive : :: core :: clone :: Clone :: clone (& self . ascii_case_insensitive ,) , rare_set : :: core :: clone :: Clone :: clone (& self . rare_set) , byte_offsets : :: core :: clone :: Clone :: clone (& self . byte_offsets) , available : :: core :: clone :: Clone :: clone (& self . available) , count : :: core :: clone :: Clone :: clone (& self . count) , rank_sum : :: core :: clone :: Clone :: clone (& self . rank_sum) , } } } # [automatically_derived] impl :: core :: fmt :: Debug for RareBytesBuilder { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { let names : & 'static _ = & ["ascii_case_insensitive" , "rare_set" , "byte_offsets" , "available" , "count" , "rank_sum" ,] ; let values : & [& dyn :: core :: fmt :: Debug] = & [& self . ascii_case_insensitive , & self . rare_set , & self . byte_offsets , & self . available , & self . count , & & self . rank_sum ,] ; :: core :: fmt :: Formatter :: debug_struct_fields_finish (f , "RareBytesBuilder" , names , values ,) } } # [doc = " A set of byte offsets, keyed by byte."] struct RareByteOffsets { # [doc = " Each entry corresponds to the maximum offset of the corresponding"] # [doc = " byte across all patterns seen."] set : [RareByteOffset ; 256] , } # [automatically_derived] impl :: core :: clone :: Clone for RareByteOffsets { # [inline] fn clone (& self) -> RareByteOffsets { let _ : :: core :: clone :: AssertParamIsClone < [RareByteOffset ; 256] > ; * self } } # [automatically_derived] impl :: core :: marker :: Copy for RareByteOffsets { } impl RareByteOffsets { # [doc = " Create a new empty set of rare byte offsets."] pub (crate) fn empty () -> RareByteOffsets { RareByteOffsets { set : [RareByteOffset :: default () ; 256] , } } # [doc = " Add the given offset for the given byte to this set. If the offset is"] # [doc = " greater than the existing offset, then it overwrites the previous"] # [doc = " value and returns false. If there is no previous value set, then this"] # [doc = " sets it and returns true."] pub (crate) fn set (& mut self , byte : u8 , off : RareByteOffset) { self . set [byte as usize] . max = cmp :: max (self . set [byte as usize] . max , off . max ,) ; } } impl core :: fmt :: Debug for RareByteOffsets { fn fmt (& self , f : & mut core :: fmt :: Formatter < '_ >) -> core :: fmt :: Result { let mut offsets = :: alloc :: vec :: Vec :: new () ; for off in self . set . iter () { if off . max > 0 { offsets . push (off) ; } } f . debug_struct ("RareByteOffsets") . field ("set" , & offsets) . finish () } } # [doc = " Offsets associated with an occurrence of a \"rare\" byte in any of the"] # [doc = " patterns used to construct a single Aho-Corasick automaton."] struct RareByteOffset { # [doc = " The maximum offset at which a particular byte occurs from the start"] # [doc = " of any pattern. This is used as a shift amount. That is, when an"] # [doc = " occurrence of this byte is found, the candidate position reported by"] # [doc = " the prefilter is `position_of_byte - max`, such that the automaton"] # [doc = " will begin its search at a position that is guaranteed to observe a"] # [doc = " match."] # [doc = ""] # [doc = " To avoid accidentally quadratic behavior, a prefilter is considered"] # [doc = " ineffective when it is asked to start scanning from a position that it"] # [doc = " has already scanned past."] # [doc = ""] # [doc = " Using a `u8` here means that if we ever see a pattern that's longer"] # [doc = " than 255 bytes, then the entire rare byte prefilter is disabled."] max : u8 , } # [automatically_derived] impl :: core :: clone :: Clone for RareByteOffset { # [inline] fn clone (& self) -> RareByteOffset { let _ : :: core :: clone :: AssertParamIsClone < u8 > ; * self } } # [automatically_derived] impl :: core :: marker :: Copy for RareByteOffset { } # [automatically_derived] impl :: core :: fmt :: Debug for RareByteOffset { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field1_finish (f , "RareByteOffset" , "max" , & & self . max ,) } } impl Default for RareByteOffset { fn default () -> RareByteOffset { RareByteOffset { max : 0 } } } impl RareByteOffset { # [doc = " Create a new rare byte offset. If the given offset is too big, then"] # [doc = " None is returned. In that case, callers should render the rare bytes"] # [doc = " prefilter inert."] fn new (max : usize) -> Option < RareByteOffset > { if max > u8 :: MAX as usize { None } else { Some (RareByteOffset { max : max as u8 }) } } } impl RareBytesBuilder { # [doc = " Create a new builder for constructing a rare byte prefilter."] fn new () -> RareBytesBuilder { RareBytesBuilder { ascii_case_insensitive : false , rare_set : ByteSet :: empty () , byte_offsets : RareByteOffsets :: empty () , available : true , count : 0 , rank_sum : 0 , } } # [doc = " Enable ASCII case insensitivity. When set, byte strings added to this"] # [doc = " builder will be interpreted without respect to ASCII case."] fn ascii_case_insensitive (mut self , yes : bool) -> RareBytesBuilder { self . ascii_case_insensitive = yes ; self } # [doc = " Build the rare bytes prefilter."] # [doc = ""] # [doc = " If there are more than 3 distinct rare bytes found, or if heuristics"] # [doc = " otherwise determine that this prefilter should not be used, then `None`"] # [doc = " is returned."] fn build (& self) -> Option < Prefilter > { fn imp (builder : & RareBytesBuilder) -> Option < Prefilter > { if ! builder . available || builder . count > 3 { return None ; } let (mut bytes , mut len) = ([0 ; 3] , 0) ; for b in 0 ..= 255 { if builder . rare_set . contains (b) { bytes [len] = b ; len += 1 ; } } let finder : Arc < dyn PrefilterI > = match len { 0 => return None , 1 => { Arc :: new (RareBytesOne { byte1 : bytes [0] , offset : builder . byte_offsets . set [bytes [0] as usize] , }) } 2 => { Arc :: new (RareBytesTwo { offsets : builder . byte_offsets , byte1 : bytes [0] , byte2 : bytes [1] , }) } 3 => { Arc :: new (RareBytesThree { offsets : builder . byte_offsets , byte1 : bytes [0] , byte2 : bytes [1] , byte3 : bytes [2] , }) } _ => { :: core :: panicking :: panic ("internal error: entered unreachable code" ,) } } ; Some (Prefilter { finder , memory_usage : 0 , }) } imp (self) } # [doc = " Add a byte string to this builder."] # [doc = ""] # [doc = " All patterns added to an Aho-Corasick automaton should be added to this"] # [doc = " builder before attempting to construct the prefilter."] fn add (& mut self , bytes : & [u8]) { if ! self . available { return ; } if self . count > 3 { self . available = false ; return ; } if bytes . len () >= 256 { self . available = false ; return ; } let mut rarest = match bytes . first () { None => return , Some (& b) => (b , freq_rank (b)) , } ; let mut found = false ; for (pos , & b) in bytes . iter () . enumerate () { self . set_offset (pos , b) ; if found { continue ; } if self . rare_set . contains (b) { found = true ; continue ; } let rank = freq_rank (b) ; if rank < rarest . 1 { rarest = (b , rank) ; } } if ! found { self . add_rare_byte (rarest . 0) ; } } fn set_offset (& mut self , pos : usize , byte : u8) { let offset = RareByteOffset :: new (pos) . unwrap () ; self . byte_offsets . set (byte , offset) ; if self . ascii_case_insensitive { self . byte_offsets . set (opposite_ascii_case (byte) , offset) ; } } fn add_rare_byte (& mut self , byte : u8) { self . add_one_rare_byte (byte) ; if self . ascii_case_insensitive { self . add_one_rare_byte (opposite_ascii_case (byte)) ; } } fn add_one_rare_byte (& mut self , byte : u8) { if ! self . rare_set . contains (byte) { self . rare_set . add (byte) ; self . count += 1 ; self . rank_sum += freq_rank (byte) as u16 ; } } } # [doc = " A prefilter for scanning for a single \"rare\" byte."] struct RareBytesOne { byte1 : u8 , offset : RareByteOffset , } # [automatically_derived] impl :: core :: clone :: Clone for RareBytesOne { # [inline] fn clone (& self) -> RareBytesOne { RareBytesOne { byte1 : :: core :: clone :: Clone :: clone (& self . byte1) , offset : :: core :: clone :: Clone :: clone (& self . offset) , } } } # [automatically_derived] impl :: core :: fmt :: Debug for RareBytesOne { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field2_finish (f , "RareBytesOne" , "byte1" , & self . byte1 , "offset" , & & self . offset ,) } } impl PrefilterI for RareBytesOne { fn find_in (& self , haystack : & [u8] , span : Span) -> Candidate { memchr :: memchr (self . byte1 , & haystack [span]) . map (| i | { let pos = span . start + i ; cmp :: max (span . start , pos . saturating_sub (usize :: from (self . offset . max)) ,) }) . map_or (Candidate :: None , Candidate :: PossibleStartOfMatch) } } # [doc = " A prefilter for scanning for two \"rare\" bytes."] struct RareBytesTwo { offsets : RareByteOffsets , byte1 : u8 , byte2 : u8 , } # [automatically_derived] impl :: core :: clone :: Clone for RareBytesTwo { # [inline] fn clone (& self) -> RareBytesTwo { RareBytesTwo { offsets : :: core :: clone :: Clone :: clone (& self . offsets) , byte1 : :: core :: clone :: Clone :: clone (& self . byte1) , byte2 : :: core :: clone :: Clone :: clone (& self . byte2) , } } } # [automatically_derived] impl :: core :: fmt :: Debug for RareBytesTwo { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field3_finish (f , "RareBytesTwo" , "offsets" , & self . offsets , "byte1" , & self . byte1 , "byte2" , & & self . byte2 ,) } } impl PrefilterI for RareBytesTwo { fn find_in (& self , haystack : & [u8] , span : Span) -> Candidate { memchr :: memchr2 (self . byte1 , self . byte2 , & haystack [span]) . map (| i | { let pos = span . start + i ; let offset = self . offsets . set [usize :: from (haystack [pos])] . max ; cmp :: max (span . start , pos . saturating_sub (usize :: from (offset))) }) . map_or (Candidate :: None , Candidate :: PossibleStartOfMatch) } } # [doc = " A prefilter for scanning for three \"rare\" bytes."] struct RareBytesThree { offsets : RareByteOffsets , byte1 : u8 , byte2 : u8 , byte3 : u8 , } # [automatically_derived] impl :: core :: clone :: Clone for RareBytesThree { # [inline] fn clone (& self) -> RareBytesThree { RareBytesThree { offsets : :: core :: clone :: Clone :: clone (& self . offsets) , byte1 : :: core :: clone :: Clone :: clone (& self . byte1) , byte2 : :: core :: clone :: Clone :: clone (& self . byte2) , byte3 : :: core :: clone :: Clone :: clone (& self . byte3) , } } } # [automatically_derived] impl :: core :: fmt :: Debug for RareBytesThree { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field4_finish (f , "RareBytesThree" , "offsets" , & self . offsets , "byte1" , & self . byte1 , "byte2" , & self . byte2 , "byte3" , & & self . byte3 ,) } } impl PrefilterI for RareBytesThree { fn find_in (& self , haystack : & [u8] , span : Span) -> Candidate { memchr :: memchr3 (self . byte1 , self . byte2 , self . byte3 , & haystack [span]) . map (| i | { let pos = span . start + i ; let offset = self . offsets . set [usize :: from (haystack [pos])] . max ; cmp :: max (span . start , pos . saturating_sub (usize :: from (offset))) }) . map_or (Candidate :: None , Candidate :: PossibleStartOfMatch) } } # [doc = " A builder for constructing a starting byte prefilter."] # [doc = ""] # [doc = " A starting byte prefilter is a simplistic prefilter that looks for possible"] # [doc = " matches by reporting all positions corresponding to a particular byte. This"] # [doc = " generally only takes affect when there are at most 3 distinct possible"] # [doc = " starting bytes. e.g., the patterns `foo`, `bar`, and `baz` have two"] # [doc = " distinct starting bytes (`f` and `b`), and this prefilter returns all"] # [doc = " occurrences of either `f` or `b`."] # [doc = ""] # [doc = " In some cases, a heuristic frequency analysis may determine that it would"] # [doc = " be better not to use this prefilter even when there are 3 or fewer distinct"] # [doc = " starting bytes."] struct StartBytesBuilder { # [doc = " Whether this prefilter should account for ASCII case insensitivity or"] # [doc = " not."] ascii_case_insensitive : bool , # [doc = " The set of starting bytes observed."] byteset : Vec < bool > , # [doc = " The number of bytes set to true in `byteset`."] count : usize , # [doc = " The sum of frequency ranks for the rare bytes detected. This is"] # [doc = " intended to give a heuristic notion of how rare the bytes are."] rank_sum : u16 , } # [automatically_derived] impl :: core :: clone :: Clone for StartBytesBuilder { # [inline] fn clone (& self) -> StartBytesBuilder { StartBytesBuilder { ascii_case_insensitive : :: core :: clone :: Clone :: clone (& self . ascii_case_insensitive ,) , byteset : :: core :: clone :: Clone :: clone (& self . byteset) , count : :: core :: clone :: Clone :: clone (& self . count) , rank_sum : :: core :: clone :: Clone :: clone (& self . rank_sum) , } } } # [automatically_derived] impl :: core :: fmt :: Debug for StartBytesBuilder { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field4_finish (f , "StartBytesBuilder" , "ascii_case_insensitive" , & self . ascii_case_insensitive , "byteset" , & self . byteset , "count" , & self . count , "rank_sum" , & & self . rank_sum ,) } } impl StartBytesBuilder { # [doc = " Create a new builder for constructing a start byte prefilter."] fn new () -> StartBytesBuilder { StartBytesBuilder { ascii_case_insensitive : false , byteset : :: alloc :: vec :: from_elem (false , 256) , count : 0 , rank_sum : 0 , } } # [doc = " Enable ASCII case insensitivity. When set, byte strings added to this"] # [doc = " builder will be interpreted without respect to ASCII case."] fn ascii_case_insensitive (mut self , yes : bool) -> StartBytesBuilder { self . ascii_case_insensitive = yes ; self } # [doc = " Build the starting bytes prefilter."] # [doc = ""] # [doc = " If there are more than 3 distinct starting bytes, or if heuristics"] # [doc = " otherwise determine that this prefilter should not be used, then `None`"] # [doc = " is returned."] fn build (& self) -> Option < Prefilter > { fn imp (builder : & StartBytesBuilder) -> Option < Prefilter > { if builder . count > 3 { return None ; } let (mut bytes , mut len) = ([0 ; 3] , 0) ; for b in 0 .. 256 { if ! builder . byteset [b] { continue ; } if b > 0x7F { return None ; } bytes [len] = b as u8 ; len += 1 ; } let finder : Arc < dyn PrefilterI > = match len { 0 => return None , 1 => Arc :: new (StartBytesOne { byte1 : bytes [0] }) , 2 => { Arc :: new (StartBytesTwo { byte1 : bytes [0] , byte2 : bytes [1] , }) } 3 => { Arc :: new (StartBytesThree { byte1 : bytes [0] , byte2 : bytes [1] , byte3 : bytes [2] , }) } _ => { :: core :: panicking :: panic ("internal error: entered unreachable code" ,) } } ; Some (Prefilter { finder , memory_usage : 0 , }) } imp (self) } # [doc = " Add a byte string to this builder."] # [doc = ""] # [doc = " All patterns added to an Aho-Corasick automaton should be added to this"] # [doc = " builder before attempting to construct the prefilter."] fn add (& mut self , bytes : & [u8]) { if self . count > 3 { return ; } if let Some (& byte) = bytes . first () { self . add_one_byte (byte) ; if self . ascii_case_insensitive { self . add_one_byte (opposite_ascii_case (byte)) ; } } } fn add_one_byte (& mut self , byte : u8) { if ! self . byteset [byte as usize] { self . byteset [byte as usize] = true ; self . count += 1 ; self . rank_sum += freq_rank (byte) as u16 ; } } } # [doc = " A prefilter for scanning for a single starting byte."] struct StartBytesOne { byte1 : u8 , } # [automatically_derived] impl :: core :: clone :: Clone for StartBytesOne { # [inline] fn clone (& self) -> StartBytesOne { StartBytesOne { byte1 : :: core :: clone :: Clone :: clone (& self . byte1) , } } } # [automatically_derived] impl :: core :: fmt :: Debug for StartBytesOne { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field1_finish (f , "StartBytesOne" , "byte1" , & & self . byte1 ,) } } impl PrefilterI for StartBytesOne { fn find_in (& self , haystack : & [u8] , span : Span) -> Candidate { memchr :: memchr (self . byte1 , & haystack [span]) . map (| i | span . start + i) . map_or (Candidate :: None , Candidate :: PossibleStartOfMatch) } } # [doc = " A prefilter for scanning for two starting bytes."] struct StartBytesTwo { byte1 : u8 , byte2 : u8 , } # [automatically_derived] impl :: core :: clone :: Clone for StartBytesTwo { # [inline] fn clone (& self) -> StartBytesTwo { StartBytesTwo { byte1 : :: core :: clone :: Clone :: clone (& self . byte1) , byte2 : :: core :: clone :: Clone :: clone (& self . byte2) , } } } # [automatically_derived] impl :: core :: fmt :: Debug for StartBytesTwo { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field2_finish (f , "StartBytesTwo" , "byte1" , & self . byte1 , "byte2" , & & self . byte2 ,) } } impl PrefilterI for StartBytesTwo { fn find_in (& self , haystack : & [u8] , span : Span) -> Candidate { memchr :: memchr2 (self . byte1 , self . byte2 , & haystack [span]) . map (| i | span . start + i) . map_or (Candidate :: None , Candidate :: PossibleStartOfMatch) } } # [doc = " A prefilter for scanning for three starting bytes."] struct StartBytesThree { byte1 : u8 , byte2 : u8 , byte3 : u8 , } # [automatically_derived] impl :: core :: clone :: Clone for StartBytesThree { # [inline] fn clone (& self) -> StartBytesThree { StartBytesThree { byte1 : :: core :: clone :: Clone :: clone (& self . byte1) , byte2 : :: core :: clone :: Clone :: clone (& self . byte2) , byte3 : :: core :: clone :: Clone :: clone (& self . byte3) , } } } # [automatically_derived] impl :: core :: fmt :: Debug for StartBytesThree { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field3_finish (f , "StartBytesThree" , "byte1" , & self . byte1 , "byte2" , & self . byte2 , "byte3" , & & self . byte3 ,) } } impl PrefilterI for StartBytesThree { fn find_in (& self , haystack : & [u8] , span : Span) -> Candidate { memchr :: memchr3 (self . byte1 , self . byte2 , self . byte3 , & haystack [span]) . map (| i | span . start + i) . map_or (Candidate :: None , Candidate :: PossibleStartOfMatch) } } # [doc = " If the given byte is an ASCII letter, then return it in the opposite case."] # [doc = " e.g., Given `b'A'`, this returns `b'a'`, and given `b'a'`, this returns"] # [doc = " `b'A'`. If a non-ASCII letter is given, then the given byte is returned."] pub (crate) fn opposite_ascii_case (b : u8) -> u8 { if b'A' <= b && b <= b'Z' { b . to_ascii_lowercase () } else if b'a' <= b && b <= b'z' { b . to_ascii_uppercase () } else { b } } # [doc = " Return the frequency rank of the given byte. The higher the rank, the more"] # [doc = " common the byte (heuristically speaking)."] fn freq_rank (b : u8) -> u8 { use crate :: util :: byte_frequencies :: BYTE_FREQUENCIES ; BYTE_FREQUENCIES [b as usize] } } pub (crate) mod primitives { # ! [doc = "\nLower level primitive types that are useful in a variety of circumstances.\n\n# Overview\n\nThis list represents the principle types in this module and briefly describes\nwhen you might want to use them.\n\n* [`PatternID`] - A type that represents the identifier of a regex pattern.\nThis is probably the most widely used type in this module (which is why it's\nalso re-exported in the crate root).\n* [`StateID`] - A type the represents the identifier of a finite automaton\nstate. This is used for both NFAs and DFAs, with the notable exception of\nthe hybrid NFA/DFA. (The hybrid NFA/DFA uses a special purpose \"lazy\" state\nidentifier.)\n* [`SmallIndex`] - The internal representation of both a `PatternID` and a\n`StateID`. Its purpose is to serve as a type that can index memory without\nbeing as big as a `usize` on 64-bit targets. The main idea behind this type\nis that there are many things in regex engines that will, in practice, never\noverflow a 32-bit integer. (For example, like the number of patterns in a regex\nor the number of states in an NFA.) Thus, a `SmallIndex` can be used to index\nmemory without peppering `as` casts everywhere. Moreover, it forces callers\nto handle errors in the case where, somehow, the value would otherwise overflow\neither a 32-bit integer or a `usize` (e.g., on 16-bit targets).\n"] # ! [allow (dead_code)] use alloc :: vec :: Vec ; use crate :: util :: int :: { Usize , U16 , U32 , U64 } ; # [doc = " A type that represents a \"small\" index."] # [doc = ""] # [doc = " The main idea of this type is to provide something that can index memory,"] # [doc = " but uses less memory than `usize` on 64-bit systems. Specifically, its"] # [doc = " representation is always a `u32` and has `repr(transparent)` enabled. (So"] # [doc = " it is safe to transmute between a `u32` and a `SmallIndex`.)"] # [doc = ""] # [doc = " A small index is typically useful in cases where there is no practical way"] # [doc = " that the index will overflow a 32-bit integer. A good example of this is"] # [doc = " an NFA state. If you could somehow build an NFA with `2^30` states, its"] # [doc = " memory usage would be exorbitant and its runtime execution would be so"] # [doc = " slow as to be completely worthless. Therefore, this crate generally deems"] # [doc = " it acceptable to return an error if it would otherwise build an NFA that"] # [doc = " requires a slice longer than what a 32-bit integer can index. In exchange,"] # [doc = " we can use 32-bit indices instead of 64-bit indices in various places."] # [doc = ""] # [doc = " This type ensures this by providing a constructor that will return an error"] # [doc = " if its argument cannot fit into the type. This makes it much easier to"] # [doc = " handle these sorts of boundary cases that are otherwise extremely subtle."] # [doc = ""] # [doc = " On all targets, this type guarantees that its value will fit in a `u32`,"] # [doc = " `i32`, `usize` and an `isize`. This means that on 16-bit targets, for"] # [doc = " example, this type's maximum value will never overflow an `isize`,"] # [doc = " which means it will never overflow a `i16` even though its internal"] # [doc = " representation is still a `u32`."] # [doc = ""] # [doc = " The purpose for making the type fit into even signed integer types like"] # [doc = " `isize` is to guarantee that the difference between any two small indices"] # [doc = " is itself also a small index. This is useful in certain contexts, e.g.,"] # [doc = " for delta encoding."] # [doc = ""] # [doc = " # Other types"] # [doc = ""] # [doc = " The following types wrap `SmallIndex` to provide a more focused use case:"] # [doc = ""] # [doc = " * [`PatternID`] is for representing the identifiers of patterns."] # [doc = " * [`StateID`] is for representing the identifiers of states in finite"] # [doc = " automata. It is used for both NFAs and DFAs."] # [doc = ""] # [doc = " # Representation"] # [doc = ""] # [doc = " This type is always represented internally by a `u32` and is marked as"] # [doc = " `repr(transparent)`. Thus, this type always has the same representation as"] # [doc = " a `u32`. It is thus safe to transmute between a `u32` and a `SmallIndex`."] # [doc = ""] # [doc = " # Indexing"] # [doc = ""] # [doc = " For convenience, callers may use a `SmallIndex` to index slices."] # [doc = ""] # [doc = " # Safety"] # [doc = ""] # [doc = " While a `SmallIndex` is meant to guarantee that its value fits into `usize`"] # [doc = " without using as much space as a `usize` on all targets, callers must"] # [doc = " not rely on this property for safety. Callers may choose to rely on this"] # [doc = " property for correctness however. For example, creating a `SmallIndex` with"] # [doc = " an invalid value can be done in entirely safe code. This may in turn result"] # [doc = " in panics or silent logical errors."] # [repr (transparent)] pub (crate) struct SmallIndex (u32) ; # [automatically_derived] impl :: core :: clone :: Clone for SmallIndex { # [inline] fn clone (& self) -> SmallIndex { let _ : :: core :: clone :: AssertParamIsClone < u32 > ; * self } } # [automatically_derived] impl :: core :: marker :: Copy for SmallIndex { } # [automatically_derived] impl :: core :: fmt :: Debug for SmallIndex { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , "SmallIndex" , & & self . 0 ,) } } # [automatically_derived] impl :: core :: default :: Default for SmallIndex { # [inline] fn default () -> SmallIndex { SmallIndex (:: core :: default :: Default :: default ()) } } # [automatically_derived] impl :: core :: cmp :: Eq for SmallIndex { # [inline] # [doc (hidden)] # [coverage (off)] fn assert_receiver_is_total_eq (& self) -> () { let _ : :: core :: cmp :: AssertParamIsEq < u32 > ; } } # [automatically_derived] impl :: core :: hash :: Hash for SmallIndex { # [inline] fn hash < __H : :: core :: hash :: Hasher > (& self , state : & mut __H) -> () { :: core :: hash :: Hash :: hash (& self . 0 , state) } } # [automatically_derived] impl :: core :: marker :: StructuralPartialEq for SmallIndex { } # [automatically_derived] impl :: core :: cmp :: PartialEq for SmallIndex { # [inline] fn eq (& self , other : & SmallIndex) -> bool { self . 0 == other . 0 } } # [automatically_derived] impl :: core :: cmp :: PartialOrd for SmallIndex { # [inline] fn partial_cmp (& self , other : & SmallIndex ,) -> :: core :: option :: Option < :: core :: cmp :: Ordering > { :: core :: cmp :: PartialOrd :: partial_cmp (& self . 0 , & other . 0) } } # [automatically_derived] impl :: core :: cmp :: Ord for SmallIndex { # [inline] fn cmp (& self , other : & SmallIndex) -> :: core :: cmp :: Ordering { :: core :: cmp :: Ord :: cmp (& self . 0 , & other . 0) } } impl SmallIndex { # [doc = " The maximum index value."] pub const MAX : SmallIndex = SmallIndex :: new_unchecked (core :: i32 :: MAX as usize - 1 ,) ; # [doc = " The total number of values that can be represented as a small index."] pub const LIMIT : usize = SmallIndex :: MAX . as_usize () + 1 ; # [doc = " The zero index value."] pub const ZERO : SmallIndex = SmallIndex :: new_unchecked (0) ; # [doc = " The number of bytes that a single small index uses in memory."] pub const SIZE : usize = core :: mem :: size_of :: < SmallIndex > () ; # [doc = " Create a new small index."] # [doc = ""] # [doc = " If the given index exceeds [`SmallIndex::MAX`], then this returns"] # [doc = " an error."] # [inline] pub fn new (index : usize) -> Result < SmallIndex , SmallIndexError > { SmallIndex :: try_from (index) } # [doc = " Create a new small index without checking whether the given value"] # [doc = " exceeds [`SmallIndex::MAX`]."] # [doc = ""] # [doc = " Using this routine with an invalid index value will result in"] # [doc = " unspecified behavior, but *not* undefined behavior. In particular, an"] # [doc = " invalid index value is likely to cause panics or possibly even silent"] # [doc = " logical errors."] # [doc = ""] # [doc = " Callers must never rely on a `SmallIndex` to be within a certain range"] # [doc = " for memory safety."] # [inline] pub const fn new_unchecked (index : usize) -> SmallIndex { SmallIndex :: from_u32_unchecked (index as u32) } # [doc = " Create a new small index from a `u32` without checking whether the"] # [doc = " given value exceeds [`SmallIndex::MAX`]."] # [doc = ""] # [doc = " Using this routine with an invalid index value will result in"] # [doc = " unspecified behavior, but *not* undefined behavior. In particular, an"] # [doc = " invalid index value is likely to cause panics or possibly even silent"] # [doc = " logical errors."] # [doc = ""] # [doc = " Callers must never rely on a `SmallIndex` to be within a certain range"] # [doc = " for memory safety."] # [inline] pub const fn from_u32_unchecked (index : u32) -> SmallIndex { SmallIndex (index) } # [doc = " Like [`SmallIndex::new`], but panics if the given index is not valid."] # [inline] pub fn must (index : usize) -> SmallIndex { SmallIndex :: new (index) . expect ("invalid small index") } # [doc = " Return this small index as a `usize`. This is guaranteed to never"] # [doc = " overflow `usize`."] # [inline] pub const fn as_usize (& self) -> usize { self . 0 as usize } # [doc = " Return this small index as a `u64`. This is guaranteed to never"] # [doc = " overflow."] # [inline] pub const fn as_u64 (& self) -> u64 { self . 0 as u64 } # [doc = " Return the internal `u32` of this small index. This is guaranteed to"] # [doc = " never overflow `u32`."] # [inline] pub const fn as_u32 (& self) -> u32 { self . 0 } # [doc = " Return the internal `u32` of this small index represented as an `i32`."] # [doc = " This is guaranteed to never overflow an `i32`."] # [inline] pub const fn as_i32 (& self) -> i32 { self . 0 as i32 } # [doc = " Returns one more than this small index as a usize."] # [doc = ""] # [doc = " Since a small index has constraints on its maximum value, adding `1` to"] # [doc = " it will always fit in a `usize`, `isize`, `u32` and a `i32`."] # [inline] pub fn one_more (& self) -> usize { self . as_usize () + 1 } # [doc = " Decode this small index from the bytes given using the native endian"] # [doc = " byte order for the current target."] # [doc = ""] # [doc = " If the decoded integer is not representable as a small index for the"] # [doc = " current target, then this returns an error."] # [inline] pub fn from_ne_bytes (bytes : [u8 ; 4]) -> Result < SmallIndex , SmallIndexError > { let id = u32 :: from_ne_bytes (bytes) ; if id > SmallIndex :: MAX . as_u32 () { return Err (SmallIndexError { attempted : u64 :: from (id) , }) ; } Ok (SmallIndex :: new_unchecked (id . as_usize ())) } # [doc = " Decode this small index from the bytes given using the native endian"] # [doc = " byte order for the current target."] # [doc = ""] # [doc = " This is analogous to [`SmallIndex::new_unchecked`] in that is does not"] # [doc = " check whether the decoded integer is representable as a small index."] # [inline] pub fn from_ne_bytes_unchecked (bytes : [u8 ; 4]) -> SmallIndex { SmallIndex :: new_unchecked (u32 :: from_ne_bytes (bytes) . as_usize ()) } # [doc = " Return the underlying small index integer as raw bytes in native endian"] # [doc = " format."] # [inline] pub fn to_ne_bytes (& self) -> [u8 ; 4] { self . 0 . to_ne_bytes () } } impl < T > core :: ops :: Index < SmallIndex > for [T] { type Output = T ; # [inline] fn index (& self , index : SmallIndex) -> & T { & self [index . as_usize ()] } } impl < T > core :: ops :: IndexMut < SmallIndex > for [T] { # [inline] fn index_mut (& mut self , index : SmallIndex) -> & mut T { & mut self [index . as_usize ()] } } impl < T > core :: ops :: Index < SmallIndex > for Vec < T > { type Output = T ; # [inline] fn index (& self , index : SmallIndex) -> & T { & self [index . as_usize ()] } } impl < T > core :: ops :: IndexMut < SmallIndex > for Vec < T > { # [inline] fn index_mut (& mut self , index : SmallIndex) -> & mut T { & mut self [index . as_usize ()] } } impl From < StateID > for SmallIndex { fn from (sid : StateID) -> SmallIndex { sid . 0 } } impl From < PatternID > for SmallIndex { fn from (pid : PatternID) -> SmallIndex { pid . 0 } } impl From < u8 > for SmallIndex { fn from (index : u8) -> SmallIndex { SmallIndex :: new_unchecked (usize :: from (index)) } } impl TryFrom < u16 > for SmallIndex { type Error = SmallIndexError ; fn try_from (index : u16) -> Result < SmallIndex , SmallIndexError > { if u32 :: from (index) > SmallIndex :: MAX . as_u32 () { return Err (SmallIndexError { attempted : u64 :: from (index) , }) ; } Ok (SmallIndex :: new_unchecked (index . as_usize ())) } } impl TryFrom < u32 > for SmallIndex { type Error = SmallIndexError ; fn try_from (index : u32) -> Result < SmallIndex , SmallIndexError > { if index > SmallIndex :: MAX . as_u32 () { return Err (SmallIndexError { attempted : u64 :: from (index) , }) ; } Ok (SmallIndex :: new_unchecked (index . as_usize ())) } } impl TryFrom < u64 > for SmallIndex { type Error = SmallIndexError ; fn try_from (index : u64) -> Result < SmallIndex , SmallIndexError > { if index > SmallIndex :: MAX . as_u64 () { return Err (SmallIndexError { attempted : index , }) ; } Ok (SmallIndex :: new_unchecked (index . as_usize ())) } } impl TryFrom < usize > for SmallIndex { type Error = SmallIndexError ; fn try_from (index : usize) -> Result < SmallIndex , SmallIndexError > { if index > SmallIndex :: MAX . as_usize () { return Err (SmallIndexError { attempted : index . as_u64 () , }) ; } Ok (SmallIndex :: new_unchecked (index)) } } # [doc = " This error occurs when a small index could not be constructed."] # [doc = ""] # [doc = " This occurs when given an integer exceeding the maximum small index value."] # [doc = ""] # [doc = " When the `std` feature is enabled, this implements the `Error` trait."] pub struct SmallIndexError { attempted : u64 , } # [automatically_derived] impl :: core :: clone :: Clone for SmallIndexError { # [inline] fn clone (& self) -> SmallIndexError { SmallIndexError { attempted : :: core :: clone :: Clone :: clone (& self . attempted) , } } } # [automatically_derived] impl :: core :: fmt :: Debug for SmallIndexError { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field1_finish (f , "SmallIndexError" , "attempted" , & & self . attempted ,) } } # [automatically_derived] impl :: core :: cmp :: Eq for SmallIndexError { # [inline] # [doc (hidden)] # [coverage (off)] fn assert_receiver_is_total_eq (& self) -> () { let _ : :: core :: cmp :: AssertParamIsEq < u64 > ; } } # [automatically_derived] impl :: core :: marker :: StructuralPartialEq for SmallIndexError { } # [automatically_derived] impl :: core :: cmp :: PartialEq for SmallIndexError { # [inline] fn eq (& self , other : & SmallIndexError) -> bool { self . attempted == other . attempted } } impl SmallIndexError { # [doc = " Returns the value that could not be converted to a small index."] pub fn attempted (& self) -> u64 { self . attempted } } impl std :: error :: Error for SmallIndexError { } impl core :: fmt :: Display for SmallIndexError { fn fmt (& self , f : & mut core :: fmt :: Formatter) -> core :: fmt :: Result { f . write_fmt (format_args ! ("failed to create small index from {0:?}, which exceeds {1:?}" , self . attempted () , SmallIndex :: MAX ,) ,) } } pub (crate) struct SmallIndexIter { rng : core :: ops :: Range < usize > , } # [automatically_derived] impl :: core :: clone :: Clone for SmallIndexIter { # [inline] fn clone (& self) -> SmallIndexIter { SmallIndexIter { rng : :: core :: clone :: Clone :: clone (& self . rng) , } } } # [automatically_derived] impl :: core :: fmt :: Debug for SmallIndexIter { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field1_finish (f , "SmallIndexIter" , "rng" , & & self . rng ,) } } impl Iterator for SmallIndexIter { type Item = SmallIndex ; fn next (& mut self) -> Option < SmallIndex > { if self . rng . start >= self . rng . end { return None ; } let next_id = self . rng . start + 1 ; let id = core :: mem :: replace (& mut self . rng . start , next_id) ; Some (SmallIndex :: new_unchecked (id)) } } # [doc = " The identifier of a pattern in an Aho-Corasick automaton."] # [doc = ""] # [doc = " It is represented by a `u32` even on 64-bit systems in order to conserve"] # [doc = " space. Namely, on all targets, this type guarantees that its value will"] # [doc = " fit in a `u32`, `i32`, `usize` and an `isize`. This means that on 16-bit"] # [doc = " targets, for example, this type's maximum value will never overflow an"] # [doc = " `isize`, which means it will never overflow a `i16` even though its"] # [doc = " internal representation is still a `u32`."] # [doc = ""] # [doc = " # Safety"] # [doc = ""] # [doc = " While a `PatternID` is meant to guarantee that its value fits into `usize`"] # [doc = " without using as much space as a `usize` on all targets, callers must"] # [doc = " not rely on this property for safety. Callers may choose to rely on this"] # [doc = " property for correctness however. For example, creating a `StateID` with an"] # [doc = " invalid value can be done in entirely safe code. This may in turn result in"] # [doc = " panics or silent logical errors."] # [repr (transparent)] pub struct PatternID (SmallIndex) ; # [automatically_derived] impl :: core :: clone :: Clone for PatternID { # [inline] fn clone (& self) -> PatternID { let _ : :: core :: clone :: AssertParamIsClone < SmallIndex > ; * self } } # [automatically_derived] impl :: core :: marker :: Copy for PatternID { } # [automatically_derived] impl :: core :: default :: Default for PatternID { # [inline] fn default () -> PatternID { PatternID (:: core :: default :: Default :: default ()) } } # [automatically_derived] impl :: core :: cmp :: Eq for PatternID { # [inline] # [doc (hidden)] # [coverage (off)] fn assert_receiver_is_total_eq (& self) -> () { let _ : :: core :: cmp :: AssertParamIsEq < SmallIndex > ; } } # [automatically_derived] impl :: core :: hash :: Hash for PatternID { # [inline] fn hash < __H : :: core :: hash :: Hasher > (& self , state : & mut __H) -> () { :: core :: hash :: Hash :: hash (& self . 0 , state) } } # [automatically_derived] impl :: core :: marker :: StructuralPartialEq for PatternID { } # [automatically_derived] impl :: core :: cmp :: PartialEq for PatternID { # [inline] fn eq (& self , other : & PatternID) -> bool { self . 0 == other . 0 } } # [automatically_derived] impl :: core :: cmp :: PartialOrd for PatternID { # [inline] fn partial_cmp (& self , other : & PatternID ,) -> :: core :: option :: Option < :: core :: cmp :: Ordering > { :: core :: cmp :: PartialOrd :: partial_cmp (& self . 0 , & other . 0) } } # [automatically_derived] impl :: core :: cmp :: Ord for PatternID { # [inline] fn cmp (& self , other : & PatternID) -> :: core :: cmp :: Ordering { :: core :: cmp :: Ord :: cmp (& self . 0 , & other . 0) } } # [doc = " The identifier of a finite automaton state."] # [doc = ""] # [doc = " It is represented by a `u32` even on 64-bit systems in order to conserve"] # [doc = " space. Namely, on all targets, this type guarantees that its value will"] # [doc = " fit in a `u32`, `i32`, `usize` and an `isize`. This means that on 16-bit"] # [doc = " targets, for example, this type's maximum value will never overflow an"] # [doc = " `isize`, which means it will never overflow a `i16` even though its"] # [doc = " internal representation is still a `u32`."] # [doc = ""] # [doc = " # Safety"] # [doc = ""] # [doc = " While a `StateID` is meant to guarantee that its value fits into `usize`"] # [doc = " without using as much space as a `usize` on all targets, callers must"] # [doc = " not rely on this property for safety. Callers may choose to rely on this"] # [doc = " property for correctness however. For example, creating a `StateID` with an"] # [doc = " invalid value can be done in entirely safe code. This may in turn result in"] # [doc = " panics or silent logical errors."] # [repr (transparent)] pub struct StateID (SmallIndex) ; # [automatically_derived] impl :: core :: clone :: Clone for StateID { # [inline] fn clone (& self) -> StateID { let _ : :: core :: clone :: AssertParamIsClone < SmallIndex > ; * self } } # [automatically_derived] impl :: core :: marker :: Copy for StateID { } # [automatically_derived] impl :: core :: default :: Default for StateID { # [inline] fn default () -> StateID { StateID (:: core :: default :: Default :: default ()) } } # [automatically_derived] impl :: core :: cmp :: Eq for StateID { # [inline] # [doc (hidden)] # [coverage (off)] fn assert_receiver_is_total_eq (& self) -> () { let _ : :: core :: cmp :: AssertParamIsEq < SmallIndex > ; } } # [automatically_derived] impl :: core :: hash :: Hash for StateID { # [inline] fn hash < __H : :: core :: hash :: Hasher > (& self , state : & mut __H) -> () { :: core :: hash :: Hash :: hash (& self . 0 , state) } } # [automatically_derived] impl :: core :: marker :: StructuralPartialEq for StateID { } # [automatically_derived] impl :: core :: cmp :: PartialEq for StateID { # [inline] fn eq (& self , other : & StateID) -> bool { self . 0 == other . 0 } } # [automatically_derived] impl :: core :: cmp :: PartialOrd for StateID { # [inline] fn partial_cmp (& self , other : & StateID ,) -> :: core :: option :: Option < :: core :: cmp :: Ordering > { :: core :: cmp :: PartialOrd :: partial_cmp (& self . 0 , & other . 0) } } # [automatically_derived] impl :: core :: cmp :: Ord for StateID { # [inline] fn cmp (& self , other : & StateID) -> :: core :: cmp :: Ordering { :: core :: cmp :: Ord :: cmp (& self . 0 , & other . 0) } } impl PatternID { # [doc = " The maximum value."] pub const MAX : PatternID = PatternID (SmallIndex :: MAX) ; # [doc = " The total number of values that can be represented."] pub const LIMIT : usize = SmallIndex :: LIMIT ; # [doc = " The zero value."] pub const ZERO : PatternID = PatternID (SmallIndex :: ZERO) ; # [doc = " The number of bytes that a single value uses in memory."] pub const SIZE : usize = SmallIndex :: SIZE ; # [doc = " Create a new value that is represented by a \"small index.\""] # [doc = ""] # [doc = " If the given index exceeds the maximum allowed value, then this"] # [doc = " returns an error."] # [inline] pub fn new (value : usize) -> Result < PatternID , PatternIDError > { SmallIndex :: new (value) . map (PatternID) . map_err (PatternIDError) } # [doc = " Create a new value without checking whether the given argument"] # [doc = " exceeds the maximum."] # [doc = ""] # [doc = " Using this routine with an invalid value will result in"] # [doc = " unspecified behavior, but *not* undefined behavior. In"] # [doc = " particular, an invalid ID value is likely to cause panics or"] # [doc = " possibly even silent logical errors."] # [doc = ""] # [doc = " Callers must never rely on this type to be within a certain"] # [doc = " range for memory safety."] # [inline] pub const fn new_unchecked (value : usize) -> PatternID { PatternID (SmallIndex :: new_unchecked (value)) } # [doc = " Create a new value from a `u32` without checking whether the"] # [doc = " given value exceeds the maximum."] # [doc = ""] # [doc = " Using this routine with an invalid value will result in"] # [doc = " unspecified behavior, but *not* undefined behavior. In"] # [doc = " particular, an invalid ID value is likely to cause panics or"] # [doc = " possibly even silent logical errors."] # [doc = ""] # [doc = " Callers must never rely on this type to be within a certain"] # [doc = " range for memory safety."] # [inline] pub const fn from_u32_unchecked (index : u32) -> PatternID { PatternID (SmallIndex :: from_u32_unchecked (index)) } # [doc = " Like `new`, but panics if the given value is not valid."] # [inline] pub fn must (value : usize) -> PatternID { PatternID :: new (value) . expect ("invalid PatternID value") } # [doc = " Return the internal value as a `usize`. This is guaranteed to"] # [doc = " never overflow `usize`."] # [inline] pub const fn as_usize (& self) -> usize { self . 0 . as_usize () } # [doc = " Return the internal value as a `u64`. This is guaranteed to"] # [doc = " never overflow."] # [inline] pub const fn as_u64 (& self) -> u64 { self . 0 . as_u64 () } # [doc = " Return the internal value as a `u32`. This is guaranteed to"] # [doc = " never overflow `u32`."] # [inline] pub const fn as_u32 (& self) -> u32 { self . 0 . as_u32 () } # [doc = " Return the internal value as a `i32`. This is guaranteed to"] # [doc = " never overflow an `i32`."] # [inline] pub const fn as_i32 (& self) -> i32 { self . 0 . as_i32 () } # [doc = " Returns one more than this value as a usize."] # [doc = ""] # [doc = " Since values represented by a \"small index\" have constraints"] # [doc = " on their maximum value, adding `1` to it will always fit in a"] # [doc = " `usize`, `u32` and a `i32`."] # [inline] pub fn one_more (& self) -> usize { self . 0 . one_more () } # [doc = " Decode this value from the bytes given using the native endian"] # [doc = " byte order for the current target."] # [doc = ""] # [doc = " If the decoded integer is not representable as a small index"] # [doc = " for the current target, then this returns an error."] # [inline] pub fn from_ne_bytes (bytes : [u8 ; 4]) -> Result < PatternID , PatternIDError > { SmallIndex :: from_ne_bytes (bytes) . map (PatternID) . map_err (PatternIDError) } # [doc = " Decode this value from the bytes given using the native endian"] # [doc = " byte order for the current target."] # [doc = ""] # [doc = " This is analogous to `new_unchecked` in that is does not check"] # [doc = " whether the decoded integer is representable as a small index."] # [inline] pub fn from_ne_bytes_unchecked (bytes : [u8 ; 4]) -> PatternID { PatternID (SmallIndex :: from_ne_bytes_unchecked (bytes)) } # [doc = " Return the underlying integer as raw bytes in native endian"] # [doc = " format."] # [inline] pub fn to_ne_bytes (& self) -> [u8 ; 4] { self . 0 . to_ne_bytes () } # [doc = " Returns an iterator over all values from 0 up to and not"] # [doc = " including the given length."] # [doc = ""] # [doc = " If the given length exceeds this type's limit, then this"] # [doc = " panics."] pub (crate) fn iter (len : usize) -> PatternIDIter { PatternIDIter :: new (len) } } impl core :: fmt :: Debug for PatternID { fn fmt (& self , f : & mut core :: fmt :: Formatter) -> core :: fmt :: Result { f . debug_tuple ("PatternID") . field (& self . as_u32 ()) . finish () } } impl < T > core :: ops :: Index < PatternID > for [T] { type Output = T ; # [inline] fn index (& self , index : PatternID) -> & T { & self [index . as_usize ()] } } impl < T > core :: ops :: IndexMut < PatternID > for [T] { # [inline] fn index_mut (& mut self , index : PatternID) -> & mut T { & mut self [index . as_usize ()] } } impl < T > core :: ops :: Index < PatternID > for Vec < T > { type Output = T ; # [inline] fn index (& self , index : PatternID) -> & T { & self [index . as_usize ()] } } impl < T > core :: ops :: IndexMut < PatternID > for Vec < T > { # [inline] fn index_mut (& mut self , index : PatternID) -> & mut T { & mut self [index . as_usize ()] } } impl From < SmallIndex > for PatternID { fn from (index : SmallIndex) -> PatternID { PatternID (index) } } impl From < u8 > for PatternID { fn from (value : u8) -> PatternID { PatternID (SmallIndex :: from (value)) } } impl TryFrom < u16 > for PatternID { type Error = PatternIDError ; fn try_from (value : u16) -> Result < PatternID , PatternIDError > { SmallIndex :: try_from (value) . map (PatternID) . map_err (PatternIDError) } } impl TryFrom < u32 > for PatternID { type Error = PatternIDError ; fn try_from (value : u32) -> Result < PatternID , PatternIDError > { SmallIndex :: try_from (value) . map (PatternID) . map_err (PatternIDError) } } impl TryFrom < u64 > for PatternID { type Error = PatternIDError ; fn try_from (value : u64) -> Result < PatternID , PatternIDError > { SmallIndex :: try_from (value) . map (PatternID) . map_err (PatternIDError) } } impl TryFrom < usize > for PatternID { type Error = PatternIDError ; fn try_from (value : usize) -> Result < PatternID , PatternIDError > { SmallIndex :: try_from (value) . map (PatternID) . map_err (PatternIDError) } } # [doc = " This error occurs when an ID could not be constructed."] # [doc = ""] # [doc = " This occurs when given an integer exceeding the maximum allowed"] # [doc = " value."] # [doc = ""] # [doc = " When the `std` feature is enabled, this implements the `Error`"] # [doc = " trait."] pub struct PatternIDError (SmallIndexError) ; # [automatically_derived] impl :: core :: clone :: Clone for PatternIDError { # [inline] fn clone (& self) -> PatternIDError { PatternIDError (:: core :: clone :: Clone :: clone (& self . 0)) } } # [automatically_derived] impl :: core :: fmt :: Debug for PatternIDError { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , "PatternIDError" , & & self . 0 ,) } } # [automatically_derived] impl :: core :: cmp :: Eq for PatternIDError { # [inline] # [doc (hidden)] # [coverage (off)] fn assert_receiver_is_total_eq (& self) -> () { let _ : :: core :: cmp :: AssertParamIsEq < SmallIndexError > ; } } # [automatically_derived] impl :: core :: marker :: StructuralPartialEq for PatternIDError { } # [automatically_derived] impl :: core :: cmp :: PartialEq for PatternIDError { # [inline] fn eq (& self , other : & PatternIDError) -> bool { self . 0 == other . 0 } } impl PatternIDError { # [doc = " Returns the value that could not be converted to an ID."] pub fn attempted (& self) -> u64 { self . 0 . attempted () } } impl std :: error :: Error for PatternIDError { } impl core :: fmt :: Display for PatternIDError { fn fmt (& self , f : & mut core :: fmt :: Formatter) -> core :: fmt :: Result { f . write_fmt (format_args ! ("failed to create {0} from {1:?}, which exceeds {2:?}" , "PatternID" , self . attempted () , PatternID :: MAX ,) ,) } } pub (crate) struct PatternIDIter (SmallIndexIter) ; # [automatically_derived] impl :: core :: clone :: Clone for PatternIDIter { # [inline] fn clone (& self) -> PatternIDIter { PatternIDIter (:: core :: clone :: Clone :: clone (& self . 0)) } } # [automatically_derived] impl :: core :: fmt :: Debug for PatternIDIter { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , "PatternIDIter" , & & self . 0 ,) } } impl PatternIDIter { fn new (len : usize) -> PatternIDIter { if ! (len <= PatternID :: LIMIT) { { :: core :: panicking :: panic_fmt (format_args ! ("cannot create iterator for {0} when number of elements exceed {1:?}" , "PatternID" , PatternID :: LIMIT ,) ,) ; } } PatternIDIter (SmallIndexIter { rng : 0 .. len }) } } impl Iterator for PatternIDIter { type Item = PatternID ; fn next (& mut self) -> Option < PatternID > { self . 0 . next () . map (PatternID) } } # [doc = " An iterator adapter that is like std::iter::Enumerate, but attaches"] # [doc = " small index values instead. It requires `ExactSizeIterator`. At"] # [doc = " construction, it ensures that the index of each element in the"] # [doc = " iterator is representable in the corresponding small index type."] pub (crate) struct WithPatternIDIter < I > { it : I , ids : PatternIDIter , } # [automatically_derived] impl < I : :: core :: clone :: Clone > :: core :: clone :: Clone for WithPatternIDIter < I > { # [inline] fn clone (& self) -> WithPatternIDIter < I > { WithPatternIDIter { it : :: core :: clone :: Clone :: clone (& self . it) , ids : :: core :: clone :: Clone :: clone (& self . ids) , } } } # [automatically_derived] impl < I : :: core :: fmt :: Debug > :: core :: fmt :: Debug for WithPatternIDIter < I > { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field2_finish (f , "WithPatternIDIter" , "it" , & self . it , "ids" , & & self . ids ,) } } impl < I : Iterator + ExactSizeIterator > WithPatternIDIter < I > { fn new (it : I) -> WithPatternIDIter < I > { let ids = PatternID :: iter (it . len ()) ; WithPatternIDIter { it , ids } } } impl < I : Iterator + ExactSizeIterator > Iterator for WithPatternIDIter < I > { type Item = (PatternID , I :: Item) ; fn next (& mut self) -> Option < (PatternID , I :: Item) > { let item = self . it . next () ? ; let id = self . ids . next () . unwrap () ; Some ((id , item)) } } impl StateID { # [doc = " The maximum value."] pub const MAX : StateID = StateID (SmallIndex :: MAX) ; # [doc = " The total number of values that can be represented."] pub const LIMIT : usize = SmallIndex :: LIMIT ; # [doc = " The zero value."] pub const ZERO : StateID = StateID (SmallIndex :: ZERO) ; # [doc = " The number of bytes that a single value uses in memory."] pub const SIZE : usize = SmallIndex :: SIZE ; # [doc = " Create a new value that is represented by a \"small index.\""] # [doc = ""] # [doc = " If the given index exceeds the maximum allowed value, then this"] # [doc = " returns an error."] # [inline] pub fn new (value : usize) -> Result < StateID , StateIDError > { SmallIndex :: new (value) . map (StateID) . map_err (StateIDError) } # [doc = " Create a new value without checking whether the given argument"] # [doc = " exceeds the maximum."] # [doc = ""] # [doc = " Using this routine with an invalid value will result in"] # [doc = " unspecified behavior, but *not* undefined behavior. In"] # [doc = " particular, an invalid ID value is likely to cause panics or"] # [doc = " possibly even silent logical errors."] # [doc = ""] # [doc = " Callers must never rely on this type to be within a certain"] # [doc = " range for memory safety."] # [inline] pub const fn new_unchecked (value : usize) -> StateID { StateID (SmallIndex :: new_unchecked (value)) } # [doc = " Create a new value from a `u32` without checking whether the"] # [doc = " given value exceeds the maximum."] # [doc = ""] # [doc = " Using this routine with an invalid value will result in"] # [doc = " unspecified behavior, but *not* undefined behavior. In"] # [doc = " particular, an invalid ID value is likely to cause panics or"] # [doc = " possibly even silent logical errors."] # [doc = ""] # [doc = " Callers must never rely on this type to be within a certain"] # [doc = " range for memory safety."] # [inline] pub const fn from_u32_unchecked (index : u32) -> StateID { StateID (SmallIndex :: from_u32_unchecked (index)) } # [doc = " Like `new`, but panics if the given value is not valid."] # [inline] pub fn must (value : usize) -> StateID { StateID :: new (value) . expect ("invalid StateID value") } # [doc = " Return the internal value as a `usize`. This is guaranteed to"] # [doc = " never overflow `usize`."] # [inline] pub const fn as_usize (& self) -> usize { self . 0 . as_usize () } # [doc = " Return the internal value as a `u64`. This is guaranteed to"] # [doc = " never overflow."] # [inline] pub const fn as_u64 (& self) -> u64 { self . 0 . as_u64 () } # [doc = " Return the internal value as a `u32`. This is guaranteed to"] # [doc = " never overflow `u32`."] # [inline] pub const fn as_u32 (& self) -> u32 { self . 0 . as_u32 () } # [doc = " Return the internal value as a `i32`. This is guaranteed to"] # [doc = " never overflow an `i32`."] # [inline] pub const fn as_i32 (& self) -> i32 { self . 0 . as_i32 () } # [doc = " Returns one more than this value as a usize."] # [doc = ""] # [doc = " Since values represented by a \"small index\" have constraints"] # [doc = " on their maximum value, adding `1` to it will always fit in a"] # [doc = " `usize`, `u32` and a `i32`."] # [inline] pub fn one_more (& self) -> usize { self . 0 . one_more () } # [doc = " Decode this value from the bytes given using the native endian"] # [doc = " byte order for the current target."] # [doc = ""] # [doc = " If the decoded integer is not representable as a small index"] # [doc = " for the current target, then this returns an error."] # [inline] pub fn from_ne_bytes (bytes : [u8 ; 4]) -> Result < StateID , StateIDError > { SmallIndex :: from_ne_bytes (bytes) . map (StateID) . map_err (StateIDError) } # [doc = " Decode this value from the bytes given using the native endian"] # [doc = " byte order for the current target."] # [doc = ""] # [doc = " This is analogous to `new_unchecked` in that is does not check"] # [doc = " whether the decoded integer is representable as a small index."] # [inline] pub fn from_ne_bytes_unchecked (bytes : [u8 ; 4]) -> StateID { StateID (SmallIndex :: from_ne_bytes_unchecked (bytes)) } # [doc = " Return the underlying integer as raw bytes in native endian"] # [doc = " format."] # [inline] pub fn to_ne_bytes (& self) -> [u8 ; 4] { self . 0 . to_ne_bytes () } # [doc = " Returns an iterator over all values from 0 up to and not"] # [doc = " including the given length."] # [doc = ""] # [doc = " If the given length exceeds this type's limit, then this"] # [doc = " panics."] pub (crate) fn iter (len : usize) -> StateIDIter { StateIDIter :: new (len) } } impl core :: fmt :: Debug for StateID { fn fmt (& self , f : & mut core :: fmt :: Formatter) -> core :: fmt :: Result { f . debug_tuple ("StateID") . field (& self . as_u32 ()) . finish () } } impl < T > core :: ops :: Index < StateID > for [T] { type Output = T ; # [inline] fn index (& self , index : StateID) -> & T { & self [index . as_usize ()] } } impl < T > core :: ops :: IndexMut < StateID > for [T] { # [inline] fn index_mut (& mut self , index : StateID) -> & mut T { & mut self [index . as_usize ()] } } impl < T > core :: ops :: Index < StateID > for Vec < T > { type Output = T ; # [inline] fn index (& self , index : StateID) -> & T { & self [index . as_usize ()] } } impl < T > core :: ops :: IndexMut < StateID > for Vec < T > { # [inline] fn index_mut (& mut self , index : StateID) -> & mut T { & mut self [index . as_usize ()] } } impl From < SmallIndex > for StateID { fn from (index : SmallIndex) -> StateID { StateID (index) } } impl From < u8 > for StateID { fn from (value : u8) -> StateID { StateID (SmallIndex :: from (value)) } } impl TryFrom < u16 > for StateID { type Error = StateIDError ; fn try_from (value : u16) -> Result < StateID , StateIDError > { SmallIndex :: try_from (value) . map (StateID) . map_err (StateIDError) } } impl TryFrom < u32 > for StateID { type Error = StateIDError ; fn try_from (value : u32) -> Result < StateID , StateIDError > { SmallIndex :: try_from (value) . map (StateID) . map_err (StateIDError) } } impl TryFrom < u64 > for StateID { type Error = StateIDError ; fn try_from (value : u64) -> Result < StateID , StateIDError > { SmallIndex :: try_from (value) . map (StateID) . map_err (StateIDError) } } impl TryFrom < usize > for StateID { type Error = StateIDError ; fn try_from (value : usize) -> Result < StateID , StateIDError > { SmallIndex :: try_from (value) . map (StateID) . map_err (StateIDError) } } # [doc = " This error occurs when an ID could not be constructed."] # [doc = ""] # [doc = " This occurs when given an integer exceeding the maximum allowed"] # [doc = " value."] # [doc = ""] # [doc = " When the `std` feature is enabled, this implements the `Error`"] # [doc = " trait."] pub struct StateIDError (SmallIndexError) ; # [automatically_derived] impl :: core :: clone :: Clone for StateIDError { # [inline] fn clone (& self) -> StateIDError { StateIDError (:: core :: clone :: Clone :: clone (& self . 0)) } } # [automatically_derived] impl :: core :: fmt :: Debug for StateIDError { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , "StateIDError" , & & self . 0 ,) } } # [automatically_derived] impl :: core :: cmp :: Eq for StateIDError { # [inline] # [doc (hidden)] # [coverage (off)] fn assert_receiver_is_total_eq (& self) -> () { let _ : :: core :: cmp :: AssertParamIsEq < SmallIndexError > ; } } # [automatically_derived] impl :: core :: marker :: StructuralPartialEq for StateIDError { } # [automatically_derived] impl :: core :: cmp :: PartialEq for StateIDError { # [inline] fn eq (& self , other : & StateIDError) -> bool { self . 0 == other . 0 } } impl StateIDError { # [doc = " Returns the value that could not be converted to an ID."] pub fn attempted (& self) -> u64 { self . 0 . attempted () } } impl std :: error :: Error for StateIDError { } impl core :: fmt :: Display for StateIDError { fn fmt (& self , f : & mut core :: fmt :: Formatter) -> core :: fmt :: Result { f . write_fmt (format_args ! ("failed to create {0} from {1:?}, which exceeds {2:?}" , "StateID" , self . attempted () , StateID :: MAX ,) ,) } } pub (crate) struct StateIDIter (SmallIndexIter) ; # [automatically_derived] impl :: core :: clone :: Clone for StateIDIter { # [inline] fn clone (& self) -> StateIDIter { StateIDIter (:: core :: clone :: Clone :: clone (& self . 0)) } } # [automatically_derived] impl :: core :: fmt :: Debug for StateIDIter { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , "StateIDIter" , & & self . 0 ,) } } impl StateIDIter { fn new (len : usize) -> StateIDIter { if ! (len <= StateID :: LIMIT) { { :: core :: panicking :: panic_fmt (format_args ! ("cannot create iterator for {0} when number of elements exceed {1:?}" , "StateID" , StateID :: LIMIT ,) ,) ; } } StateIDIter (SmallIndexIter { rng : 0 .. len }) } } impl Iterator for StateIDIter { type Item = StateID ; fn next (& mut self) -> Option < StateID > { self . 0 . next () . map (StateID) } } # [doc = " An iterator adapter that is like std::iter::Enumerate, but attaches"] # [doc = " small index values instead. It requires `ExactSizeIterator`. At"] # [doc = " construction, it ensures that the index of each element in the"] # [doc = " iterator is representable in the corresponding small index type."] pub (crate) struct WithStateIDIter < I > { it : I , ids : StateIDIter , } # [automatically_derived] impl < I : :: core :: clone :: Clone > :: core :: clone :: Clone for WithStateIDIter < I > { # [inline] fn clone (& self) -> WithStateIDIter < I > { WithStateIDIter { it : :: core :: clone :: Clone :: clone (& self . it) , ids : :: core :: clone :: Clone :: clone (& self . ids) , } } } # [automatically_derived] impl < I : :: core :: fmt :: Debug > :: core :: fmt :: Debug for WithStateIDIter < I > { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field2_finish (f , "WithStateIDIter" , "it" , & self . it , "ids" , & & self . ids ,) } } impl < I : Iterator + ExactSizeIterator > WithStateIDIter < I > { fn new (it : I) -> WithStateIDIter < I > { let ids = StateID :: iter (it . len ()) ; WithStateIDIter { it , ids } } } impl < I : Iterator + ExactSizeIterator > Iterator for WithStateIDIter < I > { type Item = (StateID , I :: Item) ; fn next (& mut self) -> Option < (StateID , I :: Item) > { let item = self . it . next () ? ; let id = self . ids . next () . unwrap () ; Some ((id , item)) } } # [doc = " A utility trait that defines a couple of adapters for making it convenient"] # [doc = " to access indices as \"small index\" types. We require ExactSizeIterator so"] # [doc = " that iterator construction can do a single check to make sure the index of"] # [doc = " each element is representable by its small index type."] pub (crate) trait IteratorIndexExt : Iterator { fn with_pattern_ids (self) -> WithPatternIDIter < Self > where Self : Sized + ExactSizeIterator , { WithPatternIDIter :: new (self) } fn with_state_ids (self) -> WithStateIDIter < Self > where Self : Sized + ExactSizeIterator , { WithStateIDIter :: new (self) } } impl < I : Iterator > IteratorIndexExt for I { } } pub (crate) mod remapper { use alloc :: vec :: Vec ; use crate :: { nfa :: noncontiguous , util :: primitives :: StateID } ; # [doc = " Remappable is a tightly coupled abstraction that facilitates remapping"] # [doc = " state identifiers in DFAs."] # [doc = ""] # [doc = " The main idea behind remapping state IDs is that DFAs often need to check"] # [doc = " if a certain state is a \"special\" state of some kind (like a match state)"] # [doc = " during a search. Since this is extremely perf critical code, we want this"] # [doc = " check to be as fast as possible. Partitioning state IDs into, for example,"] # [doc = " into \"non-match\" and \"match\" states means one can tell if a state is a"] # [doc = " match state via a simple comparison of the state ID."] # [doc = ""] # [doc = " The issue is that during the DFA construction process, it's not"] # [doc = " particularly easy to partition the states. Instead, the simplest thing is"] # [doc = " to often just do a pass over all of the states and shuffle them into their"] # [doc = " desired partitionings. To do that, we need a mechanism for swapping states."] # [doc = " Hence, this abstraction."] # [doc = ""] # [doc = " Normally, for such little code, I would just duplicate it. But this is a"] # [doc = " key optimization and the implementation is a bit subtle. So the abstraction"] # [doc = " is basically a ham-fisted attempt at DRY. The only place we use this is in"] # [doc = " the dense and one-pass DFAs."] # [doc = ""] # [doc = " See also src/dfa/special.rs for a more detailed explanation of how dense"] # [doc = " DFAs are partitioned."] pub (crate) trait Remappable : core :: fmt :: Debug { # [doc = " Return the total number of states."] fn state_len (& self) -> usize ; # [doc = " Swap the states pointed to by the given IDs. The underlying finite"] # [doc = " state machine should be mutated such that all of the transitions in"] # [doc = " `id1` are now in the memory region where the transitions for `id2`"] # [doc = " were, and all of the transitions in `id2` are now in the memory region"] # [doc = " where the transitions for `id1` were."] # [doc = ""] # [doc = " Essentially, this \"moves\" `id1` to `id2` and `id2` to `id1`."] # [doc = ""] # [doc = " It is expected that, after calling this, the underlying state machine"] # [doc = " will be left in an inconsistent state, since any other transitions"] # [doc = " pointing to, e.g., `id1` need to be updated to point to `id2`, since"] # [doc = " that's where `id1` moved to."] # [doc = ""] # [doc = " In order to \"fix\" the underlying inconsistent state, a `Remapper`"] # [doc = " should be used to guarantee that `remap` is called at the appropriate"] # [doc = " time."] fn swap_states (& mut self , id1 : StateID , id2 : StateID) ; # [doc = " This must remap every single state ID in the underlying value according"] # [doc = " to the function given. For example, in a DFA, this should remap every"] # [doc = " transition and every starting state ID."] fn remap (& mut self , map : impl Fn (StateID) -> StateID) ; } # [doc = " Remapper is an abstraction the manages the remapping of state IDs in a"] # [doc = " finite state machine. This is useful when one wants to shuffle states into"] # [doc = " different positions in the machine."] # [doc = ""] # [doc = " One of the key complexities this manages is the ability to correctly move"] # [doc = " one state multiple times."] # [doc = ""] # [doc = " Once shuffling is complete, `remap` must be called, which will rewrite"] # [doc = " all pertinent transitions to updated state IDs. Neglecting to call `remap`"] # [doc = " will almost certainly result in a corrupt machine."] pub (crate) struct Remapper { # [doc = " A map from the index of a state to its pre-multiplied identifier."] # [doc = ""] # [doc = " When a state is swapped with another, then their corresponding"] # [doc = " locations in this map are also swapped. Thus, its new position will"] # [doc = " still point to its old pre-multiplied StateID."] # [doc = ""] # [doc = " While there is a bit more to it, this then allows us to rewrite the"] # [doc = " state IDs in a DFA's transition table in a single pass. This is done"] # [doc = " by iterating over every ID in this map, then iterating over each"] # [doc = " transition for the state at that ID and re-mapping the transition from"] # [doc = " `old_id` to `map[dfa.to_index(old_id)]`. That is, we find the position"] # [doc = " in this map where `old_id` *started*, and set it to where it ended up"] # [doc = " after all swaps have been completed."] map : Vec < StateID > , # [doc = " A way to map indices to state IDs (and back)."] idx : IndexMapper , } # [automatically_derived] impl :: core :: fmt :: Debug for Remapper { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field2_finish (f , "Remapper" , "map" , & self . map , "idx" , & & self . idx ,) } } impl Remapper { # [doc = " Create a new remapper from the given remappable implementation. The"] # [doc = " remapper can then be used to swap states. The remappable value given"] # [doc = " here must the same one given to `swap` and `remap`."] # [doc = ""] # [doc = " The given stride should be the stride of the transition table expressed"] # [doc = " as a power of 2. This stride is used to map between state IDs and state"] # [doc = " indices. If state IDs and state indices are equivalent, then provide"] # [doc = " a `stride2` of `0`, which acts as an identity."] pub (crate) fn new (r : & impl Remappable , stride2 : usize) -> Remapper { let idx = IndexMapper { stride2 } ; let map = (0 .. r . state_len ()) . map (| i | idx . to_state_id (i)) . collect () ; Remapper { map , idx } } # [doc = " Swap two states. Once this is called, callers must follow through to"] # [doc = " call `remap`, or else it's possible for the underlying remappable"] # [doc = " value to be in a corrupt state."] pub (crate) fn swap (& mut self , r : & mut impl Remappable , id1 : StateID , id2 : StateID ,) { if id1 == id2 { return ; } r . swap_states (id1 , id2) ; self . map . swap (self . idx . to_index (id1) , self . idx . to_index (id2)) ; } # [doc = " Complete the remapping process by rewriting all state IDs in the"] # [doc = " remappable value according to the swaps performed."] pub (crate) fn remap (mut self , r : & mut impl Remappable) { let oldmap = self . map . clone () ; for i in 0 .. r . state_len () { let cur_id = self . idx . to_state_id (i) ; let mut new_id = oldmap [i] ; if cur_id == new_id { continue ; } loop { let id = oldmap [self . idx . to_index (new_id)] ; if cur_id == id { self . map [i] = new_id ; break ; } new_id = id ; } } r . remap (| sid | self . map [self . idx . to_index (sid)]) ; } } # [doc = " A simple type for mapping between state indices and state IDs."] # [doc = ""] # [doc = " The reason why this exists is because state IDs are \"premultiplied\" in a"] # [doc = " DFA. That is, in order to get to the transitions for a particular state,"] # [doc = " one need only use the state ID as-is, instead of having to multiply it by"] # [doc = " transition table's stride."] # [doc = ""] # [doc = " The downside of this is that it's inconvenient to map between state IDs"] # [doc = " using a dense map, e.g., Vec<StateID>. That's because state IDs look like"] # [doc = " `0`, `stride`, `2*stride`, `3*stride`, etc., instead of `0`, `1`, `2`, `3`,"] # [doc = " etc."] # [doc = ""] # [doc = " Since our state IDs are premultiplied, we can convert back-and-forth"] # [doc = " between IDs and indices by simply unmultiplying the IDs and multiplying the"] # [doc = " indices."] # [doc = ""] # [doc = " Note that for a sparse NFA, state IDs and indices are equivalent. In this"] # [doc = " case, we set the stride of the index mapped to be `0`, which acts as an"] # [doc = " identity."] struct IndexMapper { # [doc = " The power of 2 corresponding to the stride of the corresponding"] # [doc = " transition table. 'id >> stride2' de-multiplies an ID while 'index <<"] # [doc = " stride2' pre-multiplies an index to an ID."] stride2 : usize , } # [automatically_derived] impl :: core :: fmt :: Debug for IndexMapper { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field1_finish (f , "IndexMapper" , "stride2" , & & self . stride2 ,) } } impl IndexMapper { # [doc = " Convert a state ID to a state index."] fn to_index (& self , id : StateID) -> usize { id . as_usize () >> self . stride2 } # [doc = " Convert a state index to a state ID."] fn to_state_id (& self , index : usize) -> StateID { StateID :: new_unchecked (index << self . stride2) } } impl Remappable for noncontiguous :: NFA { fn state_len (& self) -> usize { noncontiguous :: NFA :: states (self) . len () } fn swap_states (& mut self , id1 : StateID , id2 : StateID) { noncontiguous :: NFA :: swap_states (self , id1 , id2) } fn remap (& mut self , map : impl Fn (StateID) -> StateID) { noncontiguous :: NFA :: remap (self , map) } } } pub (crate) mod search { use core :: ops :: { Range , RangeBounds } ; use crate :: util :: primitives :: PatternID ; # [doc = " The configuration and the haystack to use for an Aho-Corasick search."] # [doc = ""] # [doc = " When executing a search, there are a few parameters one might want to"] # [doc = " configure:"] # [doc = ""] # [doc = " * The haystack to search, provided to the [`Input::new`] constructor. This"] # [doc = " is the only required parameter."] # [doc = " * The span _within_ the haystack to limit a search to. (The default"] # [doc = " is the entire haystack.) This is configured via [`Input::span`] or"] # [doc = " [`Input::range`]."] # [doc = " * Whether to run an unanchored (matches can occur anywhere after the"] # [doc = " start of the search) or anchored (matches can only occur beginning at"] # [doc = " the start of the search) search. Unanchored search is the default. This is"] # [doc = " configured via [`Input::anchored`]."] # [doc = " * Whether to quit the search as soon as a match has been found, regardless"] # [doc = " of the [`MatchKind`] that the searcher was built with. This is configured"] # [doc = " via [`Input::earliest`]."] # [doc = ""] # [doc = " For most cases, the defaults for all optional parameters are appropriate."] # [doc = " The utility of this type is that it keeps the default or common case simple"] # [doc = " while permitting tweaking parameters in more niche use cases while reusing"] # [doc = " the same search APIs."] # [doc = ""] # [doc = " # Valid bounds and search termination"] # [doc = ""] # [doc = " An `Input` permits setting the bounds of a search via either"] # [doc = " [`Input::span`] or [`Input::range`]. The bounds set must be valid, or"] # [doc = " else a panic will occur. Bounds are valid if and only if:"] # [doc = ""] # [doc = " * The bounds represent a valid range into the input's haystack."] # [doc = " * **or** the end bound is a valid ending bound for the haystack *and*"] # [doc = " the start bound is exactly one greater than the end bound."] # [doc = ""] # [doc = " In the latter case, [`Input::is_done`] will return true and indicates any"] # [doc = " search receiving such an input should immediately return with no match."] # [doc = ""] # [doc = " Other than representing \"search is complete,\" the `Input::span` and"] # [doc = " `Input::range` APIs are never necessary. Instead, callers can slice the"] # [doc = " haystack instead, e.g., with `&haystack[start..end]`. With that said, they"] # [doc = " can be more convenient than slicing because the match positions reported"] # [doc = " when using `Input::span` or `Input::range` are in terms of the original"] # [doc = " haystack. If you instead use `&haystack[start..end]`, then you'll need to"] # [doc = " add `start` to any match position returned in order for it to be a correct"] # [doc = " index into `haystack`."] # [doc = ""] # [doc = " # Example: `&str` and `&[u8]` automatically convert to an `Input`"] # [doc = ""] # [doc = " There is a `From<&T> for Input` implementation for all `T: AsRef<[u8]>`."] # [doc = " Additionally, the [`AhoCorasick`](crate::AhoCorasick) search APIs accept"] # [doc = " a `Into<Input>`. These two things combined together mean you can provide"] # [doc = " things like `&str` and `&[u8]` to search APIs when the defaults are"] # [doc = " suitable, but also an `Input` when they're not. For example:"] # [doc = ""] # [doc = " ```"] # [doc = " use aho_corasick::{AhoCorasick, Anchored, Input, Match, StartKind};"] # [doc = ""] # [doc = " // Build a searcher that supports both unanchored and anchored modes."] # [doc = " let ac = AhoCorasick::builder()"] # [doc = "     .start_kind(StartKind::Both)"] # [doc = "     .build(&[\"abcd\", \"b\"])"] # [doc = "     .unwrap();"] # [doc = " let haystack = \"abcd\";"] # [doc = ""] # [doc = " // A search using default parameters is unanchored. With standard"] # [doc = " // semantics, this finds `b` first."] # [doc = " assert_eq!("] # [doc = "     Some(Match::must(1, 1..2)),"] # [doc = "     ac.find(haystack),"] # [doc = " );"] # [doc = " // Using the same 'find' routine, we can provide an 'Input' explicitly"] # [doc = " // that is configured to do an anchored search. Since 'b' doesn't start"] # [doc = " // at the beginning of the search, it is not reported as a match."] # [doc = " assert_eq!("] # [doc = "     Some(Match::must(0, 0..4)),"] # [doc = "     ac.find(Input::new(haystack).anchored(Anchored::Yes)),"] # [doc = " );"] # [doc = " ```"] pub struct Input < 'h > { haystack : & 'h [u8] , span : Span , anchored : Anchored , earliest : bool , } # [automatically_derived] impl < 'h > :: core :: clone :: Clone for Input < 'h > { # [inline] fn clone (& self) -> Input < 'h > { Input { haystack : :: core :: clone :: Clone :: clone (& self . haystack) , span : :: core :: clone :: Clone :: clone (& self . span) , anchored : :: core :: clone :: Clone :: clone (& self . anchored) , earliest : :: core :: clone :: Clone :: clone (& self . earliest) , } } } impl < 'h > Input < 'h > { # [doc = " Create a new search configuration for the given haystack."] # [inline] pub fn new < H : ? Sized + AsRef < [u8] > > (haystack : & 'h H) -> Input < 'h > { Input { haystack : haystack . as_ref () , span : Span { start : 0 , end : haystack . as_ref () . len () , } , anchored : Anchored :: No , earliest : false , } } # [doc = " Set the span for this search."] # [doc = ""] # [doc = " This routine is generic over how a span is provided. While"] # [doc = " a [`Span`] may be given directly, one may also provide a"] # [doc = " `std::ops::Range<usize>`. To provide anything supported by range"] # [doc = " syntax, use the [`Input::range`] method."] # [doc = ""] # [doc = " The default span is the entire haystack."] # [doc = ""] # [doc = " Note that [`Input::range`] overrides this method and vice versa."] # [doc = ""] # [doc = " # Panics"] # [doc = ""] # [doc = " This panics if the given span does not correspond to valid bounds in"] # [doc = " the haystack or the termination of a search."] # [doc = ""] # [doc = " # Example"] # [doc = ""] # [doc = " This example shows how the span of the search can impact whether a"] # [doc = " match is reported or not."] # [doc = ""] # [doc = " ```"] # [doc = " use aho_corasick::{AhoCorasick, Input, MatchKind};"] # [doc = ""] # [doc = " let patterns = &[\"b\", \"abcd\", \"abc\"];"] # [doc = " let haystack = \"abcd\";"] # [doc = ""] # [doc = " let ac = AhoCorasick::builder()"] # [doc = "     .match_kind(MatchKind::LeftmostFirst)"] # [doc = "     .build(patterns)"] # [doc = "     .unwrap();"] # [doc = " let input = Input::new(haystack).span(0..3);"] # [doc = " let mat = ac.try_find(input)?.expect(\"should have a match\");"] # [doc = " // Without the span stopping the search early, 'abcd' would be reported"] # [doc = " // because it is the correct leftmost-first match."] # [doc = " assert_eq!(\"abc\", &haystack[mat.span()]);"] # [doc = ""] # [doc = " # Ok::<(), Box<dyn std::error::Error>>(())"] # [doc = " ```"] # [inline] pub fn span < S : Into < Span > > (mut self , span : S) -> Input < 'h > { self . set_span (span) ; self } # [doc = " Like `Input::span`, but accepts any range instead."] # [doc = ""] # [doc = " The default range is the entire haystack."] # [doc = ""] # [doc = " Note that [`Input::span`] overrides this method and vice versa."] # [doc = ""] # [doc = " # Panics"] # [doc = ""] # [doc = " This routine will panic if the given range could not be converted"] # [doc = " to a valid [`Range`]. For example, this would panic when given"] # [doc = " `0..=usize::MAX` since it cannot be represented using a half-open"] # [doc = " interval in terms of `usize`."] # [doc = ""] # [doc = " This routine also panics if the given range does not correspond to"] # [doc = " valid bounds in the haystack or the termination of a search."] # [doc = ""] # [doc = " # Example"] # [doc = ""] # [doc = " ```"] # [doc = " use aho_corasick::Input;"] # [doc = ""] # [doc = " let input = Input::new(\"foobar\");"] # [doc = " assert_eq!(0..6, input.get_range());"] # [doc = ""] # [doc = " let input = Input::new(\"foobar\").range(2..=4);"] # [doc = " assert_eq!(2..5, input.get_range());"] # [doc = " ```"] # [inline] pub fn range < R : RangeBounds < usize > > (mut self , range : R) -> Input < 'h > { self . set_range (range) ; self } # [doc = " Sets the anchor mode of a search."] # [doc = ""] # [doc = " When a search is anchored (via [`Anchored::Yes`]), a match must begin"] # [doc = " at the start of a search. When a search is not anchored (that's"] # [doc = " [`Anchored::No`]), searchers will look for a match anywhere in the"] # [doc = " haystack."] # [doc = ""] # [doc = " By default, the anchored mode is [`Anchored::No`]."] # [doc = ""] # [doc = " # Support for anchored searches"] # [doc = ""] # [doc = " Anchored or unanchored searches might not always be available,"] # [doc = " depending on the type of searcher used and its configuration:"] # [doc = ""] # [doc = " * [`noncontiguous::NFA`](crate::nfa::noncontiguous::NFA) always"] # [doc = " supports both unanchored and anchored searches."] # [doc = " * [`contiguous::NFA`](crate::nfa::contiguous::NFA) always supports both"] # [doc = " unanchored and anchored searches."] # [doc = " * [`dfa::DFA`](crate::dfa::DFA) supports only unanchored"] # [doc = " searches by default."] # [doc = " [`dfa::Builder::start_kind`](crate::dfa::Builder::start_kind) can"] # [doc = " be used to change the default to supporting both kinds of searches"] # [doc = " or even just anchored searches."] # [doc = " * [`AhoCorasick`](crate::AhoCorasick) inherits the same setup as a"] # [doc = " `DFA`. Namely, it only supports unanchored searches by default, but"] # [doc = " [`AhoCorasickBuilder::start_kind`](crate::AhoCorasickBuilder::start_kind)"] # [doc = " can change this."] # [doc = ""] # [doc = " If you try to execute a search using a `try_` (\"fallible\") method with"] # [doc = " an unsupported anchor mode, then an error will be returned. For calls"] # [doc = " to infallible search methods, a panic will result."] # [doc = ""] # [doc = " # Example"] # [doc = ""] # [doc = " This demonstrates the differences between an anchored search and"] # [doc = " an unanchored search. Notice that we build our `AhoCorasick` searcher"] # [doc = " with [`StartKind::Both`] so that it supports both unanchored and"] # [doc = " anchored searches simultaneously."] # [doc = ""] # [doc = " ```"] # [doc = " use aho_corasick::{"] # [doc = "     AhoCorasick, Anchored, Input, MatchKind, StartKind,"] # [doc = " };"] # [doc = ""] # [doc = " let patterns = &[\"bcd\"];"] # [doc = " let haystack = \"abcd\";"] # [doc = ""] # [doc = " let ac = AhoCorasick::builder()"] # [doc = "     .start_kind(StartKind::Both)"] # [doc = "     .build(patterns)"] # [doc = "     .unwrap();"] # [doc = ""] # [doc = " // Note that 'Anchored::No' is the default, so it doesn't need to"] # [doc = " // be explicitly specified here."] # [doc = " let input = Input::new(haystack);"] # [doc = " let mat = ac.try_find(input)?.expect(\"should have a match\");"] # [doc = " assert_eq!(\"bcd\", &haystack[mat.span()]);"] # [doc = ""] # [doc = " // While 'bcd' occurs in the haystack, it does not begin where our"] # [doc = " // search begins, so no match is found."] # [doc = " let input = Input::new(haystack).anchored(Anchored::Yes);"] # [doc = " assert_eq!(None, ac.try_find(input)?);"] # [doc = ""] # [doc = " // However, if we start our search where 'bcd' starts, then we will"] # [doc = " // find a match."] # [doc = " let input = Input::new(haystack).range(1..).anchored(Anchored::Yes);"] # [doc = " let mat = ac.try_find(input)?.expect(\"should have a match\");"] # [doc = " assert_eq!(\"bcd\", &haystack[mat.span()]);"] # [doc = ""] # [doc = " # Ok::<(), Box<dyn std::error::Error>>(())"] # [doc = " ```"] # [inline] pub fn anchored (mut self , mode : Anchored) -> Input < 'h > { self . set_anchored (mode) ; self } # [doc = " Whether to execute an \"earliest\" search or not."] # [doc = ""] # [doc = " When running a non-overlapping search, an \"earliest\" search will"] # [doc = " return the match location as early as possible. For example, given"] # [doc = " the patterns `abc` and `b`, and a haystack of `abc`, a normal"] # [doc = " leftmost-first search will return `abc` as a match. But an \"earliest\""] # [doc = " search will return as soon as it is known that a match occurs, which"] # [doc = " happens once `b` is seen."] # [doc = ""] # [doc = " Note that when using [`MatchKind::Standard`], the \"earliest\" option"] # [doc = " has no effect since standard semantics are already \"earliest.\" Note"] # [doc = " also that this has no effect in overlapping searches, since overlapping"] # [doc = " searches also use standard semantics and report all possible matches."] # [doc = ""] # [doc = " This is disabled by default."] # [doc = ""] # [doc = " # Example"] # [doc = ""] # [doc = " This example shows the difference between \"earliest\" searching and"] # [doc = " normal leftmost searching."] # [doc = ""] # [doc = " ```"] # [doc = " use aho_corasick::{AhoCorasick, Anchored, Input, MatchKind, StartKind};"] # [doc = ""] # [doc = " let patterns = &[\"abc\", \"b\"];"] # [doc = " let haystack = \"abc\";"] # [doc = ""] # [doc = " let ac = AhoCorasick::builder()"] # [doc = "     .match_kind(MatchKind::LeftmostFirst)"] # [doc = "     .build(patterns)"] # [doc = "     .unwrap();"] # [doc = ""] # [doc = " // The normal leftmost-first match."] # [doc = " let input = Input::new(haystack);"] # [doc = " let mat = ac.try_find(input)?.expect(\"should have a match\");"] # [doc = " assert_eq!(\"abc\", &haystack[mat.span()]);"] # [doc = ""] # [doc = " // The \"earliest\" possible match, even if it isn't leftmost-first."] # [doc = " let input = Input::new(haystack).earliest(true);"] # [doc = " let mat = ac.try_find(input)?.expect(\"should have a match\");"] # [doc = " assert_eq!(\"b\", &haystack[mat.span()]);"] # [doc = ""] # [doc = " # Ok::<(), Box<dyn std::error::Error>>(())"] # [doc = " ```"] # [inline] pub fn earliest (mut self , yes : bool) -> Input < 'h > { self . set_earliest (yes) ; self } # [doc = " Set the span for this search configuration."] # [doc = ""] # [doc = " This is like the [`Input::span`] method, except this mutates the"] # [doc = " span in place."] # [doc = ""] # [doc = " This routine is generic over how a span is provided. While"] # [doc = " a [`Span`] may be given directly, one may also provide a"] # [doc = " `std::ops::Range<usize>`."] # [doc = ""] # [doc = " # Panics"] # [doc = ""] # [doc = " This panics if the given span does not correspond to valid bounds in"] # [doc = " the haystack or the termination of a search."] # [doc = ""] # [doc = " # Example"] # [doc = ""] # [doc = " ```"] # [doc = " use aho_corasick::Input;"] # [doc = ""] # [doc = " let mut input = Input::new(\"foobar\");"] # [doc = " assert_eq!(0..6, input.get_range());"] # [doc = " input.set_span(2..4);"] # [doc = " assert_eq!(2..4, input.get_range());"] # [doc = " ```"] # [inline] pub fn set_span < S : Into < Span > > (& mut self , span : S) { let span = span . into () ; if ! (span . end <= self . haystack . len () && span . start <= span . end . wrapping_add (1)) { { :: core :: panicking :: panic_fmt (format_args ! ("invalid span {0:?} for haystack of length {1}" , span , self . haystack . len () ,) ,) ; } } self . span = span ; } # [doc = " Set the span for this search configuration given any range."] # [doc = ""] # [doc = " This is like the [`Input::range`] method, except this mutates the"] # [doc = " span in place."] # [doc = ""] # [doc = " # Panics"] # [doc = ""] # [doc = " This routine will panic if the given range could not be converted"] # [doc = " to a valid [`Range`]. For example, this would panic when given"] # [doc = " `0..=usize::MAX` since it cannot be represented using a half-open"] # [doc = " interval in terms of `usize`."] # [doc = ""] # [doc = " This routine also panics if the given range does not correspond to"] # [doc = " valid bounds in the haystack or the termination of a search."] # [doc = ""] # [doc = " # Example"] # [doc = ""] # [doc = " ```"] # [doc = " use aho_corasick::Input;"] # [doc = ""] # [doc = " let mut input = Input::new(\"foobar\");"] # [doc = " assert_eq!(0..6, input.get_range());"] # [doc = " input.set_range(2..=4);"] # [doc = " assert_eq!(2..5, input.get_range());"] # [doc = " ```"] # [inline] pub fn set_range < R : RangeBounds < usize > > (& mut self , range : R) { use core :: ops :: Bound ; let start = match range . start_bound () { Bound :: Included (& i) => i , Bound :: Excluded (& i) => i . checked_add (1) . unwrap () , Bound :: Unbounded => 0 , } ; let end = match range . end_bound () { Bound :: Included (& i) => i . checked_add (1) . unwrap () , Bound :: Excluded (& i) => i , Bound :: Unbounded => self . haystack () . len () , } ; self . set_span (Span { start , end }) ; } # [doc = " Set the starting offset for the span for this search configuration."] # [doc = ""] # [doc = " This is a convenience routine for only mutating the start of a span"] # [doc = " without having to set the entire span."] # [doc = ""] # [doc = " # Panics"] # [doc = ""] # [doc = " This panics if the given span does not correspond to valid bounds in"] # [doc = " the haystack or the termination of a search."] # [doc = ""] # [doc = " # Example"] # [doc = ""] # [doc = " ```"] # [doc = " use aho_corasick::Input;"] # [doc = ""] # [doc = " let mut input = Input::new(\"foobar\");"] # [doc = " assert_eq!(0..6, input.get_range());"] # [doc = " input.set_start(5);"] # [doc = " assert_eq!(5..6, input.get_range());"] # [doc = " ```"] # [inline] pub fn set_start (& mut self , start : usize) { self . set_span (Span { start , .. self . get_span () }) ; } # [doc = " Set the ending offset for the span for this search configuration."] # [doc = ""] # [doc = " This is a convenience routine for only mutating the end of a span"] # [doc = " without having to set the entire span."] # [doc = ""] # [doc = " # Panics"] # [doc = ""] # [doc = " This panics if the given span does not correspond to valid bounds in"] # [doc = " the haystack or the termination of a search."] # [doc = ""] # [doc = " # Example"] # [doc = ""] # [doc = " ```"] # [doc = " use aho_corasick::Input;"] # [doc = ""] # [doc = " let mut input = Input::new(\"foobar\");"] # [doc = " assert_eq!(0..6, input.get_range());"] # [doc = " input.set_end(5);"] # [doc = " assert_eq!(0..5, input.get_range());"] # [doc = " ```"] # [inline] pub fn set_end (& mut self , end : usize) { self . set_span (Span { end , .. self . get_span () }) ; } # [doc = " Set the anchor mode of a search."] # [doc = ""] # [doc = " This is like [`Input::anchored`], except it mutates the search"] # [doc = " configuration in place."] # [doc = ""] # [doc = " # Example"] # [doc = ""] # [doc = " ```"] # [doc = " use aho_corasick::{Anchored, Input};"] # [doc = ""] # [doc = " let mut input = Input::new(\"foobar\");"] # [doc = " assert_eq!(Anchored::No, input.get_anchored());"] # [doc = ""] # [doc = " input.set_anchored(Anchored::Yes);"] # [doc = " assert_eq!(Anchored::Yes, input.get_anchored());"] # [doc = " ```"] # [inline] pub fn set_anchored (& mut self , mode : Anchored) { self . anchored = mode ; } # [doc = " Set whether the search should execute in \"earliest\" mode or not."] # [doc = ""] # [doc = " This is like [`Input::earliest`], except it mutates the search"] # [doc = " configuration in place."] # [doc = ""] # [doc = " # Example"] # [doc = ""] # [doc = " ```"] # [doc = " use aho_corasick::Input;"] # [doc = ""] # [doc = " let mut input = Input::new(\"foobar\");"] # [doc = " assert!(!input.get_earliest());"] # [doc = " input.set_earliest(true);"] # [doc = " assert!(input.get_earliest());"] # [doc = " ```"] # [inline] pub fn set_earliest (& mut self , yes : bool) { self . earliest = yes ; } # [doc = " Return a borrow of the underlying haystack as a slice of bytes."] # [doc = ""] # [doc = " # Example"] # [doc = ""] # [doc = " ```"] # [doc = " use aho_corasick::Input;"] # [doc = ""] # [doc = " let input = Input::new(\"foobar\");"] # [doc = " assert_eq!(b\"foobar\", input.haystack());"] # [doc = " ```"] # [inline] pub fn haystack (& self) -> & [u8] { self . haystack } # [doc = " Return the start position of this search."] # [doc = ""] # [doc = " This is a convenience routine for `search.get_span().start()`."] # [doc = ""] # [doc = " # Example"] # [doc = ""] # [doc = " ```"] # [doc = " use aho_corasick::Input;"] # [doc = ""] # [doc = " let input = Input::new(\"foobar\");"] # [doc = " assert_eq!(0, input.start());"] # [doc = ""] # [doc = " let input = Input::new(\"foobar\").span(2..4);"] # [doc = " assert_eq!(2, input.start());"] # [doc = " ```"] # [inline] pub fn start (& self) -> usize { self . get_span () . start } # [doc = " Return the end position of this search."] # [doc = ""] # [doc = " This is a convenience routine for `search.get_span().end()`."] # [doc = ""] # [doc = " # Example"] # [doc = ""] # [doc = " ```"] # [doc = " use aho_corasick::Input;"] # [doc = ""] # [doc = " let input = Input::new(\"foobar\");"] # [doc = " assert_eq!(6, input.end());"] # [doc = ""] # [doc = " let input = Input::new(\"foobar\").span(2..4);"] # [doc = " assert_eq!(4, input.end());"] # [doc = " ```"] # [inline] pub fn end (& self) -> usize { self . get_span () . end } # [doc = " Return the span for this search configuration."] # [doc = ""] # [doc = " If one was not explicitly set, then the span corresponds to the entire"] # [doc = " range of the haystack."] # [doc = ""] # [doc = " # Example"] # [doc = ""] # [doc = " ```"] # [doc = " use aho_corasick::{Input, Span};"] # [doc = ""] # [doc = " let input = Input::new(\"foobar\");"] # [doc = " assert_eq!(Span { start: 0, end: 6 }, input.get_span());"] # [doc = " ```"] # [inline] pub fn get_span (& self) -> Span { self . span } # [doc = " Return the span as a range for this search configuration."] # [doc = ""] # [doc = " If one was not explicitly set, then the span corresponds to the entire"] # [doc = " range of the haystack."] # [doc = ""] # [doc = " # Example"] # [doc = ""] # [doc = " ```"] # [doc = " use aho_corasick::Input;"] # [doc = ""] # [doc = " let input = Input::new(\"foobar\");"] # [doc = " assert_eq!(0..6, input.get_range());"] # [doc = " ```"] # [inline] pub fn get_range (& self) -> Range < usize > { self . get_span () . range () } # [doc = " Return the anchored mode for this search configuration."] # [doc = ""] # [doc = " If no anchored mode was set, then it defaults to [`Anchored::No`]."] # [doc = ""] # [doc = " # Example"] # [doc = ""] # [doc = " ```"] # [doc = " use aho_corasick::{Anchored, Input};"] # [doc = ""] # [doc = " let mut input = Input::new(\"foobar\");"] # [doc = " assert_eq!(Anchored::No, input.get_anchored());"] # [doc = ""] # [doc = " input.set_anchored(Anchored::Yes);"] # [doc = " assert_eq!(Anchored::Yes, input.get_anchored());"] # [doc = " ```"] # [inline] pub fn get_anchored (& self) -> Anchored { self . anchored } # [doc = " Return whether this search should execute in \"earliest\" mode."] # [doc = ""] # [doc = " # Example"] # [doc = ""] # [doc = " ```"] # [doc = " use aho_corasick::Input;"] # [doc = ""] # [doc = " let input = Input::new(\"foobar\");"] # [doc = " assert!(!input.get_earliest());"] # [doc = " ```"] # [inline] pub fn get_earliest (& self) -> bool { self . earliest } # [doc = " Return true if this input has been exhausted, which in turn means all"] # [doc = " subsequent searches will return no matches."] # [doc = ""] # [doc = " This occurs precisely when the start position of this search is greater"] # [doc = " than the end position of the search."] # [doc = ""] # [doc = " # Example"] # [doc = ""] # [doc = " ```"] # [doc = " use aho_corasick::Input;"] # [doc = ""] # [doc = " let mut input = Input::new(\"foobar\");"] # [doc = " assert!(!input.is_done());"] # [doc = " input.set_start(6);"] # [doc = " assert!(!input.is_done());"] # [doc = " input.set_start(7);"] # [doc = " assert!(input.is_done());"] # [doc = " ```"] # [inline] pub fn is_done (& self) -> bool { self . get_span () . start > self . get_span () . end } } impl < 'h > core :: fmt :: Debug for Input < 'h > { fn fmt (& self , f : & mut core :: fmt :: Formatter) -> core :: fmt :: Result { let mut fmter = f . debug_struct ("Input") ; match core :: str :: from_utf8 (self . haystack ()) { Ok (nice) => fmter . field ("haystack" , & nice) , Err (_) => fmter . field ("haystack" , & self . haystack ()) , } . field ("span" , & self . span) . field ("anchored" , & self . anchored) . field ("earliest" , & self . earliest) . finish () } } impl < 'h , H : ? Sized + AsRef < [u8] > > From < & 'h H > for Input < 'h > { # [inline] fn from (haystack : & 'h H) -> Input < 'h > { Input :: new (haystack) } } # [doc = " A representation of a range in a haystack."] # [doc = ""] # [doc = " A span corresponds to the starting and ending _byte offsets_ of a"] # [doc = " contiguous region of bytes. The starting offset is inclusive while the"] # [doc = " ending offset is exclusive. That is, a span is a half-open interval."] # [doc = ""] # [doc = " A span is used to report the offsets of a match, but it is also used to"] # [doc = " convey which region of a haystack should be searched via routines like"] # [doc = " [`Input::span`]."] # [doc = ""] # [doc = " This is basically equivalent to a `std::ops::Range<usize>`, except this"] # [doc = " type implements `Copy` which makes it more ergonomic to use in the context"] # [doc = " of this crate. Indeed, `Span` exists only because `Range<usize>` does"] # [doc = " not implement `Copy`. Like a range, this implements `Index` for `[u8]`"] # [doc = " and `str`, and `IndexMut` for `[u8]`. For convenience, this also impls"] # [doc = " `From<Range>`, which means things like `Span::from(5..10)` work."] # [doc = ""] # [doc = " There are no constraints on the values of a span. It is, for example, legal"] # [doc = " to create a span where `start > end`."] pub struct Span { # [doc = " The start offset of the span, inclusive."] pub start : usize , # [doc = " The end offset of the span, exclusive."] pub end : usize , } # [automatically_derived] impl :: core :: clone :: Clone for Span { # [inline] fn clone (& self) -> Span { let _ : :: core :: clone :: AssertParamIsClone < usize > ; * self } } # [automatically_derived] impl :: core :: marker :: Copy for Span { } # [automatically_derived] impl :: core :: cmp :: Eq for Span { # [inline] # [doc (hidden)] # [coverage (off)] fn assert_receiver_is_total_eq (& self) -> () { let _ : :: core :: cmp :: AssertParamIsEq < usize > ; } } # [automatically_derived] impl :: core :: hash :: Hash for Span { # [inline] fn hash < __H : :: core :: hash :: Hasher > (& self , state : & mut __H) -> () { :: core :: hash :: Hash :: hash (& self . start , state) ; :: core :: hash :: Hash :: hash (& self . end , state) } } # [automatically_derived] impl :: core :: marker :: StructuralPartialEq for Span { } # [automatically_derived] impl :: core :: cmp :: PartialEq for Span { # [inline] fn eq (& self , other : & Span) -> bool { self . start == other . start && self . end == other . end } } impl Span { # [doc = " Returns this span as a range."] # [inline] pub fn range (& self) -> Range < usize > { Range :: from (* self) } # [doc = " Returns true when this span is empty. That is, when `start >= end`."] # [inline] pub fn is_empty (& self) -> bool { self . start >= self . end } # [doc = " Returns the length of this span."] # [doc = ""] # [doc = " This returns `0` in precisely the cases that `is_empty` returns `true`."] # [inline] pub fn len (& self) -> usize { self . end . saturating_sub (self . start) } # [doc = " Returns true when the given offset is contained within this span."] # [doc = ""] # [doc = " Note that an empty span contains no offsets and will always return"] # [doc = " false."] # [inline] pub fn contains (& self , offset : usize) -> bool { ! self . is_empty () && self . start <= offset && offset <= self . end } # [doc = " Returns a new span with `offset` added to this span's `start` and `end`"] # [doc = " values."] # [inline] pub fn offset (& self , offset : usize) -> Span { Span { start : self . start + offset , end : self . end + offset , } } } impl core :: fmt :: Debug for Span { fn fmt (& self , f : & mut core :: fmt :: Formatter) -> core :: fmt :: Result { f . write_fmt (format_args ! ("{0}..{1}" , self . start , self . end)) } } impl core :: ops :: Index < Span > for [u8] { type Output = [u8] ; # [inline] fn index (& self , index : Span) -> & [u8] { & self [index . range ()] } } impl core :: ops :: IndexMut < Span > for [u8] { # [inline] fn index_mut (& mut self , index : Span) -> & mut [u8] { & mut self [index . range ()] } } impl core :: ops :: Index < Span > for str { type Output = str ; # [inline] fn index (& self , index : Span) -> & str { & self [index . range ()] } } impl From < Range < usize > > for Span { # [inline] fn from (range : Range < usize >) -> Span { Span { start : range . start , end : range . end , } } } impl From < Span > for Range < usize > { # [inline] fn from (span : Span) -> Range < usize > { Range { start : span . start , end : span . end , } } } impl PartialEq < Range < usize > > for Span { # [inline] fn eq (& self , range : & Range < usize >) -> bool { self . start == range . start && self . end == range . end } } impl PartialEq < Span > for Range < usize > { # [inline] fn eq (& self , span : & Span) -> bool { self . start == span . start && self . end == span . end } } # [doc = " The type of anchored search to perform."] # [doc = ""] # [doc = " If an Aho-Corasick searcher does not support the anchored mode selected,"] # [doc = " then the search will return an error or panic, depending on whether a"] # [doc = " fallible or an infallible routine was called."] # [non_exhaustive] pub enum Anchored { # [doc = " Run an unanchored search. This means a match may occur anywhere at or"] # [doc = " after the start position of the search up until the end position of the"] # [doc = " search."] No , # [doc = " Run an anchored search. This means that a match must begin at the start"] # [doc = " position of the search and end before the end position of the search."] Yes , } # [automatically_derived] impl :: core :: clone :: Clone for Anchored { # [inline] fn clone (& self) -> Anchored { * self } } # [automatically_derived] impl :: core :: marker :: Copy for Anchored { } # [automatically_derived] impl :: core :: fmt :: Debug for Anchored { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: write_str (f , match self { Anchored :: No => "No" , Anchored :: Yes => "Yes" , } ,) } } # [automatically_derived] impl :: core :: cmp :: Eq for Anchored { # [inline] # [doc (hidden)] # [coverage (off)] fn assert_receiver_is_total_eq (& self) -> () { } } # [automatically_derived] impl :: core :: marker :: StructuralPartialEq for Anchored { } # [automatically_derived] impl :: core :: cmp :: PartialEq for Anchored { # [inline] fn eq (& self , other : & Anchored) -> bool { let __self_discr = :: core :: intrinsics :: discriminant_value (self) ; let __arg1_discr = :: core :: intrinsics :: discriminant_value (other) ; __self_discr == __arg1_discr } } impl Anchored { # [doc = " Returns true if and only if this anchor mode corresponds to an anchored"] # [doc = " search."] # [doc = ""] # [doc = " # Example"] # [doc = ""] # [doc = " ```"] # [doc = " use aho_corasick::Anchored;"] # [doc = ""] # [doc = " assert!(!Anchored::No.is_anchored());"] # [doc = " assert!(Anchored::Yes.is_anchored());"] # [doc = " ```"] # [inline] pub fn is_anchored (& self) -> bool { # [allow (non_exhaustive_omitted_patterns)] match * self { Anchored :: Yes => true , _ => false , } } } # [doc = " A representation of a match reported by an Aho-Corasick searcher."] # [doc = ""] # [doc = " A match has two essential pieces of information: the [`PatternID`] that"] # [doc = " matches, and the [`Span`] of the match in a haystack."] # [doc = ""] # [doc = " The pattern is identified by an ID, which corresponds to its position"] # [doc = " (starting from `0`) relative to other patterns used to construct the"] # [doc = " corresponding searcher. If only a single pattern is provided, then all"] # [doc = " matches are guaranteed to have a pattern ID of `0`."] # [doc = ""] # [doc = " Every match reported by a searcher guarantees that its span has its start"] # [doc = " offset as less than or equal to its end offset."] pub struct Match { # [doc = " The pattern ID."] pattern : PatternID , # [doc = " The underlying match span."] span : Span , } # [automatically_derived] impl :: core :: clone :: Clone for Match { # [inline] fn clone (& self) -> Match { let _ : :: core :: clone :: AssertParamIsClone < PatternID > ; let _ : :: core :: clone :: AssertParamIsClone < Span > ; * self } } # [automatically_derived] impl :: core :: marker :: Copy for Match { } # [automatically_derived] impl :: core :: fmt :: Debug for Match { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field2_finish (f , "Match" , "pattern" , & self . pattern , "span" , & & self . span ,) } } # [automatically_derived] impl :: core :: cmp :: Eq for Match { # [inline] # [doc (hidden)] # [coverage (off)] fn assert_receiver_is_total_eq (& self) -> () { let _ : :: core :: cmp :: AssertParamIsEq < PatternID > ; let _ : :: core :: cmp :: AssertParamIsEq < Span > ; } } # [automatically_derived] impl :: core :: hash :: Hash for Match { # [inline] fn hash < __H : :: core :: hash :: Hasher > (& self , state : & mut __H) -> () { :: core :: hash :: Hash :: hash (& self . pattern , state) ; :: core :: hash :: Hash :: hash (& self . span , state) } } # [automatically_derived] impl :: core :: marker :: StructuralPartialEq for Match { } # [automatically_derived] impl :: core :: cmp :: PartialEq for Match { # [inline] fn eq (& self , other : & Match) -> bool { self . pattern == other . pattern && self . span == other . span } } impl Match { # [doc = " Create a new match from a pattern ID and a span."] # [doc = ""] # [doc = " This constructor is generic over how a span is provided. While"] # [doc = " a [`Span`] may be given directly, one may also provide a"] # [doc = " `std::ops::Range<usize>`."] # [doc = ""] # [doc = " # Panics"] # [doc = ""] # [doc = " This panics if `end < start`."] # [doc = ""] # [doc = " # Example"] # [doc = ""] # [doc = " This shows how to create a match for the first pattern in an"] # [doc = " Aho-Corasick searcher using convenient range syntax."] # [doc = ""] # [doc = " ```"] # [doc = " use aho_corasick::{Match, PatternID};"] # [doc = ""] # [doc = " let m = Match::new(PatternID::ZERO, 5..10);"] # [doc = " assert_eq!(0, m.pattern().as_usize());"] # [doc = " assert_eq!(5, m.start());"] # [doc = " assert_eq!(10, m.end());"] # [doc = " ```"] # [inline] pub fn new < S : Into < Span > > (pattern : PatternID , span : S) -> Match { let span = span . into () ; if ! (span . start <= span . end) { { :: core :: panicking :: panic_fmt (format_args ! ("invalid match span")) ; } } Match { pattern , span } } # [doc = " Create a new match from a pattern ID and a byte offset span."] # [doc = ""] # [doc = " This constructor is generic over how a span is provided. While"] # [doc = " a [`Span`] may be given directly, one may also provide a"] # [doc = " `std::ops::Range<usize>`."] # [doc = ""] # [doc = " This is like [`Match::new`], but accepts a `usize` instead of a"] # [doc = " [`PatternID`]. This panics if the given `usize` is not representable"] # [doc = " as a `PatternID`."] # [doc = ""] # [doc = " # Panics"] # [doc = ""] # [doc = " This panics if `end < start` or if `pattern > PatternID::MAX`."] # [doc = ""] # [doc = " # Example"] # [doc = ""] # [doc = " This shows how to create a match for the third pattern in an"] # [doc = " Aho-Corasick searcher using convenient range syntax."] # [doc = ""] # [doc = " ```"] # [doc = " use aho_corasick::Match;"] # [doc = ""] # [doc = " let m = Match::must(3, 5..10);"] # [doc = " assert_eq!(3, m.pattern().as_usize());"] # [doc = " assert_eq!(5, m.start());"] # [doc = " assert_eq!(10, m.end());"] # [doc = " ```"] # [inline] pub fn must < S : Into < Span > > (pattern : usize , span : S) -> Match { Match :: new (PatternID :: must (pattern) , span) } # [doc = " Returns the ID of the pattern that matched."] # [doc = ""] # [doc = " The ID of a pattern is derived from the position in which it was"] # [doc = " originally inserted into the corresponding searcher. The first pattern"] # [doc = " has identifier `0`, and each subsequent pattern is `1`, `2` and so on."] # [inline] pub fn pattern (& self) -> PatternID { self . pattern } # [doc = " The starting position of the match."] # [doc = ""] # [doc = " This is a convenience routine for `Match::span().start`."] # [inline] pub fn start (& self) -> usize { self . span () . start } # [doc = " The ending position of the match."] # [doc = ""] # [doc = " This is a convenience routine for `Match::span().end`."] # [inline] pub fn end (& self) -> usize { self . span () . end } # [doc = " Returns the match span as a range."] # [doc = ""] # [doc = " This is a convenience routine for `Match::span().range()`."] # [inline] pub fn range (& self) -> core :: ops :: Range < usize > { self . span () . range () } # [doc = " Returns the span for this match."] # [inline] pub fn span (& self) -> Span { self . span } # [doc = " Returns true when the span in this match is empty."] # [doc = ""] # [doc = " An empty match can only be returned when empty pattern is in the"] # [doc = " Aho-Corasick searcher."] # [inline] pub fn is_empty (& self) -> bool { self . span () . is_empty () } # [doc = " Returns the length of this match."] # [doc = ""] # [doc = " This returns `0` in precisely the cases that `is_empty` returns `true`."] # [inline] pub fn len (& self) -> usize { self . span () . len () } # [doc = " Returns a new match with `offset` added to its span's `start` and `end`"] # [doc = " values."] # [inline] pub fn offset (& self , offset : usize) -> Match { Match { pattern : self . pattern , span : Span { start : self . start () + offset , end : self . end () + offset , } , } } } # [doc = " A knob for controlling the match semantics of an Aho-Corasick automaton."] # [doc = ""] # [doc = " There are two generally different ways that Aho-Corasick automatons can"] # [doc = " report matches. The first way is the \"standard\" approach that results from"] # [doc = " implementing most textbook explanations of Aho-Corasick. The second way is"] # [doc = " to report only the leftmost non-overlapping matches. The leftmost approach"] # [doc = " is in turn split into two different ways of resolving ambiguous matches:"] # [doc = " leftmost-first and leftmost-longest."] # [doc = ""] # [doc = " The `Standard` match kind is the default and is the only one that supports"] # [doc = " overlapping matches and stream searching. (Trying to find overlapping or"] # [doc = " streaming matches using leftmost match semantics will result in an error in"] # [doc = " fallible APIs and a panic when using infallibe APIs.) The `Standard` match"] # [doc = " kind will report matches as they are seen. When searching for overlapping"] # [doc = " matches, then all possible matches are reported. When searching for"] # [doc = " non-overlapping matches, the first match seen is reported. For example, for"] # [doc = " non-overlapping matches, given the patterns `abcd` and `b` and the haystack"] # [doc = " `abcdef`, only a match for `b` is reported since it is detected first. The"] # [doc = " `abcd` match is never reported since it overlaps with the `b` match."] # [doc = ""] # [doc = " In contrast, the leftmost match kind always prefers the leftmost match"] # [doc = " among all possible matches. Given the same example as above with `abcd` and"] # [doc = " `b` as patterns and `abcdef` as the haystack, the leftmost match is `abcd`"] # [doc = " since it begins before the `b` match, even though the `b` match is detected"] # [doc = " before the `abcd` match. In this case, the `b` match is not reported at all"] # [doc = " since it overlaps with the `abcd` match."] # [doc = ""] # [doc = " The difference between leftmost-first and leftmost-longest is in how they"] # [doc = " resolve ambiguous matches when there are multiple leftmost matches to"] # [doc = " choose from. Leftmost-first always chooses the pattern that was provided"] # [doc = " earliest, where as leftmost-longest always chooses the longest matching"] # [doc = " pattern. For example, given the patterns `a` and `ab` and the subject"] # [doc = " string `ab`, the leftmost-first match is `a` but the leftmost-longest match"] # [doc = " is `ab`. Conversely, if the patterns were given in reverse order, i.e.,"] # [doc = " `ab` and `a`, then both the leftmost-first and leftmost-longest matches"] # [doc = " would be `ab`. Stated differently, the leftmost-first match depends on the"] # [doc = " order in which the patterns were given to the Aho-Corasick automaton."] # [doc = " Because of that, when leftmost-first matching is used, if a pattern `A`"] # [doc = " that appears before a pattern `B` is a prefix of `B`, then it is impossible"] # [doc = " to ever observe a match of `B`."] # [doc = ""] # [doc = " If you're not sure which match kind to pick, then stick with the standard"] # [doc = " kind, which is the default. In particular, if you need overlapping or"] # [doc = " streaming matches, then you _must_ use the standard kind. The leftmost"] # [doc = " kinds are useful in specific circumstances. For example, leftmost-first can"] # [doc = " be very useful as a way to implement match priority based on the order of"] # [doc = " patterns given and leftmost-longest can be useful for dictionary searching"] # [doc = " such that only the longest matching words are reported."] # [doc = ""] # [doc = " # Relationship with regular expression alternations"] # [doc = ""] # [doc = " Understanding match semantics can be a little tricky, and one easy way"] # [doc = " to conceptualize non-overlapping matches from an Aho-Corasick automaton"] # [doc = " is to think about them as a simple alternation of literals in a regular"] # [doc = " expression. For example, let's say we wanted to match the strings"] # [doc = " `Sam` and `Samwise`, which would turn into the regex `Sam|Samwise`. It"] # [doc = " turns out that regular expression engines have two different ways of"] # [doc = " matching this alternation. The first way, leftmost-longest, is commonly"] # [doc = " found in POSIX compatible implementations of regular expressions (such as"] # [doc = " `grep`). The second way, leftmost-first, is commonly found in backtracking"] # [doc = " implementations such as Perl. (Some regex engines, such as RE2 and Rust's"] # [doc = " regex engine do not use backtracking, but still implement leftmost-first"] # [doc = " semantics in an effort to match the behavior of dominant backtracking"] # [doc = " regex engines such as those found in Perl, Ruby, Python, Javascript and"] # [doc = " PHP.)"] # [doc = ""] # [doc = " That is, when matching `Sam|Samwise` against `Samwise`, a POSIX regex"] # [doc = " will match `Samwise` because it is the longest possible match, but a"] # [doc = " Perl-like regex will match `Sam` since it appears earlier in the"] # [doc = " alternation. Indeed, the regex `Sam|Samwise` in a Perl-like regex engine"] # [doc = " will never match `Samwise` since `Sam` will always have higher priority."] # [doc = " Conversely, matching the regex `Samwise|Sam` against `Samwise` will lead to"] # [doc = " a match of `Samwise` in both POSIX and Perl-like regexes since `Samwise` is"] # [doc = " still longest match, but it also appears earlier than `Sam`."] # [doc = ""] # [doc = " The \"standard\" match semantics of Aho-Corasick generally don't correspond"] # [doc = " to the match semantics of any large group of regex implementations, so"] # [doc = " there's no direct analogy that can be made here. Standard match semantics"] # [doc = " are generally useful for overlapping matches, or if you just want to see"] # [doc = " matches as they are detected."] # [doc = ""] # [doc = " The main conclusion to draw from this section is that the match semantics"] # [doc = " can be tweaked to precisely match either Perl-like regex alternations or"] # [doc = " POSIX regex alternations."] # [non_exhaustive] pub enum MatchKind { # [doc = " Use standard match semantics, which support overlapping matches. When"] # [doc = " used with non-overlapping matches, matches are reported as they are"] # [doc = " seen."] Standard , # [doc = " Use leftmost-first match semantics, which reports leftmost matches."] # [doc = " When there are multiple possible leftmost matches, the match"] # [doc = " corresponding to the pattern that appeared earlier when constructing"] # [doc = " the automaton is reported."] # [doc = ""] # [doc = " This does **not** support overlapping matches or stream searching. If"] # [doc = " this match kind is used, attempting to find overlapping matches or"] # [doc = " stream matches will fail."] LeftmostFirst , # [doc = " Use leftmost-longest match semantics, which reports leftmost matches."] # [doc = " When there are multiple possible leftmost matches, the longest match"] # [doc = " is chosen."] # [doc = ""] # [doc = " This does **not** support overlapping matches or stream searching. If"] # [doc = " this match kind is used, attempting to find overlapping matches or"] # [doc = " stream matches will fail."] LeftmostLongest , } # [automatically_derived] impl :: core :: clone :: Clone for MatchKind { # [inline] fn clone (& self) -> MatchKind { * self } } # [automatically_derived] impl :: core :: marker :: Copy for MatchKind { } # [automatically_derived] impl :: core :: fmt :: Debug for MatchKind { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: write_str (f , match self { MatchKind :: Standard => "Standard" , MatchKind :: LeftmostFirst => "LeftmostFirst" , MatchKind :: LeftmostLongest => "LeftmostLongest" , } ,) } } # [automatically_derived] impl :: core :: cmp :: Eq for MatchKind { # [inline] # [doc (hidden)] # [coverage (off)] fn assert_receiver_is_total_eq (& self) -> () { } } # [automatically_derived] impl :: core :: marker :: StructuralPartialEq for MatchKind { } # [automatically_derived] impl :: core :: cmp :: PartialEq for MatchKind { # [inline] fn eq (& self , other : & MatchKind) -> bool { let __self_discr = :: core :: intrinsics :: discriminant_value (self) ; let __arg1_discr = :: core :: intrinsics :: discriminant_value (other) ; __self_discr == __arg1_discr } } # [doc = " The default match kind is `MatchKind::Standard`."] impl Default for MatchKind { fn default () -> MatchKind { MatchKind :: Standard } } impl MatchKind { # [inline] pub (crate) fn is_standard (& self) -> bool { # [allow (non_exhaustive_omitted_patterns)] match * self { MatchKind :: Standard => true , _ => false , } } # [inline] pub (crate) fn is_leftmost (& self) -> bool { # [allow (non_exhaustive_omitted_patterns)] match * self { MatchKind :: LeftmostFirst | MatchKind :: LeftmostLongest => true , _ => false , } } # [inline] pub (crate) fn is_leftmost_first (& self) -> bool { # [allow (non_exhaustive_omitted_patterns)] match * self { MatchKind :: LeftmostFirst => true , _ => false , } } # [doc = " Convert this match kind into a packed match kind. If this match kind"] # [doc = " corresponds to standard semantics, then this returns None, since"] # [doc = " packed searching does not support standard semantics."] # [inline] pub (crate) fn as_packed (& self) -> Option < crate :: packed :: MatchKind > { match * self { MatchKind :: Standard => None , MatchKind :: LeftmostFirst => { Some (crate :: packed :: MatchKind :: LeftmostFirst) } MatchKind :: LeftmostLongest => { Some (crate :: packed :: MatchKind :: LeftmostLongest) } } } } # [doc = " The kind of anchored starting configurations to support in an Aho-Corasick"] # [doc = " searcher."] # [doc = ""] # [doc = " Depending on which searcher is used internally by"] # [doc = " [`AhoCorasick`](crate::AhoCorasick), supporting both unanchored"] # [doc = " and anchored searches can be quite costly. For this reason,"] # [doc = " [`AhoCorasickBuilder::start_kind`](crate::AhoCorasickBuilder::start_kind)"] # [doc = " can be used to configure whether your searcher supports unanchored,"] # [doc = " anchored or both kinds of searches."] # [doc = ""] # [doc = " This searcher configuration knob works in concert with the search time"] # [doc = " configuration [`Input::anchored`]. Namely, if one requests an unsupported"] # [doc = " anchored mode, then the search will either panic or return an error,"] # [doc = " depending on whether you're using infallible or fallibe APIs, respectively."] # [doc = ""] # [doc = " `AhoCorasick` by default only supports unanchored searches."] pub enum StartKind { # [doc = " Support both anchored and unanchored searches."] Both , # [doc = " Support only unanchored searches. Requesting an anchored search will"] # [doc = " return an error in fallible APIs and panic in infallible APIs."] Unanchored , # [doc = " Support only anchored searches. Requesting an unanchored search will"] # [doc = " return an error in fallible APIs and panic in infallible APIs."] Anchored , } # [automatically_derived] impl :: core :: clone :: Clone for StartKind { # [inline] fn clone (& self) -> StartKind { * self } } # [automatically_derived] impl :: core :: marker :: Copy for StartKind { } # [automatically_derived] impl :: core :: fmt :: Debug for StartKind { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: write_str (f , match self { StartKind :: Both => "Both" , StartKind :: Unanchored => "Unanchored" , StartKind :: Anchored => "Anchored" , } ,) } } # [automatically_derived] impl :: core :: cmp :: Eq for StartKind { # [inline] # [doc (hidden)] # [coverage (off)] fn assert_receiver_is_total_eq (& self) -> () { } } # [automatically_derived] impl :: core :: marker :: StructuralPartialEq for StartKind { } # [automatically_derived] impl :: core :: cmp :: PartialEq for StartKind { # [inline] fn eq (& self , other : & StartKind) -> bool { let __self_discr = :: core :: intrinsics :: discriminant_value (self) ; let __arg1_discr = :: core :: intrinsics :: discriminant_value (other) ; __self_discr == __arg1_discr } } impl Default for StartKind { fn default () -> StartKind { StartKind :: Unanchored } } } pub (crate) mod special { use crate :: util :: primitives :: StateID ; # [doc = " A collection of sentinel state IDs for Aho-Corasick automata."] # [doc = ""] # [doc = " This specifically enables the technique by which we determine which states"] # [doc = " are dead, matches or start states. Namely, by arranging states in a"] # [doc = " particular order, we can determine the type of a state simply by looking at"] # [doc = " its ID."] pub (crate) struct Special { # [doc = " The maximum ID of all the \"special\" states. This corresponds either to"] # [doc = " start_anchored_id when a prefilter is active and max_match_id when a"] # [doc = " prefilter is not active. The idea here is that if there is no prefilter,"] # [doc = " then there is no point in treating start states as special."] pub (crate) max_special_id : StateID , # [doc = " The maximum ID of all the match states. Any state ID bigger than this"] # [doc = " is guaranteed to be a non-match ID."] # [doc = ""] # [doc = " It is possible and legal for max_match_id to be equal to"] # [doc = " start_anchored_id, which occurs precisely in the case where the empty"] # [doc = " string is a pattern that was added to the underlying automaton."] pub (crate) max_match_id : StateID , # [doc = " The state ID of the start state used for unanchored searches."] pub (crate) start_unanchored_id : StateID , # [doc = " The state ID of the start state used for anchored searches. This is"] # [doc = " always start_unanchored_id+1."] pub (crate) start_anchored_id : StateID , } # [automatically_derived] impl :: core :: clone :: Clone for Special { # [inline] fn clone (& self) -> Special { Special { max_special_id : :: core :: clone :: Clone :: clone (& self . max_special_id) , max_match_id : :: core :: clone :: Clone :: clone (& self . max_match_id) , start_unanchored_id : :: core :: clone :: Clone :: clone (& self . start_unanchored_id ,) , start_anchored_id : :: core :: clone :: Clone :: clone (& self . start_anchored_id ,) , } } } # [automatically_derived] impl :: core :: fmt :: Debug for Special { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field4_finish (f , "Special" , "max_special_id" , & self . max_special_id , "max_match_id" , & self . max_match_id , "start_unanchored_id" , & self . start_unanchored_id , "start_anchored_id" , & & self . start_anchored_id ,) } } impl Special { # [doc = " Create a new set of \"special\" state IDs with all IDs initialized to"] # [doc = " zero. The general idea here is that they will be updated and set to"] # [doc = " correct values later."] pub (crate) fn zero () -> Special { Special { max_special_id : StateID :: ZERO , max_match_id : StateID :: ZERO , start_unanchored_id : StateID :: ZERO , start_anchored_id : StateID :: ZERO , } } } } }