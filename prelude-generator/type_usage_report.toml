[expressions."Some (1)"]
expression_str = "Some (1)"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'"use once_cell::sync::Lazy;\n"']
expression_str = '"use once_cell::sync::Lazy;\n"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'"usize"']
expression_str = '"usize"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'tokio :: fs :: write (& ast_statistics_file_path , ast_statistics_code . as_bytes ()) . await . context (format ! ("Failed to write generated AST statistics code to {:?}" , ast_statistics_file_path) ,) ?']
expression_str = 'tokio :: fs :: write (& ast_statistics_file_path , ast_statistics_code . as_bytes ()) . await . context (format ! ("Failed to write generated AST statistics code to {:?}" , ast_statistics_file_path) ,) ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'toml :: from_str (& contents) . context ("Failed to parse mapping.toml") ?']
expression_str = 'toml :: from_str (& contents) . context ("Failed to parse mapping.toml") ?'
depth = 5
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."visitor . enum_lattices"]
expression_str = "visitor . enum_lattices"
depth = 5
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'_args . test_report_input_file . clone () . ok_or_else (| | anyhow :: anyhow ! ("test_report_input_file is required when compile_tests is true")) ?']
expression_str = '_args . test_report_input_file . clone () . ok_or_else (| | anyhow :: anyhow ! ("test_report_input_file is required when compile_tests is true")) ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."tokio :: fs :: create_dir_all (& hf_validator_project_dir) . await ?"]
expression_str = "tokio :: fs :: create_dir_all (& hf_validator_project_dir) . await ?"
depth = 4
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'Lazy :: new (| | { Regex :: new (r"[^a-zA-Z0-9_]+") . unwrap () })']
expression_str = 'Lazy :: new (| | { Regex :: new (r"[^a-zA-Z0-9_]+") . unwrap () })'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."Ok (Vec :: new ())"]
expression_str = "Ok (Vec :: new ())"
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'"\n================================================================\n"']
expression_str = '"\n================================================================\n"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."& * * expr"]
expression_str = "& * * expr"
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.file_idx]
expression_str = "file_idx"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."stack . pop ()"]
expression_str = "stack . pop ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."self . total_expressions_analyzed"]
expression_str = "self . total_expressions_analyzed"
depth = 3
used_types = []
other_types_count = 0
node_type = "Field"

[expressions."prelude_generator :: public_tests :: test_modify_crate_root_dry_run"]
expression_str = "prelude_generator :: public_tests :: test_modify_crate_root_dry_run"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'format ! ("  -> Hugging Face Validation Result: {:#?}\n" , validated_file) . as_bytes ()']
expression_str = 'format ! ("  -> Hugging Face Validation Result: {:#?}\n" , validated_file) . as_bytes ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'structure . ident . to_string () == "BagOfWordsVisitor"']
expression_str = 'structure . ident . to_string () == "BagOfWordsVisitor"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Binary"

[expressions."tokio :: fs :: create_dir_all (file_path . parent () . unwrap ()) . await ?"]
expression_str = "tokio :: fs :: create_dir_all (file_path . parent () . unwrap ()) . await ?"
depth = 3
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."self . variant_type_co_occurrences . entry (variant_types)"]
expression_str = "self . variant_type_co_occurrences . entry (variant_types)"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'rust_version_counts . insert ("1.86.0" . to_string () , 295)']
expression_str = 'rust_version_counts . insert ("1.86.0" . to_string () , 295)'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'WalkDir :: new (& repo_root) . into_iter () . filter_map (| e | e . ok ()) . filter (| e | e . file_type () . is_file () && e . file_name () == "Cargo.toml")']
expression_str = 'WalkDir :: new (& repo_root) . into_iter () . filter_map (| e | e . ok ()) . filter (| e | e . file_type () . is_file () && e . file_name () == "Cargo.toml")'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'Command :: new ("rustc") . arg ("--emit=metadata") . arg ("--crate-type=lib") . arg (file_path) . output () . await . context ("Failed to execute rustc") ?']
expression_str = 'Command :: new ("rustc") . arg ("--emit=metadata") . arg ("--crate-type=lib") . arg (file_path) . output () . await . context ("Failed to execute rustc") ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."& project_root"]
expression_str = "& project_root"
depth = 3
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."let Some (config_path) = & args . config_file_path"]
expression_str = "let Some (config_path) = & args . config_file_path"
depth = 3
used_types = []
other_types_count = 0
node_type = "Let"

[expressions.'script_content . push_str ("popd\n\n")']
expression_str = 'script_content . push_str ("popd\n\n")'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'(syn :: parse_file ("") . unwrap () , Some (error_sample))']
expression_str = '(syn :: parse_file ("") . unwrap () , Some (error_sample))'
depth = 5
used_types = []
other_types_count = 0
node_type = "Tuple"

[expressions.'if path . exists () && ! force { println ! ("  -> Skipping file modification for {} (file exists, use --force to overwrite)." , path . display ()) ; } else { println ! ("  -> Modifying file: {}" , path . display ()) ; println ! ("    -> Writing modified content to: {}" , path . display ()) ; fs :: write (path , new_content) ? ; }']
expression_str = 'if path . exists () && ! force { println ! ("  -> Skipping file modification for {} (file exists, use --force to overwrite)." , path . display ()) ; } else { println ! ("  -> Modifying file: {}" , path . display ()) ; println ! ("    -> Writing modified content to: {}" , path . display ()) ; fs :: write (path , new_content) ? ; }'
depth = 5
used_types = []
other_types_count = 0
node_type = "If"

[expressions."let Err (ref e) = result"]
expression_str = "let Err (ref e) = result"
depth = 3
used_types = []
other_types_count = 0
node_type = "Let"

[expressions.'"Match" . to_string ()']
expression_str = '"Match" . to_string ()'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"    let mut column_stats = HashMap::new();\n"']
expression_str = '"    let mut column_stats = HashMap::new();\n"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'writer . write_all (format ! ("---\n--- Stage 4: AST Reconstruction from Hugging Face Dataset ---\n") . as_bytes ()) . await ?']
expression_str = 'writer . write_all (format ! ("---\n--- Stage 4: AST Reconstruction from Hugging Face Dataset ---\n") . as_bytes ()) . await ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."if let Some (bins_config) = & mut config . bins { for (_ , path) in bins_config . paths . iter_mut () { if ! path . is_absolute () { * path = project_root . join (& path) ; } } }"]
expression_str = "if let Some (bins_config) = & mut config . bins { for (_ , path) in bins_config . paths . iter_mut () { if ! path . is_absolute () { * path = project_root . join (& path) ; } } }"
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions."split_expanded_lib :: RustcInfo { version : rustc_info . version . clone () , host : rustc_info . host . clone () , }"]
expression_str = "split_expanded_lib :: RustcInfo { version : rustc_info . version . clone () , host : rustc_info . host . clone () , }"
depth = 2
used_types = []
other_types_count = 0
node_type = "Struct"

[expressions.'"# Test Verification Report\n\n"']
expression_str = '"# Test Verification Report\n\n"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.dst]
expression_str = "dst"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'writer . write_all (format ! ("        -> Running cargo rustc -Zunpretty=expanded --lib for: {}\n" , file_path . display ()) . as_bytes ()) . await']
expression_str = 'writer . write_all (format ! ("        -> Running cargo rustc -Zunpretty=expanded --lib for: {}\n" , file_path . display ()) . as_bytes ()) . await'
depth = 3
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."prelude_generator :: public_tests :: test_generate_prelude_no_force_no_overwrite"]
expression_str = "prelude_generator :: public_tests :: test_generate_prelude_no_force_no_overwrite"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'writer . write_all (format ! ("  -> Hugging Face Validation Result: {:#?}\n" , validated_file) . as_bytes () ,) . await']
expression_str = 'writer . write_all (format ! ("  -> Hugging Face Validation Result: {:#?}\n" , validated_file) . as_bytes () ,) . await'
depth = 3
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.'Some ("std::path")']
expression_str = 'Some ("std::path")'
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'"generated/ast_statistics.rs"']
expression_str = '"generated/ast_statistics.rs"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."config_parser :: read_config (config_path , & project_root)"]
expression_str = "config_parser :: read_config (config_path , & project_root)"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."crate :: constant_storage :: string_constants :: write_string_constants_to_hierarchical_structure (& string_constants , & string_output_dir ,) . await ?"]
expression_str = "crate :: constant_storage :: string_constants :: write_string_constants_to_hierarchical_structure (& string_constants , & string_output_dir ,) . await ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."generate_aggregated_test_file (output_path . as_path () , vec ! [test_func1 , test_func2] ,)"]
expression_str = "generate_aggregated_test_file (output_path . as_path () , vec ! [test_func1 , test_func2] ,)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'"Failed to serialize errors to JSON"']
expression_str = '"Failed to serialize errors to JSON"'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'writer . write_all (format ! ("---\n--- METRICS_START ---\n{}\n--- METRICS_END ---\n" , json_metrics) . as_bytes ()) . await']
expression_str = 'writer . write_all (format ! ("---\n--- METRICS_START ---\n{}\n--- METRICS_END ---\n" , json_metrics) . as_bytes ()) . await'
depth = 3
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.'"// Original content"']
expression_str = '"// Original content"'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'tokio :: fs :: write (& output_file_path , reconstructed_code . as_bytes ()) . await . context (format ! ("Failed to write generated code to {:?}" , output_file_path)) ?']
expression_str = 'tokio :: fs :: write (& output_file_path , reconstructed_code . as_bytes ()) . await . context (format ! ("Failed to write generated code to {:?}" , output_file_path)) ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.0o755]
expression_str = "0o755"
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'Command :: new ("rustc") . arg ("--version") . arg ("--verbose")']
expression_str = 'Command :: new ("rustc") . arg ("--version") . arg ("--verbose")'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."for (struct_name , lattice_info) in struct_lattices { report_content . push_str (& format ! (\"\\n### Struct: '{}' (Expressions Analyzed: {}) ###\\n\" , struct_name , lattice_info . total_expressions_analyzed)) ; if lattice_info . field_co_occurrences . is_empty () { report_content . push_str (\"  No field co-occurrence data collected.\\n\") ; } else { let mut sorted_co_occurrences : Vec < (& BTreeSet < String > , & usize) > = lattice_info . field_co_occurrences . iter () . collect () ; sorted_co_occurrences . sort_by_key (| & (_ , count) | count) ; for (field_types , count) in sorted_co_occurrences { report_content . push_str (& format ! (\"  - Co-occurring fields: {:?} (Count: {})\\n\" , field_types , count)) ; } } }"]
expression_str = '''for (struct_name , lattice_info) in struct_lattices { report_content . push_str (& format ! ("\n### Struct: '{}' (Expressions Analyzed: {}) ###\n" , struct_name , lattice_info . total_expressions_analyzed)) ; if lattice_info . field_co_occurrences . is_empty () { report_content . push_str ("  No field co-occurrence data collected.\n") ; } else { let mut sorted_co_occurrences : Vec < (& BTreeSet < String > , & usize) > = lattice_info . field_co_occurrences . iter () . collect () ; sorted_co_occurrences . sort_by_key (| & (_ , count) | count) ; for (field_types , count) in sorted_co_occurrences { report_content . push_str (& format ! ("  - Co-occurring fields: {:?} (Count: {})\n" , field_types , count)) ; } } }'''
depth = 3
used_types = [
    "& usize",
    "(& BTreeSet < String > , & usize)",
    "Vec",
    "BTreeSet",
    "& BTreeSet < String >",
]
other_types_count = 5
node_type = "ForLoop"

[expressions."fs :: create_dir (& src_dir)"]
expression_str = "fs :: create_dir (& src_dir)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'code . push_str ("        // line_stats,\n")']
expression_str = 'code . push_str ("        // line_stats,\n")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."tokio :: fs :: create_dir_all (& numerical_output_dir) . await ?"]
expression_str = "tokio :: fs :: create_dir_all (& numerical_output_dir) . await ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."args . filter_names . as_ref ()"]
expression_str = "args . filter_names . as_ref ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"std::vec"']
expression_str = '"std::vec"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'format ! ("--- End AST Node Type Report ---\n") . as_bytes ()']
expression_str = 'format ! ("--- End AST Node Type Report ---\n") . as_bytes ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'code . push_str (& format ! ("    column_stats.insert(\"{}\".to_string(), ({}, {}, {}, {}));\n" , node_type , min , max , sum , count) ,)']
expression_str = 'code . push_str (& format ! ("    column_stats.insert(\"{}\".to_string(), ({}, {}, {}, {}));\n" , node_type , min , max , sum , count) ,)'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'format ! ("  -> Generated AST statistics code written to {:?}\n" , ast_statistics_file_path) . as_bytes ()']
expression_str = 'format ! ("  -> Generated AST statistics code written to {:?}\n" , ast_statistics_file_path) . as_bytes ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'excluded_crates . insert ("dependency-analyzer" . to_string ())']
expression_str = 'excluded_crates . insert ("dependency-analyzer" . to_string ())'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."bag_of_words_visitor . visit_file (& file)"]
expression_str = "bag_of_words_visitor . visit_file (& file)"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'format ! ("Failed to create output directory {:?}" , string_output_dir)']
expression_str = 'format ! ("Failed to create output directory {:?}" , string_output_dir)'
depth = 4
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions."self . current_method_calls"]
expression_str = "self . current_method_calls"
depth = 5
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'add_primitive_type (& mut symbols , "u16")']
expression_str = 'add_primitive_type (& mut symbols , "u16")'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."i . sig"]
expression_str = "i . sig"
depth = 5
used_types = []
other_types_count = 0
node_type = "Field"

[expressions."content . as_bytes ()"]
expression_str = "content . as_bytes ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."constants . iter () . map (| c | { let tokens = quote ! { # c } ; tokens . to_string () })"]
expression_str = "constants . iter () . map (| c | { let tokens = quote ! { # c } ; tokens . to_string () })"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."! errors . is_empty ()"]
expression_str = "! errors . is_empty ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "Unary"

[expressions."self . struct_lattice_info . add_co_occurrence (self . current_field_accesses . clone ())"]
expression_str = "self . struct_lattice_info . add_co_occurrence (self . current_field_accesses . clone ())"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"struct" . to_string ()']
expression_str = '"struct" . to_string ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."prelude_generator :: public_tests :: test_process_crates_report_only"]
expression_str = "prelude_generator :: public_tests :: test_process_crates_report_only"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'add_primitive_type (& mut symbols , "i32")']
expression_str = 'add_primitive_type (& mut symbols , "i32")'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'tokio :: fs :: write (hf_validator_project_dir . join ("Cargo.toml") , cargo_toml_content) . await']
expression_str = 'tokio :: fs :: write (hf_validator_project_dir . join ("Cargo.toml") , cargo_toml_content) . await'
depth = 5
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.'writer . write_all (format ! ("  -> Executing hf-validator: {:#?}\n" , hf_validator_executable) . as_bytes ()) . await ?']
expression_str = 'writer . write_all (format ! ("  -> Executing hf-validator: {:#?}\n" , hf_validator_executable) . as_bytes ()) . await ?'
depth = 4
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."package . name"]
expression_str = "package . name"
depth = 3
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'type_name == "syn" || type_name == "String" || type_name == "HashMap" || type_name == "PathBuf" || type_name == "clap" || type_name == "serde"']
expression_str = 'type_name == "syn" || type_name == "String" || type_name == "HashMap" || type_name == "PathBuf" || type_name == "clap" || type_name == "serde"'
depth = 2
used_types = []
other_types_count = 0
node_type = "Binary"

[expressions.'project_root . join ("prelude_generator_summary.md")']
expression_str = 'project_root . join ("prelude_generator_summary.md")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"io"']
expression_str = '"io"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."i . variants"]
expression_str = "i . variants"
depth = 4
used_types = []
other_types_count = 0
node_type = "Field"

[expressions."& report_path"]
expression_str = "& report_path"
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."expr_lit . lit"]
expression_str = "expr_lit . lit"
depth = 5
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'if output_dir . exists () { tokio :: fs :: remove_dir_all (& output_dir) . await . context ("Failed to remove existing output directory") ? ; }']
expression_str = 'if output_dir . exists () { tokio :: fs :: remove_dir_all (& output_dir) . await . context ("Failed to remove existing output directory") ? ; }'
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'"Continue" . to_string ()']
expression_str = '"Continue" . to_string ()'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."self . enum_lattice_info"]
expression_str = "self . enum_lattice_info"
depth = 4
used_types = []
other_types_count = 0
node_type = "Field"

[expressions."SymbolMap :: new"]
expression_str = "SymbolMap :: new"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."visit :: visit_macro (self , i)"]
expression_str = "visit :: visit_macro (self , i)"
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'"Failed to write rustc error to writer"']
expression_str = '"Failed to write rustc error to writer"'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."lattice_info . method_co_occurrences . is_empty ()"]
expression_str = "lattice_info . method_co_occurrences . is_empty ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.AstReconstructionFunctor]
expression_str = "AstReconstructionFunctor"
depth = 2
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'tokio :: fs :: write (& output_path , content) . await . context (format ! ("Failed to write constant {:?} to {:?}" , const_name , output_path)) ?']
expression_str = 'tokio :: fs :: write (& output_path , content) . await . context (format ! ("Failed to write constant {:?} to {:?}" , const_name , output_path)) ?'
depth = 3
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'add_std_lib_symbol (& mut symbols , "Result" , "enum" , Some ("std::result"))']
expression_str = 'add_std_lib_symbol (& mut symbols , "Result" , "enum" , Some ("std::result"))'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.primitive_types]
expression_str = "primitive_types"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'"    }\n"']
expression_str = '"    }\n"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'if ! output . status . success () { let stderr = String :: from_utf8_lossy (& output . stderr) ; anyhow :: bail ! ("Rustc check failed for file {:?}:\n{}" , file_path , stderr) ; }']
expression_str = 'if ! output . status . success () { let stderr = String :: from_utf8_lossy (& output . stderr) ; anyhow :: bail ! ("Rustc check failed for file {:?}:\n{}" , file_path , stderr) ; }'
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'uses . insert ("use syn::{ItemConst, ItemStruct};\n")']
expression_str = 'uses . insert ("use syn::{ItemConst, ItemStruct};\n")'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."BTreeSet :: new"]
expression_str = "BTreeSet :: new"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."generate_prelude (& src_dir , new_prelude_content , false , false) ?"]
expression_str = "generate_prelude (& src_dir , new_prelude_content , false , false) ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.code]
expression_str = "code"
depth = 2
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."error_collection . errors . extend (errors)"]
expression_str = "error_collection . errors . extend (errors)"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'writer . write_all (format ! ("        -> PATH environment variable: {:?}\n" , std :: env :: var ("PATH")) . as_bytes ())']
expression_str = 'writer . write_all (format ! ("        -> PATH environment variable: {:?}\n" , std :: env :: var ("PATH")) . as_bytes ())'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."entry_path . is_dir ()"]
expression_str = "entry_path . is_dir ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."entry . path ()"]
expression_str = "entry . path ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."toml :: from_str (& config_content)"]
expression_str = "toml :: from_str (& config_content)"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."fs :: metadata"]
expression_str = "fs :: metadata"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'serde_json :: to_string_pretty (& collected_metrics) . context ("Failed to serialize metrics to JSON") ?']
expression_str = 'serde_json :: to_string_pretty (& collected_metrics) . context ("Failed to serialize metrics to JSON") ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."metrics . entry (function_name . to_string ())"]
expression_str = "metrics . entry (function_name . to_string ())"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.items]
expression_str = "items"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."structs . iter ()"]
expression_str = "structs . iter ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.extract_declarations_from_single_file]
expression_str = "extract_declarations_from_single_file"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."(args , config)"]
expression_str = "(args , config)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Tuple"

[expressions."all_declarations_aggregated . extend (declarations)"]
expression_str = "all_declarations_aggregated . extend (declarations)"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."crate :: constant_storage :: string_constants :: write_string_constants_to_hierarchical_structure (& all_string_constants , & string_output_dir) . await ?"]
expression_str = "crate :: constant_storage :: string_constants :: write_string_constants_to_hierarchical_structure (& all_string_constants , & string_output_dir) . await ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'crate :: utils :: validate_rust_code (& output_file_path) . await . context (format ! ("Generated code validation failed for {:?}" , output_file_path))']
expression_str = 'crate :: utils :: validate_rust_code (& output_file_path) . await . context (format ! ("Generated code validation failed for {:?}" , output_file_path))'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'if ! output . status . success () { return Err (anyhow :: anyhow ! ("cargo metadata failed with status: {:?}" , output . status)) ; }']
expression_str = 'if ! output . status . success () { return Err (anyhow :: anyhow ! ("cargo metadata failed with status: {:?}" , output . status)) ; }'
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions."default_config_path . exists ()"]
expression_str = "default_config_path . exists ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"dummy_file.rs" . to_string ()']
expression_str = '"dummy_file.rs" . to_string ()'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."self . module_path . clone ()"]
expression_str = "self . module_path . clone ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."all_impl_lattices . extend (visitor . impl_lattices)"]
expression_str = "all_impl_lattices . extend (visitor . impl_lattices)"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."syn :: visit :: Visit :: visit_file (& mut visitor , & file)"]
expression_str = "syn :: visit :: Visit :: visit_file (& mut visitor , & file)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'format ! ("---\n--- Validating Generated Code ---\n") . as_bytes ()']
expression_str = 'format ! ("---\n--- Validating Generated Code ---\n") . as_bytes ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."all_struct_lattices . extend (visitor . struct_lattices)"]
expression_str = "all_struct_lattices . extend (visitor . struct_lattices)"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."symbol_map . populate_from_cargo_metadata (& project_root)"]
expression_str = "symbol_map . populate_from_cargo_metadata (& project_root)"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."entry . count += 1"]
expression_str = "entry . count += 1"
depth = 2
used_types = []
other_types_count = 0
node_type = "Binary"

[expressions."self . crate_name . clone ()"]
expression_str = "self . crate_name . clone ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."all_collected_errors . is_empty ()"]
expression_str = "all_collected_errors . is_empty ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'if generated_decl_strings . is_empty () { return "// No constant declarations found in this module.\n" . to_string () ; }']
expression_str = 'if generated_decl_strings . is_empty () { return "// No constant declarations found in this module.\n" . to_string () ; }'
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'"collections"']
expression_str = '"collections"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."! self . current_method_calls . is_empty ()"]
expression_str = "! self . current_method_calls . is_empty ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "Unary"

[expressions."Some (crate :: config_parser :: read_config (config_file_path , & project_root) ?)"]
expression_str = "Some (crate :: config_parser :: read_config (config_file_path , & project_root) ?)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'setup_test_file (& dir , "src/main.rs" , "fn main() {}\n")']
expression_str = 'setup_test_file (& dir , "src/main.rs" , "fn main() {}\n")'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."self . current_field_accesses . is_empty ()"]
expression_str = "self . current_field_accesses . is_empty ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."prelude_generator :: public_tests :: test_generate_prelude_creates_file () ?"]
expression_str = "prelude_generator :: public_tests :: test_generate_prelude_creates_file () ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."tokio :: fs :: create_dir_all (& consts_output_dir) . await"]
expression_str = "tokio :: fs :: create_dir_all (& consts_output_dir) . await"
depth = 5
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."generate_report (& []) ?"]
expression_str = "generate_report (& []) ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."modify_crate_root (& src_dir , false , true)"]
expression_str = "modify_crate_root (& src_dir , false , true)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.output]
expression_str = "output"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."hasher . update (content . as_bytes ())"]
expression_str = "hasher . update (content . as_bytes ())"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'add_primitive_type (& mut symbols , "u64")']
expression_str = 'add_primitive_type (& mut symbols , "u64")'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."args . output_symbol_map . clone ()"]
expression_str = "args . output_symbol_map . clone ()"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"Verbatim" . to_string ()']
expression_str = '"Verbatim" . to_string ()'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'Regex :: new (r"[^a-zA-Z0-9_]+") . unwrap ()']
expression_str = 'Regex :: new (r"[^a-zA-Z0-9_]+") . unwrap ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'code . push_str ("    let mut analyzer_version_counts = HashMap::new();\n")']
expression_str = 'code . push_str ("    let mut analyzer_version_counts = HashMap::new();\n")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.sorted_user_defined_types]
expression_str = "sorted_user_defined_types"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'if ! full_path . is_empty () { full_path . push_str ("::") ; }']
expression_str = 'if ! full_path . is_empty () { full_path . push_str ("::") ; }'
depth = 4
used_types = []
other_types_count = 0
node_type = "If"

[expressions."prelude_generator :: public_tests :: test_generate_aggregated_test_file () ?"]
expression_str = "prelude_generator :: public_tests :: test_generate_aggregated_test_file () ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'"/tmp/my_project"']
expression_str = '"/tmp/my_project"'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'vec ! [FileProcessingResult { path : PathBuf :: from ("src/file1.rs") , status : FileProcessingStatus :: Success , } , FileProcessingResult { path : PathBuf :: from ("src/file2.rs") , status : FileProcessingStatus :: Skipped { reason : "already processed" . to_string () } , } , FileProcessingResult { path : PathBuf :: from ("src/file3.rs") , status : FileProcessingStatus :: Failed { error : "syntax error" . to_string () } , } ,]']
expression_str = 'vec ! [FileProcessingResult { path : PathBuf :: from ("src/file1.rs") , status : FileProcessingStatus :: Success , } , FileProcessingResult { path : PathBuf :: from ("src/file2.rs") , status : FileProcessingStatus :: Skipped { reason : "already processed" . to_string () } , } , FileProcessingResult { path : PathBuf :: from ("src/file3.rs") , status : FileProcessingStatus :: Failed { error : "syntax error" . to_string () } , } ,]'
depth = 2
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions."let Ok (content) = std :: fs :: read_to_string (& path)"]
expression_str = "let Ok (content) = std :: fs :: read_to_string (& path)"
depth = 4
used_types = []
other_types_count = 0
node_type = "Let"

[expressions."current_path = parent"]
expression_str = "current_path = parent"
depth = 4
used_types = []
other_types_count = 0
node_type = "Assign"

[expressions.'report_content . push_str (& format ! ("- Failed: {}\n\n" , failed_files))']
expression_str = 'report_content . push_str (& format ! ("- Failed: {}\n\n" , failed_files))'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."& format ! (\"\\n### Impl for Type: '{}' (Expressions Analyzed: {}) ###\\n\" , impl_for_type , lattice_info . total_expressions_analyzed)"]
expression_str = '''& format ! ("\n### Impl for Type: '{}' (Expressions Analyzed: {}) ###\n" , impl_for_type , lattice_info . total_expressions_analyzed)'''
depth = 5
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."tests . into_iter () . map (| f | f . sig . ident . to_string ()) . collect ()"]
expression_str = "tests . into_iter () . map (| f | f . sig . ident . to_string ()) . collect ()"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'| | "aarch64-unknown-linux-gnu" . to_string ()']
expression_str = '| | "aarch64-unknown-linux-gnu" . to_string ()'
depth = 3
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions."generate_prelude (& src_dir , new_prelude_content , false , true) ?"]
expression_str = "generate_prelude (& src_dir , new_prelude_content , false , true) ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."if contains_complex_attributes_for_const (i) || is_complex_type (& const_name) { entry . layer = Some (1) ; }"]
expression_str = "if contains_complex_attributes_for_const (i) || is_complex_type (& const_name) { entry . layer = Some (1) ; }"
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'for (node_type , (min , max , sum , count)) in & stats . snippet_length_stats { code . push_str (& format ! ("    snippet_length_stats.insert(\"{}\".to_string(), ({}, {}, {}, {}));\n" , node_type , min , max , sum , count) ,) ; }']
expression_str = 'for (node_type , (min , max , sum , count)) in & stats . snippet_length_stats { code . push_str (& format ! ("    snippet_length_stats.insert(\"{}\".to_string(), ({}, {}, {}, {}));\n" , node_type , min , max , sum , count) ,) ; }'
depth = 2
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions."& stats . snippet_length_stats"]
expression_str = "& stats . snippet_length_stats"
depth = 3
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."syn :: parse_file (& content)"]
expression_str = "syn :: parse_file (& content)"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."lit_float . base10_digits () . to_string ()"]
expression_str = "lit_float . base10_digits () . to_string ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'" Path to output a TOML file containing all declarations, types, modules, and crates."']
expression_str = '" Path to output a TOML file containing all declarations, types, modules, and crates."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."syn :: parse_quote ! { # [test] fn generated_test_1 () { assert_eq ! (2 , 2) ; } }"]
expression_str = "syn :: parse_quote ! { # [test] fn generated_test_1 () { assert_eq ! (2 , 2) ; } }"
depth = 2
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions."stats . processing_time_stats"]
expression_str = "stats . processing_time_stats"
depth = 4
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'code . push_str ("use once_cell::sync::Lazy;\n")']
expression_str = 'code . push_str ("use once_cell::sync::Lazy;\n")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."Lazy :: new"]
expression_str = "Lazy :: new"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'writer . write_all (format ! ("      -> Using cached expanded code for: {}\n" , file_path . display ()) . as_bytes ()) . await']
expression_str = 'writer . write_all (format ! ("      -> Using cached expanded code for: {}\n" , file_path . display ()) . as_bytes ()) . await'
depth = 4
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.'format ! ("- Failed: {}\n\n" , failed_files)']
expression_str = 'format ! ("- Failed: {}\n\n" , failed_files)'
depth = 4
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions."errors . push (e)"]
expression_str = "errors . push (e)"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."& decl . item"]
expression_str = "& decl . item"
depth = 5
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.verbose]
expression_str = "verbose"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."primitive_types . contains (& type_str . as_str ())"]
expression_str = "primitive_types . contains (& type_str . as_str ())"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."modify_file (& file_path , false , true)"]
expression_str = "modify_file (& file_path , false , true)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'project_root . file_name () . and_then (| s | s . to_str ()) . unwrap_or ("unknown_crate")']
expression_str = 'project_root . file_name () . and_then (| s | s . to_str ()) . unwrap_or ("unknown_crate")'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."for func_info in functions { if seen_test_names . insert (func_info . name . clone ()) { all_test_functions . push (func_info) ; } }"]
expression_str = "for func_info in functions { if seen_test_names . insert (func_info . name . clone ()) { all_test_functions . push (func_info) ; } }"
depth = 5
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions.'"Option"']
expression_str = '"Option"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."grouped_by_other_types . keys () . cloned ()"]
expression_str = "grouped_by_other_types . keys () . cloned ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'& format ! ("- {}\n" , test_name)']
expression_str = '& format ! ("- {}\n" , test_name)'
depth = 5
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."visit :: visit_expr_field"]
expression_str = "visit :: visit_expr_field"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."grouped_by_node_type . get (& node_type) . unwrap ()"]
expression_str = "grouped_by_node_type . get (& node_type) . unwrap ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"Vec"']
expression_str = '"Vec"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."self . max_depth"]
expression_str = "self . max_depth"
depth = 4
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'writer . write_all (format ! ("\n--- AST Node Type Report ---\n") . as_bytes ())']
expression_str = 'writer . write_all (format ! ("\n--- AST Node Type Report ---\n") . as_bytes ())'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"std::macro"']
expression_str = '"std::macro"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.20]
expression_str = "20"
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."prelude_generator :: public_tests :: test_args_custom_values ()"]
expression_str = "prelude_generator :: public_tests :: test_args_custom_values ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."& i . fields"]
expression_str = "& i . fields"
depth = 3
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'"While"']
expression_str = '"While"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'" Analyze the bag of words from all identifiers in the project."']
expression_str = '" Analyze the bag of words from all identifiers in the project."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'{ println ! ("       Successfully parsed file: {}" , path . display ()) ; for item in file . items { if let syn :: Item :: Const (constant) = item { let type_name = get_type_name (& constant . ty) ; let value_str = get_constant_value_string (& constant . expr) ; println ! ("         Found constant: {} (type: {}, value: {})" , constant . ident , type_name , value_str) ; if ! type_name . is_empty () && ! value_str . is_empty () { * constants_by_type_and_size . entry (type_name) . or_default () . entry (value_str) . or_insert (0) += 1 ; } } } }']
expression_str = '{ println ! ("       Successfully parsed file: {}" , path . display ()) ; for item in file . items { if let syn :: Item :: Const (constant) = item { let type_name = get_type_name (& constant . ty) ; let value_str = get_constant_value_string (& constant . expr) ; println ! ("         Found constant: {} (type: {}, value: {})" , constant . ident , type_name , value_str) ; if ! type_name . is_empty () && ! value_str . is_empty () { * constants_by_type_and_size . entry (type_name) . or_default () . entry (value_str) . or_insert (0) += 1 ; } } } }'
depth = 5
used_types = []
other_types_count = 0
node_type = "Block"

[expressions.'setup_test_file (& dir , "test_file.rs" , "use std::collections::HashMap;\nfn main() {}\n")']
expression_str = 'setup_test_file (& dir , "test_file.rs" , "use std::collections::HashMap;\nfn main() {}\n")'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'file_path . strip_prefix (& project_root) . unwrap_or (& file_path) . with_extension ("") . to_str () . unwrap_or ("unknown_module")']
expression_str = 'file_path . strip_prefix (& project_root) . unwrap_or (& file_path) . with_extension ("") . to_str () . unwrap_or ("unknown_module")'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."metadata . packages"]
expression_str = "metadata . packages"
depth = 3
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'node_type_counts . insert ("other" . to_string () , 230)']
expression_str = 'node_type_counts . insert ("other" . to_string () , 230)'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'stderr . write_all (format ! ("Pipeline failed: {:?}\n" , e) . as_bytes ())']
expression_str = 'stderr . write_all (format ! ("Pipeline failed: {:?}\n" , e) . as_bytes ())'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."gem_entry . identifiers"]
expression_str = "gem_entry . identifiers"
depth = 5
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.new_ast]
expression_str = "new_ast"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."& declaration . referenced_types"]
expression_str = "& declaration . referenced_types"
depth = 3
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'if ! error_collection . errors . is_empty () { let errors_json_path = project_root . join ("collected_errors.json ") ; error_collection . write_to_file (& errors_json_path) . await ? ; eprintln ! ("Errors collected during processing. See {:?} for details." , errors_json_path) ; }']
expression_str = 'if ! error_collection . errors . is_empty () { let errors_json_path = project_root . join ("collected_errors.json ") ; error_collection . write_to_file (& errors_json_path) . await ? ; eprintln ! ("Errors collected during processing. See {:?} for details." , errors_json_path) ; }'
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'toml :: from_str (& config_content) . with_context (| | format ! ("Failed to parse config file: {}" , config_path . display ())) ?']
expression_str = 'toml :: from_str (& config_content) . with_context (| | format ! ("Failed to parse config file: {}" , config_path . display ())) ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."& relevant_expanded_code"]
expression_str = "& relevant_expanded_code"
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."syn :: visit :: visit_item_fn"]
expression_str = "syn :: visit :: visit_item_fn"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."stack . push (entry_path)"]
expression_str = "stack . push (entry_path)"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.line]
expression_str = "line"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'"Async" . to_string ()']
expression_str = '"Async" . to_string ()'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."if dry_run { println ! (\"[DRY RUN] Would add 'pub mod prelude;' to: {}\" , crate_root_path . display ()) ; } else { if crate_root_path . exists () && ! force { println ! (\"  -> Skipping crate root modification for {} (file exists, use --force to overwrite).\" , crate_root_path . display ()) ; } else { println ! (\"  -> Adding 'pub mod prelude;' to: {}\" , crate_root_path . display ()) ; println ! (\"    -> Writing modified content to: {}\" , crate_root_path . display ()) ; fs :: write (& crate_root_path , new_content) ? ; } }"]
expression_str = """if dry_run { println ! ("[DRY RUN] Would add 'pub mod prelude;' to: {}" , crate_root_path . display ()) ; } else { if crate_root_path . exists () && ! force { println ! ("  -> Skipping crate root modification for {} (file exists, use --force to overwrite)." , crate_root_path . display ()) ; } else { println ! ("  -> Adding 'pub mod prelude;' to: {}" , crate_root_path . display ()) ; println ! ("    -> Writing modified content to: {}" , crate_root_path . display ()) ; fs :: write (& crate_root_path , new_content) ? ; } }"""
depth = 3
used_types = []
other_types_count = 0
node_type = "If"

[expressions."fs :: create_dir (& temp_src_dir) . await"]
expression_str = "fs :: create_dir (& temp_src_dir) . await"
depth = 4
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."contains_complex_attributes (i) || contains_complex_fields (i)"]
expression_str = "contains_complex_attributes (i) || contains_complex_fields (i)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Binary"

[expressions."expr . to_token_stream () . to_string ()"]
expression_str = "expr . to_token_stream () . to_string ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."Some (results_json_path . clone ())"]
expression_str = "Some (results_json_path . clone ())"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'writer . write_all (format ! ("---\n--- Validating Generated Code ---\n") . as_bytes ()) . await']
expression_str = 'writer . write_all (format ! ("---\n--- Validating Generated Code ---\n") . as_bytes ()) . await'
depth = 3
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.'tempdir () . context ("Failed to create temporary output directory") ?']
expression_str = 'tempdir () . context ("Failed to create temporary output directory") ?'
depth = 4
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'& format ! ("### Crate: {}\n" , crate_path . display ())']
expression_str = '& format ! ("### Crate: {}\n" , crate_path . display ())'
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."prelude_generator :: use_extractor :: rustc_info :: get_rustc_info"]
expression_str = "prelude_generator :: use_extractor :: rustc_info :: get_rustc_info"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'& format ! ("    line_stats.insert(\"{}\".to_string(), ({}, {}, {}, {}));\n" , node_type , min , max , sum , count)']
expression_str = '& format ! ("    line_stats.insert(\"{}\".to_string(), ({}, {}, {}, {}));\n" , node_type , min , max , sum , count)'
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."mapping_file_path . exists ()"]
expression_str = "mapping_file_path . exists ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."! output . status . success ()"]
expression_str = "! output . status . success ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "Unary"

[expressions.'{ println ! ("No specific command flag set. Use --help for options.") ; }']
expression_str = '{ println ! ("No specific command flag set. Use --help for options.") ; }'
depth = 4
used_types = []
other_types_count = 0
node_type = "Block"

[expressions.'return Err (anyhow :: anyhow ! ("Struct processing completed with errors."))']
expression_str = 'return Err (anyhow :: anyhow ! ("Struct processing completed with errors."))'
depth = 3
used_types = []
other_types_count = 0
node_type = "Return"

[expressions."4 * 1024"]
expression_str = "4 * 1024"
depth = 2
used_types = []
other_types_count = 0
node_type = "Binary"

[expressions."std :: env :: set_current_dir (& dir) ?"]
expression_str = "std :: env :: set_current_dir (& dir) ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'format ! ("Failed to write constant {:?} to {:?}" , const_name , output_path)']
expression_str = 'format ! ("Failed to write constant {:?} to {:?}" , const_name , output_path)'
depth = 5
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions."visit :: visit_macro"]
expression_str = "visit :: visit_macro"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'& ["prelude-generator" , "--dry-run" , "--path" , "/tmp/my_project" , "--exclude-crates" , "crate1,crate2" , "--report" , "--results-file" , "custom_results.json" , "--cache-report" , "--timeout" , "60" , "--force" ,]']
expression_str = '& ["prelude-generator" , "--dry-run" , "--path" , "/tmp/my_project" , "--exclude-crates" , "crate1,crate2" , "--report" , "--results-file" , "custom_results.json" , "--cache-report" , "--timeout" , "60" , "--force" ,]'
depth = 3
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'writer . write_all (format ! ("--- METRICS_START ---\n{}\n--- METRICS_END ---\n" , json_metrics) . as_bytes () ,)']
expression_str = 'writer . write_all (format ! ("--- METRICS_START ---\n{}\n--- METRICS_END ---\n" , json_metrics) . as_bytes () ,)'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."{ }"]
expression_str = "{ }"
depth = 4
used_types = []
other_types_count = 0
node_type = "Block"

[expressions."let Some (config_file_path) = & args . config_file_path"]
expression_str = "let Some (config_file_path) = & args . config_file_path"
depth = 3
used_types = []
other_types_count = 0
node_type = "Let"

[expressions."info . used_types . len () . saturating_sub (1)"]
expression_str = "info . used_types . len () . saturating_sub (1)"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'if let syn :: Expr :: Path (expr_path) = & * i . func { if let Some (segment) = expr_path . path . segments . last () { let resolved_dep = self . symbol_map . resolve_and_increment_usage (segment . ident . to_string () , "function" . to_string () , self . crate_name . clone () , self . module_path . clone () ,) ; if self . verbose > 0 { println ! ("Resolved Function Reference: id={}, type={}, crate={}, module={}, usage={}" , resolved_dep . id , resolved_dep . dependency_type , resolved_dep . crate_name , resolved_dep . module_path , resolved_dep . usage_count) ; } } }']
expression_str = 'if let syn :: Expr :: Path (expr_path) = & * i . func { if let Some (segment) = expr_path . path . segments . last () { let resolved_dep = self . symbol_map . resolve_and_increment_usage (segment . ident . to_string () , "function" . to_string () , self . crate_name . clone () , self . module_path . clone () ,) ; if self . verbose > 0 { println ! ("Resolved Function Reference: id={}, type={}, crate={}, module={}, usage={}" , resolved_dep . id , resolved_dep . dependency_type , resolved_dep . crate_name , resolved_dep . module_path , resolved_dep . usage_count) ; } } }'
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions.manifest_path]
expression_str = "manifest_path"
depth = 2
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."& cache_dir"]
expression_str = "& cache_dir"
depth = 5
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'"std::option"']
expression_str = '"std::option"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."fs :: write (& results_json_path , serde_json :: to_string_pretty (& dummy_results) ?)"]
expression_str = "fs :: write (& results_json_path , serde_json :: to_string_pretty (& dummy_results) ?)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'"use std::path::PathBuf;\n"']
expression_str = '"use std::path::PathBuf;\n"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'writer . write_all (format ! ("{:#?}\n" , input) . as_bytes ()) . await ?']
expression_str = 'writer . write_all (format ! ("{:#?}\n" , input) . as_bytes ()) . await ?'
depth = 4
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'writer . write_all (format ! ("--- Stage 2: Extracting Use Statements ---\n") . as_bytes ()) . await ?']
expression_str = 'writer . write_all (format ! ("--- Stage 2: Extracting Use Statements ---\n") . as_bytes ()) . await ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."ErrorCollection :: default ()"]
expression_str = "ErrorCollection :: default ()"
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."syn :: parse_file"]
expression_str = "syn :: parse_file"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."| s | { let tokens = quote ! { # s } ; tokens . to_string () }"]
expression_str = "| s | { let tokens = quote ! { # s } ; tokens . to_string () }"
depth = 4
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions."if let Some (segment) = pat_path . path . segments . last () { self . enum_lattice_info . add_co_occurrence (BTreeSet :: from ([segment . ident . to_string ()])) ; }"]
expression_str = "if let Some (segment) = pat_path . path . segments . last () { self . enum_lattice_info . add_co_occurrence (BTreeSet :: from ([segment . ident . to_string ()])) ; }"
depth = 5
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'fs :: read_to_string (file_path) . with_context (| | format ! ("Failed to read file: {}" , file_path . display ()))']
expression_str = 'fs :: read_to_string (file_path) . with_context (| | format ! ("Failed to read file: {}" , file_path . display ()))'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."lit_float . base10_digits ()"]
expression_str = "lit_float . base10_digits ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."fs :: write (crate_path . join (\"Cargo.toml\") , format ! (\"[package]\\nname = \\\"{{}}\\nversion = \\\"0.1.0\\\"\nedition = \\\"2021\\\"\n\" , crate_name))"]
expression_str = '''
fs :: write (crate_path . join ("Cargo.toml") , format ! ("[package]\nname = \"{{}}\nversion = \"0.1.0\"
edition = \"2021\"
" , crate_name))'''
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'"bool"']
expression_str = '"bool"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'report_content . push_str ("\n")']
expression_str = 'report_content . push_str ("\n")'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'args . output_type_usage_report . as_ref () . context ("Output path for type usage report must be specified")']
expression_str = 'args . output_type_usage_report . as_ref () . context ("Output path for type usage report must be specified")'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'excluded_crates . insert ("prelude-generator" . to_string ())']
expression_str = 'excluded_crates . insert ("prelude-generator" . to_string ())'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."& prelude_path"]
expression_str = "& prelude_path"
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.max_depth]
expression_str = "max_depth"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'snippet_length_stats . insert ("import" . to_string () , (14 , 85 , 812 , 18))']
expression_str = 'snippet_length_stats . insert ("import" . to_string () , (14 , 85 , 812 , 18))'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'return Ok ((syn :: parse_file ("") . unwrap () , Some (error_sample)))']
expression_str = 'return Ok ((syn :: parse_file ("") . unwrap () , Some (error_sample)))'
depth = 3
used_types = []
other_types_count = 0
node_type = "Return"

[expressions.flat_uses]
expression_str = "flat_uses"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."sub_visitor . visit_item_impl (i)"]
expression_str = "sub_visitor . visit_item_impl (i)"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'writer . write_all (format ! ("  -> AST Reconstruction completed successfully.\n") . as_bytes () ,) . await ?']
expression_str = 'writer . write_all (format ! ("  -> AST Reconstruction completed successfully.\n") . as_bytes () ,) . await ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."extract_declarations_from_single_file (file_path , rustc_info , crate_name , verbose ,)"]
expression_str = "extract_declarations_from_single_file (file_path , rustc_info , crate_name , verbose ,)"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'fs :: write (crate_path . join ("src/lib.rs") , lib_content)']
expression_str = 'fs :: write (crate_path . join ("src/lib.rs") , lib_content)'
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."prelude_generator :: public_tests :: test_generate_aggregated_test_file"]
expression_str = "prelude_generator :: public_tests :: test_generate_aggregated_test_file"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'if let Some (results_file_path) = & args . results_file { let json_content = serde_json :: to_string_pretty (& all_file_processing_results) . context ("Failed to serialize results to JSON") ? ; println ! ("  -> Attempting to save processing results to: {}" , results_file_path . display ()) ; fs :: write (results_file_path , json_content) . context ("Failed to write results to file") ? ; println ! ("Processing results saved to {}." , results_file_path . display ()) ; } else { println ! ("No results file specified. Skipping saving processing results.") ; }']
expression_str = 'if let Some (results_file_path) = & args . results_file { let json_content = serde_json :: to_string_pretty (& all_file_processing_results) . context ("Failed to serialize results to JSON") ? ; println ! ("  -> Attempting to save processing results to: {}" , results_file_path . display ()) ; fs :: write (results_file_path , json_content) . context ("Failed to write results to file") ? ; println ! ("Processing results saved to {}." , results_file_path . display ()) ; } else { println ! ("No results file specified. Skipping saving processing results.") ; }'
depth = 4
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'measurement :: record_function_exit ("PreprocessFunctor::map")']
expression_str = 'measurement :: record_function_exit ("PreprocessFunctor::map")'
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.src_dir]
expression_str = "src_dir"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."self . module_path"]
expression_str = "self . module_path"
depth = 5
used_types = []
other_types_count = 0
node_type = "Field"

[expressions."tokio :: fs :: create_dir_all (& permanent_output_dir) . await ?"]
expression_str = "tokio :: fs :: create_dir_all (& permanent_output_dir) . await ?"
depth = 4
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'"1.89.0" . to_string ()']
expression_str = '"1.89.0" . to_string ()'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."self . extract_types_from_expr (expr)"]
expression_str = "self . extract_types_from_expr (expr)"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."visitor . expressions"]
expression_str = "visitor . expressions"
depth = 5
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.sorted_uses]
expression_str = "sorted_uses"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."tests_by_crate . keys ()"]
expression_str = "tests_by_crate . keys ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."Self :: new"]
expression_str = "Self :: new"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."! status . success ()"]
expression_str = "! status . success ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "Unary"

[expressions.'"/"']
expression_str = '"/"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'"collected_errors.json "']
expression_str = '"collected_errors.json "'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'toml :: to_string_pretty (& serializable_decls) . context ("Failed to serialize declarations to TOML ")']
expression_str = 'toml :: to_string_pretty (& serializable_decls) . context ("Failed to serialize declarations to TOML ")'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'tempdir () . context ("Failed to create temporary output directory")']
expression_str = 'tempdir () . context ("Failed to create temporary output directory")'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"Await"']
expression_str = '"Await"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."& mut types"]
expression_str = "& mut types"
depth = 3
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."Path :: new (file_name)"]
expression_str = "Path :: new (file_name)"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'tokio :: fs :: create_dir_all (& consts_output_dir) . await . context (format ! ("Failed to create output directory {:?}" , consts_output_dir))']
expression_str = 'tokio :: fs :: create_dir_all (& consts_output_dir) . await . context (format ! ("Failed to create output directory {:?}" , consts_output_dir))'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."{ next_remaining_decls . push (decl) ; }"]
expression_str = "{ next_remaining_decls . push (decl) ; }"
depth = 5
used_types = []
other_types_count = 0
node_type = "Block"

[expressions."structs . iter () . map (| s | { let tokens = quote ! { # s } ; tokens . to_string () })"]
expression_str = "structs . iter () . map (| s | { let tokens = quote ! { # s } ; tokens . to_string () })"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."tokio :: fs :: read_to_string (file_path) . await"]
expression_str = "tokio :: fs :: read_to_string (file_path) . await"
depth = 4
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."temp_crate_dir . path ()"]
expression_str = "temp_crate_dir . path ()"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."& collected_metrics"]
expression_str = "& collected_metrics"
depth = 5
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."args . max_expression_depth"]
expression_str = "args . max_expression_depth"
depth = 4
used_types = []
other_types_count = 0
node_type = "Field"

[expressions."PathBuf :: from"]
expression_str = "PathBuf :: from"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."cargo_toml_path . parent ()"]
expression_str = "cargo_toml_path . parent ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'GemConfig :: load_from_file (& PathBuf :: from ("gems.toml")) ?']
expression_str = 'GemConfig :: load_from_file (& PathBuf :: from ("gems.toml")) ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."path . is_file ()"]
expression_str = "path . is_file ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'measurement :: record_function_exit ("ClassifyUsesFunctor::map")']
expression_str = 'measurement :: record_function_exit ("ClassifyUsesFunctor::map")'
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'writer . write_all (format ! ("{:#?}\n" , ast_statistics) . as_bytes ())']
expression_str = 'writer . write_all (format ! ("{:#?}\n" , ast_statistics) . as_bytes ())'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'report_content . push_str (& format ! ("### Crate: {}\n" , crate_path . display ()))']
expression_str = 'report_content . push_str (& format ! ("### Crate: {}\n" , crate_path . display ()))'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."& all_impl_lattices"]
expression_str = "& all_impl_lattices"
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.expanded_code]
expression_str = "expanded_code"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."visit :: visit_path (self , i)"]
expression_str = "visit :: visit_path (self , i)"
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'{ let mut stdout = tokio :: io :: stdout () ; stdout . write_all (b"Pipeline completed successfully.\n") . await ? ; }']
expression_str = '{ let mut stdout = tokio :: io :: stdout () ; stdout . write_all (b"Pipeline completed successfully.\n") . await ? ; }'
depth = 3
used_types = []
other_types_count = 0
node_type = "Block"

[expressions.'return Err (anyhow :: anyhow ! ("git config user.email failed: {}\nStderr: {}" , String :: from_utf8_lossy (& output . status . code () . unwrap_or (- 1) . to_string () . as_bytes ()) , String :: from_utf8_lossy (& output . stderr)))']
expression_str = 'return Err (anyhow :: anyhow ! ("git config user.email failed: {}\nStderr: {}" , String :: from_utf8_lossy (& output . status . code () . unwrap_or (- 1) . to_string () . as_bytes ()) , String :: from_utf8_lossy (& output . stderr)))'
depth = 5
used_types = []
other_types_count = 0
node_type = "Return"

[expressions."declaration . referenced_types"]
expression_str = "declaration . referenced_types"
depth = 4
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'{ println ! ("  -> Generating prelude file: {}" , prelude_path . display ()) ; println ! ("    -> Writing prelude content to: {}" , prelude_path . display ()) ; fs :: write (& prelude_path , prelude_content) ? ; }']
expression_str = '{ println ! ("  -> Generating prelude file: {}" , prelude_path . display ()) ; println ! ("    -> Writing prelude content to: {}" , prelude_path . display ()) ; fs :: write (& prelude_path , prelude_content) ? ; }'
depth = 5
used_types = []
other_types_count = 0
node_type = "Block"

[expressions."& script_path"]
expression_str = "& script_path"
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."toml :: to_string_pretty (& symbol_map . map)"]
expression_str = "toml :: to_string_pretty (& symbol_map . map)"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'for constant in all_constants { let const_name = constant . ident . to_string () ; let file_name = format ! ("{}.rs" , const_name) ; let output_path = constants_output_dir . join (& file_name) ; let content = quote ! { # constant } . to_string () ; tokio :: fs :: write (& output_path , content) . await . context (format ! ("Failed to write constant {:?} to {:?}" , const_name , output_path)) ? ; println ! ("  -> Wrote constant {:?} to {:?}" , const_name , output_path) ; if let syn :: Expr :: Lit (expr_lit) = & constant . expr . as_ref () { match & expr_lit . lit { syn :: Lit :: Int (_) | syn :: Lit :: Float (_) => all_numerical_constants . push (constant . clone ()) , syn :: Lit :: Str (_) => all_string_constants . push (constant . clone ()) , _ => { { } } , } } }']
expression_str = 'for constant in all_constants { let const_name = constant . ident . to_string () ; let file_name = format ! ("{}.rs" , const_name) ; let output_path = constants_output_dir . join (& file_name) ; let content = quote ! { # constant } . to_string () ; tokio :: fs :: write (& output_path , content) . await . context (format ! ("Failed to write constant {:?} to {:?}" , const_name , output_path)) ? ; println ! ("  -> Wrote constant {:?} to {:?}" , const_name , output_path) ; if let syn :: Expr :: Lit (expr_lit) = & constant . expr . as_ref () { match & expr_lit . lit { syn :: Lit :: Int (_) | syn :: Lit :: Float (_) => all_numerical_constants . push (constant . clone ()) , syn :: Lit :: Str (_) => all_string_constants . push (constant . clone ()) , _ => { { } } , } } }'
depth = 2
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions."self . bag_of_words . entry (subword) . or_insert (0)"]
expression_str = "self . bag_of_words . entry (subword) . or_insert (0)"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'fs :: copy (& original_cargo_toml_path , & temp_cargo_toml_path) . await . context ("Failed to copy Cargo.toml to temporary directory") ?']
expression_str = 'fs :: copy (& original_cargo_toml_path , & temp_cargo_toml_path) . await . context ("Failed to copy Cargo.toml to temporary directory") ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'structure . attrs . iter () . any (| attr | { if attr . path () . is_ident ("derive") { if let syn :: Meta :: List (meta_list) = & attr . meta { meta_list . tokens . to_string () . contains ("Serialize") || meta_list . tokens . to_string () . contains ("Deserialize") } else { false } } else { false } })']
expression_str = 'structure . attrs . iter () . any (| attr | { if attr . path () . is_ident ("derive") { if let syn :: Meta :: List (meta_list) = & attr . meta { meta_list . tokens . to_string () . contains ("Serialize") || meta_list . tokens . to_string () . contains ("Deserialize") } else { false } } else { false } })'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'tokio :: process :: Command :: new ("git") . arg ("config") . arg ("user.name") . arg ("Test User") . current_dir (& hf_validator_project_dir) . output () . await . context ("Failed to configure git user name")']
expression_str = 'tokio :: process :: Command :: new ("git") . arg ("config") . arg ("user.name") . arg ("Test User") . current_dir (& hf_validator_project_dir) . output () . await . context ("Failed to configure git user name")'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."prelude_generator :: public_tests :: test_modify_file_adds_prelude_and_removes_uses ()"]
expression_str = "prelude_generator :: public_tests :: test_modify_file_adds_prelude_and_removes_uses ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."e . ok ()"]
expression_str = "e . ok ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.stdout]
expression_str = "stdout"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'format ! ("- Successfully processed: {}\n" , successful_files)']
expression_str = 'format ! ("- Successfully processed: {}\n" , successful_files)'
depth = 4
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions.'ErrorSample { file_path : file_path . to_path_buf () , rustc_version : rustc_info . version . clone () , rustc_host : rustc_info . host . clone () , error_message : error_message . clone () , error_type : "SynParsingFailed" . to_string () , code_snippet : Some (relevant_expanded_code . to_string ()) , timestamp : Utc :: now () , context : None , }']
expression_str = 'ErrorSample { file_path : file_path . to_path_buf () , rustc_version : rustc_info . version . clone () , rustc_host : rustc_info . host . clone () , error_message : error_message . clone () , error_type : "SynParsingFailed" . to_string () , code_snippet : Some (relevant_expanded_code . to_string ()) , timestamp : Utc :: now () , context : None , }'
depth = 4
used_types = []
other_types_count = 0
node_type = "Struct"

[expressions.'{ eprintln ! ("Error: Results file not found at {}. Cannot generate report." , results_file_path . display ()) ; }']
expression_str = '{ eprintln ! ("Error: Results file not found at {}. Cannot generate report." , results_file_path . display ()) ; }'
depth = 5
used_types = []
other_types_count = 0
node_type = "Block"

[expressions."tokio :: fs :: create_dir_all (& string_output_dir) . await ?"]
expression_str = "tokio :: fs :: create_dir_all (& string_output_dir) . await ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'line_stats . insert ("import" . to_string () , (1 , 212 , 891 , 18))']
expression_str = 'line_stats . insert ("import" . to_string () , (1 , 212 , 891 , 18))'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."ClassifiedUseStatements (new_classified_uses , HashMap :: new ())"]
expression_str = "ClassifiedUseStatements (new_classified_uses , HashMap :: new ())"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."expanded_code . to_string ()"]
expression_str = "expanded_code . to_string ()"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."all_enum_lattices . extend (visitor . enum_lattices)"]
expression_str = "all_enum_lattices . extend (visitor . enum_lattices)"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."Ok ((file , None))"]
expression_str = "Ok ((file , None))"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."ident . to_string ()"]
expression_str = "ident . to_string ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.metadata]
expression_str = "metadata"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'"While" . to_string ()']
expression_str = '"While" . to_string ()'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."prelude_generator :: public_tests :: test_modify_crate_root_adds_mod_prelude ()"]
expression_str = "prelude_generator :: public_tests :: test_modify_crate_root_adds_mod_prelude ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'" Path to the directory where generated use statement test files will be placed. Required if `extract_use_statements` is true."']
expression_str = '" Path to the directory where generated use statement test files will be placed. Required if `extract_use_statements` is true."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'{ Regex :: new (r"[^a-zA-Z0-9_]+") . unwrap () }']
expression_str = '{ Regex :: new (r"[^a-zA-Z0-9_]+") . unwrap () }'
depth = 4
used_types = []
other_types_count = 0
node_type = "Block"

[expressions.report_path]
expression_str = "report_path"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."i . segments . last () . map (| s | s . ident . to_string ()) . unwrap_or_default ()"]
expression_str = "i . segments . last () . map (| s | s . ident . to_string ()) . unwrap_or_default ()"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'& format ! ("    node_type_counts.insert(\"{}\".to_string(), {});\n" , node_type , count)']
expression_str = '& format ! ("    node_type_counts.insert(\"{}\".to_string(), {});\n" , node_type , count)'
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."WalkDir :: new (repo_root) . into_iter ()"]
expression_str = "WalkDir :: new (repo_root) . into_iter ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"src/lib.rs"']
expression_str = '"src/lib.rs"'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'Box :: pin (async move { measurement :: record_function_entry ("PreprocessFunctor::map") ; let ClassifiedUseStatements (classified_uses , _) = input ; let mut new_classified_uses = Vec :: new () ; for use_statement in classified_uses { if use_statement . error . is_some () { let temp_dir = tempfile :: tempdir () ? ; let temp_file_path = temp_dir . path () . join ("main.rs") ; let content = format ! ("{}\nfn main() {{}}" , use_statement . statement) ; tokio :: fs :: write (& temp_file_path , content) . await ? ; let output = tokio :: process :: Command :: new ("rustc") . arg (& temp_file_path) . output () . await ? ; if output . status . success () { new_classified_uses . push (UseStatement { statement : use_statement . statement , error : None , git_details : None , nix_details : None , rust_details : None , cargo_details : None , syn_details : None , llvm_details : None , linux_details : None , }) ; } else { new_classified_uses . push (UseStatement { statement : use_statement . statement , error : Some (String :: from_utf8_lossy (& output . stderr) . to_string ()) , git_details : None , nix_details : None , rust_details : None , cargo_details : None , syn_details : None , llvm_details : None , linux_details : None , }) ; } } else { new_classified_uses . push (UseStatement { statement : use_statement . statement , error : use_statement . error , git_details : use_statement . git_details , nix_details : use_statement . nix_details , rust_details : use_statement . rust_details , cargo_details : use_statement . cargo_details , syn_details : use_statement . syn_details , llvm_details : use_statement . llvm_details , linux_details : use_statement . linux_details , }) ; } } let __result = Ok (ClassifiedUseStatements (new_classified_uses , HashMap :: new ())) ; measurement :: record_function_exit ("PreprocessFunctor::map") ; __result })']
expression_str = 'Box :: pin (async move { measurement :: record_function_entry ("PreprocessFunctor::map") ; let ClassifiedUseStatements (classified_uses , _) = input ; let mut new_classified_uses = Vec :: new () ; for use_statement in classified_uses { if use_statement . error . is_some () { let temp_dir = tempfile :: tempdir () ? ; let temp_file_path = temp_dir . path () . join ("main.rs") ; let content = format ! ("{}\nfn main() {{}}" , use_statement . statement) ; tokio :: fs :: write (& temp_file_path , content) . await ? ; let output = tokio :: process :: Command :: new ("rustc") . arg (& temp_file_path) . output () . await ? ; if output . status . success () { new_classified_uses . push (UseStatement { statement : use_statement . statement , error : None , git_details : None , nix_details : None , rust_details : None , cargo_details : None , syn_details : None , llvm_details : None , linux_details : None , }) ; } else { new_classified_uses . push (UseStatement { statement : use_statement . statement , error : Some (String :: from_utf8_lossy (& output . stderr) . to_string ()) , git_details : None , nix_details : None , rust_details : None , cargo_details : None , syn_details : None , llvm_details : None , linux_details : None , }) ; } } else { new_classified_uses . push (UseStatement { statement : use_statement . statement , error : use_statement . error , git_details : use_statement . git_details , nix_details : use_statement . nix_details , rust_details : use_statement . rust_details , cargo_details : use_statement . cargo_details , syn_details : use_statement . syn_details , llvm_details : use_statement . llvm_details , linux_details : use_statement . linux_details , }) ; } } let __result = Ok (ClassifiedUseStatements (new_classified_uses , HashMap :: new ())) ; measurement :: record_function_exit ("PreprocessFunctor::map") ; __result })'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."grouped_by_node_type . keys () . cloned ()"]
expression_str = "grouped_by_node_type . keys () . cloned ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'" Generates a markdown report of the file processing results."']
expression_str = '" Generates a markdown report of the file processing results."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."all_impl_lattices . clone ()"]
expression_str = "all_impl_lattices . clone ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"trait" . to_string ()']
expression_str = '"trait" . to_string ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'generated_decls_output_dir . join ("constants")']
expression_str = 'generated_decls_output_dir . join ("constants")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."& i . sig . ident"]
expression_str = "& i . sig . ident"
depth = 3
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."new_items . push (item . clone ())"]
expression_str = "new_items . push (item . clone ())"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.contains_complex_attributes_for_const]
expression_str = "contains_complex_attributes_for_const"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."walkdir :: WalkDir :: new (project_root) . into_iter () . filter_map (| e | e . ok ())"]
expression_str = "walkdir :: WalkDir :: new (project_root) . into_iter () . filter_map (| e | e . ok ())"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'| | { PathBuf :: from (& self . args . path) . join ("target/release/hf-validator") }']
expression_str = '| | { PathBuf :: from (& self . args . path) . join ("target/release/hf-validator") }'
depth = 5
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions.'tokio :: fs :: write (& error_output_path , error_json_content) . await . context (format ! ("Failed to write errors to file: {:?}" , error_output_path)) ?']
expression_str = 'tokio :: fs :: write (& error_output_path , error_json_content) . await . context (format ! ("Failed to write errors to file: {:?}" , error_output_path)) ?'
depth = 3
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."split_expanded_lib :: extract_declarations_from_single_file (& file_path , & rustc_info_for_split_expanded_lib , & current_crate_name , args . verbose ,) . await ?"]
expression_str = "split_expanded_lib :: extract_declarations_from_single_file (& file_path , & rustc_info_for_split_expanded_lib , & current_crate_name , args . verbose ,) . await ?"
depth = 4
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."{ if let Some (segment) = type_path . path . segments . last () { self . types . insert (segment . ident . to_string ()) ; } }"]
expression_str = "{ if let Some (segment) = type_path . path . segments . last () { self . types . insert (segment . ident . to_string ()) ; } }"
depth = 4
used_types = []
other_types_count = 0
node_type = "Block"

[expressions.'"ForLoop" . to_string ()']
expression_str = '"ForLoop" . to_string ()'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."| | ImplLatticeInfo :: new (impl_for_type_name . clone ())"]
expression_str = "| | ImplLatticeInfo :: new (impl_for_type_name . clone ())"
depth = 4
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions."syn :: visit :: visit_path"]
expression_str = "syn :: visit :: visit_path"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."& dir"]
expression_str = "& dir"
depth = 3
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'extract_uses_functor . map (writer , parsed_file . clone ()) . await . context ("Extracting use statements failed")']
expression_str = 'extract_uses_functor . map (writer , parsed_file . clone ()) . await . context ("Extracting use statements failed")'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'syn :: parse_file (& content) . with_context (| | format ! ("Failed to parse Rust file: {}" , file_path . display ())) ?']
expression_str = 'syn :: parse_file (& content) . with_context (| | format ! ("Failed to parse Rust file: {}" , file_path . display ())) ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."info . used_types"]
expression_str = "info . used_types"
depth = 5
used_types = []
other_types_count = 0
node_type = "Field"

[expressions."visit :: visit_item_static (self , i)"]
expression_str = "visit :: visit_item_static (self , i)"
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'"my-crate"']
expression_str = '"my-crate"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."if let Type :: Path (type_path) = i { for segment in type_path . path . segments . iter () { let type_name = segment . ident . to_string () ; let entry = self . type_map . entry (type_name . clone ()) . or_insert_with (| | TypeInfo { count : 0 , layer : Some (0) }) ; entry . count += 1 ; if is_complex_type (& type_name) { entry . layer = Some (1) ; } if let PathArguments :: AngleBracketed (angle_args) = & segment . arguments { for arg in angle_args . args . iter () { if let GenericArgument :: Type (inner_ty) = arg { self . visit_type (inner_ty) ; } } } } }"]
expression_str = "if let Type :: Path (type_path) = i { for segment in type_path . path . segments . iter () { let type_name = segment . ident . to_string () ; let entry = self . type_map . entry (type_name . clone ()) . or_insert_with (| | TypeInfo { count : 0 , layer : Some (0) }) ; entry . count += 1 ; if is_complex_type (& type_name) { entry . layer = Some (1) ; } if let PathArguments :: AngleBracketed (angle_args) = & segment . arguments { for arg in angle_args . args . iter () { if let GenericArgument :: Type (inner_ty) = arg { self . visit_type (inner_ty) ; } } } } }"
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'"ClassifyUsesFunctor::map"']
expression_str = '"ClassifyUsesFunctor::map"'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.all_constants]
expression_str = "all_constants"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.collect_all_test_cases]
expression_str = "collect_all_test_cases"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."crate :: declaration_processing :: extract_all_declarations_from_file"]
expression_str = "crate :: declaration_processing :: extract_all_declarations_from_file"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."syn :: visit :: visit_item_enum"]
expression_str = "syn :: visit :: visit_item_enum"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."prelude_generator :: public_tests :: test_generate_test_report_json"]
expression_str = "prelude_generator :: public_tests :: test_generate_test_report_json"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'{ eprintln ! ("       Failed to parse file {}: {}" , path . display () , e) ; }']
expression_str = '{ eprintln ! ("       Failed to parse file {}: {}" , path . display () , e) ; }'
depth = 5
used_types = []
other_types_count = 0
node_type = "Block"

[expressions.'format ! ("        -> Parsing expanded code for: {}\n" , file_path . display ()) . as_bytes ()']
expression_str = 'format ! ("        -> Parsing expanded code for: {}\n" , file_path . display ()) . as_bytes ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.full_path]
expression_str = "full_path"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'walkdir :: WalkDir :: new (& project_root) . into_iter () . filter_map (| e | e . ok ()) . filter (| e | e . file_type () . is_file () && e . path () . extension () . map_or (false , | ext | ext == r"rs"))']
expression_str = 'walkdir :: WalkDir :: new (& project_root) . into_iter () . filter_map (| e | e . ok ()) . filter (| e | e . file_type () . is_file () && e . path () . extension () . map_or (false , | ext | ext == r"rs"))'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'format ! ("{}.rs" , const_name)']
expression_str = 'format ! ("{}.rs" , const_name)'
depth = 3
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions."numerical_constants . push (constant)"]
expression_str = "numerical_constants . push (constant)"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."prelude_generator :: public_tests :: test_modify_crate_root_already_has_prelude () ?"]
expression_str = "prelude_generator :: public_tests :: test_modify_crate_root_already_has_prelude () ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.modify_crate_root]
expression_str = "modify_crate_root"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.sorted_crate_paths]
expression_str = "sorted_crate_paths"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'for (version , count) in & stats . rust_version_counts { code . push_str (& format ! ("    rust_version_counts.insert(\"{}\".to_string(), {});\n" , version , count) ,) ; }']
expression_str = 'for (version , count) in & stats . rust_version_counts { code . push_str (& format ! ("    rust_version_counts.insert(\"{}\".to_string(), {});\n" , version , count) ,) ; }'
depth = 2
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions."writer . write_all (format ! (\"--- Stage 4: Hugging Face Validation ---\n\") . as_bytes ())"]
expression_str = """
writer . write_all (format ! ("--- Stage 4: Hugging Face Validation ---
") . as_bytes ())"""
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."entry . call_count += 1"]
expression_str = "entry . call_count += 1"
depth = 2
used_types = []
other_types_count = 0
node_type = "Binary"

[expressions."structure . ident . to_string ()"]
expression_str = "structure . ident . to_string ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.1]
expression_str = "1"
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'"std::collections"']
expression_str = '"std::collections"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'add_primitive_type (& mut symbols , "i8")']
expression_str = 'add_primitive_type (& mut symbols , "i8")'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."ValidatedFile (parsed_file . 0 . clone () , parsed_file . 1 . clone ())"]
expression_str = "ValidatedFile (parsed_file . 0 . clone () , parsed_file . 1 . clone ())"
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'code . push_str (& format ! ("    line_stats.insert(\"{}\".to_string(), ({}, {}, {}, {}));\n" , node_type , min , max , sum , count) ,)']
expression_str = 'code . push_str (& format ! ("    line_stats.insert(\"{}\".to_string(), ({}, {}, {}, {}));\n" , node_type , min , max , sum , count) ,)'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."parse_functor . map (writer , raw_file)"]
expression_str = "parse_functor . map (writer , raw_file)"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."Instant :: now"]
expression_str = "Instant :: now"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."modify_crate_root (& src_dir , false , true) ?"]
expression_str = "modify_crate_root (& src_dir , false , true) ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.DependencyValidator]
expression_str = "DependencyValidator"
depth = 2
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."process_crates (& args)"]
expression_str = "process_crates (& args)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."b . 1 . count . cmp (& a . 1 . count)"]
expression_str = "b . 1 . count . cmp (& a . 1 . count)"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."HashSet :: new"]
expression_str = "HashSet :: new"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'writer . write_all (format ! ("  -> Returning original source code as mock reconstruction.\n") . as_bytes ()) . await ?']
expression_str = 'writer . write_all (format ! ("  -> Returning original source code as mock reconstruction.\n") . as_bytes ()) . await ?'
depth = 4
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'if current_file_size + line . len () > MAX_FILE_SIZE && current_file_size > 0 { let file_path = output_dir . join (format ! ("numerical_constants_{}.rs" , file_idx)) ; tokio :: fs :: create_dir_all (file_path . parent () . unwrap ()) . await ? ; tokio :: fs :: write (& file_path , current_file_content . as_bytes ()) . await ? ; println ! ("    -> Wrote numerical constants to {:?}\n" , file_path) ; current_file_content . clear () ; current_file_size = 0 ; file_idx += 1 ; }']
expression_str = 'if current_file_size + line . len () > MAX_FILE_SIZE && current_file_size > 0 { let file_path = output_dir . join (format ! ("numerical_constants_{}.rs" , file_idx)) ; tokio :: fs :: create_dir_all (file_path . parent () . unwrap ()) . await ? ; tokio :: fs :: write (& file_path , current_file_content . as_bytes ()) . await ? ; println ! ("    -> Wrote numerical constants to {:?}\n" , file_path) ; current_file_content . clear () ; current_file_size = 0 ; file_idx += 1 ; }'
depth = 3
used_types = []
other_types_count = 0
node_type = "If"

[expressions."let Some (toml_output_path) = & args . output_toml_report"]
expression_str = "let Some (toml_output_path) = & args . output_toml_report"
depth = 3
used_types = []
other_types_count = 0
node_type = "Let"

[expressions."& mut hasher"]
expression_str = "& mut hasher"
depth = 5
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."unique_crate_paths . iter ()"]
expression_str = "unique_crate_paths . iter ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'tokio :: fs :: write (& cached_file_path , & relevant_expanded_code) . await . with_context (| | format ! ("Failed to write expanded code to cache for {}" , file_path . display ())) ?']
expression_str = 'tokio :: fs :: write (& cached_file_path , & relevant_expanded_code) . await . with_context (| | format ! ("Failed to write expanded code to cache for {}" , file_path . display ())) ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'"Max expression depth must be specified for type usage analysis"']
expression_str = '"Max expression depth must be specified for type usage analysis"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'| | anyhow :: anyhow ! ("generated_decls_output_dir is required")']
expression_str = '| | anyhow :: anyhow ! ("generated_decls_output_dir is required")'
depth = 4
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions."args . verify_config"]
expression_str = "args . verify_config"
depth = 3
used_types = []
other_types_count = 0
node_type = "Field"

[expressions."extract_declarations_from_single_file (file_path , rustc_info , crate_name , verbose ,) . await ?"]
expression_str = "extract_declarations_from_single_file (file_path , rustc_info , crate_name , verbose ,) . await ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'"function" . to_string ()']
expression_str = '"function" . to_string ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"dummy_file.rs"']
expression_str = '"dummy_file.rs"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."let Err (e) = result"]
expression_str = "let Err (e) = result"
depth = 5
used_types = []
other_types_count = 0
node_type = "Let"

[expressions.'"std"']
expression_str = '"std"'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."decl . source_file . to_string_lossy () . to_string ()"]
expression_str = "decl . source_file . to_string_lossy () . to_string ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'if let Ok (content) = std :: fs :: read_to_string (& path) { if let Ok (file) = syn :: parse_file (& content) { bag_of_words_visitor . visit_file (& file) ; files_processed_for_bow += 1 ; } else { eprintln ! (r"Warning: Could not parse file for bag of words analysis: {}" , path . display ()) ; } } else { eprintln ! (r"Warning: Could not read file for bag of words analysis: {}" , path . display ()) ; }']
expression_str = 'if let Ok (content) = std :: fs :: read_to_string (& path) { if let Ok (file) = syn :: parse_file (& content) { bag_of_words_visitor . visit_file (& file) ; files_processed_for_bow += 1 ; } else { eprintln ! (r"Warning: Could not parse file for bag of words analysis: {}" , path . display ()) ; } } else { eprintln ! (r"Warning: Could not read file for bag of words analysis: {}" , path . display ()) ; }'
depth = 3
used_types = []
other_types_count = 0
node_type = "If"

[expressions."Path :: new"]
expression_str = "Path :: new"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'analyzer_version_counts . insert ("0.3.2000" . to_string () , 295)']
expression_str = 'analyzer_version_counts . insert ("0.3.2000" . to_string () , 295)'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'serde_json :: to_string_pretty (& test_functions) . context ("Failed to serialize test info to JSON")']
expression_str = 'serde_json :: to_string_pretty (& test_functions) . context ("Failed to serialize test info to JSON")'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."& line"]
expression_str = "& line"
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'tokio :: fs :: create_dir_all (& structs_output_dir) . await . context (format ! ("Failed to create output directory {:?}, for struct {}" , structs_output_dir , struct_name))']
expression_str = 'tokio :: fs :: create_dir_all (& structs_output_dir) . await . context (format ! ("Failed to create output directory {:?}, for struct {}" , structs_output_dir , struct_name))'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'output_dir . join ("public_symbols.json")']
expression_str = 'output_dir . join ("public_symbols.json")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."& gem_entry . identifiers"]
expression_str = "& gem_entry . identifiers"
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'"Range" . to_string ()']
expression_str = '"Range" . to_string ()'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."self . field_co_occurrences . entry (field_types)"]
expression_str = "self . field_co_occurrences . entry (field_types)"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.parse_arguments_and_config]
expression_str = "parse_arguments_and_config"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'if let Some (parent) = cargo_toml_path . parent () { if ! parent . components () . any (| c | c . as_os_str () == "target") { unique_crate_paths . insert (parent . to_path_buf ()) ; } }']
expression_str = 'if let Some (parent) = cargo_toml_path . parent () { if ! parent . components () . any (| c | c . as_os_str () == "target") { unique_crate_paths . insert (parent . to_path_buf ()) ; } }'
depth = 3
used_types = []
other_types_count = 0
node_type = "If"

[expressions."| a , b | b . 1 . cmp (a . 1)"]
expression_str = "| a , b | b . 1 . cmp (a . 1)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions."unique_crate_paths . iter () . collect ()"]
expression_str = "unique_crate_paths . iter () . collect ()"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."{ for tree in group . items . iter () { flatten_use_tree (base_path , tree , flat_uses) ; } }"]
expression_str = "{ for tree in group . items . iter () { flatten_use_tree (base_path , tree , flat_uses) ; } }"
depth = 3
used_types = []
other_types_count = 0
node_type = "Block"

[expressions.'"1.89.0"']
expression_str = '"1.89.0"'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."original_file_path . to_string_lossy () . to_string ()"]
expression_str = "original_file_path . to_string_lossy () . to_string ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.hasher]
expression_str = "hasher"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."BagOfWordsVisitor :: new"]
expression_str = "BagOfWordsVisitor :: new"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."results_file_path . exists ()"]
expression_str = "results_file_path . exists ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."self . expressions"]
expression_str = "self . expressions"
depth = 4
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'"--timeout"']
expression_str = '"--timeout"'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."if default_config_path . exists () { Some (crate :: config_parser :: read_config (& default_config_path , & project_root) ?) } else { None }"]
expression_str = "if default_config_path . exists () { Some (crate :: config_parser :: read_config (& default_config_path , & project_root) ?) } else { None }"
depth = 4
used_types = []
other_types_count = 0
node_type = "If"

[expressions.current_module_path]
expression_str = "current_module_path"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'match std :: fs :: read_to_string (& path) { Ok (c) => c , Err (e) => { eprintln ! ("Error reading file {}: {:?}" , path . display () , e) ; continue ; } }']
expression_str = 'match std :: fs :: read_to_string (& path) { Ok (c) => c , Err (e) => { eprintln ! ("Error reading file {}: {:?}" , path . display () , e) ; continue ; } }'
depth = 3
used_types = []
other_types_count = 0
node_type = "Match"

[expressions."impl_for_type_name . clone ()"]
expression_str = "impl_for_type_name . clone ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.errors]
expression_str = "errors"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."Args :: parse_from"]
expression_str = "Args :: parse_from"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.all_collected_errors]
expression_str = "all_collected_errors"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'add_std_lib_symbol (& mut symbols , "assert!" , "macro" , Some ("std::macro"))']
expression_str = 'add_std_lib_symbol (& mut symbols , "assert!" , "macro" , Some ("std::macro"))'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."f . sig . ident . to_string ()"]
expression_str = "f . sig . ident . to_string ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'PipelineFunctor :: map (& ast_reconstruction_functor , writer , validated_file . clone ()) . await . context ("AST Reconstruction failed")']
expression_str = 'PipelineFunctor :: map (& ast_reconstruction_functor , writer , validated_file . clone ()) . await . context ("AST Reconstruction failed")'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."tokio :: fs :: write (& ast_statistics_file_path , ast_statistics_code . as_bytes ()) . await"]
expression_str = "tokio :: fs :: write (& ast_statistics_file_path , ast_statistics_code . as_bytes ()) . await"
depth = 4
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."measurement :: get_collected_metrics"]
expression_str = "measurement :: get_collected_metrics"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'return Err (anyhow :: anyhow ! ("hf-validator command failed with status: {}" , status))']
expression_str = 'return Err (anyhow :: anyhow ! ("hf-validator command failed with status: {}" , status))'
depth = 5
used_types = []
other_types_count = 0
node_type = "Return"

[expressions.'if mapping_file_path . exists () { let mut file = File :: open (& mapping_file_path) . await . context ("Failed to open mapping.toml") ? ; let mut contents = String :: new () ; file . read_to_string (& mut contents) . await . context ("Failed to read mapping.toml") ? ; toml :: from_str (& contents) . context ("Failed to parse mapping.toml") ? } else { Mapping :: default () }']
expression_str = 'if mapping_file_path . exists () { let mut file = File :: open (& mapping_file_path) . await . context ("Failed to open mapping.toml") ? ; let mut contents = String :: new () ; file . read_to_string (& mut contents) . await . context ("Failed to read mapping.toml") ? ; toml :: from_str (& contents) . context ("Failed to parse mapping.toml") ? } else { Mapping :: default () }'
depth = 4
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'if use_statement . error . is_some () { let temp_dir = tempfile :: tempdir () ? ; let temp_file_path = temp_dir . path () . join ("main.rs") ; let content = format ! ("{}\nfn main() {{}}" , use_statement . statement) ; tokio :: fs :: write (& temp_file_path , content) . await ? ; let output = tokio :: process :: Command :: new ("rustc") . arg (& temp_file_path) . output () . await ? ; if output . status . success () { new_classified_uses . push (UseStatement { statement : use_statement . statement , error : None , git_details : None , nix_details : None , rust_details : None , cargo_details : None , syn_details : None , llvm_details : None , linux_details : None , }) ; } else { new_classified_uses . push (UseStatement { statement : use_statement . statement , error : Some (String :: from_utf8_lossy (& output . stderr) . to_string ()) , git_details : None , nix_details : None , rust_details : None , cargo_details : None , syn_details : None , llvm_details : None , linux_details : None , }) ; } } else { new_classified_uses . push (UseStatement { statement : use_statement . statement , error : use_statement . error , git_details : use_statement . git_details , nix_details : use_statement . nix_details , rust_details : use_statement . rust_details , cargo_details : use_statement . cargo_details , syn_details : use_statement . syn_details , llvm_details : use_statement . llvm_details , linux_details : use_statement . linux_details , }) ; }']
expression_str = 'if use_statement . error . is_some () { let temp_dir = tempfile :: tempdir () ? ; let temp_file_path = temp_dir . path () . join ("main.rs") ; let content = format ! ("{}\nfn main() {{}}" , use_statement . statement) ; tokio :: fs :: write (& temp_file_path , content) . await ? ; let output = tokio :: process :: Command :: new ("rustc") . arg (& temp_file_path) . output () . await ? ; if output . status . success () { new_classified_uses . push (UseStatement { statement : use_statement . statement , error : None , git_details : None , nix_details : None , rust_details : None , cargo_details : None , syn_details : None , llvm_details : None , linux_details : None , }) ; } else { new_classified_uses . push (UseStatement { statement : use_statement . statement , error : Some (String :: from_utf8_lossy (& output . stderr) . to_string ()) , git_details : None , nix_details : None , rust_details : None , cargo_details : None , syn_details : None , llvm_details : None , linux_details : None , }) ; } } else { new_classified_uses . push (UseStatement { statement : use_statement . statement , error : use_statement . error , git_details : use_statement . git_details , nix_details : use_statement . nix_details , rust_details : use_statement . rust_details , cargo_details : use_statement . cargo_details , syn_details : use_statement . syn_details , llvm_details : use_statement . llvm_details , linux_details : use_statement . linux_details , }) ; }'
depth = 5
used_types = []
other_types_count = 0
node_type = "If"

[expressions."current_layer_decls . push (decl)"]
expression_str = "current_layer_decls . push (decl)"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."visit :: visit_item_enum (self , i)"]
expression_str = "visit :: visit_item_enum (self , i)"
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'writer . write_all (format ! ("  -> Short ID for hf-validator project: {}\n" , short_id) . as_bytes ()) . await ?']
expression_str = 'writer . write_all (format ! ("  -> Short ID for hf-validator project: {}\n" , short_id) . as_bytes ()) . await ?'
depth = 4
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."args . output_toml_report"]
expression_str = "args . output_toml_report"
depth = 5
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'fs :: write (& prelude_path , "// Original content")']
expression_str = 'fs :: write (& prelude_path , "// Original content")'
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."report_content . push_str (\"================================================================\n\")"]
expression_str = """
report_content . push_str ("================================================================
")"""
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."syn :: visit :: visit_item_const"]
expression_str = "syn :: visit :: visit_item_const"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.result]
expression_str = "result"
depth = 2
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'src_dir . join ("prelude.rs")']
expression_str = 'src_dir . join ("prelude.rs")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'writer . write_all (format ! ("{:#?}\n" , classified_uses) . as_bytes ()) . await ?']
expression_str = 'writer . write_all (format ! ("{:#?}\n" , classified_uses) . as_bytes ()) . await ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'for entry in walker { let file_path = entry . path () . to_path_buf () ; let should_process_file = args . filter_names . as_ref () . map_or (true , | filter_names | { filter_names . iter () . any (| f | file_path . to_string_lossy () . contains (f)) }) ; if should_process_file { let (declarations , errors , _file_metadata , public_symbols) = split_expanded_lib :: extract_declarations_from_single_file (& file_path , & rustc_info_for_split_expanded_lib , & crate_name , args . verbose ,) . await ? ; all_collected_errors . extend (errors) ; all_public_symbols . extend (public_symbols) ; for decl in declarations { match & decl . item { split_expanded_lib :: DeclarationItem :: Const (s) => { if let Ok (item_const) = syn :: parse_str :: < syn :: ItemConst > (s) { if item_const . ident . to_string () . ends_with ("_NUM") { all_numerical_constants . push (item_const) ; } else { all_string_constants . push (item_const) ; } } } , _ => { } , } } } }']
expression_str = 'for entry in walker { let file_path = entry . path () . to_path_buf () ; let should_process_file = args . filter_names . as_ref () . map_or (true , | filter_names | { filter_names . iter () . any (| f | file_path . to_string_lossy () . contains (f)) }) ; if should_process_file { let (declarations , errors , _file_metadata , public_symbols) = split_expanded_lib :: extract_declarations_from_single_file (& file_path , & rustc_info_for_split_expanded_lib , & crate_name , args . verbose ,) . await ? ; all_collected_errors . extend (errors) ; all_public_symbols . extend (public_symbols) ; for decl in declarations { match & decl . item { split_expanded_lib :: DeclarationItem :: Const (s) => { if let Ok (item_const) = syn :: parse_str :: < syn :: ItemConst > (s) { if item_const . ident . to_string () . ends_with ("_NUM") { all_numerical_constants . push (item_const) ; } else { all_string_constants . push (item_const) ; } } } , _ => { } , } } } }'
depth = 2
used_types = ["ItemConst"]
other_types_count = 1
node_type = "ForLoop"

[expressions.symbols]
expression_str = "symbols"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'serde_json :: to_string_pretty (& all_file_processing_results) . context ("Failed to serialize results to JSON") ?']
expression_str = 'serde_json :: to_string_pretty (& all_file_processing_results) . context ("Failed to serialize results to JSON") ?'
depth = 5
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'"Match"']
expression_str = '"Match"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'".prelude_cache"']
expression_str = '".prelude_cache"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."self . impl_lattices . entry (impl_for_type_name . clone ())"]
expression_str = "self . impl_lattices . entry (impl_for_type_name . clone ())"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.type_map]
expression_str = "type_map"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'if parent . join ("Cargo.toml") . exists () { tests_by_crate . entry (parent . to_path_buf ()) . or_default () . push (info . name) ; break ; }']
expression_str = 'if parent . join ("Cargo.toml") . exists () { tests_by_crate . entry (parent . to_path_buf ()) . or_default () . push (info . name) ; break ; }'
depth = 4
used_types = []
other_types_count = 0
node_type = "If"

[expressions."current_layer_idents . insert (decl . get_identifier ())"]
expression_str = "current_layer_idents . insert (decl . get_identifier ())"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'" Generate a single test file with all unique use statements"']
expression_str = '" Generate a single test file with all unique use statements"'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."entry . layer = Some (1)"]
expression_str = "entry . layer = Some (1)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Assign"

[expressions.'crate_path . join ("Cargo.toml")']
expression_str = 'crate_path . join ("Cargo.toml")'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'writer . write_all (format ! ("      -> Wrote expanded code to cache: {}\n" , cached_file_path . display ()) . as_bytes ())']
expression_str = 'writer . write_all (format ! ("      -> Wrote expanded code to cache: {}\n" , cached_file_path . display ()) . as_bytes ())'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.file]
expression_str = "file"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'crate_root . join ("src/lib.rs")']
expression_str = 'crate_root . join ("src/lib.rs")'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'writer . write_all (format ! ("--- Stage 1: Parsing ---\n") . as_bytes ()) . await ?']
expression_str = 'writer . write_all (format ! ("--- Stage 1: Parsing ---\n") . as_bytes ()) . await ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'src_dir . join ("main.rs")']
expression_str = 'src_dir . join ("main.rs")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.all_expression_info]
expression_str = "all_expression_info"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'ResolvedDependency { id : crate_name . clone () , dependency_type : "crate" . to_string () , crate_name : crate_name . clone () , module_path : crate_name . clone () , usage_count : 0 , }']
expression_str = 'ResolvedDependency { id : crate_name . clone () , dependency_type : "crate" . to_string () , crate_name : crate_name . clone () , module_path : crate_name . clone () , usage_count : 0 , }'
depth = 4
used_types = []
other_types_count = 0
node_type = "Struct"

[expressions.'add_std_lib_symbol (& mut symbols , "Vec" , "type" , Some ("std::vec"))']
expression_str = 'add_std_lib_symbol (& mut symbols , "Vec" , "type" , Some ("std::vec"))'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."prelude_generator :: public_tests :: test_collect_all_test_cases"]
expression_str = "prelude_generator :: public_tests :: test_collect_all_test_cases"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."collector . visit_expr (expr)"]
expression_str = "collector . visit_expr (expr)"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'" Rustc host triple (e.g., \"aarch64-unknown-linux-gnu\") for split-expanded-bin."']
expression_str = '" Rustc host triple (e.g., \"aarch64-unknown-linux-gnu\") for split-expanded-bin."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."unique_crate_paths . insert (parent . to_path_buf ())"]
expression_str = "unique_crate_paths . insert (parent . to_path_buf ())"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'file . write_all (toml_string . as_bytes ()) . await . context ("Failed to write mapping.toml") ?']
expression_str = 'file . write_all (toml_string . as_bytes ()) . await . context ("Failed to write mapping.toml") ?'
depth = 4
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."add_uses_from_type_path (type_path , & mut uses)"]
expression_str = "add_uses_from_type_path (type_path , & mut uses)"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'format ! ("        -> rustc stdout for {}: {}\n" , file_path . display () , String :: from_utf8_lossy (& output . stdout)) . as_bytes ()']
expression_str = 'format ! ("        -> rustc stdout for {}: {}\n" , file_path . display () , String :: from_utf8_lossy (& output . stdout)) . as_bytes ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."if let PathArguments :: AngleBracketed (angle_args) = & segment . arguments { for arg in angle_args . args . iter () { if let GenericArgument :: Type (inner_ty) = arg { self . visit_type (inner_ty) ; } } }"]
expression_str = "if let PathArguments :: AngleBracketed (angle_args) = & segment . arguments { for arg in angle_args . args . iter () { if let GenericArgument :: Type (inner_ty) = arg { self . visit_type (inner_ty) ; } } }"
depth = 4
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'writer . write_all (format ! ("  -> Generated code written to {:?}\n" , output_file_path) . as_bytes ())']
expression_str = 'writer . write_all (format ! ("  -> Generated code written to {:?}\n" , output_file_path) . as_bytes ())'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'& format ! ("- Failed: {}\n\n" , failed_files)']
expression_str = '& format ! ("- Failed: {}\n\n" , failed_files)'
depth = 3
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'if ! errors . is_empty () { eprintln ! (r"\n--- Errors Encountered during constant processing ---") ; for error in & errors { eprintln ! (r"{:{}}" , error) ; } eprintln ! (r"-----------------------------------------------------") ; return Err (anyhow :: anyhow ! ("Constant processing completed with errors.")) ; } else { println ! (r"Declaration processing completed successfully.") ; crate :: constant_reporting :: generate_numerical_constants_report (& numerical_output_dir) . await ? ; return Ok (()) }']
expression_str = 'if ! errors . is_empty () { eprintln ! (r"\n--- Errors Encountered during constant processing ---") ; for error in & errors { eprintln ! (r"{:{}}" , error) ; } eprintln ! (r"-----------------------------------------------------") ; return Err (anyhow :: anyhow ! ("Constant processing completed with errors.")) ; } else { println ! (r"Declaration processing completed successfully.") ; crate :: constant_reporting :: generate_numerical_constants_report (& numerical_output_dir) . await ? ; return Ok (()) }'
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions."[]"]
expression_str = "[]"
depth = 5
used_types = []
other_types_count = 0
node_type = "Array"

[expressions."fs :: create_dir"]
expression_str = "fs :: create_dir"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."& results"]
expression_str = "& results"
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."split_expanded_lib :: extract_declarations_from_single_file (& file_path , & rustc_info_for_split_expanded_lib , & crate_name , args . verbose ,) . await ?"]
expression_str = "split_expanded_lib :: extract_declarations_from_single_file (& file_path , & rustc_info_for_split_expanded_lib , & crate_name , args . verbose ,) . await ?"
depth = 4
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'"aarch64-unknown-linux-gnu"']
expression_str = '"aarch64-unknown-linux-gnu"'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."{ filter_names . iter () . any (| f | file_path . to_string_lossy () . contains (f)) }"]
expression_str = "{ filter_names . iter () . any (| f | file_path . to_string_lossy () . contains (f)) }"
depth = 5
used_types = []
other_types_count = 0
node_type = "Block"

[expressions."crate_name . clone ()"]
expression_str = "crate_name . clone ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'add_primitive_type (& mut symbols , "i16")']
expression_str = 'add_primitive_type (& mut symbols , "i16")'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.break]
expression_str = "break"
depth = 4
used_types = []
other_types_count = 0
node_type = "Break"

[expressions.'{ if attr . path () . is_ident ("derive") { if let syn :: Meta :: List (meta_list) = & attr . meta { meta_list . tokens . to_string () . contains ("Serialize") || meta_list . tokens . to_string () . contains ("Deserialize") } else { false } } else { false } }']
expression_str = '{ if attr . path () . is_ident ("derive") { if let syn :: Meta :: List (meta_list) = & attr . meta { meta_list . tokens . to_string () . contains ("Serialize") || meta_list . tokens . to_string () . contains ("Deserialize") } else { false } } else { false } }'
depth = 5
used_types = []
other_types_count = 0
node_type = "Block"

[expressions.'format ! ("    node_type_counts.insert(\"{}\".to_string(), {});\n" , node_type , count)']
expression_str = 'format ! ("    node_type_counts.insert(\"{}\".to_string(), {});\n" , node_type , count)'
depth = 5
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions.current_layer_num]
expression_str = "current_layer_num"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'| | PathBuf :: from ("./generated_declarations")']
expression_str = '| | PathBuf :: from ("./generated_declarations")'
depth = 3
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions."entry . usage_count"]
expression_str = "entry . usage_count"
depth = 3
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'"Path" . to_string ()']
expression_str = '"Path" . to_string ()'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.results_json_path]
expression_str = "results_json_path"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."serde_json :: from_str"]
expression_str = "serde_json :: from_str"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.structure]
expression_str = "structure"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'_project_root . join (r"generated/numerical_constants")']
expression_str = '_project_root . join (r"generated/numerical_constants")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."command_handlers :: handle_run_decl_splitter (& args , & project_root , & rustc_info)"]
expression_str = "command_handlers :: handle_run_decl_splitter (& args , & project_root , & rustc_info)"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."id . to_string ()"]
expression_str = "id . to_string ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."fs :: read_to_string (& args . results_file) ?"]
expression_str = "fs :: read_to_string (& args . results_file) ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'"tests"']
expression_str = '"tests"'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."ErrorCollection :: default"]
expression_str = "ErrorCollection :: default"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'let Some (path_env) = std :: env :: var_os ("PATH")']
expression_str = 'let Some (path_env) = std :: env :: var_os ("PATH")'
depth = 5
used_types = []
other_types_count = 0
node_type = "Let"

[expressions."prelude_generator :: public_tests :: test_modify_file_dry_run"]
expression_str = "prelude_generator :: public_tests :: test_modify_file_dry_run"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'writer . write_all (format ! ("  -> Classified use statements:\n") . as_bytes ()) . await ?']
expression_str = 'writer . write_all (format ! ("  -> Classified use statements:\n") . as_bytes ()) . await ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'dir . path () . join ("test_file.rs")']
expression_str = 'dir . path () . join ("test_file.rs")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"module"']
expression_str = '"module"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.dir]
expression_str = "dir"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'match syn :: parse_file (& relevant_expanded_code) { Ok (file) => Ok ((file , None)) , Err (e) => { let error_message = format ! ("Failed to parse expanded code for {}: {}" , file_path . display () , e) ; writer . write_all (format ! ("        -> {}\n" , error_message) . as_bytes ()) . await . context ("Failed to write parsing error to writer") ? ; let error_sample = ErrorSample { file_path : file_path . to_path_buf () , rustc_version : rustc_info . version . clone () , rustc_host : rustc_info . host . clone () , error_message : error_message . clone () , error_type : "SynParsingFailed" . to_string () , code_snippet : Some (relevant_expanded_code . to_string ()) , timestamp : Utc :: now () , context : None , } ; Ok ((syn :: parse_file ("") . unwrap () , Some (error_sample))) } }']
expression_str = 'match syn :: parse_file (& relevant_expanded_code) { Ok (file) => Ok ((file , None)) , Err (e) => { let error_message = format ! ("Failed to parse expanded code for {}: {}" , file_path . display () , e) ; writer . write_all (format ! ("        -> {}\n" , error_message) . as_bytes ()) . await . context ("Failed to write parsing error to writer") ? ; let error_sample = ErrorSample { file_path : file_path . to_path_buf () , rustc_version : rustc_info . version . clone () , rustc_host : rustc_info . host . clone () , error_message : error_message . clone () , error_type : "SynParsingFailed" . to_string () , code_snippet : Some (relevant_expanded_code . to_string ()) , timestamp : Utc :: now () , context : None , } ; Ok ((syn :: parse_file ("") . unwrap () , Some (error_sample))) } }'
depth = 2
used_types = []
other_types_count = 0
node_type = "Match"

[expressions."self . current_method_calls . insert (i . method . to_string ())"]
expression_str = "self . current_method_calls . insert (i . method . to_string ())"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'serde_json :: to_string_pretty (& all_collected_errors_aggregated) . context ("Failed to serialize errors to JSON") ?']
expression_str = 'serde_json :: to_string_pretty (& all_collected_errors_aggregated) . context ("Failed to serialize errors to JSON") ?'
depth = 3
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'"::"']
expression_str = '"::"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."layered_decls . insert (current_layer_num , current_layer_decls)"]
expression_str = "layered_decls . insert (current_layer_num , current_layer_decls)"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'parse_functor . map (writer , raw_file) . await . context ("Parsing failed") ?']
expression_str = 'parse_functor . map (writer , raw_file) . await . context ("Parsing failed") ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.base_path]
expression_str = "base_path"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'"Failed to create temporary src directory"']
expression_str = '"Failed to create temporary src directory"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'"generated/numerical_constants"']
expression_str = '"generated/numerical_constants"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'format ! ("Failed to write symbol map to file: {:?}" , output_path)']
expression_str = 'format ! ("Failed to write symbol map to file: {:?}" , output_path)'
depth = 5
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions.'"ExtractUsesFunctor::map"']
expression_str = '"ExtractUsesFunctor::map"'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.current_dst]
expression_str = "current_dst"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."structure . attrs . iter ()"]
expression_str = "structure . attrs . iter ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"serde"']
expression_str = '"serde"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."all_declarations . into_iter () . map (Into :: into) . collect ()"]
expression_str = "all_declarations . into_iter () . map (Into :: into) . collect ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."String :: from_utf8_lossy (& output . stdout) . to_string ()"]
expression_str = "String :: from_utf8_lossy (& output . stdout) . to_string ()"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."& mut type_map"]
expression_str = "& mut type_map"
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.8]
expression_str = "8"
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'"primitive_type" . to_string ()']
expression_str = '"primitive_type" . to_string ()'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'{ let file_content = fs :: read_to_string (& file_path) . context (format ! ("Failed to read file: {:?}" , file_path)) ? ; match syn :: parse_file (& file_content) { Ok (file) => parsed_files . push ((file_path . clone () , file)) , Err (e) => { eprintln ! ("Warning: Could not re-parse file for Pass 2 {}: {}" , file_path . display () , e) ; } } for decl in declarations { match dependency_validator . validate (& decl) { Ok (_) => all_declarations . push (decl) , Err (e) => { eprintln ! ("Validation Error for declaration {:?}: {:?}" , decl . get_identifier () , e) ; } } } error_collection . errors . extend (errors) ; }']
expression_str = '{ let file_content = fs :: read_to_string (& file_path) . context (format ! ("Failed to read file: {:?}" , file_path)) ? ; match syn :: parse_file (& file_content) { Ok (file) => parsed_files . push ((file_path . clone () , file)) , Err (e) => { eprintln ! ("Warning: Could not re-parse file for Pass 2 {}: {}" , file_path . display () , e) ; } } for decl in declarations { match dependency_validator . validate (& decl) { Ok (_) => all_declarations . push (decl) , Err (e) => { eprintln ! ("Validation Error for declaration {:?}: {:?}" , decl . get_identifier () , e) ; } } } error_collection . errors . extend (errors) ; }'
depth = 4
used_types = []
other_types_count = 0
node_type = "Block"

[expressions.'tokio :: fs :: remove_dir_all (& output_dir) . await . context ("Failed to remove existing output directory")']
expression_str = 'tokio :: fs :: remove_dir_all (& output_dir) . await . context ("Failed to remove existing output directory")'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"Failed to run cargo metadata"']
expression_str = '"Failed to run cargo metadata"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."std :: fs :: read_to_string (config_path)"]
expression_str = "std :: fs :: read_to_string (config_path)"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.ValidatedFile]
expression_str = "ValidatedFile"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.current_file_content]
expression_str = "current_file_content"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'writer . write_all (format ! ("---\n--- Stage 1: Parsing ---\n") . as_bytes ()) . await']
expression_str = 'writer . write_all (format ! ("---\n--- Stage 1: Parsing ---\n") . as_bytes ()) . await'
depth = 3
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.'full_path . push_str ("* ")']
expression_str = 'full_path . push_str ("* ")'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."parsed_file . 0"]
expression_str = "parsed_file . 0"
depth = 4
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.stack]
expression_str = "stack"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'add_primitive_type (& mut symbols , "f64")']
expression_str = 'add_primitive_type (& mut symbols , "f64")'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."& file_path"]
expression_str = "& file_path"
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'type_name == "clap"']
expression_str = 'type_name == "clap"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Binary"

[expressions.'Args :: parse_from (& ["prelude-generator" , "--dry-run" , "--path" , "/tmp/my_project" , "--exclude-crates" , "crate1,crate2" , "--report" , "--results-file" , "custom_results.json" , "--cache-report" , "--timeout" , "60" , "--force" ,])']
expression_str = 'Args :: parse_from (& ["prelude-generator" , "--dry-run" , "--path" , "/tmp/my_project" , "--exclude-crates" , "crate1,crate2" , "--report" , "--results-file" , "custom_results.json" , "--cache-report" , "--timeout" , "60" , "--force" ,])'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'matches ! (ident_str . as_str () , "bool" | "u8" | "u16" | "u32" | "u64" | "u128" | "i8" | "i16" | "i32" | "i64" | "i128" | "f32" | "f64" | "char" | "str" | "usize" | "isize")']
expression_str = 'matches ! (ident_str . as_str () , "bool" | "u8" | "u16" | "u32" | "u64" | "u128" | "i8" | "i16" | "i32" | "i64" | "i128" | "f32" | "f64" | "char" | "str" | "usize" | "isize")'
depth = 5
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions.'"Group" . to_string ()']
expression_str = '"Group" . to_string ()'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."r#\"\n            #[test]\n            fn another_mod_test() { }\n        \"#"]
expression_str = """
r#"
            #[test]
            fn another_mod_test() { }
        "#"""
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."prelude_generator :: public_tests :: test_generate_report_empty_results ()"]
expression_str = "prelude_generator :: public_tests :: test_generate_report_empty_results ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."TypeCollector { type_map : & mut type_map , }"]
expression_str = "TypeCollector { type_map : & mut type_map , }"
depth = 3
used_types = []
other_types_count = 0
node_type = "Struct"

[expressions."& Some (config . clone ())"]
expression_str = "& Some (config . clone ())"
depth = 5
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."* self . field_co_occurrences . entry (field_types) . or_insert (0)"]
expression_str = "* self . field_co_occurrences . entry (field_types) . or_insert (0)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Unary"

[expressions.'"Failed to create prelude cache directory"']
expression_str = '"Failed to create prelude cache directory"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."serde_json :: from_str (& results_file_content) ?"]
expression_str = "serde_json :: from_str (& results_file_content) ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."let syn :: Pat :: Path (pat_path) = & arm . pat"]
expression_str = "let syn :: Pat :: Path (pat_path) = & arm . pat"
depth = 5
used_types = []
other_types_count = 0
node_type = "Let"

[expressions."r#\"\n            #[test]\n            fn my_test_1() { assert_eq!(1, 1); }\n\n            fn not_a_test() { }\n\n            #[cfg(test)]\n            mod my_tests {\n                #[test]\n                fn nested_test() { assert_eq!(2, 2); }\n            }\n\n            #[test]\n            async fn my_test_2() -> Result<()> { Ok(()) }\n        \"#"]
expression_str = """
r#"
            #[test]
            fn my_test_1() { assert_eq!(1, 1); }

            fn not_a_test() { }

            #[cfg(test)]
            mod my_tests {
                #[test]
                fn nested_test() { assert_eq!(2, 2); }
            }

            #[test]
            async fn my_test_2() -> Result<()> { Ok(()) }
        "#"""
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'"Array"']
expression_str = '"Array"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."used_types . len ()"]
expression_str = "used_types . len ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."ast . clone ()"]
expression_str = "ast . clone ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'if structure . attrs . iter () . any (| attr | { if attr . path () . is_ident ("derive") { if let syn :: Meta :: List (meta_list) = & attr . meta { meta_list . tokens . to_string () . contains ("Parser") } else { false } } else { false } }) { uses . insert ("use clap::{Parser, Args, Command};\n") ; uses . insert ("use std::path::PathBuf;\n") ; }']
expression_str = 'if structure . attrs . iter () . any (| attr | { if attr . path () . is_ident ("derive") { if let syn :: Meta :: List (meta_list) = & attr . meta { meta_list . tokens . to_string () . contains ("Parser") } else { false } } else { false } }) { uses . insert ("use clap::{Parser, Args, Command};\n") ; uses . insert ("use std::path::PathBuf;\n") ; }'
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions.next_remaining_decls]
expression_str = "next_remaining_decls"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."handle_pipeline_result (result) . await"]
expression_str = "handle_pipeline_result (result) . await"
depth = 2
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.'{ report_content . push_str (& format ! ("- Status:  Skipped (Reason: {}\n\n" , reason)) ; }']
expression_str = '{ report_content . push_str (& format ! ("- Status:  Skipped (Reason: {}\n\n" , reason)) ; }'
depth = 5
used_types = []
other_types_count = 0
node_type = "Block"

[expressions.sorted_types]
expression_str = "sorted_types"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."if let syn :: Pat :: TupleStruct (pat_tuple_struct) = & * expr_let . pat { if let Some (segment) = pat_tuple_struct . path . segments . last () { self . enum_lattice_info . add_co_occurrence (BTreeSet :: from ([segment . ident . to_string ()])) ; } } else if let syn :: Pat :: Path (pat_path) = & * expr_let . pat { if let Some (segment) = pat_path . path . segments . last () { self . enum_lattice_info . add_co_occurrence (BTreeSet :: from ([segment . ident . to_string ()])) ; } }"]
expression_str = "if let syn :: Pat :: TupleStruct (pat_tuple_struct) = & * expr_let . pat { if let Some (segment) = pat_tuple_struct . path . segments . last () { self . enum_lattice_info . add_co_occurrence (BTreeSet :: from ([segment . ident . to_string ()])) ; } } else if let syn :: Pat :: Path (pat_path) = & * expr_let . pat { if let Some (segment) = pat_path . path . segments . last () { self . enum_lattice_info . add_co_occurrence (BTreeSet :: from ([segment . ident . to_string ()])) ; } }"
depth = 3
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'& format ! ("    processing_time_stats.insert(\"{}\".to_string(), ({}, {}, {}, {}));\n" , node_type , min , max , sum , count)']
expression_str = '& format ! ("    processing_time_stats.insert(\"{}\".to_string(), ({}, {}, {}, {}));\n" , node_type , min , max , sum , count)'
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."toml :: to_string_pretty (& collected_data)"]
expression_str = "toml :: to_string_pretty (& collected_data)"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'writer . write_all (format ! ("        -> {}\n" , error_message) . as_bytes ()) . await . context ("Failed to write parsing error to writer") ?']
expression_str = 'writer . write_all (format ! ("        -> {}\n" , error_message) . as_bytes ()) . await . context ("Failed to write parsing error to writer") ?'
depth = 4
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'if let Item :: Mod (mod_item) = item { if mod_item . ident == "prelude" { has_prelude_mod = true ; break ; } }']
expression_str = 'if let Item :: Mod (mod_item) = item { if mod_item . ident == "prelude" { has_prelude_mod = true ; break ; } }'
depth = 3
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'add_primitive_type (& mut symbols , "bool")']
expression_str = 'add_primitive_type (& mut symbols , "bool")'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'" Generates a test verification script and a Markdown report."']
expression_str = '" Generates a test verification script and a Markdown report."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."hf_dataset_reader :: analyze_hf_dataset_asts (& dataset_output_path) . await"]
expression_str = "hf_dataset_reader :: analyze_hf_dataset_asts (& dataset_output_path) . await"
depth = 4
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."self . impl_lattice_info"]
expression_str = "self . impl_lattice_info"
depth = 4
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.sub_visitor]
expression_str = "sub_visitor"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'"use clap::{Parser, Args, Command};\n"']
expression_str = '"use clap::{Parser, Args, Command};\n"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."* i . func"]
expression_str = "* i . func"
depth = 5
used_types = []
other_types_count = 0
node_type = "Unary"

[expressions."if let Some (segment) = pat_tuple_struct . path . segments . last () { matched_variant_types . insert (segment . ident . to_string ()) ; }"]
expression_str = "if let Some (segment) = pat_tuple_struct . path . segments . last () { matched_variant_types . insert (segment . ident . to_string ()) ; }"
depth = 4
used_types = []
other_types_count = 0
node_type = "If"

[expressions.all_struct_lattices]
expression_str = "all_struct_lattices"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."all_expression_info . insert (expr_str , info)"]
expression_str = "all_expression_info . insert (expr_str , info)"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'writer . write_all (format ! ("{:#?}\n" , classified_uses) . as_bytes ())']
expression_str = 'writer . write_all (format ! ("{:#?}\n" , classified_uses) . as_bytes ())'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."visit :: visit_item_const (self , i)"]
expression_str = "visit :: visit_item_const (self , i)"
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."& ident . to_string ()"]
expression_str = "& ident . to_string ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'GemConfig :: load_from_file (& PathBuf :: from ("gems.toml"))']
expression_str = 'GemConfig :: load_from_file (& PathBuf :: from ("gems.toml"))'
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'fs :: write (& output_path , toml_string) . context (format ! ("Failed to write TOML to file: {:?}" , output_path))']
expression_str = 'fs :: write (& output_path , toml_string) . context (format ! ("Failed to write TOML to file: {:?}" , output_path))'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'" Path to the directory where the test verification script and report will be generated. Required if `compile_tests` is true."']
expression_str = '" Path to the directory where the test verification script and report will be generated. Required if `compile_tests` is true."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'"generated/string_constants"']
expression_str = '"generated/string_constants"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."fs :: metadata (& script_path) ? . permissions ()"]
expression_str = "fs :: metadata (& script_path) ? . permissions ()"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."results . iter () . filter (| r | matches ! (r . status , FileProcessingStatus :: Skipped { .. }))"]
expression_str = "results . iter () . filter (| r | matches ! (r . status , FileProcessingStatus :: Skipped { .. }))"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'format ! ("Failed to read file: {}" , file_path . display ())']
expression_str = 'format ! ("Failed to read file: {}" , file_path . display ())'
depth = 5
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions.'{ report_content . push_str ("- Status:  Successfully Processed\n\n") ; }']
expression_str = '{ report_content . push_str ("- Status:  Successfully Processed\n\n") ; }'
depth = 5
used_types = []
other_types_count = 0
node_type = "Block"

[expressions.'tokio :: fs :: create_dir_all (& consts_output_dir) . await . context (format ! ("Failed to create output directory {:?}" , consts_output_dir)) ?']
expression_str = 'tokio :: fs :: create_dir_all (& consts_output_dir) . await . context (format ! ("Failed to create output directory {:?}" , consts_output_dir)) ?'
depth = 3
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'writer . write_all (format ! ("--- Stage 2: Extracting Use Statements ---\n") . as_bytes ()) . await']
expression_str = 'writer . write_all (format ! ("--- Stage 2: Extracting Use Statements ---\n") . as_bytes ()) . await'
depth = 3
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.module_path]
expression_str = "module_path"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'"Continue"']
expression_str = '"Continue"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'format ! ("Failed to parse Rust file: {}" , file_path . display ())']
expression_str = 'format ! ("Failed to parse Rust file: {}" , file_path . display ())'
depth = 5
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions."WalkDir :: new (& args . path)"]
expression_str = "WalkDir :: new (& args . path)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."tests_by_crate . keys () . collect ()"]
expression_str = "tests_by_crate . keys () . collect ()"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.rustc_info]
expression_str = "rustc_info"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."StructLatticeInfo :: new (struct_name)"]
expression_str = "StructLatticeInfo :: new (struct_name)"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."fs :: read_to_string (& args . results_file . unwrap ()) ?"]
expression_str = "fs :: read_to_string (& args . results_file . unwrap ()) ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."collect_all_test_cases (& crate_root) ?"]
expression_str = "collect_all_test_cases (& crate_root) ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'writer . write_all (format ! ("        -> Running cargo rustc -Zunpretty=expanded --lib for: {}\n" , file_path . display ()) . as_bytes ())']
expression_str = 'writer . write_all (format ! ("        -> Running cargo rustc -Zunpretty=expanded --lib for: {}\n" , file_path . display ()) . as_bytes ())'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."fs :: read_to_string (file_path)"]
expression_str = "fs :: read_to_string (file_path)"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.all_user_defined_types]
expression_str = "all_user_defined_types"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'temp_src_dir . join ("lib.rs")']
expression_str = 'temp_src_dir . join ("lib.rs")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."tokio :: fs :: create_dir_all (& constants_output_dir)"]
expression_str = "tokio :: fs :: create_dir_all (& constants_output_dir)"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."syn :: parse_file (& file_content)"]
expression_str = "syn :: parse_file (& file_content)"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'project_root . join ("generated/numerical_constants")']
expression_str = 'project_root . join ("generated/numerical_constants")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."fs :: metadata (& script_path) ?"]
expression_str = "fs :: metadata (& script_path) ?"
depth = 3
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."syn :: visit :: visit_item_struct (self , i)"]
expression_str = "syn :: visit :: visit_item_struct (self , i)"
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'if use_statement . contains ("rust") || use_statement . contains ("std") || use_statement . contains ("core") { current_use_statement . rust_details = Some (pipeline_traits :: RustDetails :: Info (pipeline_traits :: RustDetailsInfo { version : "inferred_from_use" . to_string () , crate_name : "inferred_from_use" . to_string () , item_path : "inferred_from_use" . to_string () , })) ; }']
expression_str = 'if use_statement . contains ("rust") || use_statement . contains ("std") || use_statement . contains ("core") { current_use_statement . rust_details = Some (pipeline_traits :: RustDetails :: Info (pipeline_traits :: RustDetailsInfo { version : "inferred_from_use" . to_string () , crate_name : "inferred_from_use" . to_string () , item_path : "inferred_from_use" . to_string () , })) ; }'
depth = 5
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'" The maximum expression depth to consider for type usage analysis. Required if `analyze_type_usage` is true."']
expression_str = '" The maximum expression depth to consider for type usage analysis. Required if `analyze_type_usage` is true."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.constants_output_dir]
expression_str = "constants_output_dir"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'r"generated/numerical_constants"']
expression_str = 'r"generated/numerical_constants"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.parsed_files]
expression_str = "parsed_files"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.error_message]
expression_str = "error_message"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'structure . ident . to_string () == "Level0DeclsVisitor"']
expression_str = 'structure . ident . to_string () == "Level0DeclsVisitor"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Binary"

[expressions."fs :: write (output_path , & report_content)"]
expression_str = "fs :: write (output_path , & report_content)"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."prelude_generator :: public_tests :: test_generate_prelude_dry_run"]
expression_str = "prelude_generator :: public_tests :: test_generate_prelude_dry_run"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'{ c . bins . paths . get ("hf_validator") . map (| p | p . to_path_buf ()) }']
expression_str = '{ c . bins . paths . get ("hf_validator") . map (| p | p . to_path_buf ()) }'
depth = 4
used_types = []
other_types_count = 0
node_type = "Block"

[expressions."RustcInfo { version , host }"]
expression_str = "RustcInfo { version , host }"
depth = 3
used_types = []
other_types_count = 0
node_type = "Struct"

[expressions."stats . rust_version_counts"]
expression_str = "stats . rust_version_counts"
depth = 4
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.script_content]
expression_str = "script_content"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'measurement :: record_function_exit ("ExtractUsesFunctor::map")']
expression_str = 'measurement :: record_function_exit ("ExtractUsesFunctor::map")'
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'{ let mut sorted_co_occurrences : Vec < (& BTreeSet < String > , & usize) > = lattice_info . method_co_occurrences . iter () . collect () ; sorted_co_occurrences . sort_by_key (| & (_ , count) | count) ; for (method_names , count) in sorted_co_occurrences { report_content . push_str (& format ! ("  - Co-occurring methods: {:?} (Count: {})\n" , method_names , count)) ; } }']
expression_str = '{ let mut sorted_co_occurrences : Vec < (& BTreeSet < String > , & usize) > = lattice_info . method_co_occurrences . iter () . collect () ; sorted_co_occurrences . sort_by_key (| & (_ , count) | count) ; for (method_names , count) in sorted_co_occurrences { report_content . push_str (& format ! ("  - Co-occurring methods: {:?} (Count: {})\n" , method_names , count)) ; } }'
depth = 5
used_types = [
    "BTreeSet",
    "Vec",
    "& BTreeSet < String >",
    "(& BTreeSet < String > , & usize)",
    "& usize",
]
other_types_count = 5
node_type = "Block"

[expressions."if ! struct_lattices . is_empty () { report_content . push_str (\"\\n\\nStruct Lattice Information\\n\") ; report_content . push_str (\"================================================================\n\") ; for (struct_name , lattice_info) in struct_lattices { report_content . push_str (& format ! (\"\\n### Struct: '{}' (Expressions Analyzed: {}) ###\\n\" , struct_name , lattice_info . total_expressions_analyzed)) ; if lattice_info . field_co_occurrences . is_empty () { report_content . push_str (\"  No field co-occurrence data collected.\\n\") ; } else { let mut sorted_co_occurrences : Vec < (& BTreeSet < String > , & usize) > = lattice_info . field_co_occurrences . iter () . collect () ; sorted_co_occurrences . sort_by_key (| & (_ , count) | count) ; for (field_types , count) in sorted_co_occurrences { report_content . push_str (& format ! (\"  - Co-occurring fields: {:?} (Count: {})\\n\" , field_types , count)) ; } } } }"]
expression_str = '''
if ! struct_lattices . is_empty () { report_content . push_str ("\n\nStruct Lattice Information\n") ; report_content . push_str ("================================================================
") ; for (struct_name , lattice_info) in struct_lattices { report_content . push_str (& format ! ("\n### Struct: '{}' (Expressions Analyzed: {}) ###\n" , struct_name , lattice_info . total_expressions_analyzed)) ; if lattice_info . field_co_occurrences . is_empty () { report_content . push_str ("  No field co-occurrence data collected.\n") ; } else { let mut sorted_co_occurrences : Vec < (& BTreeSet < String > , & usize) > = lattice_info . field_co_occurrences . iter () . collect () ; sorted_co_occurrences . sort_by_key (| & (_ , count) | count) ; for (field_types , count) in sorted_co_occurrences { report_content . push_str (& format ! ("  - Co-occurring fields: {:?} (Count: {})\n" , field_types , count)) ; } } } }'''
depth = 2
used_types = [
    "& BTreeSet < String >",
    "BTreeSet",
    "(& BTreeSet < String > , & usize)",
    "Vec",
    "& usize",
]
other_types_count = 5
node_type = "If"

[expressions."matches ! (r . status , FileProcessingStatus :: Skipped { .. })"]
expression_str = "matches ! (r . status , FileProcessingStatus :: Skipped { .. })"
depth = 5
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions.'"assert!"']
expression_str = '"assert!"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'processing_time_stats . insert ("import" . to_string () , (1 , 1 , 18 , 18))']
expression_str = 'processing_time_stats . insert ("import" . to_string () , (1 , 1 , 18 , 18))'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."self . add_ident_to_bag (& i . ident)"]
expression_str = "self . add_ident_to_bag (& i . ident)"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'writer . write_all (format ! ("        -> rustc status for {}: {}\n" , file_path . display () , output . status) . as_bytes ())']
expression_str = 'writer . write_all (format ! ("        -> rustc status for {}: {}\n" , file_path . display () , output . status) . as_bytes ())'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."fs :: set_permissions (& script_path , perms)"]
expression_str = "fs :: set_permissions (& script_path , perms)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'writer . write_all (format ! ("---\n--- Validating Generated Code ---\n") . as_bytes ()) . await ?']
expression_str = 'writer . write_all (format ! ("---\n--- Validating Generated Code ---\n") . as_bytes ()) . await ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'stdout . lines () . find (| line | line . starts_with ("host: "))']
expression_str = 'stdout . lines () . find (| line | line . starts_with ("host: "))'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."Ok (RustcInfo { version , host })"]
expression_str = "Ok (RustcInfo { version , host })"
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'""']
expression_str = '""'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'"fn main() { println!(\"Hello, world!\"); }"']
expression_str = '"fn main() { println!(\"Hello, world!\"); }"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."Some (content . to_string ())"]
expression_str = "Some (content . to_string ())"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'"Macro" . to_string ()']
expression_str = '"Macro" . to_string ()'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."Ok ((args , config))"]
expression_str = "Ok ((args , config))"
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."prelude_generator :: public_tests :: test_process_crates_integration () ?"]
expression_str = "prelude_generator :: public_tests :: test_process_crates_integration () ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."prelude_generator :: public_tests :: test_args_default_values ()"]
expression_str = "prelude_generator :: public_tests :: test_args_default_values ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'format ! ("--- Stage 1: Parsing ---\n") . as_bytes ()']
expression_str = 'format ! ("--- Stage 1: Parsing ---\n") . as_bytes ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.config]
expression_str = "config"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'fs :: write (crate_path . join ("src/lib.rs") , lib_content) . unwrap ()']
expression_str = 'fs :: write (crate_path . join ("src/lib.rs") , lib_content) . unwrap ()'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'uses . insert ("use std::path::PathBuf;\n")']
expression_str = 'uses . insert ("use std::path::PathBuf;\n")'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'writer . write_all (format ! ("        -> {}\n" , error_message) . as_bytes ()) . await . context ("Failed to write rustc error to writer") ?']
expression_str = 'writer . write_all (format ! ("        -> {}\n" , error_message) . as_bytes ()) . await . context ("Failed to write rustc error to writer") ?'
depth = 3
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.input]
expression_str = "input"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."tests . into_iter ()"]
expression_str = "tests . into_iter ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.info]
expression_str = "info"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.tests_by_crate]
expression_str = "tests_by_crate"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'"## Summary\n"']
expression_str = '"## Summary\n"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."& a . 1 . count"]
expression_str = "& a . 1 . count"
depth = 5
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'utils :: validate_rust_code (& output_path) . await . context (format ! ("Constant {:?} validation failed for {:?}" , const_name , output_path)) ?']
expression_str = 'utils :: validate_rust_code (& output_path) . await . context (format ! ("Constant {:?} validation failed for {:?}" , const_name , output_path)) ?'
depth = 5
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."PathBuf :: from (& args . path)"]
expression_str = "PathBuf :: from (& args . path)"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'match use_tree { UseTree :: Path (path) => { base_path . push (path . ident . to_string ()) ; flatten_use_tree (base_path , & path . tree , flat_uses) ; base_path . pop () ; } UseTree :: Name (_name) => { let full_path = base_path . join ("::") ; flat_uses . push (UseStatement { statement : format ! ("use {};" , full_path) , error : None , git_details : None , nix_details : None , rust_details : None , cargo_details : None , syn_details : None , llvm_details : None , linux_details : None , }) ; } UseTree :: Rename (rename) => { let mut full_path = base_path . join ("::") ; if ! full_path . is_empty () { full_path . push_str ("::") ; } flat_uses . push (UseStatement { statement : format ! ("use {} as {};" , full_path , rename . rename . to_string ()) , error : None , git_details : None , nix_details : None , rust_details : None , cargo_details : None , syn_details : None , llvm_details : None , linux_details : None , }) ; } UseTree :: Glob (_glob) => { let mut full_path = base_path . join ("::") ; if ! full_path . is_empty () { full_path . push_str ("::") ; } full_path . push_str ("* ") ; flat_uses . push (UseStatement { statement : format ! ("use {};" , full_path) , error : None , git_details : None , nix_details : None , rust_details : None , cargo_details : None , syn_details : None , llvm_details : None , linux_details : None , }) ; } UseTree :: Group (group) => { for tree in group . items . iter () { flatten_use_tree (base_path , tree , flat_uses) ; } } }']
expression_str = 'match use_tree { UseTree :: Path (path) => { base_path . push (path . ident . to_string ()) ; flatten_use_tree (base_path , & path . tree , flat_uses) ; base_path . pop () ; } UseTree :: Name (_name) => { let full_path = base_path . join ("::") ; flat_uses . push (UseStatement { statement : format ! ("use {};" , full_path) , error : None , git_details : None , nix_details : None , rust_details : None , cargo_details : None , syn_details : None , llvm_details : None , linux_details : None , }) ; } UseTree :: Rename (rename) => { let mut full_path = base_path . join ("::") ; if ! full_path . is_empty () { full_path . push_str ("::") ; } flat_uses . push (UseStatement { statement : format ! ("use {} as {};" , full_path , rename . rename . to_string ()) , error : None , git_details : None , nix_details : None , rust_details : None , cargo_details : None , syn_details : None , llvm_details : None , linux_details : None , }) ; } UseTree :: Glob (_glob) => { let mut full_path = base_path . join ("::") ; if ! full_path . is_empty () { full_path . push_str ("::") ; } full_path . push_str ("* ") ; flat_uses . push (UseStatement { statement : format ! ("use {};" , full_path) , error : None , git_details : None , nix_details : None , rust_details : None , cargo_details : None , syn_details : None , llvm_details : None , linux_details : None , }) ; } UseTree :: Group (group) => { for tree in group . items . iter () { flatten_use_tree (base_path , tree , flat_uses) ; } } }'
depth = 2
used_types = []
other_types_count = 0
node_type = "Match"

[expressions."has_use_statements = true"]
expression_str = "has_use_statements = true"
depth = 4
used_types = []
other_types_count = 0
node_type = "Assign"

[expressions.'match ident_str . as_str () { "HashMap" => { uses . insert ("use std::collections::HashMap;\n") ; } , "PathBuf" => { uses . insert ("use std::path::PathBuf;\n") ; } , "String" => { uses . insert ("use std::string::String;\n") ; } , "syn" => { uses . insert ("use syn::{ItemConst, ItemStruct};\n") ; uses . insert ("use syn::visit::Visit;\n") ; } , "clap" => { uses . insert ("use clap::{Parser, Args, Command};\n") ; } , "serde" => { uses . insert ("use serde::{Serialize, Deserialize};\n") ; } , _ => { } , }']
expression_str = 'match ident_str . as_str () { "HashMap" => { uses . insert ("use std::collections::HashMap;\n") ; } , "PathBuf" => { uses . insert ("use std::path::PathBuf;\n") ; } , "String" => { uses . insert ("use std::string::String;\n") ; } , "syn" => { uses . insert ("use syn::{ItemConst, ItemStruct};\n") ; uses . insert ("use syn::visit::Visit;\n") ; } , "clap" => { uses . insert ("use clap::{Parser, Args, Command};\n") ; } , "serde" => { uses . insert ("use serde::{Serialize, Deserialize};\n") ; } , _ => { } , }'
depth = 4
used_types = []
other_types_count = 0
node_type = "Match"

[expressions."{ if let Some (names) = filter_names { names . iter () . any (| name | e . file_name () . to_string_lossy () . contains (name)) } else { true } }"]
expression_str = "{ if let Some (names) = filter_names { names . iter () . any (| name | e . file_name () . to_string_lossy () . contains (name)) } else { true } }"
depth = 5
used_types = []
other_types_count = 0
node_type = "Block"

[expressions."self . hf_validator_path . clone ()"]
expression_str = "self . hf_validator_path . clone ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."| r | matches ! (r . status , FileProcessingStatus :: Success)"]
expression_str = "| r | matches ! (r . status , FileProcessingStatus :: Success)"
depth = 4
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions."crate :: constant_storage :: string_constants :: write_string_constants_to_hierarchical_structure (& string_constants , & string_output_dir ,) . await"]
expression_str = "crate :: constant_storage :: string_constants :: write_string_constants_to_hierarchical_structure (& string_constants , & string_output_dir ,) . await"
depth = 3
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.'e . file_type () . is_file () && e . path () . extension () . map_or (false , | ext | ext == r"rs")']
expression_str = 'e . file_type () . is_file () && e . path () . extension () . map_or (false , | ext | ext == r"rs")'
depth = 5
used_types = []
other_types_count = 0
node_type = "Binary"

[expressions.'fs :: create_dir_all (& project_root) . context (format ! ("Failed to create project root: {:?}" , project_root)) ?']
expression_str = 'fs :: create_dir_all (& project_root) . context (format ! ("Failed to create project root: {:?}" , project_root)) ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."prelude_generator :: public_tests :: test_generate_report_with_results () ?"]
expression_str = "prelude_generator :: public_tests :: test_generate_report_with_results () ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'uses . insert ("use serde::{Serialize, Deserialize};\n")']
expression_str = 'uses . insert ("use serde::{Serialize, Deserialize};\n")'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.original_dir]
expression_str = "original_dir"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'format ! ("Failed to write Test_Verification_Report.md to {}" , report_path . display ())']
expression_str = 'format ! ("Failed to write Test_Verification_Report.md to {}" , report_path . display ())'
depth = 5
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions."current_dst . join (relative_path)"]
expression_str = "current_dst . join (relative_path)"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'tokio :: fs :: write (& source_file_path , source_code . as_bytes ()) . await . context ("Failed to write source code to persistent file") ?']
expression_str = 'tokio :: fs :: write (& source_file_path , source_code . as_bytes ()) . await . context ("Failed to write source code to persistent file") ?'
depth = 4
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'args . split_expanded_rustc_version . clone () . unwrap_or_else (| | "1.89.0" . to_string ())']
expression_str = 'args . split_expanded_rustc_version . clone () . unwrap_or_else (| | "1.89.0" . to_string ())'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'writer . write_all (format ! ("---\n--- Stage 4: AST Reconstruction from Hugging Face Dataset ---\n") . as_bytes ())']
expression_str = 'writer . write_all (format ! ("---\n--- Stage 4: AST Reconstruction from Hugging Face Dataset ---\n") . as_bytes ())'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'{ for (type_name , values) in & constants_by_type_and_size { println ! ("Type: {}" , type_name) ; let mut sorted_values : Vec < (& String , & usize) > = values . iter () . collect () ; sorted_values . sort_by (| a , b | a . 0 . cmp (b . 0)) ; for (value , count) in sorted_values { println ! ("  Value: {}, Count: {}" , value , count) ; } } }']
expression_str = '{ for (type_name , values) in & constants_by_type_and_size { println ! ("Type: {}" , type_name) ; let mut sorted_values : Vec < (& String , & usize) > = values . iter () . collect () ; sorted_values . sort_by (| a , b | a . 0 . cmp (b . 0)) ; for (value , count) in sorted_values { println ! ("  Value: {}, Count: {}" , value , count) ; } } }'
depth = 3
used_types = [
    "& usize",
    "Vec",
    "(& String , & usize)",
    "& String",
]
other_types_count = 4
node_type = "Block"

[expressions."TypeCollector { types : & mut types }"]
expression_str = "TypeCollector { types : & mut types }"
depth = 2
used_types = []
other_types_count = 0
node_type = "Struct"

[expressions."if ! enum_lattices . is_empty () { report_content . push_str (\"\\n\\nEnum Lattice Information\\n\") ; report_content . push_str (\"================================================================\n\") ; for (enum_name , lattice_info) in enum_lattices { report_content . push_str (& format ! (\"\\n### Enum: '{}' (Expressions Analyzed: {}) ###\\n\" , enum_name , lattice_info . total_expressions_analyzed)) ; if lattice_info . variant_type_co_occurrences . is_empty () { report_content . push_str (\"  No variant type co-occurrence data collected.\\n\") ; } else { let mut sorted_co_occurrences : Vec < (& BTreeSet < String > , & usize) > = lattice_info . variant_type_co_occurrences . iter () . collect () ; sorted_co_occurrences . sort_by_key (| & (_ , count) | count) ; for (variant_types , count) in sorted_co_occurrences { report_content . push_str (& format ! (\"  - Co-occurring variant types: {:?} (Count: {})\\n\" , variant_types , count)) ; } } } }"]
expression_str = '''
if ! enum_lattices . is_empty () { report_content . push_str ("\n\nEnum Lattice Information\n") ; report_content . push_str ("================================================================
") ; for (enum_name , lattice_info) in enum_lattices { report_content . push_str (& format ! ("\n### Enum: '{}' (Expressions Analyzed: {}) ###\n" , enum_name , lattice_info . total_expressions_analyzed)) ; if lattice_info . variant_type_co_occurrences . is_empty () { report_content . push_str ("  No variant type co-occurrence data collected.\n") ; } else { let mut sorted_co_occurrences : Vec < (& BTreeSet < String > , & usize) > = lattice_info . variant_type_co_occurrences . iter () . collect () ; sorted_co_occurrences . sort_by_key (| & (_ , count) | count) ; for (variant_types , count) in sorted_co_occurrences { report_content . push_str (& format ! ("  - Co-occurring variant types: {:?} (Count: {})\n" , variant_types , count)) ; } } } }'''
depth = 2
used_types = [
    "BTreeSet",
    "& usize",
    "& BTreeSet < String >",
    "Vec",
    "(& BTreeSet < String > , & usize)",
]
other_types_count = 5
node_type = "If"

[expressions.'column_stats . insert ("variable" . to_string () , (1 , 1 , 41 , 41))']
expression_str = 'column_stats . insert ("variable" . to_string () , (1 , 1 , 41 , 41))'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'if cache_dir . exists () { let count = fs :: read_dir (& cache_dir) ? . count () ; println ! ("Prelude cache at {} contains {} items." , cache_dir . display () , count) ; } else { println ! ("Prelude cache directory not found at {}." , cache_dir . display ()) ; }']
expression_str = 'if cache_dir . exists () { let count = fs :: read_dir (& cache_dir) ? . count () ; println ! ("Prelude cache at {} contains {} items." , cache_dir . display () , count) ; } else { println ! ("Prelude cache directory not found at {}." , cache_dir . display ()) ; }'
depth = 3
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'parse_functor . map (writer , raw_file) . await . context ("Parsing failed")']
expression_str = 'parse_functor . map (writer , raw_file) . await . context ("Parsing failed")'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."match i { Type :: Path (type_path) => { if let Some (segment) = type_path . path . segments . last () { self . types . insert (segment . ident . to_string ()) ; } } , _ => { self . types . insert (type_str) ; } }"]
expression_str = "match i { Type :: Path (type_path) => { if let Some (segment) = type_path . path . segments . last () { self . types . insert (segment . ident . to_string ()) ; } } , _ => { self . types . insert (type_str) ; } }"
depth = 3
used_types = []
other_types_count = 0
node_type = "Match"

[expressions.lib_content]
expression_str = "lib_content"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'"public_symbols.json"']
expression_str = '"public_symbols.json"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'"Macro"']
expression_str = '"Macro"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."constants . iter ()"]
expression_str = "constants . iter ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.dependency_type]
expression_str = "dependency_type"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."for (enum_name , lattice_info) in enum_lattices { report_content . push_str (& format ! (\"\\n### Enum: '{}' (Expressions Analyzed: {}) ###\\n\" , enum_name , lattice_info . total_expressions_analyzed)) ; if lattice_info . variant_type_co_occurrences . is_empty () { report_content . push_str (\"  No variant type co-occurrence data collected.\\n\") ; } else { let mut sorted_co_occurrences : Vec < (& BTreeSet < String > , & usize) > = lattice_info . variant_type_co_occurrences . iter () . collect () ; sorted_co_occurrences . sort_by_key (| & (_ , count) | count) ; for (variant_types , count) in sorted_co_occurrences { report_content . push_str (& format ! (\"  - Co-occurring variant types: {:?} (Count: {})\\n\" , variant_types , count)) ; } } }"]
expression_str = '''for (enum_name , lattice_info) in enum_lattices { report_content . push_str (& format ! ("\n### Enum: '{}' (Expressions Analyzed: {}) ###\n" , enum_name , lattice_info . total_expressions_analyzed)) ; if lattice_info . variant_type_co_occurrences . is_empty () { report_content . push_str ("  No variant type co-occurrence data collected.\n") ; } else { let mut sorted_co_occurrences : Vec < (& BTreeSet < String > , & usize) > = lattice_info . variant_type_co_occurrences . iter () . collect () ; sorted_co_occurrences . sort_by_key (| & (_ , count) | count) ; for (variant_types , count) in sorted_co_occurrences { report_content . push_str (& format ! ("  - Co-occurring variant types: {:?} (Count: {})\n" , variant_types , count)) ; } } }'''
depth = 3
used_types = [
    "& usize",
    "Vec",
    "& BTreeSet < String >",
    "(& BTreeSet < String > , & usize)",
    "BTreeSet",
]
other_types_count = 5
node_type = "ForLoop"

[expressions.'"Field" . to_string ()']
expression_str = '"Field" . to_string ()'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."| segment | segment . ident . to_string ()"]
expression_str = "| segment | segment . ident . to_string ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions.'for (node_type , (min , max , sum , count)) in & stats . line_stats { code . push_str (& format ! ("    line_stats.insert(\"{}\".to_string(), ({}, {}, {}, {}));\n" , node_type , min , max , sum , count) ,) ; }']
expression_str = 'for (node_type , (min , max , sum , count)) in & stats . line_stats { code . push_str (& format ! ("    line_stats.insert(\"{}\".to_string(), ({}, {}, {}, {}));\n" , node_type , min , max , sum , count) ,) ; }'
depth = 2
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions.'"use std::collections::HashMap;\nfn main() {}\n"']
expression_str = '"use std::collections::HashMap;\nfn main() {}\n"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."generate_report (& all_expression_info , max_expression_depth , output_path , & all_struct_lattices , & all_enum_lattices , & all_impl_lattices) ?"]
expression_str = "generate_report (& all_expression_info , max_expression_depth , output_path , & all_struct_lattices , & all_enum_lattices , & all_impl_lattices) ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."generate_prelude (& src_dir , prelude_content , true , false)"]
expression_str = "generate_prelude (& src_dir , prelude_content , true , false)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'return Ok ((syn :: parse_file (& expanded_code) . with_context (| | format ! ("Failed to parse cached expanded code for {}" , file_path . display ())) ? , None))']
expression_str = 'return Ok ((syn :: parse_file (& expanded_code) . with_context (| | format ! ("Failed to parse cached expanded code for {}" , file_path . display ())) ? , None))'
depth = 3
used_types = []
other_types_count = 0
node_type = "Return"

[expressions.'code . push_str ("use std::collections::HashMap;\n")']
expression_str = 'code . push_str ("use std::collections::HashMap;\n")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"i64"']
expression_str = '"i64"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."prelude_generator :: public_tests :: test_generate_aggregated_test_file ()"]
expression_str = "prelude_generator :: public_tests :: test_generate_aggregated_test_file ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'" Command-line arguments for the prelude generator."']
expression_str = '" Command-line arguments for the prelude generator."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.modify_file]
expression_str = "modify_file"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."Box :: pin"]
expression_str = "Box :: pin"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'"Block" . to_string ()']
expression_str = '"Block" . to_string ()'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."prelude_generator :: public_tests :: test_modify_file_no_use_statements"]
expression_str = "prelude_generator :: public_tests :: test_modify_file_no_use_statements"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.relevant_expanded_code]
expression_str = "relevant_expanded_code"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'"clap"']
expression_str = '"clap"'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.prelude_content]
expression_str = "prelude_content"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."Self :: new ()"]
expression_str = "Self :: new ()"
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."METRICS . lock () . unwrap () . clone ()"]
expression_str = "METRICS . lock () . unwrap () . clone ()"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'type_name == "syn" || type_name == "String" || type_name == "HashMap" || type_name == "PathBuf"']
expression_str = 'type_name == "syn" || type_name == "String" || type_name == "HashMap" || type_name == "PathBuf"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Binary"

[expressions.'writer . write_all (format ! ("        -> Parsing expanded code for: {}\n" , file_path . display ()) . as_bytes ()) . await']
expression_str = 'writer . write_all (format ! ("        -> Parsing expanded code for: {}\n" , file_path . display ()) . as_bytes ()) . await'
depth = 3
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."| e | e . ok ()"]
expression_str = "| e | e . ok ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions.'measurement :: record_function_entry ("HuggingFaceValidatorFunctor::map")']
expression_str = 'measurement :: record_function_entry ("HuggingFaceValidatorFunctor::map")'
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."type_path . path . segments . iter ()"]
expression_str = "type_path . path . segments . iter ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."run_category_pipeline (& mut stdout , & content , & file_path_str , & args , & config ,) . await"]
expression_str = "run_category_pipeline (& mut stdout , & content , & file_path_str , & args , & config ,) . await"
depth = 2
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.function_name]
expression_str = "function_name"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."new_ast . items"]
expression_str = "new_ast . items"
depth = 4
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'Command :: new ("rustc") . arg ("--emit=metadata") . arg ("--crate-type=lib") . arg (file_path) . output ()']
expression_str = 'Command :: new ("rustc") . arg ("--emit=metadata") . arg ("--crate-type=lib") . arg (file_path) . output ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'if args . analyze_type_usage { type_usage_analyzer :: analyze_type_usage (& args) . await ? ; } else { println ! ("No specific command flag set. Use --help for options.") ; }']
expression_str = 'if args . analyze_type_usage { type_usage_analyzer :: analyze_type_usage (& args) . await ? ; } else { println ! ("No specific command flag set. Use --help for options.") ; }'
depth = 3
used_types = []
other_types_count = 0
node_type = "If"

[expressions."if let Some (layer0_structs) = all_structs_by_layer . get (& 0) { for structure in layer0_structs { let struct_name = structure . ident . to_string () ; let layer = 0 ; let structs_output_dir = generated_decls_output_dir . join (format ! (\"layer_{}\" , layer)) . join (\"struct\") ; println ! (\"Attempting to create directory: {}\" , structs_output_dir . display ()) ; tokio :: fs :: create_dir_all (& structs_output_dir) . await . context (format ! (\"Failed to create output directory {:?}, for struct {}\" , structs_output_dir , struct_name)) ? ; let file_name = format ! (\"{}.rs\" , struct_name) ; let output_path = structs_output_dir . join (& file_name) ; println ! (\"Attempting to write file: {}\" , output_path . display ()) ; let content = quote :: quote ! { # structure } . to_string () ; let code = match struct_name . as_str () { \"DeclsVisitor\" => { format ! (\"use syn::{{visit::Visit, ItemConst, ItemFn, ItemStruct, ItemEnum, ItemStatic, Item}};\n{}\" , content) } , \"TypeCollector\" => { format ! (\"use std::collections::HashMap;\nuse crate::type_extractor::TypeInfo;\n{}\" , content) } , _ => content , } ; let result = async { tokio :: fs :: write (& output_path , code . as_bytes ()) . await . context (format ! (\"Failed to write struct {:?} to {:?}\" , struct_name , output_path)) ? ; println ! (\"  -> Wrote struct {:?} to {:?}\" , struct_name , output_path) ; utils :: format_rust_code (& output_path) . await . context (format ! (\"Struct {:?} formatting failed for {:?}\" , struct_name , output_path)) ? ; println ! (\"  -> Struct {:?} formatted successfully.\\n\" , struct_name) ; utils :: validate_rust_code (& output_path) . await . context (format ! (\"Struct {:?} validation failed for {:?}\" , struct_name , output_path)) ? ; println ! (r\"  -> Struct {:?} validated successfully.\\n\" , struct_name) ; Ok (()) } . await ; if let Err (e) = result { eprintln ! (r\"Error processing struct {}: {:?}\\n\" , struct_name , e) ; errors . push (e) ; } } } else { println ! (\"No Level 0 structs found to process.\") ; }"]
expression_str = '''
if let Some (layer0_structs) = all_structs_by_layer . get (& 0) { for structure in layer0_structs { let struct_name = structure . ident . to_string () ; let layer = 0 ; let structs_output_dir = generated_decls_output_dir . join (format ! ("layer_{}" , layer)) . join ("struct") ; println ! ("Attempting to create directory: {}" , structs_output_dir . display ()) ; tokio :: fs :: create_dir_all (& structs_output_dir) . await . context (format ! ("Failed to create output directory {:?}, for struct {}" , structs_output_dir , struct_name)) ? ; let file_name = format ! ("{}.rs" , struct_name) ; let output_path = structs_output_dir . join (& file_name) ; println ! ("Attempting to write file: {}" , output_path . display ()) ; let content = quote :: quote ! { # structure } . to_string () ; let code = match struct_name . as_str () { "DeclsVisitor" => { format ! ("use syn::{{visit::Visit, ItemConst, ItemFn, ItemStruct, ItemEnum, ItemStatic, Item}};
{}" , content) } , "TypeCollector" => { format ! ("use std::collections::HashMap;
use crate::type_extractor::TypeInfo;
{}" , content) } , _ => content , } ; let result = async { tokio :: fs :: write (& output_path , code . as_bytes ()) . await . context (format ! ("Failed to write struct {:?} to {:?}" , struct_name , output_path)) ? ; println ! ("  -> Wrote struct {:?} to {:?}" , struct_name , output_path) ; utils :: format_rust_code (& output_path) . await . context (format ! ("Struct {:?} formatting failed for {:?}" , struct_name , output_path)) ? ; println ! ("  -> Struct {:?} formatted successfully.\n" , struct_name) ; utils :: validate_rust_code (& output_path) . await . context (format ! ("Struct {:?} validation failed for {:?}" , struct_name , output_path)) ? ; println ! (r"  -> Struct {:?} validated successfully.\n" , struct_name) ; Ok (()) } . await ; if let Err (e) = result { eprintln ! (r"Error processing struct {}: {:?}\n" , struct_name , e) ; errors . push (e) ; } } } else { println ! ("No Level 0 structs found to process.") ; }'''
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions."toml :: from_str (& content) ?"]
expression_str = "toml :: from_str (& content) ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."fs :: read_to_string"]
expression_str = "fs :: read_to_string"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'crate1_path . join ("src/lib.rs")']
expression_str = 'crate1_path . join ("src/lib.rs")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."visit :: visit_expr_match"]
expression_str = "visit :: visit_expr_match"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'"        column_stats,\n"']
expression_str = '"        column_stats,\n"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'& format ! ("    analyzer_version_counts.insert(\"{}\".to_string(), {});\n" , version , count)']
expression_str = '& format ! ("    analyzer_version_counts.insert(\"{}\".to_string(), {});\n" , version , count)'
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."sub_visitor . visit_item_enum (i)"]
expression_str = "sub_visitor . visit_item_enum (i)"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.version]
expression_str = "version"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."remaining_decls . into_iter ()"]
expression_str = "remaining_decls . into_iter ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'PathBuf :: from ("gems.toml")']
expression_str = 'PathBuf :: from ("gems.toml")'
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'"Unary"']
expression_str = '"Unary"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.sorted_other_types_keys]
expression_str = "sorted_other_types_keys"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."metrics . get_mut (function_name)"]
expression_str = "metrics . get_mut (function_name)"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."{ base_path . push (path . ident . to_string ()) ; flatten_use_tree (base_path , & path . tree , flat_uses) ; base_path . pop () ; }"]
expression_str = "{ base_path . push (path . ident . to_string ()) ; flatten_use_tree (base_path , & path . tree , flat_uses) ; base_path . pop () ; }"
depth = 3
used_types = []
other_types_count = 0
node_type = "Block"

[expressions.'fs :: write (& output_path , toml_string) . context (format ! ("Failed to write symbol map to file: {:?}" , output_path)) ?']
expression_str = 'fs :: write (& output_path , toml_string) . context (format ! ("Failed to write symbol map to file: {:?}" , output_path)) ?'
depth = 3
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."Ok (extract_test_functions_from_items (ast . items , file_path))"]
expression_str = "Ok (extract_test_functions_from_items (ast . items , file_path))"
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'if let Some (field_ident) = i . member . clone () . into_token_stream () . to_string () . strip_prefix (".") . map (| s | s . to_string ()) { self . current_field_accesses . insert (field_ident) ; }']
expression_str = 'if let Some (field_ident) = i . member . clone () . into_token_stream () . to_string () . strip_prefix (".") . map (| s | s . to_string ()) { self . current_field_accesses . insert (field_ident) ; }'
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions."classify_uses_functor . map (writer , use_statements)"]
expression_str = "classify_uses_functor . map (writer , use_statements)"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."* self . method_co_occurrences . entry (method_names) . or_insert (0)"]
expression_str = "* self . method_co_occurrences . entry (method_names) . or_insert (0)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Unary"

[expressions.'"isize"']
expression_str = '"isize"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'"std::path"']
expression_str = '"std::path"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.b]
expression_str = "b"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'host_line . and_then (| line | line . split_whitespace () . nth (1)) . unwrap_or ("unknown")']
expression_str = 'host_line . and_then (| line | line . split_whitespace () . nth (1)) . unwrap_or ("unknown")'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'writer . write_all (format ! ("  -> Hugging Face Validation Result: Dataset generated at {:#?}\n" , output_path) . as_bytes ()) . await']
expression_str = 'writer . write_all (format ! ("  -> Hugging Face Validation Result: Dataset generated at {:#?}\n" , output_path) . as_bytes ()) . await'
depth = 5
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.gem_config]
expression_str = "gem_config"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."String :: from_utf8_lossy"]
expression_str = "String :: from_utf8_lossy"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."bag_of_words_visitor . bag_of_words . iter ()"]
expression_str = "bag_of_words_visitor . bag_of_words . iter ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."! has_prelude_mod"]
expression_str = "! has_prelude_mod"
depth = 3
used_types = []
other_types_count = 0
node_type = "Unary"

[expressions.'add_primitive_type (& mut symbols , "u128")']
expression_str = 'add_primitive_type (& mut symbols , "u128")'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."syn :: parse_quote ! { use crate :: prelude ::*; }"]
expression_str = "syn :: parse_quote ! { use crate :: prelude ::*; }"
depth = 3
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions.'" The path to the Rust project or file to analyze AST for. Only used if `analyze_ast` is true."']
expression_str = '" The path to the Rust project or file to analyze AST for. Only used if `analyze_ast` is true."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'writer . write_all (format ! ("        -> rustc stdout for {}: {}\n" , file_path . display () , String :: from_utf8_lossy (& output . stdout)) . as_bytes ()) . await']
expression_str = 'writer . write_all (format ! ("        -> rustc stdout for {}: {}\n" , file_path . display () , String :: from_utf8_lossy (& output . stdout)) . as_bytes ()) . await'
depth = 3
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."error_collection . errors"]
expression_str = "error_collection . errors"
depth = 5
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.process_crates]
expression_str = "process_crates"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."contains_complex_attributes (i)"]
expression_str = "contains_complex_attributes (i)"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'if use_statement . contains ("linux") { current_use_statement . linux_details = Some (pipeline_traits :: LinuxDetails :: Info (pipeline_traits :: LinuxInfo { kernel_version : "inferred_from_use" . to_string () , architecture : "inferred_from_use" . to_string () , })) ; }']
expression_str = 'if use_statement . contains ("linux") { current_use_statement . linux_details = Some (pipeline_traits :: LinuxDetails :: Info (pipeline_traits :: LinuxInfo { kernel_version : "inferred_from_use" . to_string () , architecture : "inferred_from_use" . to_string () , })) ; }'
depth = 5
used_types = []
other_types_count = 0
node_type = "If"

[expressions."crate :: constant_storage :: string_constants :: write_string_constants_to_hierarchical_structure (& string_constants , & string_output_dir ,)"]
expression_str = "crate :: constant_storage :: string_constants :: write_string_constants_to_hierarchical_structure (& string_constants , & string_output_dir ,)"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."fs :: write (& output_path , toml_string)"]
expression_str = "fs :: write (& output_path , toml_string)"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."contains_complex_attributes_for_const (i)"]
expression_str = "contains_complex_attributes_for_const (i)"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."let Some (output_path) = _output_symbol_map"]
expression_str = "let Some (output_path) = _output_symbol_map"
depth = 3
used_types = []
other_types_count = 0
node_type = "Let"

[expressions."used_type . clone ()"]
expression_str = "used_type . clone ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."fs :: read_to_string (& file_path) ?"]
expression_str = "fs :: read_to_string (& file_path) ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'"other" . to_string ()']
expression_str = '"other" . to_string ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."{ Mapping :: default () }"]
expression_str = "{ Mapping :: default () }"
depth = 5
used_types = []
other_types_count = 0
node_type = "Block"

[expressions.'"* "']
expression_str = '"* "'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'for identifier in & gem_entry . identifiers { symbol_map . add_declaration (identifier . clone () , "builtin" . to_string () , gem_entry . crate_name . clone () , gem_entry . crate_name . clone () ,) ; }']
expression_str = 'for identifier in & gem_entry . identifiers { symbol_map . add_declaration (identifier . clone () , "builtin" . to_string () , gem_entry . crate_name . clone () , gem_entry . crate_name . clone () ,) ; }'
depth = 3
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions."visit :: visit_item_fn (self , i)"]
expression_str = "visit :: visit_item_fn (self , i)"
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'args . split_expanded_rustc_host . clone () . unwrap_or_else (| | "aarch64-unknown-linux-gnu" . to_string ())']
expression_str = 'args . split_expanded_rustc_host . clone () . unwrap_or_else (| | "aarch64-unknown-linux-gnu" . to_string ())'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"fn main() {}\n"']
expression_str = '"fn main() {}\n"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."& info . used_types"]
expression_str = "& info . used_types"
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'report_content . push_str (& format ! ("Type Usage Report (Max Depth: {})" , max_expression_depth))']
expression_str = 'report_content . push_str (& format ! ("Type Usage Report (Max Depth: {})" , max_expression_depth))'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."Ok (())"]
expression_str = "Ok (())"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."if let Some (segment) = type_path . path . segments . last () { self . types . insert (segment . ident . to_string ()) ; }"]
expression_str = "if let Some (segment) = type_path . path . segments . last () { self . types . insert (segment . ident . to_string ()) ; }"
depth = 5
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'type_name == "syn" || type_name == "String" || type_name == "HashMap" || type_name == "PathBuf" || type_name == "clap"']
expression_str = 'type_name == "syn" || type_name == "String" || type_name == "HashMap" || type_name == "PathBuf" || type_name == "clap"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Binary"

[expressions.'tokio :: fs :: remove_dir_all (& output_dir) . await . context ("Failed to remove existing output directory") ?']
expression_str = 'tokio :: fs :: remove_dir_all (& output_dir) . await . context ("Failed to remove existing output directory") ?'
depth = 3
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."args . split_expanded_rustc_host"]
expression_str = "args . split_expanded_rustc_host"
depth = 4
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'"Unsafe"']
expression_str = '"Unsafe"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.metrics]
expression_str = "metrics"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'match expr { Expr :: Array (_) => "Array" . to_string () , Expr :: Assign (_) => "Assign" . to_string () , Expr :: Async (_) => "Async" . to_string () , Expr :: Await (_) => "Await" . to_string () , Expr :: Binary (_) => "Binary" . to_string () , Expr :: Block (_) => "Block" . to_string () , Expr :: Break (_) => "Break" . to_string () , Expr :: Call (_) => "Call" . to_string () , Expr :: Cast (_) => "Cast" . to_string () , Expr :: Closure (_) => "Closure" . to_string () , Expr :: Continue (_) => "Continue" . to_string () , Expr :: Field (_) => "Field" . to_string () , Expr :: ForLoop (_) => "ForLoop" . to_string () , Expr :: Group (_) => "Group" . to_string () , Expr :: If (_) => "If" . to_string () , Expr :: Index (_) => "Index" . to_string () , Expr :: Infer (_) => "Infer" . to_string () , Expr :: Let (_) => "Let" . to_string () , Expr :: Lit (_) => "Lit" . to_string () , Expr :: Loop (_) => "Loop" . to_string () , Expr :: Macro (_) => "Macro" . to_string () , Expr :: Match (_) => "Match" . to_string () , Expr :: MethodCall (_) => "MethodCall" . to_string () , Expr :: Paren (_) => "Paren" . to_string () , Expr :: Path (_) => "Path" . to_string () , Expr :: Range (_) => "Range" . to_string () , Expr :: Reference (_) => "Reference" . to_string () , Expr :: Repeat (_) => "Repeat" . to_string () , Expr :: Return (_) => "Return" . to_string () , Expr :: Struct (_) => "Struct" . to_string () , Expr :: Tuple (_) => "Tuple" . to_string () , Expr :: Unary (_) => "Unary" . to_string () , Expr :: Unsafe (_) => "Unsafe" . to_string () , Expr :: Verbatim (_) => "Verbatim" . to_string () , Expr :: While (_) => "While" . to_string () , Expr :: Yield (_) => "Yield" . to_string () , _ => "Unknown" . to_string () , }']
expression_str = 'match expr { Expr :: Array (_) => "Array" . to_string () , Expr :: Assign (_) => "Assign" . to_string () , Expr :: Async (_) => "Async" . to_string () , Expr :: Await (_) => "Await" . to_string () , Expr :: Binary (_) => "Binary" . to_string () , Expr :: Block (_) => "Block" . to_string () , Expr :: Break (_) => "Break" . to_string () , Expr :: Call (_) => "Call" . to_string () , Expr :: Cast (_) => "Cast" . to_string () , Expr :: Closure (_) => "Closure" . to_string () , Expr :: Continue (_) => "Continue" . to_string () , Expr :: Field (_) => "Field" . to_string () , Expr :: ForLoop (_) => "ForLoop" . to_string () , Expr :: Group (_) => "Group" . to_string () , Expr :: If (_) => "If" . to_string () , Expr :: Index (_) => "Index" . to_string () , Expr :: Infer (_) => "Infer" . to_string () , Expr :: Let (_) => "Let" . to_string () , Expr :: Lit (_) => "Lit" . to_string () , Expr :: Loop (_) => "Loop" . to_string () , Expr :: Macro (_) => "Macro" . to_string () , Expr :: Match (_) => "Match" . to_string () , Expr :: MethodCall (_) => "MethodCall" . to_string () , Expr :: Paren (_) => "Paren" . to_string () , Expr :: Path (_) => "Path" . to_string () , Expr :: Range (_) => "Range" . to_string () , Expr :: Reference (_) => "Reference" . to_string () , Expr :: Repeat (_) => "Repeat" . to_string () , Expr :: Return (_) => "Return" . to_string () , Expr :: Struct (_) => "Struct" . to_string () , Expr :: Tuple (_) => "Tuple" . to_string () , Expr :: Unary (_) => "Unary" . to_string () , Expr :: Unsafe (_) => "Unsafe" . to_string () , Expr :: Verbatim (_) => "Verbatim" . to_string () , Expr :: While (_) => "While" . to_string () , Expr :: Yield (_) => "Yield" . to_string () , _ => "Unknown" . to_string () , }'
depth = 2
used_types = []
other_types_count = 0
node_type = "Match"

[expressions.extract_test_functions_from_items]
expression_str = "extract_test_functions_from_items"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."UseStatement { statement : use_statement . clone () , error : None , git_details : None , nix_details : None , rust_details : None , cargo_details : None , syn_details : None , llvm_details : None , linux_details : None , }"]
expression_str = "UseStatement { statement : use_statement . clone () , error : None , git_details : None , nix_details : None , rust_details : None , cargo_details : None , syn_details : None , llvm_details : None , linux_details : None , }"
depth = 5
used_types = []
other_types_count = 0
node_type = "Struct"

[expressions.'self . map . insert (crate_name . clone () , ResolvedDependency { id : crate_name . clone () , dependency_type : "crate" . to_string () , crate_name : crate_name . clone () , module_path : crate_name . clone () , usage_count : 0 , })']
expression_str = 'self . map . insert (crate_name . clone () , ResolvedDependency { id : crate_name . clone () , dependency_type : "crate" . to_string () , crate_name : crate_name . clone () , module_path : crate_name . clone () , usage_count : 0 , })'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"Reference"']
expression_str = '"Reference"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'fs :: read_to_string (& file_path) . context (format ! ("Failed to read file: {:?}" , file_path)) ?']
expression_str = 'fs :: read_to_string (& file_path) . context (format ! ("Failed to read file: {:?}" , file_path)) ?'
depth = 5
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."prelude_generator :: public_tests :: test_modify_crate_root_no_force_no_overwrite () ?"]
expression_str = "prelude_generator :: public_tests :: test_modify_crate_root_no_force_no_overwrite () ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.ident]
expression_str = "ident"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."& stats . node_type_counts"]
expression_str = "& stats . node_type_counts"
depth = 3
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'writer . write_all (format ! ("  -> Extracted {} use statements.\n" , use_statements . 0 . len ()) . as_bytes () ,) . await']
expression_str = 'writer . write_all (format ! ("  -> Extracted {} use statements.\n" , use_statements . 0 . len ()) . as_bytes () ,) . await'
depth = 3
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.Some]
expression_str = "Some"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."current_path . parent ()"]
expression_str = "current_path . parent ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.output_path]
expression_str = "output_path"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."serde_json :: to_string_pretty (& all_collected_errors_aggregated)"]
expression_str = "serde_json :: to_string_pretty (& all_collected_errors_aggregated)"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.sorted_node_types]
expression_str = "sorted_node_types"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'PipelineFunctor :: map (& ast_reconstruction_functor , writer , validated_file . clone () ,) . await . context ("AST Reconstruction failed")']
expression_str = 'PipelineFunctor :: map (& ast_reconstruction_functor , writer , validated_file . clone () ,) . await . context ("AST Reconstruction failed")'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."i . path . segments"]
expression_str = "i . path . segments"
depth = 4
used_types = []
other_types_count = 0
node_type = "Field"

[expressions."_args . test_report_input_file"]
expression_str = "_args . test_report_input_file"
depth = 5
used_types = []
other_types_count = 0
node_type = "Field"

[expressions."visit :: visit_item_struct (self , i)"]
expression_str = "visit :: visit_item_struct (self , i)"
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'"PathBuf"']
expression_str = '"PathBuf"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'tokio :: fs :: create_dir_all (cached_file_path . parent () . unwrap ()) . await . context ("Failed to create parent directories for cache file")']
expression_str = 'tokio :: fs :: create_dir_all (cached_file_path . parent () . unwrap ()) . await . context ("Failed to create parent directories for cache file")'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"        // rust_version_counts,\n"']
expression_str = '"        // rust_version_counts,\n"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'"generated/self_generated_code.rs"']
expression_str = '"generated/self_generated_code.rs"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."(file , None)"]
expression_str = "(file , None)"
depth = 4
used_types = []
other_types_count = 0
node_type = "Tuple"

[expressions."& output . stdout"]
expression_str = "& output . stdout"
depth = 3
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.is_complex_type]
expression_str = "is_complex_type"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'report_content . push_str ("This report summarizes the processing of Rust files during prelude generation.\n\n")']
expression_str = 'report_content . push_str ("This report summarizes the processing of Rust files during prelude generation.\n\n")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."all_public_symbols_aggregated . extend (public_symbols)"]
expression_str = "all_public_symbols_aggregated . extend (public_symbols)"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'_args . use_statements_output_dir . clone () . ok_or_else (| | anyhow :: anyhow ! ("use_statements_output_dir is required when extract_use_statements is true")) ?']
expression_str = '_args . use_statements_output_dir . clone () . ok_or_else (| | anyhow :: anyhow ! ("use_statements_output_dir is required when extract_use_statements is true")) ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'" Generates the `prelude.rs` file for a crate."']
expression_str = '" Generates the `prelude.rs` file for a crate."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."expr_path . path . segments . last ()"]
expression_str = "expr_path . path . segments . last ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'serde_json :: from_str (& json_content) . context ("Failed to deserialize results from JSON") ?']
expression_str = 'serde_json :: from_str (& json_content) . context ("Failed to deserialize results from JSON") ?'
depth = 5
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'report_content . push_str ("\n\nEnum Lattice Information\n")']
expression_str = 'report_content . push_str ("\n\nEnum Lattice Information\n")'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."{ let tokens = quote ! { # s } ; tokens . to_string () }"]
expression_str = "{ let tokens = quote ! { # s } ; tokens . to_string () }"
depth = 5
used_types = []
other_types_count = 0
node_type = "Block"

[expressions.'writer . write_all (format ! ("  -> PATH: {:#?}\n" , path_env) . as_bytes ()) . await ?']
expression_str = 'writer . write_all (format ! ("  -> PATH: {:#?}\n" , path_env) . as_bytes ()) . await ?'
depth = 5
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."modify_file (& file_path , true , false)"]
expression_str = "modify_file (& file_path , true , false)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'tokio :: fs :: read_to_string (file_path) . await . with_context (| | format ! ("Failed to read file content for hashing: {}" , file_path . display ()))']
expression_str = 'tokio :: fs :: read_to_string (file_path) . await . with_context (| | format ! ("Failed to read file content for hashing: {}" , file_path . display ()))'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."& results_json_path"]
expression_str = "& results_json_path"
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."super :: report :: generate_report (& [])"]
expression_str = "super :: report :: generate_report (& [])"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."& file"]
expression_str = "& file"
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'fs :: read_to_string (& cached_file_path) . await . with_context (| | format ! ("Failed to read cached expanded code for {}" , file_path . display ()))']
expression_str = 'fs :: read_to_string (& cached_file_path) . await . with_context (| | format ! ("Failed to read cached expanded code for {}" , file_path . display ()))'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'writer . write_all (format ! ("      -> Wrote expanded code to cache: {}\n" , cached_file_path . display ()) . as_bytes ()) . await']
expression_str = 'writer . write_all (format ! ("      -> Wrote expanded code to cache: {}\n" , cached_file_path . display ()) . as_bytes ()) . await'
depth = 3
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.'for crate_path in sorted_crate_paths { script_content . push_str (& format ! ("echo \"Running tests in {}...\"\n" , crate_path . display ())) ; script_content . push_str (& format ! ("pushd \"{}\"\n" , crate_path . display ())) ; script_content . push_str ("cargo test\n") ; script_content . push_str ("popd\n\n") ; }']
expression_str = 'for crate_path in sorted_crate_paths { script_content . push_str (& format ! ("echo \"Running tests in {}...\"\n" , crate_path . display ())) ; script_content . push_str (& format ! ("pushd \"{}\"\n" , crate_path . display ())) ; script_content . push_str ("cargo test\n") ; script_content . push_str ("popd\n\n") ; }'
depth = 2
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions."args . split_expanded_rustc_host . clone ()"]
expression_str = "args . split_expanded_rustc_host . clone ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'ResolvedDependency { id : id . to_string () , dependency_type : dep_type . to_string () , crate_name : "std" . to_string () , module_path : module_path . unwrap_or ("std") . to_string () , usage_count : 0 , }']
expression_str = 'ResolvedDependency { id : id . to_string () , dependency_type : dep_type . to_string () , crate_name : "std" . to_string () , module_path : module_path . unwrap_or ("std") . to_string () , usage_count : 0 , }'
depth = 3
used_types = []
other_types_count = 0
node_type = "Struct"

[expressions.1024]
expression_str = "1024"
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."if let syn :: Pat :: Path (pat_path) = & * expr_let . pat { if let Some (segment) = pat_path . path . segments . last () { self . enum_lattice_info . add_co_occurrence (BTreeSet :: from ([segment . ident . to_string ()])) ; } }"]
expression_str = "if let syn :: Pat :: Path (pat_path) = & * expr_let . pat { if let Some (segment) = pat_path . path . segments . last () { self . enum_lattice_info . add_co_occurrence (BTreeSet :: from ([segment . ident . to_string ()])) ; } }"
depth = 4
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'" The maximum number of batches to run"']
expression_str = '" The maximum number of batches to run"'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'| | anyhow :: anyhow ! ("use_statements_output_dir is required when extract_use_statements is true")']
expression_str = '| | anyhow :: anyhow ! ("use_statements_output_dir is required when extract_use_statements is true")'
depth = 4
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions.all_enum_lattices]
expression_str = "all_enum_lattices"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."TypeInfo { count : 0 , layer : Some (0) }"]
expression_str = "TypeInfo { count : 0 , layer : Some (0) }"
depth = 4
used_types = []
other_types_count = 0
node_type = "Struct"

[expressions.'extract_uses_functor . map (writer , parsed_file . clone ()) . await . context ("Extracting use statements failed") ?']
expression_str = 'extract_uses_functor . map (writer , parsed_file . clone ()) . await . context ("Extracting use statements failed") ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."& string_constants"]
expression_str = "& string_constants"
depth = 5
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."process_crates (& args) ?"]
expression_str = "process_crates (& args) ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'format ! ("    analyzer_version_counts.insert(\"{}\".to_string(), {});\n" , version , count)']
expression_str = 'format ! ("    analyzer_version_counts.insert(\"{}\".to_string(), {});\n" , version , count)'
depth = 5
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions.'writer . write_all (format ! ("  -> AST Reconstruction completed successfully.\n") . as_bytes () ,)']
expression_str = 'writer . write_all (format ! ("  -> AST Reconstruction completed successfully.\n") . as_bytes () ,)'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'if dry_run { println ! ("[DRY RUN] Would modify file: {}\n---\n{}---" , path . display () , new_content) ; } else { if path . exists () && ! force { println ! ("  -> Skipping file modification for {} (file exists, use --force to overwrite)." , path . display ()) ; } else { println ! ("  -> Modifying file: {}" , path . display ()) ; println ! ("    -> Writing modified content to: {}" , path . display ()) ; fs :: write (path , new_content) ? ; } }']
expression_str = 'if dry_run { println ! ("[DRY RUN] Would modify file: {}\n---\n{}---" , path . display () , new_content) ; } else { if path . exists () && ! force { println ! ("  -> Skipping file modification for {} (file exists, use --force to overwrite)." , path . display ()) ; } else { println ! ("  -> Modifying file: {}" , path . display ()) ; println ! ("    -> Writing modified content to: {}" , path . display ()) ; fs :: write (path , new_content) ? ; } }'
depth = 3
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'writer . write_all (format ! ("        -> Writing expanded code to cache for: {}\n" , file_path . display ()) . as_bytes ()) . await']
expression_str = 'writer . write_all (format ! ("        -> Writing expanded code to cache for: {}\n" , file_path . display ()) . as_bytes ()) . await'
depth = 3
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.'toml :: from_str (& config_content) . with_context (| | format ! ("Failed to parse config file: {}" , config_path . display ()))']
expression_str = 'toml :: from_str (& config_content) . with_context (| | format ! ("Failed to parse config file: {}" , config_path . display ()))'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'format ! ("### Crate: {}\n" , crate_path . display ())']
expression_str = 'format ! ("### Crate: {}\n" , crate_path . display ())'
depth = 5
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions."results . iter () . filter (| r | matches ! (r . status , FileProcessingStatus :: Failed { .. })) . count ()"]
expression_str = "results . iter () . filter (| r | matches ! (r . status , FileProcessingStatus :: Failed { .. })) . count ()"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'anyhow :: anyhow ! ("cargo metadata failed with status: {:?}" , output . status)']
expression_str = 'anyhow :: anyhow ! ("cargo metadata failed with status: {:?}" , output . status)'
depth = 5
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions.'tokio :: fs :: create_dir_all (& numerical_output_dir) . await . context (format ! ("Failed to create output directory {:?}" , numerical_output_dir)) ?']
expression_str = 'tokio :: fs :: create_dir_all (& numerical_output_dir) . await . context (format ! ("Failed to create output directory {:?}" , numerical_output_dir)) ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."new_ast . items . insert (0 , prelude_mod)"]
expression_str = "new_ast . items . insert (0 , prelude_mod)"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'PathBuf :: from ("generated_workspace")']
expression_str = 'PathBuf :: from ("generated_workspace")'
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'symbols . insert (id . to_string () , ResolvedDependency { id : id . to_string () , dependency_type : dep_type . to_string () , crate_name : "std" . to_string () , module_path : module_path . unwrap_or ("std") . to_string () , usage_count : 0 , })']
expression_str = 'symbols . insert (id . to_string () , ResolvedDependency { id : id . to_string () , dependency_type : dep_type . to_string () , crate_name : "std" . to_string () , module_path : module_path . unwrap_or ("std") . to_string () , usage_count : 0 , })'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."tokio :: fs :: create_dir_all (& hf_validator_project_dir) . await"]
expression_str = "tokio :: fs :: create_dir_all (& hf_validator_project_dir) . await"
depth = 5
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."& * expr_let . pat"]
expression_str = "& * expr_let . pat"
depth = 5
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."prelude_generator :: public_tests :: test_args_default_values () ?"]
expression_str = "prelude_generator :: public_tests :: test_args_default_values () ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."let syn :: Pat :: TupleStruct (pat_tuple_struct) = & arm . pat"]
expression_str = "let syn :: Pat :: TupleStruct (pat_tuple_struct) = & arm . pat"
depth = 4
used_types = []
other_types_count = 0
node_type = "Let"

[expressions."Vec :: new ()"]
expression_str = "Vec :: new ()"
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."std :: env :: set_current_dir (& original_dir) ?"]
expression_str = "std :: env :: set_current_dir (& original_dir) ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'script_content . push_str ("#!/bin/bash\n\n")']
expression_str = 'script_content . push_str ("#!/bin/bash\n\n")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'format ! ("Failed to write errors to file: {:?}" , error_output_path)']
expression_str = 'format ! ("Failed to write errors to file: {:?}" , error_output_path)'
depth = 5
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions."& all_public_symbols_aggregated"]
expression_str = "& all_public_symbols_aggregated"
depth = 5
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."args . path . clone ()"]
expression_str = "args . path . clone ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'! matches ! (ident_str . as_str () , "bool" | "u8" | "u16" | "u32" | "u64" | "u128" | "i8" | "i16" | "i32" | "i64" | "i128" | "f32" | "f64" | "char" | "str" | "usize" | "isize")']
expression_str = '! matches ! (ident_str . as_str () , "bool" | "u8" | "u16" | "u32" | "u64" | "u128" | "i8" | "i16" | "i32" | "i64" | "i128" | "f32" | "f64" | "char" | "str" | "usize" | "isize")'
depth = 4
used_types = []
other_types_count = 0
node_type = "Unary"

[expressions."symbol_map . populate_from_cargo_metadata (& project_root) ?"]
expression_str = "symbol_map . populate_from_cargo_metadata (& project_root) ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."type_extractor :: extract_bag_of_types (project_root , & args . filter_names)"]
expression_str = "type_extractor :: extract_bag_of_types (project_root , & args . filter_names)"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."file_content . to_string ()"]
expression_str = "file_content . to_string ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'for gem_entry in & gem_config . gem { for identifier in & gem_entry . identifiers { symbol_map . add_declaration (identifier . clone () , "builtin" . to_string () , gem_entry . crate_name . clone () , gem_entry . crate_name . clone () ,) ; } }']
expression_str = 'for gem_entry in & gem_config . gem { for identifier in & gem_entry . identifiers { symbol_map . add_declaration (identifier . clone () , "builtin" . to_string () , gem_entry . crate_name . clone () , gem_entry . crate_name . clone () ,) ; } }'
depth = 2
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions."fs :: File :: create (& file_path) . unwrap ()"]
expression_str = "fs :: File :: create (& file_path) . unwrap ()"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."if info . used_types . contains (& target_type) { let other_types_count = info . used_types . len () . saturating_sub (1) ; grouped_by_node_type . entry (info . node_type . clone ()) . or_default () . entry (other_types_count) . or_default () . entry (info . depth) . or_default () . push (info) ; }"]
expression_str = "if info . used_types . contains (& target_type) { let other_types_count = info . used_types . len () . saturating_sub (1) ; grouped_by_node_type . entry (info . node_type . clone ()) . or_default () . entry (other_types_count) . or_default () . entry (info . depth) . or_default () . push (info) ; }"
depth = 4
used_types = []
other_types_count = 0
node_type = "If"

[expressions."let Some (segment) = type_path . path . segments . last ()"]
expression_str = "let Some (segment) = type_path . path . segments . last ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "Let"

[expressions.'project_root . join ("dummy_results.json")']
expression_str = 'project_root . join ("dummy_results.json")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'{ let mut node_type_counts = HashMap :: new () ; node_type_counts . insert ("variable" . to_string () , 41) ; node_type_counts . insert ("import" . to_string () , 18) ; node_type_counts . insert ("function" . to_string () , 6) ; node_type_counts . insert ("other" . to_string () , 230) ; let mut line_stats = HashMap :: new () ; line_stats . insert ("other" . to_string () , (12 , 295 , 36092 , 230)) ; line_stats . insert ("import" . to_string () , (1 , 212 , 891 , 18)) ; line_stats . insert ("variable" . to_string () , (25 , 274 , 5772 , 41)) ; line_stats . insert ("function" . to_string () , (18 , 208 , 905 , 6)) ; let mut column_stats = HashMap :: new () ; column_stats . insert ("import" . to_string () , (1 , 1 , 18 , 18)) ; column_stats . insert ("variable" . to_string () , (1 , 1 , 41 , 41)) ; column_stats . insert ("function" . to_string () , (1 , 1 , 6 , 6)) ; column_stats . insert ("other" . to_string () , (1 , 1 , 230 , 230)) ; let mut processing_time_stats = HashMap :: new () ; processing_time_stats . insert ("other" . to_string () , (1 , 1 , 230 , 230)) ; processing_time_stats . insert ("import" . to_string () , (1 , 1 , 18 , 18)) ; processing_time_stats . insert ("variable" . to_string () , (1 , 1 , 41 , 41)) ; processing_time_stats . insert ("function" . to_string () , (1 , 1 , 6 , 6)) ; let mut rust_version_counts = HashMap :: new () ; rust_version_counts . insert ("1.86.0" . to_string () , 295) ; let mut analyzer_version_counts = HashMap :: new () ; analyzer_version_counts . insert ("0.3.2000" . to_string () , 295) ; let mut snippet_length_stats = HashMap :: new () ; snippet_length_stats . insert ("function" . to_string () , (39 , 83 , 434 , 6)) ; snippet_length_stats . insert ("other" . to_string () , (1 , 92 , 7273 , 230)) ; snippet_length_stats . insert ("import" . to_string () , (14 , 85 , 812 , 18)) ; snippet_length_stats . insert ("variable" . to_string () , (29 , 89 , 2362 , 41)) ; AstStatistics { node_type_counts , line_stats , column_stats , processing_time_stats , rust_version_counts , analyzer_version_counts , snippet_length_stats , } }']
expression_str = '{ let mut node_type_counts = HashMap :: new () ; node_type_counts . insert ("variable" . to_string () , 41) ; node_type_counts . insert ("import" . to_string () , 18) ; node_type_counts . insert ("function" . to_string () , 6) ; node_type_counts . insert ("other" . to_string () , 230) ; let mut line_stats = HashMap :: new () ; line_stats . insert ("other" . to_string () , (12 , 295 , 36092 , 230)) ; line_stats . insert ("import" . to_string () , (1 , 212 , 891 , 18)) ; line_stats . insert ("variable" . to_string () , (25 , 274 , 5772 , 41)) ; line_stats . insert ("function" . to_string () , (18 , 208 , 905 , 6)) ; let mut column_stats = HashMap :: new () ; column_stats . insert ("import" . to_string () , (1 , 1 , 18 , 18)) ; column_stats . insert ("variable" . to_string () , (1 , 1 , 41 , 41)) ; column_stats . insert ("function" . to_string () , (1 , 1 , 6 , 6)) ; column_stats . insert ("other" . to_string () , (1 , 1 , 230 , 230)) ; let mut processing_time_stats = HashMap :: new () ; processing_time_stats . insert ("other" . to_string () , (1 , 1 , 230 , 230)) ; processing_time_stats . insert ("import" . to_string () , (1 , 1 , 18 , 18)) ; processing_time_stats . insert ("variable" . to_string () , (1 , 1 , 41 , 41)) ; processing_time_stats . insert ("function" . to_string () , (1 , 1 , 6 , 6)) ; let mut rust_version_counts = HashMap :: new () ; rust_version_counts . insert ("1.86.0" . to_string () , 295) ; let mut analyzer_version_counts = HashMap :: new () ; analyzer_version_counts . insert ("0.3.2000" . to_string () , 295) ; let mut snippet_length_stats = HashMap :: new () ; snippet_length_stats . insert ("function" . to_string () , (39 , 83 , 434 , 6)) ; snippet_length_stats . insert ("other" . to_string () , (1 , 92 , 7273 , 230)) ; snippet_length_stats . insert ("import" . to_string () , (14 , 85 , 812 , 18)) ; snippet_length_stats . insert ("variable" . to_string () , (29 , 89 , 2362 , 41)) ; AstStatistics { node_type_counts , line_stats , column_stats , processing_time_stats , rust_version_counts , analyzer_version_counts , snippet_length_stats , } }'
depth = 4
used_types = []
other_types_count = 0
node_type = "Block"

[expressions."for gem_entry in & self . gem { for identifier in & gem_entry . identifiers { map . insert (identifier . clone () , gem_entry . name . clone ()) ; } }"]
expression_str = "for gem_entry in & self . gem { for identifier in & gem_entry . identifiers { map . insert (identifier . clone () , gem_entry . name . clone ()) ; } }"
depth = 2
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions.'| e | e . file_type () . is_file () && e . path () . extension () . map_or (false , | ext | ext == r"rs")']
expression_str = '| e | e . file_type () . is_file () && e . path () . extension () . map_or (false , | ext | ext == r"rs")'
depth = 4
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions.'for item in & ast . items { if let Item :: Mod (mod_item) = item { if mod_item . ident == "prelude" { has_prelude_mod = true ; break ; } } }']
expression_str = 'for item in & ast . items { if let Item :: Mod (mod_item) = item { if mod_item . ident == "prelude" { has_prelude_mod = true ; break ; } } }'
depth = 2
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions.'fs :: write ("prelude_generator_summary.md" , report_content)']
expression_str = 'fs :: write ("prelude_generator_summary.md" , report_content)'
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."syn :: visit :: visit_path (self , i)"]
expression_str = "syn :: visit :: visit_path (self , i)"
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'"        node_type_counts,\n"']
expression_str = '"        node_type_counts,\n"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.file_path_str]
expression_str = "file_path_str"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."syn :: visit :: visit_item_static"]
expression_str = "syn :: visit :: visit_item_static"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'| | PathBuf :: from ("test_report.json")']
expression_str = '| | PathBuf :: from ("test_report.json")'
depth = 3
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions.'if project_root . exists () { fs :: remove_dir_all (& project_root) . context (format ! ("Failed to remove existing project root: {:?}" , project_root)) ? ; }']
expression_str = 'if project_root . exists () { fs :: remove_dir_all (& project_root) . context (format ! ("Failed to remove existing project root: {:?}" , project_root)) ? ; }'
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'tokio :: fs :: create_dir_all (& constants_output_dir) . await . context (format ! ("Failed to create output directory {:?}" , constants_output_dir))']
expression_str = 'tokio :: fs :: create_dir_all (& constants_output_dir) . await . context (format ! ("Failed to create output directory {:?}" , constants_output_dir))'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"Infer"']
expression_str = '"Infer"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."fs :: read_to_string (path) . await"]
expression_str = "fs :: read_to_string (path) . await"
depth = 5
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."& format ! (\"\\n### Struct: '{}' (Expressions Analyzed: {}) ###\\n\" , struct_name , lattice_info . total_expressions_analyzed)"]
expression_str = '''& format ! ("\n### Struct: '{}' (Expressions Analyzed: {}) ###\n" , struct_name , lattice_info . total_expressions_analyzed)'''
depth = 5
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.temp_src_dir]
expression_str = "temp_src_dir"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'for (node_type , count) in & stats . node_type_counts { code . push_str (& format ! ("    node_type_counts.insert(\"{}\".to_string(), {});\n" , node_type , count)) ; }']
expression_str = 'for (node_type , count) in & stats . node_type_counts { code . push_str (& format ! ("    node_type_counts.insert(\"{}\".to_string(), {});\n" , node_type , count)) ; }'
depth = 2
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions."files_processed_for_bow += 1"]
expression_str = "files_processed_for_bow += 1"
depth = 5
used_types = []
other_types_count = 0
node_type = "Binary"

[expressions."Duration :: from_secs"]
expression_str = "Duration :: from_secs"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."tests_by_crate . get (crate_path)"]
expression_str = "tests_by_crate . get (crate_path)"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."for depth in sorted_depth_keys { let mut expressions_at_depth = grouped_by_depth . get (& depth) . unwrap () . clone () ; expressions_at_depth . sort_by_key (| info | info . expression_str . clone ()) ; report_content . push_str (& format ! (\"    Depth {}: (Count: {})\n\" , depth , expressions_at_depth . len ())) ; for info in expressions_at_depth { report_content . push_str (& format ! (\"      - '{}' (Used Types: {:?})\\n\" , info . expression_str , info . used_types)) ; } }"]
expression_str = '''
for depth in sorted_depth_keys { let mut expressions_at_depth = grouped_by_depth . get (& depth) . unwrap () . clone () ; expressions_at_depth . sort_by_key (| info | info . expression_str . clone ()) ; report_content . push_str (& format ! ("    Depth {}: (Count: {})
" , depth , expressions_at_depth . len ())) ; for info in expressions_at_depth { report_content . push_str (& format ! ("      - '{}' (Used Types: {:?})\n" , info . expression_str , info . used_types)) ; } }'''
depth = 5
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions.'format ! ("Generated code validation failed for {:?}" , output_file_path)']
expression_str = 'format ! ("Generated code validation failed for {:?}" , output_file_path)'
depth = 4
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions.'writer . write_all (format ! ("        -> {}\n" , error_message) . as_bytes ()) . await . context ("Failed to write rustc error to writer")']
expression_str = 'writer . write_all (format ! ("        -> {}\n" , error_message) . as_bytes ()) . await . context ("Failed to write rustc error to writer")'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.flatten_use_tree]
expression_str = "flatten_use_tree"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'add_primitive_type (& mut symbols , "char")']
expression_str = 'add_primitive_type (& mut symbols , "char")'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."for target_type in sorted_user_defined_types { report_content . push_str (& format ! (\"\\n### Analyzing expressions using type: '{}' ###\\n\" , target_type)) ; let mut grouped_by_node_type : HashMap < String , HashMap < usize , HashMap < usize , Vec < & ExpressionInfo > > > > = HashMap :: new () ; for (_ , info) in all_expression_info { if info . used_types . contains (& target_type) { let other_types_count = info . used_types . len () . saturating_sub (1) ; grouped_by_node_type . entry (info . node_type . clone ()) . or_default () . entry (other_types_count) . or_default () . entry (info . depth) . or_default () . push (info) ; } } let mut sorted_node_types : Vec < String > = grouped_by_node_type . keys () . cloned () . collect () ; sorted_node_types . sort_unstable () ; for node_type in sorted_node_types { report_content . push_str (& format ! (\"\\n--- AST Node Type: {} ---\\n\" , node_type)) ; let grouped_by_other_types = grouped_by_node_type . get (& node_type) . unwrap () ; let mut sorted_other_types_keys : Vec < usize > = grouped_by_other_types . keys () . cloned () . collect () ; sorted_other_types_keys . sort_unstable () ; for other_types_count in sorted_other_types_keys { report_content . push_str (& format ! (\"  Expressions using '{}' with {} other type(s):\\n\" , target_type , other_types_count)) ; let grouped_by_depth = grouped_by_other_types . get (& other_types_count) . unwrap () ; let mut sorted_depth_keys : Vec < usize > = grouped_by_depth . keys () . cloned () . collect () ; sorted_depth_keys . sort_unstable () ; for depth in sorted_depth_keys { let mut expressions_at_depth = grouped_by_depth . get (& depth) . unwrap () . clone () ; expressions_at_depth . sort_by_key (| info | info . expression_str . clone ()) ; report_content . push_str (& format ! (\"    Depth {}: (Count: {})\n\" , depth , expressions_at_depth . len ())) ; for info in expressions_at_depth { report_content . push_str (& format ! (\"      - '{}' (Used Types: {:?})\\n\" , info . expression_str , info . used_types)) ; } } } } }"]
expression_str = '''
for target_type in sorted_user_defined_types { report_content . push_str (& format ! ("\n### Analyzing expressions using type: '{}' ###\n" , target_type)) ; let mut grouped_by_node_type : HashMap < String , HashMap < usize , HashMap < usize , Vec < & ExpressionInfo > > > > = HashMap :: new () ; for (_ , info) in all_expression_info { if info . used_types . contains (& target_type) { let other_types_count = info . used_types . len () . saturating_sub (1) ; grouped_by_node_type . entry (info . node_type . clone ()) . or_default () . entry (other_types_count) . or_default () . entry (info . depth) . or_default () . push (info) ; } } let mut sorted_node_types : Vec < String > = grouped_by_node_type . keys () . cloned () . collect () ; sorted_node_types . sort_unstable () ; for node_type in sorted_node_types { report_content . push_str (& format ! ("\n--- AST Node Type: {} ---\n" , node_type)) ; let grouped_by_other_types = grouped_by_node_type . get (& node_type) . unwrap () ; let mut sorted_other_types_keys : Vec < usize > = grouped_by_other_types . keys () . cloned () . collect () ; sorted_other_types_keys . sort_unstable () ; for other_types_count in sorted_other_types_keys { report_content . push_str (& format ! ("  Expressions using '{}' with {} other type(s):\n" , target_type , other_types_count)) ; let grouped_by_depth = grouped_by_other_types . get (& other_types_count) . unwrap () ; let mut sorted_depth_keys : Vec < usize > = grouped_by_depth . keys () . cloned () . collect () ; sorted_depth_keys . sort_unstable () ; for depth in sorted_depth_keys { let mut expressions_at_depth = grouped_by_depth . get (& depth) . unwrap () . clone () ; expressions_at_depth . sort_by_key (| info | info . expression_str . clone ()) ; report_content . push_str (& format ! ("    Depth {}: (Count: {})
" , depth , expressions_at_depth . len ())) ; for info in expressions_at_depth { report_content . push_str (& format ! ("      - '{}' (Used Types: {:?})\n" , info . expression_str , info . used_types)) ; } } } } }'''
depth = 2
used_types = [
    "& ExpressionInfo",
    "Vec",
    "ExpressionInfo",
    "HashMap",
]
other_types_count = 4
node_type = "ForLoop"

[expressions.'"aggregated_tests.rs"']
expression_str = '"aggregated_tests.rs"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'writer . write_all (format ! ("--- Stage 1: Parsing ---\n") . as_bytes ())']
expression_str = 'writer . write_all (format ! ("--- Stage 1: Parsing ---\n") . as_bytes ())'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."modify_file (& file_path , false , true) ?"]
expression_str = "modify_file (& file_path , false , true) ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.constant]
expression_str = "constant"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."& self . gem"]
expression_str = "& self . gem"
depth = 3
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'args . split_expanded_project_root . clone () . unwrap_or_else (| | PathBuf :: from ("generated_workspace"))']
expression_str = 'args . split_expanded_project_root . clone () . unwrap_or_else (| | PathBuf :: from ("generated_workspace"))'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.test_infos]
expression_str = "test_infos"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'writer . write_all (format ! ("        -> {}\n" , error_message) . as_bytes ()) . await . context ("Failed to write parsing error to writer")']
expression_str = 'writer . write_all (format ! ("        -> {}\n" , error_message) . as_bytes ()) . await . context ("Failed to write parsing error to writer")'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."& arm . pat"]
expression_str = "& arm . pat"
depth = 5
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'format ! ("        -> rustc status for {}: {}\n" , file_path . display () , output . status) . as_bytes ()']
expression_str = 'format ! ("        -> rustc status for {}: {}\n" , file_path . display () , output . status) . as_bytes ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."lit_int . base10_digits () . to_string ()"]
expression_str = "lit_int . base10_digits () . to_string ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.original_content]
expression_str = "original_content"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'if args . verify_config { eprintln ! ("Configuration verification complete. Exiting.") ; return Ok (()) ; }']
expression_str = 'if args . verify_config { eprintln ! ("Configuration verification complete. Exiting.") ; return Ok (()) ; }'
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'" The path to the workspace root."']
expression_str = '" The path to the workspace root."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."numerical_constants . iter () . chain (string_constants . iter ())"]
expression_str = "numerical_constants . iter () . chain (string_constants . iter ())"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."{ format ! (\"use std::collections::HashMap;\nuse crate::type_extractor::TypeInfo;\n{}\" , content) }"]
expression_str = """
{ format ! ("use std::collections::HashMap;
use crate::type_extractor::TypeInfo;
{}" , content) }"""
depth = 5
used_types = []
other_types_count = 0
node_type = "Block"

[expressions.'& format ! ("    rust_version_counts.insert(\"{}\".to_string(), {});\n" , version , count)']
expression_str = '& format ! ("    rust_version_counts.insert(\"{}\".to_string(), {});\n" , version , count)'
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."file . write_all (content . as_bytes ()) . unwrap ()"]
expression_str = "file . write_all (content . as_bytes ()) . unwrap ()"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'writer . write_all (format ! ("  -> Classified use statements:\n") . as_bytes ()) . await']
expression_str = 'writer . write_all (format ! ("  -> Classified use statements:\n") . as_bytes ()) . await'
depth = 3
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.'if let Some (output_path) = _output_global_toml { let serializable_decls : Vec < SerializableDeclaration > = all_declarations . into_iter () . map (Into :: into) . collect () ; let toml_string = toml :: to_string_pretty (& serializable_decls) . context ("Failed to serialize declarations to TOML ") ? ; fs :: write (& output_path , toml_string) . context (format ! ("Failed to write TOML to file: {:?}" , output_path)) ? ; println ! ("Successfully wrote declarations to {:?}" , output_path) ; }']
expression_str = 'if let Some (output_path) = _output_global_toml { let serializable_decls : Vec < SerializableDeclaration > = all_declarations . into_iter () . map (Into :: into) . collect () ; let toml_string = toml :: to_string_pretty (& serializable_decls) . context ("Failed to serialize declarations to TOML ") ? ; fs :: write (& output_path , toml_string) . context (format ! ("Failed to write TOML to file: {:?}" , output_path)) ? ; println ! ("Successfully wrote declarations to {:?}" , output_path) ; }'
depth = 2
used_types = [
    "SerializableDeclaration",
    "Vec",
]
other_types_count = 2
node_type = "If"

[expressions.'return Err (anyhow :: anyhow ! ("git commit --allow-empty failed: {}\nStderr: {}" , String :: from_utf8_lossy (& output . status . code () . unwrap_or (- 1) . to_string () . as_bytes ()) , String :: from_utf8_lossy (& output . stderr)))']
expression_str = 'return Err (anyhow :: anyhow ! ("git commit --allow-empty failed: {}\nStderr: {}" , String :: from_utf8_lossy (& output . status . code () . unwrap_or (- 1) . to_string () . as_bytes ()) , String :: from_utf8_lossy (& output . stderr)))'
depth = 5
used_types = []
other_types_count = 0
node_type = "Return"

[expressions.'if self . verbose > 0 { println ! ("Resolved Type Reference: id={}, type={}, crate={}, module={}, usage={}" , resolved_dep . id , resolved_dep . dependency_type , resolved_dep . crate_name , resolved_dep . module_path , resolved_dep . usage_count) ; }']
expression_str = 'if self . verbose > 0 { println ! ("Resolved Type Reference: id={}, type={}, crate={}, module={}, usage={}" , resolved_dep . id , resolved_dep . dependency_type , resolved_dep . crate_name , resolved_dep . module_path , resolved_dep . usage_count) ; }'
depth = 3
used_types = []
other_types_count = 0
node_type = "If"

[expressions."let Type :: Path (type_path) = i"]
expression_str = "let Type :: Path (type_path) = i"
depth = 3
used_types = []
other_types_count = 0
node_type = "Let"

[expressions.crate_root_path]
expression_str = "crate_root_path"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'format ! ("{:x}" , hasher . finish ())']
expression_str = 'format ! ("{:x}" , hasher . finish ())'
depth = 4
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions.'if let Err (e) = result { eprintln ! (r"Error processing struct {}: {:?}\n" , struct_name , e) ; errors . push (e) ; }']
expression_str = 'if let Err (e) = result { eprintln ! (r"Error processing struct {}: {:?}\n" , struct_name , e) ; errors . push (e) ; }'
depth = 4
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'for package in metadata . packages { let crate_name = package . name ; self . map . insert (crate_name . clone () , ResolvedDependency { id : crate_name . clone () , dependency_type : "crate" . to_string () , crate_name : crate_name . clone () , module_path : crate_name . clone () , usage_count : 0 , }) ; }']
expression_str = 'for package in metadata . packages { let crate_name = package . name ; self . map . insert (crate_name . clone () , ResolvedDependency { id : crate_name . clone () , dependency_type : "crate" . to_string () , crate_name : crate_name . clone () , module_path : crate_name . clone () , usage_count : 0 , }) ; }'
depth = 2
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions.'format ! ("---\n--- Stage 4: AST Reconstruction from Hugging Face Dataset ---\n") . as_bytes ()']
expression_str = 'format ! ("---\n--- Stage 4: AST Reconstruction from Hugging Face Dataset ---\n") . as_bytes ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."file_path . to_string_lossy () . as_bytes ()"]
expression_str = "file_path . to_string_lossy () . as_bytes ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'classify_uses_functor . map (writer , use_statements) . await . context ("Classifying use statements failed") ?']
expression_str = 'classify_uses_functor . map (writer , use_statements) . await . context ("Classifying use statements failed") ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."tokio :: fs :: write (& file_path , current_file_content . as_bytes ())"]
expression_str = "tokio :: fs :: write (& file_path , current_file_content . as_bytes ())"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'structure . attrs . iter () . any (| attr | { if attr . path () . is_ident ("derive") { if let Meta :: List (meta_list) = & attr . meta { let tokens_str = meta_list . tokens . to_string () ; tokens_str . contains ("Parser") || tokens_str . contains ("Serialize") || tokens_str . contains ("Deserialize") } else { false } } else { false } })']
expression_str = 'structure . attrs . iter () . any (| attr | { if attr . path () . is_ident ("derive") { if let Meta :: List (meta_list) = & attr . meta { let tokens_str = meta_list . tokens . to_string () ; tokens_str . contains ("Parser") || tokens_str . contains ("Serialize") || tokens_str . contains ("Deserialize") } else { false } } else { false } })'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"// This module contains extracted constant declarations.\n// It is automatically generated.\n\n"']
expression_str = '"// This module contains extracted constant declarations.\n// It is automatically generated.\n\n"'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."let Type :: Path (type_path) = & * i . self_ty"]
expression_str = "let Type :: Path (type_path) = & * i . self_ty"
depth = 3
used_types = []
other_types_count = 0
node_type = "Let"

[expressions.'report_content . push_str (& format ! ("\n--- AST Node Type: {} ---\n" , node_type))']
expression_str = 'report_content . push_str (& format ! ("\n--- AST Node Type: {} ---\n" , node_type))'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'Some ("std::vec")']
expression_str = 'Some ("std::vec")'
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'setup_test_file (& dir , "src/lib.rs" , "pub mod prelude;\nfn main() {}\n" ,)']
expression_str = 'setup_test_file (& dir , "src/lib.rs" , "pub mod prelude;\nfn main() {}\n" ,)'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."serde_json :: to_string_pretty (& collected_metrics)"]
expression_str = "serde_json :: to_string_pretty (& collected_metrics)"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'" Path to output the global symbol map TOML file."']
expression_str = '" Path to output the global symbol map TOML file."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'" Path to a rustc wrapper script to use for macro expansion."']
expression_str = '" Path to a rustc wrapper script to use for macro expansion."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'writer . write_all (format ! ("  -> Parsed file successfully.\n") . as_bytes ())']
expression_str = 'writer . write_all (format ! ("  -> Parsed file successfully.\n") . as_bytes ())'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."tokio :: fs :: create_dir_all (cached_file_path . parent () . unwrap ())"]
expression_str = "tokio :: fs :: create_dir_all (cached_file_path . parent () . unwrap ())"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'format ! ("expanded_{}_{}_{}_{}" , content_hash , rustc_info . version , rustc_info . host , "2021")']
expression_str = 'format ! ("expanded_{}_{}_{}_{}" , content_hash , rustc_info . version , rustc_info . host , "2021")'
depth = 2
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions.'"use serde::{Serialize, Deserialize};\n"']
expression_str = '"use serde::{Serialize, Deserialize};\n"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."report_content . push_str (& format ! (\"\\n### Struct: '{}' (Expressions Analyzed: {}) ###\\n\" , struct_name , lattice_info . total_expressions_analyzed))"]
expression_str = '''report_content . push_str (& format ! ("\n### Struct: '{}' (Expressions Analyzed: {}) ###\n" , struct_name , lattice_info . total_expressions_analyzed))'''
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'if lattice_info . variant_type_co_occurrences . is_empty () { report_content . push_str ("  No variant type co-occurrence data collected.\n") ; } else { let mut sorted_co_occurrences : Vec < (& BTreeSet < String > , & usize) > = lattice_info . variant_type_co_occurrences . iter () . collect () ; sorted_co_occurrences . sort_by_key (| & (_ , count) | count) ; for (variant_types , count) in sorted_co_occurrences { report_content . push_str (& format ! ("  - Co-occurring variant types: {:?} (Count: {})\n" , variant_types , count)) ; } }']
expression_str = 'if lattice_info . variant_type_co_occurrences . is_empty () { report_content . push_str ("  No variant type co-occurrence data collected.\n") ; } else { let mut sorted_co_occurrences : Vec < (& BTreeSet < String > , & usize) > = lattice_info . variant_type_co_occurrences . iter () . collect () ; sorted_co_occurrences . sort_by_key (| & (_ , count) | count) ; for (variant_types , count) in sorted_co_occurrences { report_content . push_str (& format ! ("  - Co-occurring variant types: {:?} (Count: {})\n" , variant_types , count)) ; } }'
depth = 4
used_types = [
    "BTreeSet",
    "Vec",
    "(& BTreeSet < String > , & usize)",
    "& BTreeSet < String >",
    "& usize",
]
other_types_count = 5
node_type = "If"

[expressions."serde_json :: from_str (& results_file_content ,)"]
expression_str = "serde_json :: from_str (& results_file_content ,)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."prelude_generator :: public_tests :: test_args_custom_values () ?"]
expression_str = "prelude_generator :: public_tests :: test_args_custom_values () ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."fs :: copy (file_path , & temp_lib_rs_path)"]
expression_str = "fs :: copy (file_path , & temp_lib_rs_path)"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'line_stats . insert ("other" . to_string () , (12 , 295 , 36092 , 230))']
expression_str = 'line_stats . insert ("other" . to_string () , (12 , 295 , 36092 , 230))'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."self . crate_name"]
expression_str = "self . crate_name"
depth = 5
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'"crate" . to_string ()']
expression_str = '"crate" . to_string ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'tokio :: task :: spawn_blocking (move | | -> anyhow :: Result < _ > { let ast = match syn :: parse_file (& content) { Ok (ast) => ast , Err (_) => { return Err (anyhow :: anyhow ! ("Failed to parse file and expand macros")) ; } } ; Ok (prettyplease :: unparse (& ast)) }) . await . context ("Blocking task for parsing failed") ?']
expression_str = 'tokio :: task :: spawn_blocking (move | | -> anyhow :: Result < _ > { let ast = match syn :: parse_file (& content) { Ok (ast) => ast , Err (_) => { return Err (anyhow :: anyhow ! ("Failed to parse file and expand macros")) ; } } ; Ok (prettyplease :: unparse (& ast)) }) . await . context ("Blocking task for parsing failed") ?'
depth = 5
used_types = [
    "_",
    "Result",
]
other_types_count = 2
node_type = "Unknown"

[expressions."pipeline :: run_category_pipeline (& mut stdout , & dummy_content , & dummy_path , & args , & Some (config . clone ()) ,) . await"]
expression_str = "pipeline :: run_category_pipeline (& mut stdout , & dummy_content , & dummy_path , & args , & Some (config . clone ()) ,) . await"
depth = 3
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.get_rustc_info]
expression_str = "get_rustc_info"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."type_extractor :: extract_bag_of_types"]
expression_str = "type_extractor :: extract_bag_of_types"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'"Assign" . to_string ()']
expression_str = '"Assign" . to_string ()'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."extract_declarations_from_single_file (file_path , & rustc_info , & current_crate_name , verbose ,)"]
expression_str = "extract_declarations_from_single_file (file_path , & rustc_info , & current_crate_name , verbose ,)"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'if ! all_collected_errors . is_empty () { let error_output_path = output_dir . join ("errors.json") ; let error_json_content = serde_json :: to_string_pretty (& all_collected_errors) . context ("Failed to serialize errors to JSON") ? ; tokio :: fs :: write (& error_output_path , error_json_content) . await . context (format ! ("Failed to write errors to file: {:?}" , error_output_path)) ? ; eprintln ! ("{} errors collected during declaration extraction. See {:?}" , all_collected_errors . len () , error_output_path) ; }']
expression_str = 'if ! all_collected_errors . is_empty () { let error_output_path = output_dir . join ("errors.json") ; let error_json_content = serde_json :: to_string_pretty (& all_collected_errors) . context ("Failed to serialize errors to JSON") ? ; tokio :: fs :: write (& error_output_path , error_json_content) . await . context (format ! ("Failed to write errors to file: {:?}" , error_output_path)) ? ; eprintln ! ("{} errors collected during declaration extraction. See {:?}" , all_collected_errors . len () , error_output_path) ; }'
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions."args . split_expanded_rustc_version . clone ()"]
expression_str = "args . split_expanded_rustc_version . clone ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."struct_name . as_str ()"]
expression_str = "struct_name . as_str ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"Paren"']
expression_str = '"Paren"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."& args . path"]
expression_str = "& args . path"
depth = 5
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'format ! ("Failed to write type usage report to {:?}" , output_path)']
expression_str = 'format ! ("Failed to write type usage report to {:?}" , output_path)'
depth = 4
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions.'vec ! [FileProcessingResult { path : PathBuf :: from ("dummy/file.rs") , status : FileProcessingStatus :: Success , } ,]']
expression_str = 'vec ! [FileProcessingResult { path : PathBuf :: from ("dummy/file.rs") , status : FileProcessingStatus :: Success , } ,]'
depth = 2
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions.'"pub mod prelude;\nfn main() {}\n"']
expression_str = '"pub mod prelude;\nfn main() {}\n"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."& src_dir"]
expression_str = "& src_dir"
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'"i8"']
expression_str = '"i8"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."extract_test_cases_from_file (& file_path)"]
expression_str = "extract_test_cases_from_file (& file_path)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."mapping . files . insert (original_file_path . to_string_lossy () . to_string () , short_id . clone ())"]
expression_str = "mapping . files . insert (original_file_path . to_string_lossy () . to_string () , short_id . clone ())"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."self . map . entry (id . clone ())"]
expression_str = "self . map . entry (id . clone ())"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'for file_path in & files_to_process { println ! ("Processing file for declarations: {:?}" , file_path) ; let current_crate_name = project_root . file_name () . and_then (| s | s . to_str ()) . unwrap_or ("unknown_crate") . to_string () ; match extract_declarations_from_single_file (file_path , & rustc_info , & current_crate_name , verbose ,) . await { Ok ((declarations , errors , _file_metadata , _public_symbols)) => { let file_content = fs :: read_to_string (& file_path) . context (format ! ("Failed to read file: {:?}" , file_path)) ? ; match syn :: parse_file (& file_content) { Ok (file) => parsed_files . push ((file_path . clone () , file)) , Err (e) => { eprintln ! ("Warning: Could not re-parse file for Pass 2 {}: {}" , file_path . display () , e) ; } } for decl in declarations { match dependency_validator . validate (& decl) { Ok (_) => all_declarations . push (decl) , Err (e) => { eprintln ! ("Validation Error for declaration {:?}: {:?}" , decl . get_identifier () , e) ; } } } error_collection . errors . extend (errors) ; } , Err (e) => { eprintln ! ("Error extracting declarations from file {:?}: {}" , file_path , e) ; } } }']
expression_str = 'for file_path in & files_to_process { println ! ("Processing file for declarations: {:?}" , file_path) ; let current_crate_name = project_root . file_name () . and_then (| s | s . to_str ()) . unwrap_or ("unknown_crate") . to_string () ; match extract_declarations_from_single_file (file_path , & rustc_info , & current_crate_name , verbose ,) . await { Ok ((declarations , errors , _file_metadata , _public_symbols)) => { let file_content = fs :: read_to_string (& file_path) . context (format ! ("Failed to read file: {:?}" , file_path)) ? ; match syn :: parse_file (& file_content) { Ok (file) => parsed_files . push ((file_path . clone () , file)) , Err (e) => { eprintln ! ("Warning: Could not re-parse file for Pass 2 {}: {}" , file_path . display () , e) ; } } for decl in declarations { match dependency_validator . validate (& decl) { Ok (_) => all_declarations . push (decl) , Err (e) => { eprintln ! ("Validation Error for declaration {:?}: {:?}" , decl . get_identifier () , e) ; } } } error_collection . errors . extend (errors) ; } , Err (e) => { eprintln ! ("Error extracting declarations from file {:?}: {}" , file_path , e) ; } } }'
depth = 2
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions.'return "// No struct declarations found in this module.\n" . to_string ()']
expression_str = 'return "// No struct declarations found in this module.\n" . to_string ()'
depth = 3
used_types = []
other_types_count = 0
node_type = "Return"

[expressions.entry]
expression_str = "entry"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."extract_test_functions_from_items (ast . items , file_path)"]
expression_str = "extract_test_functions_from_items (ast . items , file_path)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'"Cargo.toml"']
expression_str = '"Cargo.toml"'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."visit :: visit_expr"]
expression_str = "visit :: visit_expr"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."& mut uses"]
expression_str = "& mut uses"
depth = 5
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'{ if attr . path () . is_ident ("derive") { if let Meta :: List (meta_list) = & attr . meta { let tokens_str = meta_list . tokens . to_string () ; tokens_str . contains ("Parser") || tokens_str . contains ("Serialize") || tokens_str . contains ("Deserialize") } else { false } } else { false } }']
expression_str = '{ if attr . path () . is_ident ("derive") { if let Meta :: List (meta_list) = & attr . meta { let tokens_str = meta_list . tokens . to_string () ; tokens_str . contains ("Parser") || tokens_str . contains ("Serialize") || tokens_str . contains ("Deserialize") } else { false } } else { false } }'
depth = 4
used_types = []
other_types_count = 0
node_type = "Block"

[expressions.'script_content . push_str (& format ! ("echo \"Running tests in {}...\"\n" , crate_path . display ()))']
expression_str = 'script_content . push_str (& format ! ("echo \"Running tests in {}...\"\n" , crate_path . display ()))'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.sorted_terms]
expression_str = "sorted_terms"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."BagOfWordsVisitor :: new ()"]
expression_str = "BagOfWordsVisitor :: new ()"
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'code . push_str ("    let mut processing_time_stats = HashMap::new();\n")']
expression_str = 'code . push_str ("    let mut processing_time_stats = HashMap::new();\n")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."generate_prelude :: generate_prelude (& src_dir , new_prelude_content , false , true)"]
expression_str = "generate_prelude :: generate_prelude (& src_dir , new_prelude_content , false , true)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'format ! ("{:#?}\n" , classified_uses) . as_bytes ()']
expression_str = 'format ! ("{:#?}\n" , classified_uses) . as_bytes ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.classified_uses]
expression_str = "classified_uses"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'"dependency-analyzer" . to_string ()']
expression_str = '"dependency-analyzer" . to_string ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'format ! ("Failed to write run_all_tests.sh to {}" , script_path . display ())']
expression_str = 'format ! ("Failed to write run_all_tests.sh to {}" , script_path . display ())'
depth = 5
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions."& stats . line_stats"]
expression_str = "& stats . line_stats"
depth = 3
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'fs :: write (& output_path , toml_string) . context (format ! ("Failed to write TOML to file: {:?}" , output_path)) ?']
expression_str = 'fs :: write (& output_path , toml_string) . context (format ! ("Failed to write TOML to file: {:?}" , output_path)) ?'
depth = 3
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'" Extract and organize numerical constants into a hierarchical directory structure."']
expression_str = '" Extract and organize numerical constants into a hierarchical directory structure."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'for (value , count) in sorted_values { println ! ("  Value: {}, Count: {}" , value , count) ; }']
expression_str = 'for (value , count) in sorted_values { println ! ("  Value: {}, Count: {}" , value , count) ; }'
depth = 5
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions.'"#!/bin/bash\n\n"']
expression_str = '"#!/bin/bash\n\n"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'report_content . push_str ("## Detailed Results\n")']
expression_str = 'report_content . push_str ("## Detailed Results\n")'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."if let Some (struct_lattice_info) = self . struct_lattices . get_mut (& impl_for_type_name) { let mut sub_visitor = StructFieldCoOccurrenceVisitor { _struct_name : & impl_for_type_name , current_field_accesses : BTreeSet :: new () , struct_lattice_info , } ; sub_visitor . visit_item_impl (i) ; }"]
expression_str = "if let Some (struct_lattice_info) = self . struct_lattices . get_mut (& impl_for_type_name) { let mut sub_visitor = StructFieldCoOccurrenceVisitor { _struct_name : & impl_for_type_name , current_field_accesses : BTreeSet :: new () , struct_lattice_info , } ; sub_visitor . visit_item_impl (i) ; }"
depth = 3
used_types = []
other_types_count = 0
node_type = "If"

[expressions."i . method"]
expression_str = "i . method"
depth = 4
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'"Array" . to_string ()']
expression_str = '"Array" . to_string ()'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."parse_functor . map (writer , raw_file) . await"]
expression_str = "parse_functor . map (writer , raw_file) . await"
depth = 4
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.'fs :: create_dir_all (& crate_path . join ("src"))']
expression_str = 'fs :: create_dir_all (& crate_path . join ("src"))'
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."args . filter_names"]
expression_str = "args . filter_names"
depth = 5
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'"rustc "']
expression_str = '"rustc "'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'structure . attrs . iter () . any (| attr | { if attr . path () . is_ident ("derive") { if let syn :: Meta :: List (meta_list) = & attr . meta { meta_list . tokens . to_string () . contains ("Parser") } else { false } } else { false } })']
expression_str = 'structure . attrs . iter () . any (| attr | { if attr . path () . is_ident ("derive") { if let syn :: Meta :: List (meta_list) = & attr . meta { meta_list . tokens . to_string () . contains ("Parser") } else { false } } else { false } })'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."& mut symbol_map"]
expression_str = "& mut symbol_map"
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'code . push_str ("pub static AST_STATISTICS: Lazy<AstStatistics> = Lazy::new(|| {\n")']
expression_str = 'code . push_str ("pub static AST_STATISTICS: Lazy<AstStatistics> = Lazy::new(|| {\n")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."for arg in angle_args . args . iter () { if let syn :: GenericArgument :: Type (syn :: Type :: Path (inner_type_path)) = arg { add_uses_from_type_path (inner_type_path , uses) ; } }"]
expression_str = "for arg in angle_args . args . iter () { if let syn :: GenericArgument :: Type (syn :: Type :: Path (inner_type_path)) = arg { add_uses_from_type_path (inner_type_path , uses) ; } }"
depth = 5
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions.'base_path . join ("::")']
expression_str = 'base_path . join ("::")'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"--report"']
expression_str = '"--report"'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."WalkDir :: new (& repo_root) . into_iter ()"]
expression_str = "WalkDir :: new (& repo_root) . into_iter ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'if let Some (ld_library_path_env) = std :: env :: var_os ("LD_LIBRARY_PATH") { writer . write_all (format ! ("  -> LD_LIBRARY_PATH: {:#?}\n" , ld_library_path_env) . as_bytes ()) . await ? ; }']
expression_str = 'if let Some (ld_library_path_env) = std :: env :: var_os ("LD_LIBRARY_PATH") { writer . write_all (format ! ("  -> LD_LIBRARY_PATH: {:#?}\n" , ld_library_path_env) . as_bytes ()) . await ? ; }'
depth = 4
used_types = []
other_types_count = 0
node_type = "If"

[expressions.impl_lattice_info]
expression_str = "impl_lattice_info"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."self . current_depth"]
expression_str = "self . current_depth"
depth = 3
used_types = []
other_types_count = 0
node_type = "Field"

[expressions."if main_rs . exists () { main_rs } else { return Ok (()) ; }"]
expression_str = "if main_rs . exists () { main_rs } else { return Ok (()) ; }"
depth = 3
used_types = []
other_types_count = 0
node_type = "If"

[expressions."tokio :: fs :: write (& cached_file_path , & relevant_expanded_code) . await"]
expression_str = "tokio :: fs :: write (& cached_file_path , & relevant_expanded_code) . await"
depth = 4
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."tokio :: io :: stdout"]
expression_str = "tokio :: io :: stdout"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."* self . bag_of_words . entry (subword) . or_insert (0)"]
expression_str = "* self . bag_of_words . entry (subword) . or_insert (0)"
depth = 4
used_types = []
other_types_count = 0
node_type = "Unary"

[expressions.'if current_file_size > 0 { let file_path = output_dir . join (format ! ("numerical_constants_{}.rs" , file_idx)) ; tokio :: fs :: create_dir_all (file_path . parent () . unwrap ()) . await ? ; tokio :: fs :: write (& file_path , current_file_content . as_bytes ()) . await ? ; println ! ("    -> Wrote numerical constants to {:?}\n" , file_path) ; }']
expression_str = 'if current_file_size > 0 { let file_path = output_dir . join (format ! ("numerical_constants_{}.rs" , file_idx)) ; tokio :: fs :: create_dir_all (file_path . parent () . unwrap ()) . await ? ; tokio :: fs :: write (& file_path , current_file_content . as_bytes ()) . await ? ; println ! ("    -> Wrote numerical constants to {:?}\n" , file_path) ; }'
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'add_primitive_type (& mut symbols , "isize")']
expression_str = 'add_primitive_type (& mut symbols , "isize")'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."grouped_by_node_type . keys ()"]
expression_str = "grouped_by_node_type . keys ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"tests/integration_test.rs"']
expression_str = '"tests/integration_test.rs"'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."fs :: read_to_string (& crate_root_path)"]
expression_str = "fs :: read_to_string (& crate_root_path)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."identifier . clone ()"]
expression_str = "identifier . clone ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'" Run in dry-run mode, printing changes without modifying files."']
expression_str = '" Run in dry-run mode, printing changes without modifying files."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'" Process a single file"']
expression_str = '" Process a single file"'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'format ! ("{}.rs" , struct_name)']
expression_str = 'format ! ("{}.rs" , struct_name)'
depth = 4
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions.'"./generated_declarations"']
expression_str = '"./generated_declarations"'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'"Let" . to_string ()']
expression_str = '"Let" . to_string ()'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'["bool" , "char" , "f32" , "f64" , "i8" , "i16" , "i32" , "i64" , "i128" , "isize" , "u8" , "u16" , "u32" , "u64" , "u128" , "usize" , "str" , "String" , "Vec" , "Option" , "Result" , "HashMap" , "HashSet" , "Box" , "Arc" , "Rc" ,]']
expression_str = '["bool" , "char" , "f32" , "f64" , "i8" , "i16" , "i32" , "i64" , "i128" , "isize" , "u8" , "u16" , "u32" , "u64" , "u128" , "usize" , "str" , "String" , "Vec" , "Option" , "Result" , "HashMap" , "HashSet" , "Box" , "Arc" , "Rc" ,]'
depth = 2
used_types = []
other_types_count = 0
node_type = "Array"

[expressions."all_user_defined_types . into_iter () . collect ()"]
expression_str = "all_user_defined_types . into_iter () . collect ()"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'version_line . and_then (| line | line . split_whitespace () . nth (1)) . unwrap_or ("unknown")']
expression_str = 'version_line . and_then (| line | line . split_whitespace () . nth (1)) . unwrap_or ("unknown")'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'writer . write_all (format ! ("---\n--- Stage 3: Classifying Use Statements ---\n") . as_bytes ())']
expression_str = 'writer . write_all (format ! ("---\n--- Stage 3: Classifying Use Statements ---\n") . as_bytes ())'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"// New prelude content"']
expression_str = '"// New prelude content"'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'match syn :: parse_file (& file_content) { Ok (file) => parsed_files . push ((file_path . clone () , file)) , Err (e) => { eprintln ! ("Warning: Could not re-parse file for Pass 2 {}: {}" , file_path . display () , e) ; } }']
expression_str = 'match syn :: parse_file (& file_content) { Ok (file) => parsed_files . push ((file_path . clone () , file)) , Err (e) => { eprintln ! ("Warning: Could not re-parse file for Pass 2 {}: {}" , file_path . display () , e) ; } }'
depth = 5
used_types = []
other_types_count = 0
node_type = "Match"

[expressions.'"aarch64-unknown-linux-gnu" . to_string ()']
expression_str = '"aarch64-unknown-linux-gnu" . to_string ()'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"generated_workspace"']
expression_str = '"generated_workspace"'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."ImplLatticeInfo :: new (impl_for_type_name . clone ())"]
expression_str = "ImplLatticeInfo :: new (impl_for_type_name . clone ())"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'"HashSet"']
expression_str = '"HashSet"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."lattice_info . variant_type_co_occurrences . is_empty ()"]
expression_str = "lattice_info . variant_type_co_occurrences . is_empty ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."fs :: read_to_string (& output_path)"]
expression_str = "fs :: read_to_string (& output_path)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.constants]
expression_str = "constants"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'"type"']
expression_str = '"type"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."Default :: default ()"]
expression_str = "Default :: default ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."prelude_generator :: public_tests :: test_modify_crate_root_already_has_prelude ()"]
expression_str = "prelude_generator :: public_tests :: test_modify_crate_root_already_has_prelude ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.validated_file]
expression_str = "validated_file"
depth = 2
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'"// No struct declarations found in this module.\n" . to_string ()']
expression_str = '"// No struct declarations found in this module.\n" . to_string ()'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'report_content . push_str ("  No method co-occurrence data collected.\n")']
expression_str = 'report_content . push_str ("  No method co-occurrence data collected.\n")'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'writer . write_all (format ! ("--- Stage 3: Classifying Use Statements ---\n") . as_bytes ())']
expression_str = 'writer . write_all (format ! ("--- Stage 3: Classifying Use Statements ---\n") . as_bytes ())'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."stats . snippet_length_stats"]
expression_str = "stats . snippet_length_stats"
depth = 4
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'"use syn::visit::Visit;\n"']
expression_str = '"use syn::visit::Visit;\n"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'writer . write_all (format ! ("        -> Writing expanded code to cache for: {}\n" , file_path . display ()) . as_bytes ()) . await ?']
expression_str = 'writer . write_all (format ! ("        -> Writing expanded code to cache for: {}\n" , file_path . display ()) . as_bytes ()) . await ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."& declarations"]
expression_str = "& declarations"
depth = 3
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'if let Some (config_path) = & args . config_file_path { Some (config_parser :: read_config (config_path , & project_root) ?) } else { let default_config_path = project_root . join ("config.toml") ; if default_config_path . exists () { Some (config_parser :: read_config (& default_config_path , & project_root) ?) } else { None } }']
expression_str = 'if let Some (config_path) = & args . config_file_path { Some (config_parser :: read_config (config_path , & project_root) ?) } else { let default_config_path = project_root . join ("config.toml") ; if default_config_path . exists () { Some (config_parser :: read_config (& default_config_path , & project_root) ?) } else { None } }'
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'"Binary"']
expression_str = '"Binary"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."get_rustc_info () ?"]
expression_str = "get_rustc_info () ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'fs :: write (& script_path , script_content) . with_context (| | format ! ("Failed to write run_all_tests.sh to {}" , script_path . display ())) ?']
expression_str = 'fs :: write (& script_path , script_content) . with_context (| | format ! ("Failed to write run_all_tests.sh to {}" , script_path . display ())) ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'{ if attr . path () . is_ident ("derive") { if let syn :: Meta :: List (meta_list) = & attr . meta { meta_list . tokens . to_string () . contains ("Parser") } else { false } } else { false } }']
expression_str = '{ if attr . path () . is_ident ("derive") { if let syn :: Meta :: List (meta_list) = & attr . meta { meta_list . tokens . to_string () . contains ("Parser") } else { false } } else { false } }'
depth = 5
used_types = []
other_types_count = 0
node_type = "Block"

[expressions.'| | format ! ("Failed to read config file: {}" , config_path . display ())']
expression_str = '| | format ! ("Failed to read config file: {}" , config_path . display ())'
depth = 4
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions."fs :: create_dir_all (& dst) . await"]
expression_str = "fs :: create_dir_all (& dst) . await"
depth = 3
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.'"MacroExpansionFailed"']
expression_str = '"MacroExpansionFailed"'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.contains_complex_attributes]
expression_str = "contains_complex_attributes"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."tokio :: fs :: create_dir_all (& output_dir) . await"]
expression_str = "tokio :: fs :: create_dir_all (& output_dir) . await"
depth = 4
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."for (_ , info) in all_expression_info { if info . used_types . contains (& target_type) { let other_types_count = info . used_types . len () . saturating_sub (1) ; grouped_by_node_type . entry (info . node_type . clone ()) . or_default () . entry (other_types_count) . or_default () . entry (info . depth) . or_default () . push (info) ; } }"]
expression_str = "for (_ , info) in all_expression_info { if info . used_types . contains (& target_type) { let other_types_count = info . used_types . len () . saturating_sub (1) ; grouped_by_node_type . entry (info . node_type . clone ()) . or_default () . entry (other_types_count) . or_default () . entry (info . depth) . or_default () . push (info) ; } }"
depth = 3
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions."DependencyCollector { dependencies : HashSet :: new () , }"]
expression_str = "DependencyCollector { dependencies : HashSet :: new () , }"
depth = 2
used_types = []
other_types_count = 0
node_type = "Struct"

[expressions.'writer . write_all (format ! ("  -> Extracted {} use statements.\n" , use_statements . 0 . len ()) . as_bytes () ,)']
expression_str = 'writer . write_all (format ! ("  -> Extracted {} use statements.\n" , use_statements . 0 . len ()) . as_bytes () ,)'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."generate_prelude (& src_dir , prelude_content , false , false) ?"]
expression_str = "generate_prelude (& src_dir , prelude_content , false , false) ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'fs :: copy (file_path , & temp_lib_rs_path) . await . context ("Failed to copy source file to temporary lib.rs")']
expression_str = 'fs :: copy (file_path , & temp_lib_rs_path) . await . context ("Failed to copy source file to temporary lib.rs")'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."config . bins"]
expression_str = "config . bins"
depth = 5
used_types = []
other_types_count = 0
node_type = "Field"

[expressions."& mut all_declarations"]
expression_str = "& mut all_declarations"
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."String :: new"]
expression_str = "String :: new"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'fs :: create_dir_all (& project_root) . context (format ! ("Failed to create project root: {:?}" , project_root))']
expression_str = 'fs :: create_dir_all (& project_root) . context (format ! ("Failed to create project root: {:?}" , project_root))'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."vec ! []"]
expression_str = "vec ! []"
depth = 3
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions."& stats . processing_time_stats"]
expression_str = "& stats . processing_time_stats"
depth = 3
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'"u32"']
expression_str = '"u32"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."| s | s . to_string ()"]
expression_str = "| s | s . to_string ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions."HuggingFaceValidatorFunctor { args : args . clone () , hf_validator_path , }"]
expression_str = "HuggingFaceValidatorFunctor { args : args . clone () , hf_validator_path , }"
depth = 2
used_types = []
other_types_count = 0
node_type = "Struct"

[expressions.'fs :: read_to_string (file_path) . with_context (| | format ! ("Failed to read file: {}" , file_path . display ())) ?']
expression_str = 'fs :: read_to_string (file_path) . with_context (| | format ! ("Failed to read file: {}" , file_path . display ())) ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'file_path . is_file () && file_path . extension () . map_or (false , | ext | ext == "rs")']
expression_str = 'file_path . is_file () && file_path . extension () . map_or (false , | ext | ext == "rs")'
depth = 4
used_types = []
other_types_count = 0
node_type = "Binary"

[expressions.'format ! ("        -> PATH environment variable: {:?}\n" , std :: env :: var ("PATH")) . as_bytes ()']
expression_str = 'format ! ("        -> PATH environment variable: {:?}\n" , std :: env :: var ("PATH")) . as_bytes ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."if is_complex_type (& type_name) { entry . layer = Some (1) ; }"]
expression_str = "if is_complex_type (& type_name) { entry . layer = Some (1) ; }"
depth = 4
used_types = []
other_types_count = 0
node_type = "If"

[expressions."& crate_root_path"]
expression_str = "& crate_root_path"
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'format ! ("Failed to create output directory {:?}" , consts_output_dir)']
expression_str = 'format ! ("Failed to create output directory {:?}" , consts_output_dir)'
depth = 5
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions.'anyhow :: anyhow ! ("test_verification_output_dir is required when compile_tests is true")']
expression_str = 'anyhow :: anyhow ! ("test_verification_output_dir is required when compile_tests is true")'
depth = 5
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions.'{ let full_path = base_path . join ("::") ; flat_uses . push (UseStatement { statement : format ! ("use {};" , full_path) , error : None , git_details : None , nix_details : None , rust_details : None , cargo_details : None , syn_details : None , llvm_details : None , linux_details : None , }) ; }']
expression_str = '{ let full_path = base_path . join ("::") ; flat_uses . push (UseStatement { statement : format ! ("use {};" , full_path) , error : None , git_details : None , nix_details : None , rust_details : None , cargo_details : None , syn_details : None , llvm_details : None , linux_details : None , }) ; }'
depth = 3
used_types = []
other_types_count = 0
node_type = "Block"

[expressions."Ok (config)"]
expression_str = "Ok (config)"
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."self . verbose > 0"]
expression_str = "self . verbose > 0"
depth = 4
used_types = []
other_types_count = 0
node_type = "Binary"

[expressions."& * i . self_ty"]
expression_str = "& * i . self_ty"
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."for field in structure . fields . iter () { if let Type :: Path (type_path) = & field . ty { for segment in type_path . path . segments . iter () { let ident_str = segment . ident . to_string () ; if is_complex_type (& ident_str) { return true ; } if let PathArguments :: AngleBracketed (angle_args) = & segment . arguments { for arg in angle_args . args . iter () { if let GenericArgument :: Type (inner_ty) = arg { if contains_complex_type_in_type (inner_ty) { return true ; } } } } } } }"]
expression_str = "for field in structure . fields . iter () { if let Type :: Path (type_path) = & field . ty { for segment in type_path . path . segments . iter () { let ident_str = segment . ident . to_string () ; if is_complex_type (& ident_str) { return true ; } if let PathArguments :: AngleBracketed (angle_args) = & segment . arguments { for arg in angle_args . args . iter () { if let GenericArgument :: Type (inner_ty) = arg { if contains_complex_type_in_type (inner_ty) { return true ; } } } } } } }"
depth = 2
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions."TypeUsageVisitor { max_depth , current_depth : 0 , expressions : HashMap :: new () , struct_lattices : HashMap :: new () , enum_lattices : HashMap :: new () , impl_lattices : HashMap :: new () , }"]
expression_str = "TypeUsageVisitor { max_depth , current_depth : 0 , expressions : HashMap :: new () , struct_lattices : HashMap :: new () , enum_lattices : HashMap :: new () , impl_lattices : HashMap :: new () , }"
depth = 2
used_types = []
other_types_count = 0
node_type = "Struct"

[expressions.prelude_mod]
expression_str = "prelude_mod"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.cached_file_path]
expression_str = "cached_file_path"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'code . push_str (& format ! ("    snippet_length_stats.insert(\"{}\".to_string(), ({}, {}, {}, {}));\n" , node_type , min , max , sum , count) ,)']
expression_str = 'code . push_str (& format ! ("    snippet_length_stats.insert(\"{}\".to_string(), ({}, {}, {}, {}));\n" , node_type , min , max , sum , count) ,)'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'node_type_counts . insert ("function" . to_string () , 6)']
expression_str = 'node_type_counts . insert ("function" . to_string () , 6)'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.struct_lattice_info]
expression_str = "struct_lattice_info"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'"Failed to remove existing output directory"']
expression_str = '"Failed to remove existing output directory"'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."sorted_terms . iter ()"]
expression_str = "sorted_terms . iter ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."all_user_defined_types . into_iter ()"]
expression_str = "all_user_defined_types . into_iter ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"Box"']
expression_str = '"Box"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."& output_path"]
expression_str = "& output_path"
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."& field . ty"]
expression_str = "& field . ty"
depth = 5
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."METRICS . lock ()"]
expression_str = "METRICS . lock ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."tokio :: fs :: write (& file_path , current_file_content . as_bytes ()) . await ?"]
expression_str = "tokio :: fs :: write (& file_path , current_file_content . as_bytes ()) . await ?"
depth = 3
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'Command :: new ("rustc") . arg ("--version") . arg ("--verbose") . output ()']
expression_str = 'Command :: new ("rustc") . arg ("--version") . arg ("--verbose") . output ()'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'report_content . push_str (& format ! ("- Total files processed: {}\n" , total_files))']
expression_str = 'report_content . push_str (& format ! ("- Total files processed: {}\n" , total_files))'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."fs :: read_to_string (path) ?"]
expression_str = "fs :: read_to_string (path) ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."quote :: quote ! { # structure }"]
expression_str = "quote :: quote ! { # structure }"
depth = 5
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions.'writer . write_all (format ! ("        -> Running cargo rustc -Zunpretty=expanded --lib for: {}\n" , file_path . display ()) . as_bytes ()) . await ?']
expression_str = 'writer . write_all (format ! ("        -> Running cargo rustc -Zunpretty=expanded --lib for: {}\n" , file_path . display ()) . as_bytes ()) . await ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."MetadataCommand :: new () . current_dir (workspace_path)"]
expression_str = "MetadataCommand :: new () . current_dir (workspace_path)"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."entry . end_time"]
expression_str = "entry . end_time"
depth = 5
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.impl_for_type]
expression_str = "impl_for_type"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."expr . to_token_stream ()"]
expression_str = "expr . to_token_stream ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'uses . insert ("use std::collections::HashMap;\n")']
expression_str = 'uses . insert ("use std::collections::HashMap;\n")'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."std :: fs :: read_to_string (path) ?"]
expression_str = "std :: fs :: read_to_string (path) ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."for subword in tokenize_ident_to_subwords (& ident . to_string ()) { * self . bag_of_words . entry (subword) . or_insert (0) += 1 ; }"]
expression_str = "for subword in tokenize_ident_to_subwords (& ident . to_string ()) { * self . bag_of_words . entry (subword) . or_insert (0) += 1 ; }"
depth = 2
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions."write_numerical_constants_to_hierarchical_structure (& all_numerical_constants , & numerical_output_dir)"]
expression_str = "write_numerical_constants_to_hierarchical_structure (& all_numerical_constants , & numerical_output_dir)"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'| | format ! ("Failed to write Test_Verification_Report.md to {}" , report_path . display ())']
expression_str = '| | format ! ("Failed to write Test_Verification_Report.md to {}" , report_path . display ())'
depth = 4
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions."grouped_by_depth . keys () . cloned () . collect ()"]
expression_str = "grouped_by_depth . keys () . cloned () . collect ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.test_functions]
expression_str = "test_functions"
depth = 2
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."args . report"]
expression_str = "args . report"
depth = 3
used_types = []
other_types_count = 0
node_type = "Field"

[expressions."line . len ()"]
expression_str = "line . len ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."output . status"]
expression_str = "output . status"
depth = 5
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'if constants_by_type_and_size . is_empty () { println ! ("No numerical constants found.") ; } else { for (type_name , values) in & constants_by_type_and_size { println ! ("Type: {}" , type_name) ; let mut sorted_values : Vec < (& String , & usize) > = values . iter () . collect () ; sorted_values . sort_by (| a , b | a . 0 . cmp (b . 0)) ; for (value , count) in sorted_values { println ! ("  Value: {}, Count: {}" , value , count) ; } } }']
expression_str = 'if constants_by_type_and_size . is_empty () { println ! ("No numerical constants found.") ; } else { for (type_name , values) in & constants_by_type_and_size { println ! ("Type: {}" , type_name) ; let mut sorted_values : Vec < (& String , & usize) > = values . iter () . collect () ; sorted_values . sort_by (| a , b | a . 0 . cmp (b . 0)) ; for (value , count) in sorted_values { println ! ("  Value: {}, Count: {}" , value , count) ; } } }'
depth = 2
used_types = [
    "& usize",
    "& String",
    "(& String , & usize)",
    "Vec",
]
other_types_count = 4
node_type = "If"

[expressions."dir . join (crate_name)"]
expression_str = "dir . join (crate_name)"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."quote ! (# use_item)"]
expression_str = "quote ! (# use_item)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions.'"Break" . to_string ()']
expression_str = '"Break" . to_string ()'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'tokio :: fs :: write (hf_validator_project_dir . join ("Cargo.toml") , cargo_toml_content) . await ?']
expression_str = 'tokio :: fs :: write (hf_validator_project_dir . join ("Cargo.toml") , cargo_toml_content) . await ?'
depth = 4
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."std :: fs :: read_to_string"]
expression_str = "std :: fs :: read_to_string"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'i . member . clone () . into_token_stream () . to_string () . strip_prefix (".") . map (| s | s . to_string ())']
expression_str = 'i . member . clone () . into_token_stream () . to_string () . strip_prefix (".") . map (| s | s . to_string ())'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"unknown_crate"']
expression_str = '"unknown_crate"'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'hf_dataset_reader :: analyze_hf_dataset_asts (& dataset_output_path) . await . context ("Failed to analyze ASTs from Hugging Face dataset")']
expression_str = 'hf_dataset_reader :: analyze_hf_dataset_asts (& dataset_output_path) . await . context ("Failed to analyze ASTs from Hugging Face dataset")'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."! all_collected_errors_aggregated . is_empty ()"]
expression_str = "! all_collected_errors_aggregated . is_empty ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "Unary"

[expressions."syn :: visit :: visit_item_enum (self , i)"]
expression_str = "syn :: visit :: visit_item_enum (self , i)"
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'if use_statement . contains ("syn") { current_use_statement . syn_details = Some (pipeline_traits :: SynDetails :: Info (pipeline_traits :: SynInfo { parsed_type : "ItemUse" . to_string () , version : "inferred_from_use" . to_string () , })) ; }']
expression_str = 'if use_statement . contains ("syn") { current_use_statement . syn_details = Some (pipeline_traits :: SynDetails :: Info (pipeline_traits :: SynInfo { parsed_type : "ItemUse" . to_string () , version : "inferred_from_use" . to_string () , })) ; }'
depth = 5
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'"primitive_type"']
expression_str = '"primitive_type"'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."rustc_info . host"]
expression_str = "rustc_info . host"
depth = 4
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.crate_root]
expression_str = "crate_root"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.None]
expression_str = "None"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.tempdir]
expression_str = "tempdir"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'UseStatement { statement : format ! ("use {} as {};" , full_path , rename . rename . to_string ()) , error : None , git_details : None , nix_details : None , rust_details : None , cargo_details : None , syn_details : None , llvm_details : None , linux_details : None , }']
expression_str = 'UseStatement { statement : format ! ("use {} as {};" , full_path , rename . rename . to_string ()) , error : None , git_details : None , nix_details : None , rust_details : None , cargo_details : None , syn_details : None , llvm_details : None , linux_details : None , }'
depth = 5
used_types = []
other_types_count = 0
node_type = "Struct"

[expressions.'& format ! ("pushd \"{}\"\n" , crate_path . display ())']
expression_str = '& format ! ("pushd \"{}\"\n" , crate_path . display ())'
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."Ok (use_statements)"]
expression_str = "Ok (use_statements)"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."& const_name"]
expression_str = "& const_name"
depth = 5
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."& file_name"]
expression_str = "& file_name"
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."pipeline :: run_category_pipeline (& mut stdout , & dummy_content , & dummy_path , & args , & Some (config . clone ()) ,) . await ?"]
expression_str = "pipeline :: run_category_pipeline (& mut stdout , & dummy_content , & dummy_path , & args , & Some (config . clone ()) ,) . await ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'UseStatement { statement : format ! ("use {};" , full_path) , error : None , git_details : None , nix_details : None , rust_details : None , cargo_details : None , syn_details : None , llvm_details : None , linux_details : None , }']
expression_str = 'UseStatement { statement : format ! ("use {};" , full_path) , error : None , git_details : None , nix_details : None , rust_details : None , cargo_details : None , syn_details : None , llvm_details : None , linux_details : None , }'
depth = 5
used_types = []
other_types_count = 0
node_type = "Struct"

[expressions.'" Path to the directory where individually generated Level 0 declaration files will be placed."']
expression_str = '" Path to the directory where individually generated Level 0 declaration files will be placed."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'{ eprintln ! (r"Warning: Could not parse file for bag of words analysis: {}" , path . display ()) ; }']
expression_str = '{ eprintln ! (r"Warning: Could not parse file for bag of words analysis: {}" , path . display ()) ; }'
depth = 5
used_types = []
other_types_count = 0
node_type = "Block"

[expressions.'report_content . push_str ("# Test Verification Report\n\n")']
expression_str = 'report_content . push_str ("# Test Verification Report\n\n")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.hf_validator_project_dir]
expression_str = "hf_validator_project_dir"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."self . enum_lattice_info . add_co_occurrence (matched_variant_types)"]
expression_str = "self . enum_lattice_info . add_co_occurrence (matched_variant_types)"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."struct_lattices . is_empty ()"]
expression_str = "struct_lattices . is_empty ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'_args . test_verification_output_dir . clone () . ok_or_else (| | anyhow :: anyhow ! ("test_verification_output_dir is required when compile_tests is true")) ?']
expression_str = '_args . test_verification_output_dir . clone () . ok_or_else (| | anyhow :: anyhow ! ("test_verification_output_dir is required when compile_tests is true")) ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."Default :: default"]
expression_str = "Default :: default"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.use_statements]
expression_str = "use_statements"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'if lattice_info . field_co_occurrences . is_empty () { report_content . push_str ("  No field co-occurrence data collected.\n") ; } else { let mut sorted_co_occurrences : Vec < (& BTreeSet < String > , & usize) > = lattice_info . field_co_occurrences . iter () . collect () ; sorted_co_occurrences . sort_by_key (| & (_ , count) | count) ; for (field_types , count) in sorted_co_occurrences { report_content . push_str (& format ! ("  - Co-occurring fields: {:?} (Count: {})\n" , field_types , count)) ; } }']
expression_str = 'if lattice_info . field_co_occurrences . is_empty () { report_content . push_str ("  No field co-occurrence data collected.\n") ; } else { let mut sorted_co_occurrences : Vec < (& BTreeSet < String > , & usize) > = lattice_info . field_co_occurrences . iter () . collect () ; sorted_co_occurrences . sort_by_key (| & (_ , count) | count) ; for (field_types , count) in sorted_co_occurrences { report_content . push_str (& format ! ("  - Co-occurring fields: {:?} (Count: {})\n" , field_types , count)) ; } }'
depth = 4
used_types = [
    "BTreeSet",
    "& usize",
    "(& BTreeSet < String > , & usize)",
    "& BTreeSet < String >",
    "Vec",
]
other_types_count = 5
node_type = "If"

[expressions."prelude_generator :: public_tests :: test_modify_file_adds_prelude_and_removes_uses"]
expression_str = "prelude_generator :: public_tests :: test_modify_file_adds_prelude_and_removes_uses"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."error_message . clone ()"]
expression_str = "error_message . clone ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."if let syn :: Type :: Path (type_path) = & field . ty { add_uses_from_type_path (type_path , & mut uses) ; }"]
expression_str = "if let syn :: Type :: Path (type_path) = & field . ty { add_uses_from_type_path (type_path , & mut uses) ; }"
depth = 3
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'fs :: copy (& original_cargo_toml_path , & temp_cargo_toml_path) . await . context ("Failed to copy Cargo.toml to temporary directory")']
expression_str = 'fs :: copy (& original_cargo_toml_path , & temp_cargo_toml_path) . await . context ("Failed to copy Cargo.toml to temporary directory")'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."& std :: path :: PathBuf :: new ()"]
expression_str = "& std :: path :: PathBuf :: new ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."! enum_lattices . is_empty ()"]
expression_str = "! enum_lattices . is_empty ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "Unary"

[expressions."PathBuf :: from (file_path_str . clone ())"]
expression_str = "PathBuf :: from (file_path_str . clone ())"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."RawFile (file_path_str . to_string () , file_content . to_string ())"]
expression_str = "RawFile (file_path_str . to_string () , file_content . to_string ())"
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'setup_test_crate (& project_root , "my-crate" , "use std::collections::HashMap;\nfn my_func() {}\n" ,)']
expression_str = 'setup_test_crate (& project_root , "my-crate" , "use std::collections::HashMap;\nfn my_func() {}\n" ,)'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."prelude_generator :: public_tests :: test_generate_prelude_dry_run () ?"]
expression_str = "prelude_generator :: public_tests :: test_generate_prelude_dry_run () ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'node_type_counts . insert ("variable" . to_string () , 41)']
expression_str = 'node_type_counts . insert ("variable" . to_string () , 41)'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'processing_time_stats . insert ("variable" . to_string () , (1 , 1 , 41 , 41))']
expression_str = 'processing_time_stats . insert ("variable" . to_string () , (1 , 1 , 41 , 41))'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"assert_eq!"']
expression_str = '"assert_eq!"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'report_content . push_str ("\n================================================================\n")']
expression_str = 'report_content . push_str ("\n================================================================\n")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.lib_rs]
expression_str = "lib_rs"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'writer . write_all (format ! ("--- Stage 3: Classifying Use Statements ---\n") . as_bytes ()) . await ?']
expression_str = 'writer . write_all (format ! ("--- Stage 3: Classifying Use Statements ---\n") . as_bytes ()) . await ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."prettyplease :: unparse (& new_ast)"]
expression_str = "prettyplease :: unparse (& new_ast)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'snippet_length_stats . insert ("other" . to_string () , (1 , 92 , 7273 , 230))']
expression_str = 'snippet_length_stats . insert ("other" . to_string () , (1 , 92 , 7273 , 230))'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."matched_variant_types . insert (segment . ident . to_string ())"]
expression_str = "matched_variant_types . insert (segment . ident . to_string ())"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'Box :: pin (async move { measurement :: record_function_entry ("AstReconstructionFunctor::map") ; let ValidatedFile (source_code , dataset_path) = input ; writer . write_all (format ! ("--- Stage 5: AST Reconstruction from Hugging Face Dataset (Mock) ---\n") . as_bytes ()) . await ? ; writer . write_all (format ! ("  -> Dataset path: {:#?}\n" , dataset_path) . as_bytes ()) . await ? ; writer . write_all (format ! ("  -> Returning original source code as mock reconstruction.\n") . as_bytes ()) . await ? ; let __result = Ok (source_code) ; measurement :: record_function_exit ("AstReconstructionFunctor::map") ; __result })']
expression_str = 'Box :: pin (async move { measurement :: record_function_entry ("AstReconstructionFunctor::map") ; let ValidatedFile (source_code , dataset_path) = input ; writer . write_all (format ! ("--- Stage 5: AST Reconstruction from Hugging Face Dataset (Mock) ---\n") . as_bytes ()) . await ? ; writer . write_all (format ! ("  -> Dataset path: {:#?}\n" , dataset_path) . as_bytes ()) . await ? ; writer . write_all (format ! ("  -> Returning original source code as mock reconstruction.\n") . as_bytes ()) . await ? ; let __result = Ok (source_code) ; measurement :: record_function_exit ("AstReconstructionFunctor::map") ; __result })'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."all_collected_errors_aggregated . extend (errors)"]
expression_str = "all_collected_errors_aggregated . extend (errors)"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."& impl_for_type_name"]
expression_str = "& impl_for_type_name"
depth = 5
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."! impl_lattices . is_empty ()"]
expression_str = "! impl_lattices . is_empty ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "Unary"

[expressions."fs :: write (& report_path , report_content)"]
expression_str = "fs :: write (& report_path , report_content)"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."entry_path . strip_prefix (& current_src) . unwrap ()"]
expression_str = "entry_path . strip_prefix (& current_src) . unwrap ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."Ok (ClassifiedUseStatements (classified_uses , HashMap :: new ()))"]
expression_str = "Ok (ClassifiedUseStatements (classified_uses , HashMap :: new ()))"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'generated_decls_output_dir . join (format ! ("layer_{}" , layer))']
expression_str = 'generated_decls_output_dir . join (format ! ("layer_{}" , layer))'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."tokio :: fs :: create_dir_all (& output_dir)"]
expression_str = "tokio :: fs :: create_dir_all (& output_dir)"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."cache_dir . join (cache_key)"]
expression_str = "cache_dir . join (cache_key)"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.max_expression_depth]
expression_str = "max_expression_depth"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'tokio :: fs :: create_dir_all (& string_output_dir) . await . context (format ! ("Failed to create output directory {:?}" , string_output_dir))']
expression_str = 'tokio :: fs :: create_dir_all (& string_output_dir) . await . context (format ! ("Failed to create output directory {:?}" , string_output_dir))'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"Failed to execute rustfmt"']
expression_str = '"Failed to execute rustfmt"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."ident_str . clone ()"]
expression_str = "ident_str . clone ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."| r | matches ! (r . status , FileProcessingStatus :: Failed { .. })"]
expression_str = "| r | matches ! (r . status , FileProcessingStatus :: Failed { .. })"
depth = 4
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions."fs :: read_dir (& current_src) . await"]
expression_str = "fs :: read_dir (& current_src) . await"
depth = 4
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."read_input_file (& args) . await ?"]
expression_str = "read_input_file (& args) . await ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'if args . run_decl_splitter { let project_root = args . path . clone () ; let rustc_info = prelude_generator :: use_extractor :: rustc_info :: get_rustc_info () ? ; command_handlers :: handle_run_decl_splitter (& args , & project_root , & rustc_info) . await ? ; } else if args . analyze_type_usage { type_usage_analyzer :: analyze_type_usage (& args) . await ? ; } else { println ! ("No specific command flag set. Use --help for options.") ; }']
expression_str = 'if args . run_decl_splitter { let project_root = args . path . clone () ; let rustc_info = prelude_generator :: use_extractor :: rustc_info :: get_rustc_info () ? ; command_handlers :: handle_run_decl_splitter (& args , & project_root , & rustc_info) . await ? ; } else if args . analyze_type_usage { type_usage_analyzer :: analyze_type_usage (& args) . await ? ; } else { println ! ("No specific command flag set. Use --help for options.") ; }'
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'format ! ("numerical_constants_{}.rs" , file_idx)']
expression_str = 'format ! ("numerical_constants_{}.rs" , file_idx)'
depth = 4
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions.'fs :: create_dir_all (output_dir) . with_context (| | format ! ("Failed to create output directory {}" , output_dir . display ()))']
expression_str = 'fs :: create_dir_all (output_dir) . with_context (| | format ! ("Failed to create output directory {}" , output_dir . display ()))'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'File :: create (& mapping_file_path) . await . context ("Failed to create mapping.toml") ?']
expression_str = 'File :: create (& mapping_file_path) . await . context ("Failed to create mapping.toml") ?'
depth = 4
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."ReferenceVisitor :: new (& mut symbol_map , & mut all_declarations , current_crate_name , current_module_path , args . verbose ,)"]
expression_str = "ReferenceVisitor :: new (& mut symbol_map , & mut all_declarations , current_crate_name , current_module_path , args . verbose ,)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."for segment in & i . path . segments { self . add_dependency (& segment . ident) ; }"]
expression_str = "for segment in & i . path . segments { self . add_dependency (& segment . ident) ; }"
depth = 2
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions.'format ! ("    line_stats.insert(\"{}\".to_string(), ({}, {}, {}, {}));\n" , node_type , min , max , sum , count)']
expression_str = 'format ! ("    line_stats.insert(\"{}\".to_string(), ({}, {}, {}, {}));\n" , node_type , min , max , sum , count)'
depth = 5
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions.'"Failed to serialize collected analysis data to TOML"']
expression_str = '"Failed to serialize collected analysis data to TOML"'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."tokio :: fs :: write (& public_symbols_output_path , json_content) . await"]
expression_str = "tokio :: fs :: write (& public_symbols_output_path , json_content) . await"
depth = 4
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.0]
expression_str = "0"
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'generated_decls_output_dir . join (format ! ("layer_{}" , layer)) . join ("struct")']
expression_str = 'generated_decls_output_dir . join (format ! ("layer_{}" , layer)) . join ("struct")'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."all_structs_by_layer . get (& 0)"]
expression_str = "all_structs_by_layer . get (& 0)"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.impl_for_type_name]
expression_str = "impl_for_type_name"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'ErrorSample { file_path : file_path . to_path_buf () , rustc_version : rustc_info . version . clone () , rustc_host : rustc_info . host . clone () , error_message : error_message . clone () , error_type : "MacroExpansionFailed" . to_string () , code_snippet : Some (content . to_string ()) , timestamp : Utc :: now () , context : None , }']
expression_str = 'ErrorSample { file_path : file_path . to_path_buf () , rustc_version : rustc_info . version . clone () , rustc_host : rustc_info . host . clone () , error_message : error_message . clone () , error_type : "MacroExpansionFailed" . to_string () , code_snippet : Some (content . to_string ()) , timestamp : Utc :: now () , context : None , }'
depth = 3
used_types = []
other_types_count = 0
node_type = "Struct"

[expressions.'Command :: new ("rustc") . arg ("--version")']
expression_str = 'Command :: new ("rustc") . arg ("--version")'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'format ! ("Failed to write expanded code to cache for {}" , file_path . display ())']
expression_str = 'format ! ("Failed to write expanded code to cache for {}" , file_path . display ())'
depth = 5
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions.'for use_statement in use_statements { let mut current_use_statement = UseStatement { statement : use_statement . clone () , error : None , git_details : None , nix_details : None , rust_details : None , cargo_details : None , syn_details : None , llvm_details : None , linux_details : None , } ; if use_statement . contains ("git") { current_use_statement . git_details = Some (pipeline_traits :: GitDetails :: Info (pipeline_traits :: GitInfo { repo_url : "inferred_from_use" . to_string () , branch : "inferred_from_use" . to_string () , commit_hash : "inferred_from_use" . to_string () , })) ; } if use_statement . contains ("nix") { current_use_statement . nix_details = Some (pipeline_traits :: NixDetails :: Info (pipeline_traits :: NixInfo { flake_path : "inferred_from_use" . to_string () , output_type : "inferred_from_use" . to_string () , })) ; } if use_statement . contains ("rust") || use_statement . contains ("std") || use_statement . contains ("core") { current_use_statement . rust_details = Some (pipeline_traits :: RustDetails :: Info (pipeline_traits :: RustDetailsInfo { version : "inferred_from_use" . to_string () , crate_name : "inferred_from_use" . to_string () , item_path : "inferred_from_use" . to_string () , })) ; } if use_statement . contains ("cargo") { current_use_statement . cargo_details = Some (pipeline_traits :: CargoDetails :: Info (pipeline_traits :: CargoInfo { package_name : "inferred_from_use" . to_string () , version : "inferred_from_use" . to_string () , })) ; } if use_statement . contains ("syn") { current_use_statement . syn_details = Some (pipeline_traits :: SynDetails :: Info (pipeline_traits :: SynInfo { parsed_type : "ItemUse" . to_string () , version : "inferred_from_use" . to_string () , })) ; } if use_statement . contains ("llvm") { current_use_statement . llvm_details = Some (pipeline_traits :: LlvmDetails :: Info (pipeline_traits :: LlvmInfo { ir_version : "inferred_from_use" . to_string () , target_triple : "inferred_from_use" . to_string () , })) ; } if use_statement . contains ("linux") { current_use_statement . linux_details = Some (pipeline_traits :: LinuxDetails :: Info (pipeline_traits :: LinuxInfo { kernel_version : "inferred_from_use" . to_string () , architecture : "inferred_from_use" . to_string () , })) ; } match syn :: parse_str :: < syn :: ItemUse > (& use_statement) { Ok (_) => { } , Err (e) => { current_use_statement . error = Some (e . to_string ()) ; } , } classified_uses . push (current_use_statement) ; }']
expression_str = 'for use_statement in use_statements { let mut current_use_statement = UseStatement { statement : use_statement . clone () , error : None , git_details : None , nix_details : None , rust_details : None , cargo_details : None , syn_details : None , llvm_details : None , linux_details : None , } ; if use_statement . contains ("git") { current_use_statement . git_details = Some (pipeline_traits :: GitDetails :: Info (pipeline_traits :: GitInfo { repo_url : "inferred_from_use" . to_string () , branch : "inferred_from_use" . to_string () , commit_hash : "inferred_from_use" . to_string () , })) ; } if use_statement . contains ("nix") { current_use_statement . nix_details = Some (pipeline_traits :: NixDetails :: Info (pipeline_traits :: NixInfo { flake_path : "inferred_from_use" . to_string () , output_type : "inferred_from_use" . to_string () , })) ; } if use_statement . contains ("rust") || use_statement . contains ("std") || use_statement . contains ("core") { current_use_statement . rust_details = Some (pipeline_traits :: RustDetails :: Info (pipeline_traits :: RustDetailsInfo { version : "inferred_from_use" . to_string () , crate_name : "inferred_from_use" . to_string () , item_path : "inferred_from_use" . to_string () , })) ; } if use_statement . contains ("cargo") { current_use_statement . cargo_details = Some (pipeline_traits :: CargoDetails :: Info (pipeline_traits :: CargoInfo { package_name : "inferred_from_use" . to_string () , version : "inferred_from_use" . to_string () , })) ; } if use_statement . contains ("syn") { current_use_statement . syn_details = Some (pipeline_traits :: SynDetails :: Info (pipeline_traits :: SynInfo { parsed_type : "ItemUse" . to_string () , version : "inferred_from_use" . to_string () , })) ; } if use_statement . contains ("llvm") { current_use_statement . llvm_details = Some (pipeline_traits :: LlvmDetails :: Info (pipeline_traits :: LlvmInfo { ir_version : "inferred_from_use" . to_string () , target_triple : "inferred_from_use" . to_string () , })) ; } if use_statement . contains ("linux") { current_use_statement . linux_details = Some (pipeline_traits :: LinuxDetails :: Info (pipeline_traits :: LinuxInfo { kernel_version : "inferred_from_use" . to_string () , architecture : "inferred_from_use" . to_string () , })) ; } match syn :: parse_str :: < syn :: ItemUse > (& use_statement) { Ok (_) => { } , Err (e) => { current_use_statement . error = Some (e . to_string ()) ; } , } classified_uses . push (current_use_statement) ; }'
depth = 4
used_types = ["ItemUse"]
other_types_count = 1
node_type = "ForLoop"

[expressions.'"Unary" . to_string ()']
expression_str = '"Unary" . to_string ()'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'" Process files in batches of this size"']
expression_str = '" Process files in batches of this size"'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'format ! ("pushd \"{}\"\n" , crate_path . display ())']
expression_str = 'format ! ("pushd \"{}\"\n" , crate_path . display ())'
depth = 5
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions.'"set -e\n\n"']
expression_str = '"set -e\n\n"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."extract_uses_functor . map (writer , parsed_file . clone ()) . await"]
expression_str = "extract_uses_functor . map (writer , parsed_file . clone ()) . await"
depth = 4
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."& all_struct_lattices"]
expression_str = "& all_struct_lattices"
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'fs :: write (& report_path , report_content) . with_context (| | format ! ("Failed to write Test_Verification_Report.md to {}" , report_path . display ())) ?']
expression_str = 'fs :: write (& report_path , report_content) . with_context (| | format ! ("Failed to write Test_Verification_Report.md to {}" , report_path . display ())) ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'PathBuf :: from (format ! ("generated/hf_validator_projects/{}" , short_id))']
expression_str = 'PathBuf :: from (format ! ("generated/hf_validator_projects/{}" , short_id))'
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'"    let mut node_type_counts = HashMap::new();\n"']
expression_str = '"    let mut node_type_counts = HashMap::new();\n"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."visit :: visit_expr_if"]
expression_str = "visit :: visit_expr_if"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."sorted_user_defined_types . sort_unstable ()"]
expression_str = "sorted_user_defined_types . sort_unstable ()"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."prelude_generator :: public_tests :: test_process_crates_integration"]
expression_str = "prelude_generator :: public_tests :: test_process_crates_integration"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."stats . column_stats"]
expression_str = "stats . column_stats"
depth = 4
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'{ let default_config_path = project_root . join ("config.toml") ; if default_config_path . exists () { Some (config_parser :: read_config (& default_config_path , & project_root) ?) } else { None } }']
expression_str = '{ let default_config_path = project_root . join ("config.toml") ; if default_config_path . exists () { Some (config_parser :: read_config (& default_config_path , & project_root) ?) } else { None } }'
depth = 3
used_types = []
other_types_count = 0
node_type = "Block"

[expressions.'tokio :: fs :: write (& ast_statistics_file_path , ast_statistics_code . as_bytes ()) . await . context (format ! ("Failed to write generated AST statistics code to {:?}" , ast_statistics_file_path) ,)']
expression_str = 'tokio :: fs :: write (& ast_statistics_file_path , ast_statistics_code . as_bytes ()) . await . context (format ! ("Failed to write generated AST statistics code to {:?}" , ast_statistics_file_path) ,)'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."new_items . insert (0 , prelude_use)"]
expression_str = "new_items . insert (0 , prelude_use)"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'add_primitive_type (& mut symbols , "f32")']
expression_str = 'add_primitive_type (& mut symbols , "f32")'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'report_content . push_str ("## Tests by Crate\n")']
expression_str = 'report_content . push_str ("## Tests by Crate\n")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."self . dependencies"]
expression_str = "self . dependencies"
depth = 3
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'format ! ("To run all tests, execute the generated script:\n\n```bash\n./{}\n```\n\n" , script_path . file_name () . unwrap () . to_str () . unwrap ())']
expression_str = 'format ! ("To run all tests, execute the generated script:\n\n```bash\n./{}\n```\n\n" , script_path . file_name () . unwrap () . to_str () . unwrap ())'
depth = 4
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions.'type_name == "serde"']
expression_str = 'type_name == "serde"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Binary"

[expressions."tokio :: fs :: write (& error_output_path , error_json_content) . await"]
expression_str = "tokio :: fs :: write (& error_output_path , error_json_content) . await"
depth = 5
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."crate :: declaration_processing :: extract_all_declarations_from_file (file_path , & std :: path :: PathBuf :: new () , false , verbose , & rustc_info , crate_name ,) . await"]
expression_str = "crate :: declaration_processing :: extract_all_declarations_from_file (file_path , & std :: path :: PathBuf :: new () , false , verbose , & rustc_info , crate_name ,) . await"
depth = 3
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.'fs :: write (output_path , json_content) . with_context (| | format ! ("Failed to write aggregated test report to {}" , output_path . display ()))']
expression_str = 'fs :: write (output_path , json_content) . with_context (| | format ! ("Failed to write aggregated test report to {}" , output_path . display ()))'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"Tuple" . to_string ()']
expression_str = '"Tuple" . to_string ()'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"\n\nStruct Lattice Information\n"']
expression_str = '"\n\nStruct Lattice Information\n"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'& format ! ("To run all tests, execute the generated script:\n\n```bash\n./{}\n```\n\n" , script_path . file_name () . unwrap () . to_str () . unwrap ())']
expression_str = '& format ! ("To run all tests, execute the generated script:\n\n```bash\n./{}\n```\n\n" , script_path . file_name () . unwrap () . to_str () . unwrap ())'
depth = 3
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'report_content . push_str ("  No variant type co-occurrence data collected.\n")']
expression_str = 'report_content . push_str ("  No variant type co-occurrence data collected.\n")'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."| line | line . split_whitespace () . nth (1)"]
expression_str = "| line | line . split_whitespace () . nth (1)"
depth = 5
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions."CollectedAnalysisData { expressions : all_expression_info . clone () , struct_lattices : all_struct_lattices . clone () , enum_lattices : all_enum_lattices . clone () , impl_lattices : all_impl_lattices . clone () , }"]
expression_str = "CollectedAnalysisData { expressions : all_expression_info . clone () , struct_lattices : all_struct_lattices . clone () , enum_lattices : all_enum_lattices . clone () , impl_lattices : all_impl_lattices . clone () , }"
depth = 3
used_types = []
other_types_count = 0
node_type = "Struct"

[expressions.'"use pipeline_traits::AstStatistics;\n\n"']
expression_str = '"use pipeline_traits::AstStatistics;\n\n"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."file_path . to_path_buf ()"]
expression_str = "file_path . to_path_buf ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'code . push_str ("        // rust_version_counts,\n")']
expression_str = 'code . push_str ("        // rust_version_counts,\n")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."grouped_by_node_type . entry (info . node_type . clone ()) . or_default () . entry (other_types_count) . or_default () . entry (info . depth) . or_default () . push (info)"]
expression_str = "grouped_by_node_type . entry (info . node_type . clone ()) . or_default () . entry (other_types_count) . or_default () . entry (info . depth) . or_default () . push (info)"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."prelude_generator :: public_tests :: test_modify_file_dry_run ()"]
expression_str = "prelude_generator :: public_tests :: test_modify_file_dry_run ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'"        line_stats,\n"']
expression_str = '"        line_stats,\n"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'writer . write_all (format ! ("  -> AST Reconstruction completed successfully.\n") . as_bytes ()) . await']
expression_str = 'writer . write_all (format ! ("  -> AST Reconstruction completed successfully.\n") . as_bytes ()) . await'
depth = 3
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."main_rs . exists ()"]
expression_str = "main_rs . exists ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions._project_root]
expression_str = "_project_root"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'"Extracting use statements failed"']
expression_str = '"Extracting use statements failed"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'"        // processing_time_stats,\n"']
expression_str = '"        // processing_time_stats,\n"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.symbol_map]
expression_str = "symbol_map"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."_args . test_verification_output_dir . clone ()"]
expression_str = "_args . test_verification_output_dir . clone ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."& dummy_path"]
expression_str = "& dummy_path"
depth = 5
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."args . output_type_usage_report"]
expression_str = "args . output_type_usage_report"
depth = 5
used_types = []
other_types_count = 0
node_type = "Field"

[expressions."all_declarations . into_iter () . map (Into :: into)"]
expression_str = "all_declarations . into_iter () . map (Into :: into)"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."lit_int . base10_digits ()"]
expression_str = "lit_int . base10_digits ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'| | "1.89.0" . to_string ()']
expression_str = '| | "1.89.0" . to_string ()'
depth = 3
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions."(declarations , symbol_map , errors , file_metadata , public_symbols)"]
expression_str = "(declarations , symbol_map , errors , file_metadata , public_symbols)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Tuple"

[expressions.'add_std_lib_symbol (& mut symbols , "HashSet" , "type" , Some ("std::collections"))']
expression_str = 'add_std_lib_symbol (& mut symbols , "HashSet" , "type" , Some ("std::collections"))'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'generated_decl_strings . join ("\n\n")']
expression_str = 'generated_decl_strings . join ("\n\n")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.add_primitive_type]
expression_str = "add_primitive_type"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."& report_content"]
expression_str = "& report_content"
depth = 5
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."grouped_by_other_types . keys () . cloned () . collect ()"]
expression_str = "grouped_by_other_types . keys () . cloned () . collect ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'crate_path . join ("src")']
expression_str = 'crate_path . join ("src")'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'writer . write_all (format ! ("  -> AST Reconstruction completed successfully.\n") . as_bytes ()) . await ?']
expression_str = 'writer . write_all (format ! ("  -> AST Reconstruction completed successfully.\n") . as_bytes ()) . await ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'| | format ! ("Failed to read file content for hashing: {}" , file_path . display ())']
expression_str = '| | format ! ("Failed to read file content for hashing: {}" , file_path . display ())'
depth = 4
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions."tokio :: fs :: write (& cached_file_path , & relevant_expanded_code)"]
expression_str = "tokio :: fs :: write (& cached_file_path , & relevant_expanded_code)"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."results . len ()"]
expression_str = "results . len ()"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'type_name == "syn" || type_name == "String" || type_name == "HashMap"']
expression_str = 'type_name == "syn" || type_name == "String" || type_name == "HashMap"'
depth = 5
used_types = []
other_types_count = 0
node_type = "Binary"

[expressions."& * * ty"]
expression_str = "& * * ty"
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."let Some (ref cfg) = config"]
expression_str = "let Some (ref cfg) = config"
depth = 3
used_types = []
other_types_count = 0
node_type = "Let"

[expressions.relative_path]
expression_str = "relative_path"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'"    let mut line_stats = HashMap::new();\n"']
expression_str = '"    let mut line_stats = HashMap::new();\n"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'for decl in & declarations { symbol_map . add_declaration (decl . get_identifier () , match & decl . item { split_expanded_lib :: DeclarationItem :: Const (_) => "const" . to_string () , split_expanded_lib :: DeclarationItem :: Struct (_) => "struct" . to_string () , split_expanded_lib :: DeclarationItem :: Enum (_) => "enum" . to_string () , split_expanded_lib :: DeclarationItem :: Fn (_) => "function" . to_string () , split_expanded_lib :: DeclarationItem :: Static (_) => "static" . to_string () , split_expanded_lib :: DeclarationItem :: Macro (_) => "macro" . to_string () , split_expanded_lib :: DeclarationItem :: Mod (_) => "module" . to_string () , split_expanded_lib :: DeclarationItem :: Trait (_) => "trait" . to_string () , split_expanded_lib :: DeclarationItem :: TraitAlias (_) => "trait_alias" . to_string () , split_expanded_lib :: DeclarationItem :: Type (_) => "type_alias" . to_string () , split_expanded_lib :: DeclarationItem :: Union (_) => "union" . to_string () , split_expanded_lib :: DeclarationItem :: Other (_) => "other" . to_string () , } , decl . crate_name . clone () , decl . source_file . to_string_lossy () . to_string () ,) ; }']
expression_str = 'for decl in & declarations { symbol_map . add_declaration (decl . get_identifier () , match & decl . item { split_expanded_lib :: DeclarationItem :: Const (_) => "const" . to_string () , split_expanded_lib :: DeclarationItem :: Struct (_) => "struct" . to_string () , split_expanded_lib :: DeclarationItem :: Enum (_) => "enum" . to_string () , split_expanded_lib :: DeclarationItem :: Fn (_) => "function" . to_string () , split_expanded_lib :: DeclarationItem :: Static (_) => "static" . to_string () , split_expanded_lib :: DeclarationItem :: Macro (_) => "macro" . to_string () , split_expanded_lib :: DeclarationItem :: Mod (_) => "module" . to_string () , split_expanded_lib :: DeclarationItem :: Trait (_) => "trait" . to_string () , split_expanded_lib :: DeclarationItem :: TraitAlias (_) => "trait_alias" . to_string () , split_expanded_lib :: DeclarationItem :: Type (_) => "type_alias" . to_string () , split_expanded_lib :: DeclarationItem :: Union (_) => "union" . to_string () , split_expanded_lib :: DeclarationItem :: Other (_) => "other" . to_string () , } , decl . crate_name . clone () , decl . source_file . to_string_lossy () . to_string () ,) ; }'
depth = 2
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions.'"i128"']
expression_str = '"i128"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."if entry_path . is_dir () { copy_dir_all (& entry_path , & destination_path) . await ? ; } else { tokio :: fs :: copy (& entry_path , & destination_path) . await ? ; }"]
expression_str = "if entry_path . is_dir () { copy_dir_all (& entry_path , & destination_path) . await ? ; } else { tokio :: fs :: copy (& entry_path , & destination_path) . await ? ; }"
depth = 5
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'args . max_expression_depth . context ("Max expression depth must be specified for type usage analysis")']
expression_str = 'args . max_expression_depth . context ("Max expression depth must be specified for type usage analysis")'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."crate :: constant_storage :: numerical_constants :: write_numerical_constants_to_hierarchical_structure (& numerical_constants , & numerical_output_dir ,)"]
expression_str = "crate :: constant_storage :: numerical_constants :: write_numerical_constants_to_hierarchical_structure (& numerical_constants , & numerical_output_dir ,)"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."let Ok (file) = syn :: parse_file (& content)"]
expression_str = "let Ok (file) = syn :: parse_file (& content)"
depth = 5
used_types = []
other_types_count = 0
node_type = "Let"

[expressions."error_collection . write_to_file (& errors_json_path) . await ?"]
expression_str = "error_collection . write_to_file (& errors_json_path) . await ?"
depth = 3
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'"60"']
expression_str = '"60"'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."let Some (results_file_path) = & args . results_file"]
expression_str = "let Some (results_file_path) = & args . results_file"
depth = 5
used_types = []
other_types_count = 0
node_type = "Let"

[expressions.'"u8"']
expression_str = '"u8"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'flat_uses . push (UseStatement { statement : format ! ("use {} as {};" , full_path , rename . rename . to_string ()) , error : None , git_details : None , nix_details : None , rust_details : None , cargo_details : None , syn_details : None , llvm_details : None , linux_details : None , })']
expression_str = 'flat_uses . push (UseStatement { statement : format ! ("use {} as {};" , full_path , rename . rename . to_string ()) , error : None , git_details : None , nix_details : None , rust_details : None , cargo_details : None , syn_details : None , llvm_details : None , linux_details : None , })'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."* self . variant_type_co_occurrences . entry (variant_types) . or_insert (0) += 1"]
expression_str = "* self . variant_type_co_occurrences . entry (variant_types) . or_insert (0) += 1"
depth = 2
used_types = []
other_types_count = 0
node_type = "Binary"

[expressions."& i . variants"]
expression_str = "& i . variants"
depth = 3
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'writer . write_all (format ! ("        -> {}\n" , error_message) . as_bytes ()) . await']
expression_str = 'writer . write_all (format ! ("        -> {}\n" , error_message) . as_bytes ()) . await'
depth = 5
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.'self . hf_validator_path . clone () . unwrap_or_else (| | { PathBuf :: from (& self . args . path) . join ("target/release/hf-validator") })']
expression_str = 'self . hf_validator_path . clone () . unwrap_or_else (| | { PathBuf :: from (& self . args . path) . join ("target/release/hf-validator") })'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."self . verbose"]
expression_str = "self . verbose"
depth = 5
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'"const"']
expression_str = '"const"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'Box :: pin (async move { measurement :: record_function_entry ("ParseFunctor::map") ; let RawFile (file_path_str , content) = input ; let file_path = PathBuf :: from (file_path_str . clone ()) ; let parsed_code = tokio :: task :: spawn_blocking (move | | -> anyhow :: Result < _ > { let ast = match syn :: parse_file (& content) { Ok (ast) => ast , Err (_) => { return Err (anyhow :: anyhow ! ("Failed to parse file and expand macros")) ; } } ; Ok (prettyplease :: unparse (& ast)) }) . await . context ("Blocking task for parsing failed") ? ? ; measurement :: record_function_exit ("ParseFunctor::map") ; Ok (ParsedFile (parsed_code , file_path)) })']
expression_str = 'Box :: pin (async move { measurement :: record_function_entry ("ParseFunctor::map") ; let RawFile (file_path_str , content) = input ; let file_path = PathBuf :: from (file_path_str . clone ()) ; let parsed_code = tokio :: task :: spawn_blocking (move | | -> anyhow :: Result < _ > { let ast = match syn :: parse_file (& content) { Ok (ast) => ast , Err (_) => { return Err (anyhow :: anyhow ! ("Failed to parse file and expand macros")) ; } } ; Ok (prettyplease :: unparse (& ast)) }) . await . context ("Blocking task for parsing failed") ? ? ; measurement :: record_function_exit ("ParseFunctor::map") ; Ok (ParsedFile (parsed_code , file_path)) })'
depth = 2
used_types = [
    "_",
    "Result",
]
other_types_count = 2
node_type = "Call"

[expressions.'"Failed to serialize metrics to JSON"']
expression_str = '"Failed to serialize metrics to JSON"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'tokio :: process :: Command :: new ("git") . arg ("init") . current_dir (& hf_validator_project_dir) . output () . await . context ("Failed to initialize git repository")']
expression_str = 'tokio :: process :: Command :: new ("git") . arg ("init") . current_dir (& hf_validator_project_dir) . output () . await . context ("Failed to initialize git repository")'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'WalkDir :: new (project_root) . into_iter () . filter_map (| e | e . ok ()) . filter (| e | e . file_type () . is_file () && e . path () . extension () . map_or (false , | ext | ext == "rs")) . filter (| e | { if let Some (names) = filter_names { names . iter () . any (| name | e . file_name () . to_string_lossy () . contains (name)) } else { true } })']
expression_str = 'WalkDir :: new (project_root) . into_iter () . filter_map (| e | e . ok ()) . filter (| e | e . file_type () . is_file () && e . path () . extension () . map_or (false , | ext | ext == "rs")) . filter (| e | { if let Some (names) = filter_names { names . iter () . any (| name | e . file_name () . to_string_lossy () . contains (name)) } else { true } })'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."Some (config_parser :: read_config (& default_config_path , & project_root) ?)"]
expression_str = "Some (config_parser :: read_config (& default_config_path , & project_root) ?)"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."syn :: parse_file (& content) ?"]
expression_str = "syn :: parse_file (& content) ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.ExtractUsesFunctor]
expression_str = "ExtractUsesFunctor"
depth = 2
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'args . generated_decls_output_dir . clone () . unwrap_or_else (| | { project_root . join ("generated/level0_decls") })']
expression_str = 'args . generated_decls_output_dir . clone () . unwrap_or_else (| | { project_root . join ("generated/level0_decls") })'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'writer . write_all (format ! ("        -> PATH environment variable: {:?}\n" , std :: env :: var ("PATH")) . as_bytes ()) . await ?']
expression_str = 'writer . write_all (format ! ("        -> PATH environment variable: {:?}\n" , std :: env :: var ("PATH")) . as_bytes ()) . await ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'writer . write_all (format ! ("  -> LD_LIBRARY_PATH: {:#?}\n" , ld_library_path_env) . as_bytes ()) . await ?']
expression_str = 'writer . write_all (format ! ("  -> LD_LIBRARY_PATH: {:#?}\n" , ld_library_path_env) . as_bytes ()) . await ?'
depth = 5
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."& 0"]
expression_str = "& 0"
depth = 5
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'writer . write_all (format ! ("  -> Extracted {} use statements.\n" , use_statements . 0 . len ()) . as_bytes ()) . await ?']
expression_str = 'writer . write_all (format ! ("  -> Extracted {} use statements.\n" , use_statements . 0 . len ()) . as_bytes ()) . await ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."b . 1 . count"]
expression_str = "b . 1 . count"
depth = 5
used_types = []
other_types_count = 0
node_type = "Field"

[expressions."for segment in type_path . path . segments . iter () { let type_name = segment . ident . to_string () ; let entry = self . type_map . entry (type_name . clone ()) . or_insert_with (| | TypeInfo { count : 0 , layer : Some (0) }) ; entry . count += 1 ; if is_complex_type (& type_name) { entry . layer = Some (1) ; } if let PathArguments :: AngleBracketed (angle_args) = & segment . arguments { for arg in angle_args . args . iter () { if let GenericArgument :: Type (inner_ty) = arg { self . visit_type (inner_ty) ; } } } }"]
expression_str = "for segment in type_path . path . segments . iter () { let type_name = segment . ident . to_string () ; let entry = self . type_map . entry (type_name . clone ()) . or_insert_with (| | TypeInfo { count : 0 , layer : Some (0) }) ; entry . count += 1 ; if is_complex_type (& type_name) { entry . layer = Some (1) ; } if let PathArguments :: AngleBracketed (angle_args) = & segment . arguments { for arg in angle_args . args . iter () { if let GenericArgument :: Type (inner_ty) = arg { self . visit_type (inner_ty) ; } } } }"
depth = 3
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions."Ok (type_map)"]
expression_str = "Ok (type_map)"
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."sorted_values . sort_by (| a , b | a . 0 . cmp (b . 0))"]
expression_str = "sorted_values . sort_by (| a , b | a . 0 . cmp (b . 0))"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."EnumLatticeInfo :: new (enum_name . clone ())"]
expression_str = "EnumLatticeInfo :: new (enum_name . clone ())"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."fs :: read_to_string (& cached_file_path) . await"]
expression_str = "fs :: read_to_string (& cached_file_path) . await"
depth = 5
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."DependencyCollector :: new ()"]
expression_str = "DependencyCollector :: new ()"
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'report_content . push_str ("  No field co-occurrence data collected.\n")']
expression_str = 'report_content . push_str ("  No field co-occurrence data collected.\n")'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."if let Some (segment) = type_path . path . segments . last () { return segment . ident . to_string () ; }"]
expression_str = "if let Some (segment) = type_path . path . segments . last () { return segment . ident . to_string () ; }"
depth = 3
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'writer . write_all (format ! ("  -> Generated code written to {:?}\n" , output_file_path) . as_bytes () ,)']
expression_str = 'writer . write_all (format ! ("  -> Generated code written to {:?}\n" , output_file_path) . as_bytes () ,)'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'code . push_str ("        rust_version_counts,\n")']
expression_str = 'code . push_str ("        rust_version_counts,\n")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."args . config_file_path"]
expression_str = "args . config_file_path"
depth = 5
used_types = []
other_types_count = 0
node_type = "Field"

[expressions."{ let tokens = quote ! { # c } ; tokens . to_string () }"]
expression_str = "{ let tokens = quote ! { # c } ; tokens . to_string () }"
depth = 5
used_types = []
other_types_count = 0
node_type = "Block"

[expressions."if ! matched_variant_types . is_empty () { self . enum_lattice_info . add_co_occurrence (matched_variant_types) ; }"]
expression_str = "if ! matched_variant_types . is_empty () { self . enum_lattice_info . add_co_occurrence (matched_variant_types) ; }"
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'processing_time_stats . insert ("function" . to_string () , (1 , 1 , 6 , 6))']
expression_str = 'processing_time_stats . insert ("function" . to_string () , (1 , 1 , 6 , 6))'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"This report summarizes the tests found and provides a script to run them.\n\n"']
expression_str = '"This report summarizes the tests found and provides a script to run them.\n\n"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.source_code]
expression_str = "source_code"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."if let syn :: Expr :: Lit (expr_lit) = & * constant . expr { match & expr_lit . lit { syn :: Lit :: Int (_) | syn :: Lit :: Float (_) => numerical_constants . push (constant) , syn :: Lit :: Str (_) => string_constants . push (constant) , _ => { } } } else { }"]
expression_str = "if let syn :: Expr :: Lit (expr_lit) = & * constant . expr { match & expr_lit . lit { syn :: Lit :: Int (_) | syn :: Lit :: Float (_) => numerical_constants . push (constant) , syn :: Lit :: Str (_) => string_constants . push (constant) , _ => { } } } else { }"
depth = 3
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'PathBuf :: from ("./generated_declarations")']
expression_str = 'PathBuf :: from ("./generated_declarations")'
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.setup_test_file]
expression_str = "setup_test_file"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.true]
expression_str = "true"
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'fs :: create_dir_all (& cache_dir) . context ("Failed to create prelude cache directory")']
expression_str = 'fs :: create_dir_all (& cache_dir) . context ("Failed to create prelude cache directory")'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."fs :: write (crate_root . join (\"src/another_mod.rs\") , r#\"\n            #[test]\n            fn another_mod_test() { }\n        \"# ,) ?"]
expression_str = """
fs :: write (crate_root . join ("src/another_mod.rs") , r#"
            #[test]
            fn another_mod_test() { }
        "# ,) ?"""
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."if let PathArguments :: AngleBracketed (angle_args) = & segment . arguments { for arg in angle_args . args . iter () { if let GenericArgument :: Type (inner_ty) = arg { if contains_complex_type_in_type (inner_ty) { return true ; } } } }"]
expression_str = "if let PathArguments :: AngleBracketed (angle_args) = & segment . arguments { for arg in angle_args . args . iter () { if let GenericArgument :: Type (inner_ty) = arg { if contains_complex_type_in_type (inner_ty) { return true ; } } } }"
depth = 5
used_types = []
other_types_count = 0
node_type = "If"

[expressions."lib_rs . exists ()"]
expression_str = "lib_rs . exists ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."let Some (entry) = entries . next_entry () . await ?"]
expression_str = "let Some (entry) = entries . next_entry () . await ?"
depth = 5
used_types = []
other_types_count = 0
node_type = "Let"

[expressions.'"prelude_generator_summary.md"']
expression_str = '"prelude_generator_summary.md"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.node_type]
expression_str = "node_type"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'code . push_str ("        column_stats,\n")']
expression_str = 'code . push_str ("        column_stats,\n")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."info . file_path"]
expression_str = "info . file_path"
depth = 4
used_types = []
other_types_count = 0
node_type = "Field"

[expressions."FunctionMetrics { start_time : Instant :: now () , end_time : None , duration_micros : None , call_count : 0 , }"]
expression_str = "FunctionMetrics { start_time : Instant :: now () , end_time : None , duration_micros : None , call_count : 0 , }"
depth = 2
used_types = []
other_types_count = 0
node_type = "Struct"

[expressions.'(syn :: parse_file (& expanded_code) . with_context (| | format ! ("Failed to parse cached expanded code for {}" , file_path . display ())) ? , None)']
expression_str = '(syn :: parse_file (& expanded_code) . with_context (| | format ! ("Failed to parse cached expanded code for {}" , file_path . display ())) ? , None)'
depth = 5
used_types = []
other_types_count = 0
node_type = "Tuple"

[expressions."b . 1 . cmp (a . 1)"]
expression_str = "b . 1 . cmp (a . 1)"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."tests_by_crate . entry (parent . to_path_buf ()) . or_default () . push (info . name)"]
expression_str = "tests_by_crate . entry (parent . to_path_buf ()) . or_default () . push (info . name)"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'format ! ("Failed to create output directory {}" , output_dir . display ())']
expression_str = 'format ! ("Failed to create output directory {}" , output_dir . display ())'
depth = 5
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions.'add_primitive_type (& mut symbols , "u8")']
expression_str = 'add_primitive_type (& mut symbols , "u8")'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."current_file_content . push_str (& line)"]
expression_str = "current_file_content . push_str (& line)"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.package]
expression_str = "package"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."current_file_size + line . len () > MAX_FILE_SIZE"]
expression_str = "current_file_size + line . len () > MAX_FILE_SIZE"
depth = 5
used_types = []
other_types_count = 0
node_type = "Binary"

[expressions."crate :: constant_storage :: numerical_constants :: write_numerical_constants_to_hierarchical_structure"]
expression_str = "crate :: constant_storage :: numerical_constants :: write_numerical_constants_to_hierarchical_structure"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."& mut config . bins"]
expression_str = "& mut config . bins"
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'if results_file_path . exists () { let json_content = fs :: read_to_string (results_file_path) . context ("Failed to read results file") ? ; let results : Vec < FileProcessingResult > = serde_json :: from_str (& json_content) . context ("Failed to deserialize results from JSON") ? ; generate_report (& results) ? ; } else { eprintln ! ("Error: Results file not found at {}. Cannot generate report." , results_file_path . display ()) ; }']
expression_str = 'if results_file_path . exists () { let json_content = fs :: read_to_string (results_file_path) . context ("Failed to read results file") ? ; let results : Vec < FileProcessingResult > = serde_json :: from_str (& json_content) . context ("Failed to deserialize results from JSON") ? ; generate_report (& results) ? ; } else { eprintln ! ("Error: Results file not found at {}. Cannot generate report." , results_file_path . display ()) ; }'
depth = 4
used_types = [
    "Vec",
    "FileProcessingResult",
]
other_types_count = 2
node_type = "If"

[expressions."& constants_by_type_and_size"]
expression_str = "& constants_by_type_and_size"
depth = 5
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'"AST Reconstruction failed"']
expression_str = '"AST Reconstruction failed"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'"Arc"']
expression_str = '"Arc"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."let Some (segment) = pat_tuple_struct . path . segments . last ()"]
expression_str = "let Some (segment) = pat_tuple_struct . path . segments . last ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "Let"

[expressions."current_layer_decls . is_empty ()"]
expression_str = "current_layer_decls . is_empty ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."measurement :: record_function_entry"]
expression_str = "measurement :: record_function_entry"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.field_ident]
expression_str = "field_ident"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'output_dir . join (format ! ("numerical_constants_{}.rs" , file_idx))']
expression_str = 'output_dir . join (format ! ("numerical_constants_{}.rs" , file_idx))'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."RE_SPLIT_IDENT . split (ident_str)"]
expression_str = "RE_SPLIT_IDENT . split (ident_str)"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'& format ! ("echo \"Running tests in {}...\"\n" , crate_path . display ())']
expression_str = '& format ! ("echo \"Running tests in {}...\"\n" , crate_path . display ())'
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'for info in test_infos { let mut current_path = info . file_path . as_path () ; while let Some (parent) = current_path . parent () { if parent . join ("Cargo.toml") . exists () { tests_by_crate . entry (parent . to_path_buf ()) . or_default () . push (info . name) ; break ; } current_path = parent ; } }']
expression_str = 'for info in test_infos { let mut current_path = info . file_path . as_path () ; while let Some (parent) = current_path . parent () { if parent . join ("Cargo.toml") . exists () { tests_by_crate . entry (parent . to_path_buf ()) . or_default () . push (info . name) ; break ; } current_path = parent ; } }'
depth = 2
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions.'format ! ("Failed to create project root: {:?}" , project_root)']
expression_str = 'format ! ("Failed to create project root: {:?}" , project_root)'
depth = 4
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions."tokio :: io :: stdout ()"]
expression_str = "tokio :: io :: stdout ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."ResolvedDependency { id , dependency_type , crate_name , module_path , usage_count : 0 , }"]
expression_str = "ResolvedDependency { id , dependency_type , crate_name , module_path , usage_count : 0 , }"
depth = 4
used_types = []
other_types_count = 0
node_type = "Struct"

[expressions."let Type :: Path (type_path) = & * * ty"]
expression_str = "let Type :: Path (type_path) = & * * ty"
depth = 3
used_types = []
other_types_count = 0
node_type = "Let"

[expressions."fs :: write (& prelude_path , original_content)"]
expression_str = "fs :: write (& prelude_path , original_content)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."ident_str . is_empty ()"]
expression_str = "ident_str . is_empty ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'add_primitive_type (& mut symbols , "u32")']
expression_str = 'add_primitive_type (& mut symbols , "u32")'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."visit :: visit_expr (self , i)"]
expression_str = "visit :: visit_expr (self , i)"
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'& format ! ("    snippet_length_stats.insert(\"{}\".to_string(), ({}, {}, {}, {}));\n" , node_type , min , max , sum , count)']
expression_str = '& format ! ("    snippet_length_stats.insert(\"{}\".to_string(), ({}, {}, {}, {}));\n" , node_type , min , max , sum , count)'
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."tests . into_iter () . map (| f | f . sig . ident . to_string ())"]
expression_str = "tests . into_iter () . map (| f | f . sig . ident . to_string ())"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'writer . write_all (format ! ("---\n--- Stage 4: AST Reconstruction from Hugging Face Dataset ---\n") . as_bytes ()) . await']
expression_str = 'writer . write_all (format ! ("---\n--- Stage 4: AST Reconstruction from Hugging Face Dataset ---\n") . as_bytes ()) . await'
depth = 3
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.'"        // snippet_length_stats,\n"']
expression_str = '"        // snippet_length_stats,\n"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'{ return Err (anyhow :: anyhow ! ("No file specified to process. Use --file argument.") ,) ; }']
expression_str = '{ return Err (anyhow :: anyhow ! ("No file specified to process. Use --file argument.") ,) ; }'
depth = 4
used_types = []
other_types_count = 0
node_type = "Block"

[expressions."tokio :: fs :: write (& ast_statistics_file_path , ast_statistics_code . as_bytes ())"]
expression_str = "tokio :: fs :: write (& ast_statistics_file_path , ast_statistics_code . as_bytes ())"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."file . write_all (content . as_bytes ())"]
expression_str = "file . write_all (content . as_bytes ())"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'symbol_map . add_declaration (decl . get_identifier () , match & decl . item { split_expanded_lib :: DeclarationItem :: Const (_) => "const" . to_string () , split_expanded_lib :: DeclarationItem :: Struct (_) => "struct" . to_string () , split_expanded_lib :: DeclarationItem :: Enum (_) => "enum" . to_string () , split_expanded_lib :: DeclarationItem :: Fn (_) => "function" . to_string () , split_expanded_lib :: DeclarationItem :: Static (_) => "static" . to_string () , split_expanded_lib :: DeclarationItem :: Macro (_) => "macro" . to_string () , split_expanded_lib :: DeclarationItem :: Mod (_) => "module" . to_string () , split_expanded_lib :: DeclarationItem :: Trait (_) => "trait" . to_string () , split_expanded_lib :: DeclarationItem :: TraitAlias (_) => "trait_alias" . to_string () , split_expanded_lib :: DeclarationItem :: Type (_) => "type_alias" . to_string () , split_expanded_lib :: DeclarationItem :: Union (_) => "union" . to_string () , split_expanded_lib :: DeclarationItem :: Other (_) => "other" . to_string () , } , decl . crate_name . clone () , decl . source_file . to_string_lossy () . to_string () ,)']
expression_str = 'symbol_map . add_declaration (decl . get_identifier () , match & decl . item { split_expanded_lib :: DeclarationItem :: Const (_) => "const" . to_string () , split_expanded_lib :: DeclarationItem :: Struct (_) => "struct" . to_string () , split_expanded_lib :: DeclarationItem :: Enum (_) => "enum" . to_string () , split_expanded_lib :: DeclarationItem :: Fn (_) => "function" . to_string () , split_expanded_lib :: DeclarationItem :: Static (_) => "static" . to_string () , split_expanded_lib :: DeclarationItem :: Macro (_) => "macro" . to_string () , split_expanded_lib :: DeclarationItem :: Mod (_) => "module" . to_string () , split_expanded_lib :: DeclarationItem :: Trait (_) => "trait" . to_string () , split_expanded_lib :: DeclarationItem :: TraitAlias (_) => "trait_alias" . to_string () , split_expanded_lib :: DeclarationItem :: Type (_) => "type_alias" . to_string () , split_expanded_lib :: DeclarationItem :: Union (_) => "union" . to_string () , split_expanded_lib :: DeclarationItem :: Other (_) => "other" . to_string () , } , decl . crate_name . clone () , decl . source_file . to_string_lossy () . to_string () ,)'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."extract_declarations_from_single_file (file_path , & rustc_info , & current_crate_name , verbose ,) . await"]
expression_str = "extract_declarations_from_single_file (file_path , & rustc_info , & current_crate_name , verbose ,) . await"
depth = 4
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."flatten_use_tree (base_path , tree , flat_uses)"]
expression_str = "flatten_use_tree (base_path , tree , flat_uses)"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.crate1_path]
expression_str = "crate1_path"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'format ! ("        -> Writing expanded code to cache for: {}\n" , file_path . display ()) . as_bytes ()']
expression_str = 'format ! ("        -> Writing expanded code to cache for: {}\n" , file_path . display ()) . as_bytes ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."serde_json :: from_str (& results_file_content ,) ?"]
expression_str = "serde_json :: from_str (& results_file_content ,) ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."prelude_generator :: public_tests :: test_modify_file_force_overwrite () ?"]
expression_str = "prelude_generator :: public_tests :: test_modify_file_force_overwrite () ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'tempfile :: tempdir () . context ("Failed to create temporary directory") ?']
expression_str = 'tempfile :: tempdir () . context ("Failed to create temporary directory") ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'"    let mut processing_time_stats = HashMap::new();\n"']
expression_str = '"    let mut processing_time_stats = HashMap::new();\n"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'code . push_str ("use pipeline_traits::AstStatistics;\n\n")']
expression_str = 'code . push_str ("use pipeline_traits::AstStatistics;\n\n")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."{ for segment in type_path . path . segments . iter () { let ident_str = segment . ident . to_string () ; if is_complex_type (& ident_str) { return true ; } if let PathArguments :: AngleBracketed (angle_args) = & segment . arguments { for arg in angle_args . args . iter () { if let GenericArgument :: Type (inner_ty) = arg { if contains_complex_type_in_type (inner_ty) { return true ; } } } } } false }"]
expression_str = "{ for segment in type_path . path . segments . iter () { let ident_str = segment . ident . to_string () ; if is_complex_type (& ident_str) { return true ; } if let PathArguments :: AngleBracketed (angle_args) = & segment . arguments { for arg in angle_args . args . iter () { if let GenericArgument :: Type (inner_ty) = arg { if contains_complex_type_in_type (inner_ty) { return true ; } } } } } false }"
depth = 3
used_types = []
other_types_count = 0
node_type = "Block"

[expressions.'e . file_type () . is_file () && e . file_name () == "Cargo.toml"']
expression_str = 'e . file_type () . is_file () && e . file_name () == "Cargo.toml"'
depth = 5
used_types = []
other_types_count = 0
node_type = "Binary"

[expressions.'while let Some (parent) = current_path . parent () { if parent . join ("Cargo.toml") . exists () { tests_by_crate . entry (parent . to_path_buf ()) . or_default () . push (info . name) ; break ; } current_path = parent ; }']
expression_str = 'while let Some (parent) = current_path . parent () { if parent . join ("Cargo.toml") . exists () { tests_by_crate . entry (parent . to_path_buf ()) . or_default () . push (info . name) ; break ; } current_path = parent ; }'
depth = 3
used_types = []
other_types_count = 0
node_type = "While"

[expressions."format ! (\"--- Stage 4: Hugging Face Validation ---\n\") . as_bytes ()"]
expression_str = """
format ! ("--- Stage 4: Hugging Face Validation ---
") . as_bytes ()"""
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."fs :: set_permissions (& script_path , perms) ?"]
expression_str = "fs :: set_permissions (& script_path , perms) ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."lattice_info . field_co_occurrences . is_empty ()"]
expression_str = "lattice_info . field_co_occurrences . is_empty ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'format ! ("  -> Parsed file successfully.\n") . as_bytes ()']
expression_str = 'format ! ("  -> Parsed file successfully.\n") . as_bytes ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'generated_decls_output_dir . join (format ! ("layer_{}" , layer)) . join ("const")']
expression_str = 'generated_decls_output_dir . join (format ! ("layer_{}" , layer)) . join ("const")'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."project_root . file_name () . and_then (| s | s . to_str ())"]
expression_str = "project_root . file_name () . and_then (| s | s . to_str ())"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."tempdir () ?"]
expression_str = "tempdir () ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."dir . path () . to_path_buf ()"]
expression_str = "dir . path () . to_path_buf ()"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."crate :: constant_reporting :: generate_numerical_constants_report (& numerical_output_dir) . await"]
expression_str = "crate :: constant_reporting :: generate_numerical_constants_report (& numerical_output_dir) . await"
depth = 5
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."self . map . entry (id . clone ()) . or_insert_with (| | ResolvedDependency { id , dependency_type , crate_name , module_path , usage_count : 0 , })"]
expression_str = "self . map . entry (id . clone ()) . or_insert_with (| | ResolvedDependency { id , dependency_type , crate_name , module_path , usage_count : 0 , })"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."prelude_generator :: public_tests :: test_modify_crate_root_force_overwrite"]
expression_str = "prelude_generator :: public_tests :: test_modify_crate_root_force_overwrite"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."a . 1"]
expression_str = "a . 1"
depth = 5
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'Args :: parse_from (& ["prelude-generator"])']
expression_str = 'Args :: parse_from (& ["prelude-generator"])'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'fs :: create_dir (& temp_src_dir) . await . context ("Failed to create temporary src directory") ?']
expression_str = 'fs :: create_dir (& temp_src_dir) . await . context ("Failed to create temporary src directory") ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."if let syn :: Pat :: TupleStruct (pat_tuple_struct) = & arm . pat { if let Some (segment) = pat_tuple_struct . path . segments . last () { matched_variant_types . insert (segment . ident . to_string ()) ; } } else if let syn :: Pat :: Path (pat_path) = & arm . pat { if let Some (segment) = pat_path . path . segments . last () { matched_variant_types . insert (segment . ident . to_string ()) ; } }"]
expression_str = "if let syn :: Pat :: TupleStruct (pat_tuple_struct) = & arm . pat { if let Some (segment) = pat_tuple_struct . path . segments . last () { matched_variant_types . insert (segment . ident . to_string ()) ; } } else if let syn :: Pat :: Path (pat_path) = & arm . pat { if let Some (segment) = pat_path . path . segments . last () { matched_variant_types . insert (segment . ident . to_string ()) ; } }"
depth = 3
used_types = []
other_types_count = 0
node_type = "If"

[expressions."remaining_decls = next_remaining_decls"]
expression_str = "remaining_decls = next_remaining_decls"
depth = 3
used_types = []
other_types_count = 0
node_type = "Assign"

[expressions."self . current_method_calls . clone ()"]
expression_str = "self . current_method_calls . clone ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"use std::collections::HashMap;\nfn my_func() {}\n"']
expression_str = '"use std::collections::HashMap;\nfn my_func() {}\n"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'Args :: parse_from (& ["prelude-generator" , "--dry-run" , "--path" , "/tmp/my_project" , "--exclude-crates" , "crate1,crate2" , "--report" , "--results-file" , "custom_results.json" , "--cache-report" , "--timeout" , "60" , "--force" ,] ,)']
expression_str = 'Args :: parse_from (& ["prelude-generator" , "--dry-run" , "--path" , "/tmp/my_project" , "--exclude-crates" , "crate1,crate2" , "--report" , "--results-file" , "custom_results.json" , "--cache-report" , "--timeout" , "60" , "--force" ,] ,)'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."prelude_generator :: public_tests :: test_args_custom_values"]
expression_str = "prelude_generator :: public_tests :: test_args_custom_values"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."super :: report :: generate_report (& []) ?"]
expression_str = "super :: report :: generate_report (& []) ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'match & decl . item { split_expanded_lib :: DeclarationItem :: Const (_) => "const" . to_string () , split_expanded_lib :: DeclarationItem :: Struct (_) => "struct" . to_string () , split_expanded_lib :: DeclarationItem :: Enum (_) => "enum" . to_string () , split_expanded_lib :: DeclarationItem :: Fn (_) => "function" . to_string () , split_expanded_lib :: DeclarationItem :: Static (_) => "static" . to_string () , split_expanded_lib :: DeclarationItem :: Macro (_) => "macro" . to_string () , split_expanded_lib :: DeclarationItem :: Mod (_) => "module" . to_string () , split_expanded_lib :: DeclarationItem :: Trait (_) => "trait" . to_string () , split_expanded_lib :: DeclarationItem :: TraitAlias (_) => "trait_alias" . to_string () , split_expanded_lib :: DeclarationItem :: Type (_) => "type_alias" . to_string () , split_expanded_lib :: DeclarationItem :: Union (_) => "union" . to_string () , split_expanded_lib :: DeclarationItem :: Other (_) => "other" . to_string () , }']
expression_str = 'match & decl . item { split_expanded_lib :: DeclarationItem :: Const (_) => "const" . to_string () , split_expanded_lib :: DeclarationItem :: Struct (_) => "struct" . to_string () , split_expanded_lib :: DeclarationItem :: Enum (_) => "enum" . to_string () , split_expanded_lib :: DeclarationItem :: Fn (_) => "function" . to_string () , split_expanded_lib :: DeclarationItem :: Static (_) => "static" . to_string () , split_expanded_lib :: DeclarationItem :: Macro (_) => "macro" . to_string () , split_expanded_lib :: DeclarationItem :: Mod (_) => "module" . to_string () , split_expanded_lib :: DeclarationItem :: Trait (_) => "trait" . to_string () , split_expanded_lib :: DeclarationItem :: TraitAlias (_) => "trait_alias" . to_string () , split_expanded_lib :: DeclarationItem :: Type (_) => "type_alias" . to_string () , split_expanded_lib :: DeclarationItem :: Union (_) => "union" . to_string () , split_expanded_lib :: DeclarationItem :: Other (_) => "other" . to_string () , }'
depth = 4
used_types = []
other_types_count = 0
node_type = "Match"

[expressions.'for constant in numerical_constants . iter () . chain (string_constants . iter ()) { let const_name = constant . ident . to_string () ; let layer = type_map . get (& const_name) . and_then (| info | info . layer) . unwrap_or (0) ; let consts_output_dir = generated_decls_output_dir . join (format ! ("layer_{}" , layer)) . join ("const") ; println ! ("Attempting to create directory: {}" , consts_output_dir . display ()) ; tokio :: fs :: create_dir_all (& consts_output_dir) . await . context (format ! ("Failed to create output directory {:?}" , consts_output_dir)) ? ; let file_name = format ! ("{}.rs" , const_name) ; let output_path = consts_output_dir . join (& file_name) ; println ! ("Attempting to write file: {}" , output_path . display ()) ; let result = async { let tokens = quote ! { # constant } ; let mut code = tokens . to_string () ; let required_uses = use_statements :: get_required_uses_for_item_const (& constant) ; code = format ! ("{}{}" , required_uses , code) ; tokio :: fs :: write (& output_path , code . as_bytes ()) . await . context (format ! ("Failed to write constant {:?} to {:?}" , const_name , output_path)) ? ; println ! ("  -> Wrote constant {:?} to {:?}" , const_name , output_path) ; utils :: format_rust_code (& output_path) . await . context (format ! ("Constant {:?} formatting failed for {:?}" , const_name , output_path)) ? ; println ! ("  -> Constant {:?} formatted successfully.\n" , const_name) ; utils :: validate_rust_code (& output_path) . await . context (format ! ("Constant {:?} validation failed for {:?}" , const_name , output_path)) ? ; println ! (r"  -> Constant {:?} validated successfully.\n" , const_name) ; Ok (()) } . await ; if let Err (e) = result { eprintln ! (r"Error processing constant {}: {:?}\n" , const_name , e) ; errors . push (e) ; } }']
expression_str = 'for constant in numerical_constants . iter () . chain (string_constants . iter ()) { let const_name = constant . ident . to_string () ; let layer = type_map . get (& const_name) . and_then (| info | info . layer) . unwrap_or (0) ; let consts_output_dir = generated_decls_output_dir . join (format ! ("layer_{}" , layer)) . join ("const") ; println ! ("Attempting to create directory: {}" , consts_output_dir . display ()) ; tokio :: fs :: create_dir_all (& consts_output_dir) . await . context (format ! ("Failed to create output directory {:?}" , consts_output_dir)) ? ; let file_name = format ! ("{}.rs" , const_name) ; let output_path = consts_output_dir . join (& file_name) ; println ! ("Attempting to write file: {}" , output_path . display ()) ; let result = async { let tokens = quote ! { # constant } ; let mut code = tokens . to_string () ; let required_uses = use_statements :: get_required_uses_for_item_const (& constant) ; code = format ! ("{}{}" , required_uses , code) ; tokio :: fs :: write (& output_path , code . as_bytes ()) . await . context (format ! ("Failed to write constant {:?} to {:?}" , const_name , output_path)) ? ; println ! ("  -> Wrote constant {:?} to {:?}" , const_name , output_path) ; utils :: format_rust_code (& output_path) . await . context (format ! ("Constant {:?} formatting failed for {:?}" , const_name , output_path)) ? ; println ! ("  -> Constant {:?} formatted successfully.\n" , const_name) ; utils :: validate_rust_code (& output_path) . await . context (format ! ("Constant {:?} validation failed for {:?}" , const_name , output_path)) ? ; println ! (r"  -> Constant {:?} validated successfully.\n" , const_name) ; Ok (()) } . await ; if let Err (e) = result { eprintln ! (r"Error processing constant {}: {:?}\n" , const_name , e) ; errors . push (e) ; } }'
depth = 2
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions."walkdir :: WalkDir :: new (& project_root) . into_iter () . filter_map (| e | e . ok ())"]
expression_str = "walkdir :: WalkDir :: new (& project_root) . into_iter () . filter_map (| e | e . ok ())"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."stats . line_stats"]
expression_str = "stats . line_stats"
depth = 4
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'format ! ("  -> Generated code written to {:?}\n" , output_file_path) . as_bytes ()']
expression_str = 'format ! ("  -> Generated code written to {:?}\n" , output_file_path) . as_bytes ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"use std::collections::HashMap;\n"']
expression_str = '"use std::collections::HashMap;\n"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'fs :: read_to_string (& file_path) . context (format ! ("Failed to read file: {:?}" , file_path))']
expression_str = 'fs :: read_to_string (& file_path) . context (format ! ("Failed to read file: {:?}" , file_path))'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.temp_dir]
expression_str = "temp_dir"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."sorted_terms . sort_by (| a , b | b . 1 . cmp (a . 1))"]
expression_str = "sorted_terms . sort_by (| a , b | b . 1 . cmp (a . 1))"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"fs"']
expression_str = '"fs"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."RE_SPLIT_IDENT . split (ident_str) . filter (| s | ! s . is_empty ()) . map (| s | s . to_lowercase ())"]
expression_str = "RE_SPLIT_IDENT . split (ident_str) . filter (| s | ! s . is_empty ()) . map (| s | s . to_lowercase ())"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'tokio :: fs :: create_dir_all (& string_output_dir) . await . context (format ! ("Failed to create output directory {:?}" , string_output_dir)) ?']
expression_str = 'tokio :: fs :: create_dir_all (& string_output_dir) . await . context (format ! ("Failed to create output directory {:?}" , string_output_dir)) ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'hf_validator_project_dir . join ("main.rs")']
expression_str = 'hf_validator_project_dir . join ("main.rs")'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."| a , b | a . cmp (b)"]
expression_str = "| a , b | a . cmp (b)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions.'Command :: new ("rustfmt") . arg (file_path) . arg ("--edition=2021") . arg ("--emit=files") . output () . await . context ("Failed to execute rustfmt") ?']
expression_str = 'Command :: new ("rustfmt") . arg (file_path) . arg ("--edition=2021") . arg ("--emit=files") . output () . await . context ("Failed to execute rustfmt") ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'return Err (anyhow :: anyhow ! ("Constant processing completed with errors."))']
expression_str = 'return Err (anyhow :: anyhow ! ("Constant processing completed with errors."))'
depth = 3
used_types = []
other_types_count = 0
node_type = "Return"

[expressions."| | StructLatticeInfo :: new (struct_name)"]
expression_str = "| | StructLatticeInfo :: new (struct_name)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions.'"Assign"']
expression_str = '"Assign"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."temp_dir . path ()"]
expression_str = "temp_dir . path ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."prelude_generator :: public_tests :: test_collect_all_test_cases () ?"]
expression_str = "prelude_generator :: public_tests :: test_collect_all_test_cases () ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."std :: env :: current_dir"]
expression_str = "std :: env :: current_dir"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."Some (crate :: config_parser :: read_config (& default_config_path , & project_root) ?)"]
expression_str = "Some (crate :: config_parser :: read_config (& default_config_path , & project_root) ?)"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.writer]
expression_str = "writer"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'match & result . status { FileProcessingStatus :: Success => { report_content . push_str ("- Status:  Successfully Processed\n\n") ; } FileProcessingStatus :: Skipped { reason } => { report_content . push_str (& format ! ("- Status:  Skipped (Reason: {}\n\n" , reason)) ; } FileProcessingStatus :: Failed { error } => { report_content . push_str (& format ! ("- Status:  Failed (Error: {}\n\n" , error)) ; } }']
expression_str = 'match & result . status { FileProcessingStatus :: Success => { report_content . push_str ("- Status:  Successfully Processed\n\n") ; } FileProcessingStatus :: Skipped { reason } => { report_content . push_str (& format ! ("- Status:  Skipped (Reason: {}\n\n" , reason)) ; } FileProcessingStatus :: Failed { error } => { report_content . push_str (& format ! ("- Status:  Failed (Error: {}\n\n" , error)) ; } }'
depth = 4
used_types = []
other_types_count = 0
node_type = "Match"

[expressions."self . type_map . entry (type_name . clone ()) . or_insert_with (| | TypeInfo { count : 0 , layer : Some (0) })"]
expression_str = "self . type_map . entry (type_name . clone ()) . or_insert_with (| | TypeInfo { count : 0 , layer : Some (0) })"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'for error in & errors { eprintln ! ("{:?}" , error) ; }']
expression_str = 'for error in & errors { eprintln ! ("{:?}" , error) ; }'
depth = 3
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions."all_struct_lattices . clone ()"]
expression_str = "all_struct_lattices . clone ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.4]
expression_str = "4"
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'measurement :: record_function_entry ("ParseFunctor::map")']
expression_str = 'measurement :: record_function_entry ("ParseFunctor::map")'
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'"        // column_stats,\n"']
expression_str = '"        // column_stats,\n"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.use_tree]
expression_str = "use_tree"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."map . insert (identifier . clone () , gem_entry . name . clone ())"]
expression_str = "map . insert (identifier . clone () , gem_entry . name . clone ())"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'serde_json :: to_string_pretty (& all_collected_errors) . context ("Failed to serialize errors to JSON")']
expression_str = 'serde_json :: to_string_pretty (& all_collected_errors) . context ("Failed to serialize errors to JSON")'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."EnumLatticeInfo :: new"]
expression_str = "EnumLatticeInfo :: new"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'writer . write_all (format ! ("--- Stage 2: Extracting Use Statements ---\n") . as_bytes ())']
expression_str = 'writer . write_all (format ! ("--- Stage 2: Extracting Use Statements ---\n") . as_bytes ())'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."read_input_file (& args)"]
expression_str = "read_input_file (& args)"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'" Extract all Level 0 declarations (constants) from all modules and write to a global module."']
expression_str = '" Extract all Level 0 declarations (constants) from all modules and write to a global module."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."base_path . pop ()"]
expression_str = "base_path . pop ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'tokio :: fs :: create_dir_all (& numerical_output_dir) . await . context (format ! ("Failed to create output directory {:?}" , numerical_output_dir))']
expression_str = 'tokio :: fs :: create_dir_all (& numerical_output_dir) . await . context (format ! ("Failed to create output directory {:?}" , numerical_output_dir))'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"Failed to create temporary directory"']
expression_str = '"Failed to create temporary directory"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'Command :: new ("rustc") . arg ("--emit=metadata") . arg ("--crate-type=lib") . arg (file_path) . output () . await']
expression_str = 'Command :: new ("rustc") . arg ("--emit=metadata") . arg ("--crate-type=lib") . arg (file_path) . output () . await'
depth = 4
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.'serde_json :: to_string_pretty (& all_public_symbols_aggregated) . context ("Failed to serialize public symbols to JSON") ?']
expression_str = 'serde_json :: to_string_pretty (& all_public_symbols_aggregated) . context ("Failed to serialize public symbols to JSON") ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."! all_collected_errors . is_empty ()"]
expression_str = "! all_collected_errors . is_empty ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "Unary"

[expressions.'for (type_name , info) in sorted_types . iter () { println ! ("{:<30} {:<10} {:<10?}" , type_name , info . count , info . layer) ; }']
expression_str = 'for (type_name , info) in sorted_types . iter () { println ! ("{:<30} {:<10} {:<10?}" , type_name , info . count , info . layer) ; }'
depth = 2
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions.used_types]
expression_str = "used_types"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."self . current_field_accesses . clone ()"]
expression_str = "self . current_field_accesses . clone ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."& all_expression_info"]
expression_str = "& all_expression_info"
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."self . add_ident_to_bag (ident)"]
expression_str = "self . add_ident_to_bag (ident)"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"MethodCall"']
expression_str = '"MethodCall"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."self . method_co_occurrences . entry (method_names) . or_insert (0)"]
expression_str = "self . method_co_occurrences . entry (method_names) . or_insert (0)"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'code . push_str (& format ! ("    node_type_counts.insert(\"{}\".to_string(), {});\n" , node_type , count) ,)']
expression_str = 'code . push_str (& format ! ("    node_type_counts.insert(\"{}\".to_string(), {});\n" , node_type , count) ,)'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."serde_json :: to_string_pretty"]
expression_str = "serde_json :: to_string_pretty"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.results]
expression_str = "results"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."toml :: to_string_pretty (& serializable_decls)"]
expression_str = "toml :: to_string_pretty (& serializable_decls)"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."entry . layer"]
expression_str = "entry . layer"
depth = 4
used_types = []
other_types_count = 0
node_type = "Field"

[expressions."visitor . visit_file (& file)"]
expression_str = "visitor . visit_file (& file)"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."dst . as_ref () . join (current_src . strip_prefix (src . as_ref ()) . unwrap ())"]
expression_str = "dst . as_ref () . join (current_src . strip_prefix (src . as_ref ()) . unwrap ())"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"const" . to_string ()']
expression_str = '"const" . to_string ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'measurement :: record_function_entry ("ClassifyUsesFunctor::map")']
expression_str = 'measurement :: record_function_entry ("ClassifyUsesFunctor::map")'
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."self . dependencies . insert (ident . to_string ())"]
expression_str = "self . dependencies . insert (ident . to_string ())"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'| | format ! ("Failed to write expanded code to cache for {}" , file_path . display ())']
expression_str = '| | format ! ("Failed to write expanded code to cache for {}" , file_path . display ())'
depth = 4
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions.add_uses_from_type_path]
expression_str = "add_uses_from_type_path"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'e . file_type () . is_file () && e . path () . extension () . map_or (false , | ext | ext == "rs")']
expression_str = 'e . file_type () . is_file () && e . path () . extension () . map_or (false , | ext | ext == "rs")'
depth = 4
used_types = []
other_types_count = 0
node_type = "Binary"

[expressions."i . ident . to_string ()"]
expression_str = "i . ident . to_string ()"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."MetadataCommand :: new () . current_dir (workspace_path) . exec ()"]
expression_str = "MetadataCommand :: new () . current_dir (workspace_path) . exec ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."classify_uses_functor . map (writer , use_statements) . await"]
expression_str = "classify_uses_functor . map (writer , use_statements) . await"
depth = 4
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."tokio :: fs :: create_dir_all (file_path . parent () . unwrap ())"]
expression_str = "tokio :: fs :: create_dir_all (file_path . parent () . unwrap ())"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'tokio :: fs :: read_to_string (file_path) . await . with_context (| | format ! ("Failed to read file content for hashing: {}" , file_path . display ())) ?']
expression_str = 'tokio :: fs :: read_to_string (file_path) . await . with_context (| | format ! ("Failed to read file content for hashing: {}" , file_path . display ())) ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'"# Prelude Generation Summary Report\n\n"']
expression_str = '"# Prelude Generation Summary Report\n\n"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.workspace_path]
expression_str = "workspace_path"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."| | TypeInfo { count : 0 , layer : Some (0) }"]
expression_str = "| | TypeInfo { count : 0 , layer : Some (0) }"
depth = 3
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions."for tree in group . items . iter () { flatten_use_tree (base_path , tree , flat_uses) ; }"]
expression_str = "for tree in group . items . iter () { flatten_use_tree (base_path , tree , flat_uses) ; }"
depth = 4
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions.'fs :: write (toml_output_path , toml_content) . context (format ! ("Failed to write TOML report to {:?}" , toml_output_path)) ?']
expression_str = 'fs :: write (toml_output_path , toml_content) . context (format ! ("Failed to write TOML report to {:?}" , toml_output_path)) ?'
depth = 3
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."tempfile :: tempdir"]
expression_str = "tempfile :: tempdir"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'file_path . strip_prefix (& project_root) . unwrap_or (& file_path) . with_extension ("") . to_str () . unwrap_or ("unknown_module") . to_string ()']
expression_str = 'file_path . strip_prefix (& project_root) . unwrap_or (& file_path) . with_extension ("") . to_str () . unwrap_or ("unknown_module") . to_string ()'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'format ! ("{:x}" , hasher . finalize ())']
expression_str = 'format ! ("{:x}" , hasher . finalize ())'
depth = 2
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions."_args . ast_analysis_path"]
expression_str = "_args . ast_analysis_path"
depth = 5
used_types = []
other_types_count = 0
node_type = "Field"

[expressions."prelude_generator :: public_tests :: test_modify_crate_root_force_overwrite () ?"]
expression_str = "prelude_generator :: public_tests :: test_modify_crate_root_force_overwrite () ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."args . run_decl_splitter"]
expression_str = "args . run_decl_splitter"
depth = 3
used_types = []
other_types_count = 0
node_type = "Field"

[expressions."variant . ident"]
expression_str = "variant . ident"
depth = 5
used_types = []
other_types_count = 0
node_type = "Field"

[expressions."{ for func_info in functions { if seen_test_names . insert (func_info . name . clone ()) { all_test_functions . push (func_info) ; } } }"]
expression_str = "{ for func_info in functions { if seen_test_names . insert (func_info . name . clone ()) { all_test_functions . push (func_info) ; } } }"
depth = 4
used_types = []
other_types_count = 0
node_type = "Block"

[expressions.'PathBuf :: from (".")']
expression_str = 'PathBuf :: from (".")'
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.has_use_statements]
expression_str = "has_use_statements"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'toml :: to_string_pretty (& collected_data) . context ("Failed to serialize collected analysis data to TOML")']
expression_str = 'toml :: to_string_pretty (& collected_data) . context ("Failed to serialize collected analysis data to TOML")'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'tempfile :: tempdir () . context ("Failed to create temporary directory")']
expression_str = 'tempfile :: tempdir () . context ("Failed to create temporary directory")'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'" Run the split-expanded-bin functionality."']
expression_str = '" Run the split-expanded-bin functionality."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'for crate_path in sorted_crates { report_content . push_str (& format ! ("### Crate: {}\n" , crate_path . display ())) ; let mut sorted_test_names = tests_by_crate . get (crate_path) . unwrap () . clone () ; sorted_test_names . sort () ; for test_name in sorted_test_names { report_content . push_str (& format ! ("- {}\n" , test_name)) ; } report_content . push_str ("\n") ; }']
expression_str = 'for crate_path in sorted_crates { report_content . push_str (& format ! ("### Crate: {}\n" , crate_path . display ())) ; let mut sorted_test_names = tests_by_crate . get (crate_path) . unwrap () . clone () ; sorted_test_names . sort () ; for test_name in sorted_test_names { report_content . push_str (& format ! ("- {}\n" , test_name)) ; } report_content . push_str ("\n") ; }'
depth = 2
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions."entry . start_time = Instant :: now ()"]
expression_str = "entry . start_time = Instant :: now ()"
depth = 2
used_types = []
other_types_count = 0
node_type = "Assign"

[expressions."dst . as_ref ()"]
expression_str = "dst . as_ref ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."temp_output_dir . path ()"]
expression_str = "temp_output_dir . path ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'tokio :: process :: Command :: new ("git") . arg ("commit") . arg ("--allow-empty") . arg ("-m") . arg ("Initial empty commit") . current_dir (& hf_validator_project_dir) . output () . await . context ("Failed to make initial empty git commit")']
expression_str = 'tokio :: process :: Command :: new ("git") . arg ("commit") . arg ("--allow-empty") . arg ("-m") . arg ("Initial empty commit") . current_dir (& hf_validator_project_dir) . output () . await . context ("Failed to make initial empty git commit")'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'writer . write_all (format ! ("        -> rustc status for {}: {}\n" , file_path . display () , output . status) . as_bytes ()) . await']
expression_str = 'writer . write_all (format ! ("        -> rustc status for {}: {}\n" , file_path . display () , output . status) . as_bytes ()) . await'
depth = 3
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."structure . attrs"]
expression_str = "structure . attrs"
depth = 4
used_types = []
other_types_count = 0
node_type = "Field"

[expressions."tokio :: fs :: write (& output_path , content) . await"]
expression_str = "tokio :: fs :: write (& output_path , content) . await"
depth = 5
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.all_declarations_aggregated]
expression_str = "all_declarations_aggregated"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'anyhow :: anyhow ! ("use_statements_output_dir is required when extract_use_statements is true")']
expression_str = 'anyhow :: anyhow ! ("use_statements_output_dir is required when extract_use_statements is true")'
depth = 5
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions."entry . path () . to_path_buf ()"]
expression_str = "entry . path () . to_path_buf ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.declaration]
expression_str = "declaration"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.unique_crate_paths]
expression_str = "unique_crate_paths"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'module_path . unwrap_or ("std")']
expression_str = 'module_path . unwrap_or ("std")'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."for constant in all_constants { if let syn :: Expr :: Lit (expr_lit) = & * constant . expr { match & expr_lit . lit { syn :: Lit :: Int (_) | syn :: Lit :: Float (_) => numerical_constants . push (constant) , syn :: Lit :: Str (_) => string_constants . push (constant) , _ => { } } } else { } }"]
expression_str = "for constant in all_constants { if let syn :: Expr :: Lit (expr_lit) = & * constant . expr { match & expr_lit . lit { syn :: Lit :: Int (_) | syn :: Lit :: Float (_) => numerical_constants . push (constant) , syn :: Lit :: Str (_) => string_constants . push (constant) , _ => { } } } else { } }"
depth = 2
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions."visit :: visit_item_enum"]
expression_str = "visit :: visit_item_enum"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."split_expanded_lib :: extract_declarations_from_single_file (& file_path , & rustc_info_for_split_expanded_lib , & current_crate_name , args . verbose ,) . await"]
expression_str = "split_expanded_lib :: extract_declarations_from_single_file (& file_path , & rustc_info_for_split_expanded_lib , & current_crate_name , args . verbose ,) . await"
depth = 5
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."fs :: read_dir (& current_src) . await ?"]
expression_str = "fs :: read_dir (& current_src) . await ?"
depth = 3
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."crate :: declaration_processing :: extract_all_declarations_from_file (file_path , & std :: path :: PathBuf :: new () , false , verbose , & rustc_info , crate_name ,) . await ?"]
expression_str = "crate :: declaration_processing :: extract_all_declarations_from_file (file_path , & std :: path :: PathBuf :: new () , false , verbose , & rustc_info , crate_name ,) . await ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."indoc ! { r#\"[package]\n                name = \"temp_hf_project\"\n                version = \"0.1.0\"\n                edition = \"2021\"\n\n                [[bin]]\n                name = \"temp_hf_project\"\n                path = \"main.rs\"\n\n                [dependencies]\n                anyhow = \"1.0\"\n                tokio = { version = \"1\", features = [\"full\"] }\n\n                [workspace]\n                \"# }"]
expression_str = """
indoc ! { r#"[package]
                name = "temp_hf_project"
                version = "0.1.0"
                edition = "2021"

                [[bin]]
                name = "temp_hf_project"
                path = "main.rs"

                [dependencies]
                anyhow = "1.0"
                tokio = { version = "1", features = ["full"] }

                [workspace]
                "# }"""
depth = 4
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions.'args . generated_decls_output_dir . clone () . ok_or_else (| | anyhow :: anyhow ! ("generated_decls_output_dir is required")) ?']
expression_str = 'args . generated_decls_output_dir . clone () . ok_or_else (| | anyhow :: anyhow ! ("generated_decls_output_dir is required")) ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."output . stdout"]
expression_str = "output . stdout"
depth = 4
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'format ! ("Failed to remove existing project root: {:?}" , project_root)']
expression_str = 'format ! ("Failed to remove existing project root: {:?}" , project_root)'
depth = 5
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions.add_std_lib_symbol]
expression_str = "add_std_lib_symbol"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."report_content . push_str (& format ! (\"\\n### Enum: '{}' (Expressions Analyzed: {}) ###\\n\" , enum_name , lattice_info . total_expressions_analyzed))"]
expression_str = '''report_content . push_str (& format ! ("\n### Enum: '{}' (Expressions Analyzed: {}) ###\n" , enum_name , lattice_info . total_expressions_analyzed))'''
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'add_std_lib_symbol (& mut symbols , "PathBuf" , "type" , Some ("std::path"))']
expression_str = 'add_std_lib_symbol (& mut symbols , "PathBuf" , "type" , Some ("std::path"))'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."project_root . clone ()"]
expression_str = "project_root . clone ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."crate :: constant_reporting :: generate_numerical_constants_report (& numerical_output_dir) . await ?"]
expression_str = "crate :: constant_reporting :: generate_numerical_constants_report (& numerical_output_dir) . await ?"
depth = 4
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."args . results_file"]
expression_str = "args . results_file"
depth = 5
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'writer . write_all (format ! ("{:#?}\n" , input) . as_bytes ()) . await']
expression_str = 'writer . write_all (format ! ("{:#?}\n" , input) . as_bytes ()) . await'
depth = 5
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.'writer . write_all (format ! ("--- Stage 3: Classifying Use Statements ---\n") . as_bytes ()) . await']
expression_str = 'writer . write_all (format ! ("--- Stage 3: Classifying Use Statements ---\n") . as_bytes ()) . await'
depth = 3
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."_args . ast_analysis_path . clone ()"]
expression_str = "_args . ast_analysis_path . clone ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'" Generates a JSON report of all collected test cases."']
expression_str = '" Generates a JSON report of all collected test cases."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."Some (Instant :: now ())"]
expression_str = "Some (Instant :: now ())"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."& * constant . expr"]
expression_str = "& * constant . expr"
depth = 5
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'writer . write_all (format ! ("  -> Returning original source code as mock reconstruction.\n") . as_bytes ()) . await']
expression_str = 'writer . write_all (format ! ("  -> Returning original source code as mock reconstruction.\n") . as_bytes ()) . await'
depth = 5
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."args . split_expanded_project_root . clone ()"]
expression_str = "args . split_expanded_project_root . clone ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'report_content . push_str ("\n\nImpl Lattice Information\n")']
expression_str = 'report_content . push_str ("\n\nImpl Lattice Information\n")'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.struct_lattices]
expression_str = "struct_lattices"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'setup_test_file (& dir , "test_file.rs" , "use std::collections::HashMap;\nuse crate::another_module;\n\nfn main() {}\n")']
expression_str = 'setup_test_file (& dir , "test_file.rs" , "use std::collections::HashMap;\nuse crate::another_module;\n\nfn main() {}\n")'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'{ println ! (r"Declaration processing completed successfully.") ; crate :: constant_reporting :: generate_numerical_constants_report (& numerical_output_dir) . await ? ; return Ok (()) }']
expression_str = '{ println ! (r"Declaration processing completed successfully.") ; crate :: constant_reporting :: generate_numerical_constants_report (& numerical_output_dir) . await ? ; return Ok (()) }'
depth = 3
used_types = []
other_types_count = 0
node_type = "Block"

[expressions.tests]
expression_str = "tests"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."prelude_generator :: public_tests :: test_generate_test_report_json () ?"]
expression_str = "prelude_generator :: public_tests :: test_generate_test_report_json () ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."crate :: constant_storage :: numerical_constants :: write_numerical_constants_to_hierarchical_structure (& numerical_constants , & numerical_output_dir ,) . await ?"]
expression_str = "crate :: constant_storage :: numerical_constants :: write_numerical_constants_to_hierarchical_structure (& numerical_constants , & numerical_output_dir ,) . await ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."if let syn :: Expr :: Let (expr_let) = & * i . cond { if let syn :: Pat :: TupleStruct (pat_tuple_struct) = & * expr_let . pat { if let Some (segment) = pat_tuple_struct . path . segments . last () { self . enum_lattice_info . add_co_occurrence (BTreeSet :: from ([segment . ident . to_string ()])) ; } } else if let syn :: Pat :: Path (pat_path) = & * expr_let . pat { if let Some (segment) = pat_path . path . segments . last () { self . enum_lattice_info . add_co_occurrence (BTreeSet :: from ([segment . ident . to_string ()])) ; } } }"]
expression_str = "if let syn :: Expr :: Let (expr_let) = & * i . cond { if let syn :: Pat :: TupleStruct (pat_tuple_struct) = & * expr_let . pat { if let Some (segment) = pat_tuple_struct . path . segments . last () { self . enum_lattice_info . add_co_occurrence (BTreeSet :: from ([segment . ident . to_string ()])) ; } } else if let syn :: Pat :: Path (pat_path) = & * expr_let . pat { if let Some (segment) = pat_path . path . segments . last () { self . enum_lattice_info . add_co_occurrence (BTreeSet :: from ([segment . ident . to_string ()])) ; } } }"
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'| | anyhow :: anyhow ! ("test_report_input_file is required when compile_tests is true")']
expression_str = '| | anyhow :: anyhow ! ("test_report_input_file is required when compile_tests is true")'
depth = 4
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions.decl]
expression_str = "decl"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."& file_path_str"]
expression_str = "& file_path_str"
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'code . push_str ("    let mut node_type_counts = HashMap::new();\n")']
expression_str = 'code . push_str ("    let mut node_type_counts = HashMap::new();\n")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."modify_file (& file_path , false , false)"]
expression_str = "modify_file (& file_path , false , false)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'writer . write_all (format ! ("  -> Generated AST statistics code written to {:?}\n" , ast_statistics_file_path) . as_bytes () ,) . await ?']
expression_str = 'writer . write_all (format ! ("  -> Generated AST statistics code written to {:?}\n" , ast_statistics_file_path) . as_bytes () ,) . await ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."generate_prelude :: generate_prelude (& src_dir , prelude_content , true , false)"]
expression_str = "generate_prelude :: generate_prelude (& src_dir , prelude_content , true , false)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'" Paths to the input Rust files (e.g., expanded .rs files) for split-expanded-bin."']
expression_str = '" Paths to the input Rust files (e.g., expanded .rs files) for split-expanded-bin."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."fs :: read_to_string (path) . await ?"]
expression_str = "fs :: read_to_string (path) . await ?"
depth = 4
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."{ String :: new () }"]
expression_str = "{ String :: new () }"
depth = 3
used_types = []
other_types_count = 0
node_type = "Block"

[expressions."_args . test_report_output_file"]
expression_str = "_args . test_report_output_file"
depth = 4
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'fs :: write (results_file_path , json_content) . context ("Failed to write results to file") ?']
expression_str = 'fs :: write (results_file_path , json_content) . context ("Failed to write results to file") ?'
depth = 5
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."perms . set_mode (0o755)"]
expression_str = "perms . set_mode (0o755)"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."Sha256 :: new ()"]
expression_str = "Sha256 :: new ()"
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."self . type_map . entry (const_name . clone ())"]
expression_str = "self . type_map . entry (const_name . clone ())"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.walker]
expression_str = "walker"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'"Call" . to_string ()']
expression_str = '"Call" . to_string ()'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.sorted_crates]
expression_str = "sorted_crates"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.public_symbols]
expression_str = "public_symbols"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'{ eprintln ! ("Warning: Could not extract tests from {}: {}" , file_path . display () , e) ; }']
expression_str = '{ eprintln ! ("Warning: Could not extract tests from {}: {}" , file_path . display () , e) ; }'
depth = 4
used_types = []
other_types_count = 0
node_type = "Block"

[expressions."hasher . update (crate_root . to_string_lossy () . as_bytes ())"]
expression_str = "hasher . update (crate_root . to_string_lossy () . as_bytes ())"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."std :: marker :: PhantomData"]
expression_str = "std :: marker :: PhantomData"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'code . push_str ("    let mut rust_version_counts = HashMap::new();\n")']
expression_str = 'code . push_str ("    let mut rust_version_counts = HashMap::new();\n")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"Rc"']
expression_str = '"Rc"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."all_collected_errors_aggregated . is_empty ()"]
expression_str = "all_collected_errors_aggregated . is_empty ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."& args . config_file_path"]
expression_str = "& args . config_file_path"
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'| | { project_root . join ("generated/level0_decls") }']
expression_str = '| | { project_root . join ("generated/level0_decls") }'
depth = 3
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions.'format ! ("        -> Running cargo rustc -Zunpretty=expanded --lib for: {}\n" , file_path . display ()) . as_bytes ()']
expression_str = 'format ! ("        -> Running cargo rustc -Zunpretty=expanded --lib for: {}\n" , file_path . display ()) . as_bytes ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."| s | s . to_lowercase ()"]
expression_str = "| s | s . to_lowercase ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions.all_public_symbols]
expression_str = "all_public_symbols"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.host]
expression_str = "host"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'if use_statement . contains ("nix") { current_use_statement . nix_details = Some (pipeline_traits :: NixDetails :: Info (pipeline_traits :: NixInfo { flake_path : "inferred_from_use" . to_string () , output_type : "inferred_from_use" . to_string () , })) ; }']
expression_str = 'if use_statement . contains ("nix") { current_use_statement . nix_details = Some (pipeline_traits :: NixDetails :: Info (pipeline_traits :: NixInfo { flake_path : "inferred_from_use" . to_string () , output_type : "inferred_from_use" . to_string () , })) ; }'
depth = 5
used_types = []
other_types_count = 0
node_type = "If"

[expressions."args . timeout . map (Duration :: from_secs)"]
expression_str = "args . timeout . map (Duration :: from_secs)"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."& expr_lit . lit"]
expression_str = "& expr_lit . lit"
depth = 5
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'Err (anyhow :: anyhow ! ("Constant processing completed with errors."))']
expression_str = 'Err (anyhow :: anyhow ! ("Constant processing completed with errors."))'
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'Err (anyhow :: anyhow ! ("cargo metadata failed with status: {:?}" , output . status))']
expression_str = 'Err (anyhow :: anyhow ! ("cargo metadata failed with status: {:?}" , output . status))'
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."syn :: visit :: visit_item_static (self , i)"]
expression_str = "syn :: visit :: visit_item_static (self , i)"
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."& field . ident"]
expression_str = "& field . ident"
depth = 5
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'PathBuf :: from ("generated/self_generated_code.rs")']
expression_str = 'PathBuf :: from ("generated/self_generated_code.rs")'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'| | format ! ("Failed to parse Rust file: {}" , file_path . display ())']
expression_str = '| | format ! ("Failed to parse Rust file: {}" , file_path . display ())'
depth = 4
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions.'code . push_str ("    }\n")']
expression_str = 'code . push_str ("    }\n")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'code = format ! ("{}{}" , required_uses , code)']
expression_str = 'code = format ! ("{}{}" , required_uses , code)'
depth = 5
used_types = []
other_types_count = 0
node_type = "Assign"

[expressions.'add_std_lib_symbol (& mut symbols , "vec!" , "macro" , Some ("std::macro"))']
expression_str = 'add_std_lib_symbol (& mut symbols , "vec!" , "macro" , Some ("std::macro"))'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.prelude_path]
expression_str = "prelude_path"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'if should_process_file { let (declarations , errors , _file_metadata , public_symbols) = split_expanded_lib :: extract_declarations_from_single_file (& file_path , & rustc_info_for_split_expanded_lib , & crate_name , args . verbose ,) . await ? ; all_collected_errors . extend (errors) ; all_public_symbols . extend (public_symbols) ; for decl in declarations { match & decl . item { split_expanded_lib :: DeclarationItem :: Const (s) => { if let Ok (item_const) = syn :: parse_str :: < syn :: ItemConst > (s) { if item_const . ident . to_string () . ends_with ("_NUM") { all_numerical_constants . push (item_const) ; } else { all_string_constants . push (item_const) ; } } } , _ => { } , } } }']
expression_str = 'if should_process_file { let (declarations , errors , _file_metadata , public_symbols) = split_expanded_lib :: extract_declarations_from_single_file (& file_path , & rustc_info_for_split_expanded_lib , & crate_name , args . verbose ,) . await ? ; all_collected_errors . extend (errors) ; all_public_symbols . extend (public_symbols) ; for decl in declarations { match & decl . item { split_expanded_lib :: DeclarationItem :: Const (s) => { if let Ok (item_const) = syn :: parse_str :: < syn :: ItemConst > (s) { if item_const . ident . to_string () . ends_with ("_NUM") { all_numerical_constants . push (item_const) ; } else { all_string_constants . push (item_const) ; } } } , _ => { } , } } }'
depth = 3
used_types = ["ItemConst"]
other_types_count = 1
node_type = "If"

[expressions.'writer . write_all (format ! ("--- Inspecting: {} ---\n" , self . label) . as_bytes ()) . await ?']
expression_str = 'writer . write_all (format ! ("--- Inspecting: {} ---\n" , self . label) . as_bytes ()) . await ?'
depth = 4
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'serde_json :: to_string_pretty (& collected_metrics) . context ("Failed to serialize metrics to JSON")']
expression_str = 'serde_json :: to_string_pretty (& collected_metrics) . context ("Failed to serialize metrics to JSON")'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."| | ResolvedDependency { id , dependency_type , crate_name , module_path , usage_count : 0 , }"]
expression_str = "| | ResolvedDependency { id , dependency_type , crate_name , module_path , usage_count : 0 , }"
depth = 3
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions.'"Repeat"']
expression_str = '"Repeat"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."hasher . update (file_path . to_string_lossy () . as_bytes ())"]
expression_str = "hasher . update (file_path . to_string_lossy () . as_bytes ())"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'& format ! ("\n--- AST Node Type: {} ---\n" , node_type)']
expression_str = '& format ! ("\n--- AST Node Type: {} ---\n" , node_type)'
depth = 5
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'"});\n"']
expression_str = '"});\n"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."temp_dir . path () . to_path_buf ()"]
expression_str = "temp_dir . path () . to_path_buf ()"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"        analyzer_version_counts,\n"']
expression_str = '"        analyzer_version_counts,\n"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.run_category_pipeline]
expression_str = "run_category_pipeline"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'code . push_str ("        // analyzer_version_counts,\n")']
expression_str = 'code . push_str ("        // analyzer_version_counts,\n")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'match & decl . item { split_expanded_lib :: DeclarationItem :: Const (s) => { if let Ok (item_const) = syn :: parse_str :: < syn :: ItemConst > (s) { if item_const . ident . to_string () . ends_with ("_NUM") { all_numerical_constants . push (item_const) ; } else { all_string_constants . push (item_const) ; } } } , _ => { } , }']
expression_str = 'match & decl . item { split_expanded_lib :: DeclarationItem :: Const (s) => { if let Ok (item_const) = syn :: parse_str :: < syn :: ItemConst > (s) { if item_const . ident . to_string () . ends_with ("_NUM") { all_numerical_constants . push (item_const) ; } else { all_string_constants . push (item_const) ; } } } , _ => { } , }'
depth = 5
used_types = ["ItemConst"]
other_types_count = 1
node_type = "Match"

[expressions."fs :: write (output_path , json_content)"]
expression_str = "fs :: write (output_path , json_content)"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'async { let tokens = quote ! { # constant } ; let mut code = tokens . to_string () ; let required_uses = use_statements :: get_required_uses_for_item_const (& constant) ; code = format ! ("{}{}" , required_uses , code) ; tokio :: fs :: write (& output_path , code . as_bytes ()) . await . context (format ! ("Failed to write constant {:?} to {:?}" , const_name , output_path)) ? ; println ! ("  -> Wrote constant {:?} to {:?}" , const_name , output_path) ; utils :: format_rust_code (& output_path) . await . context (format ! ("Constant {:?} formatting failed for {:?}" , const_name , output_path)) ? ; println ! ("  -> Constant {:?} formatted successfully.\n" , const_name) ; utils :: validate_rust_code (& output_path) . await . context (format ! ("Constant {:?} validation failed for {:?}" , const_name , output_path)) ? ; println ! (r"  -> Constant {:?} validated successfully.\n" , const_name) ; Ok (()) } . await']
expression_str = 'async { let tokens = quote ! { # constant } ; let mut code = tokens . to_string () ; let required_uses = use_statements :: get_required_uses_for_item_const (& constant) ; code = format ! ("{}{}" , required_uses , code) ; tokio :: fs :: write (& output_path , code . as_bytes ()) . await . context (format ! ("Failed to write constant {:?} to {:?}" , const_name , output_path)) ? ; println ! ("  -> Wrote constant {:?} to {:?}" , const_name , output_path) ; utils :: format_rust_code (& output_path) . await . context (format ! ("Constant {:?} formatting failed for {:?}" , const_name , output_path)) ? ; println ! ("  -> Constant {:?} formatted successfully.\n" , const_name) ; utils :: validate_rust_code (& output_path) . await . context (format ! ("Constant {:?} validation failed for {:?}" , const_name , output_path)) ? ; println ! (r"  -> Constant {:?} validated successfully.\n" , const_name) ; Ok (()) } . await'
depth = 3
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."SymbolMap :: new ()"]
expression_str = "SymbolMap :: new ()"
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."WalkDir :: new"]
expression_str = "WalkDir :: new"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."WalkDir :: new (output_dir) . into_iter ()"]
expression_str = "WalkDir :: new (output_dir) . into_iter ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."fs :: File :: create"]
expression_str = "fs :: File :: create"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'"AstReconstructionFunctor::map"']
expression_str = '"AstReconstructionFunctor::map"'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'tokio :: process :: Command :: new ("git") . arg ("config") . arg ("user.name") . arg ("Test User") . current_dir (& hf_validator_project_dir) . output () . await . context ("Failed to configure git user name") ?']
expression_str = 'tokio :: process :: Command :: new ("git") . arg ("config") . arg ("user.name") . arg ("Test User") . current_dir (& hf_validator_project_dir) . output () . await . context ("Failed to configure git user name") ?'
depth = 4
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.new_prelude_content]
expression_str = "new_prelude_content"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'"enum"']
expression_str = '"enum"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'temp_crate_path . join ("src")']
expression_str = 'temp_crate_path . join ("src")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.ast_statistics]
expression_str = "ast_statistics"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."for arg in angle_args . args . iter () { if let GenericArgument :: Type (inner_ty) = arg { self . visit_type (inner_ty) ; } }"]
expression_str = "for arg in angle_args . args . iter () { if let GenericArgument :: Type (inner_ty) = arg { self . visit_type (inner_ty) ; } }"
depth = 5
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions.'report_content . push_str (& format ! ("- Successfully processed: {}\n" , successful_files))']
expression_str = 'report_content . push_str (& format ! ("- Successfully processed: {}\n" , successful_files))'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.layer0_structs]
expression_str = "layer0_structs"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'writer . write_all (format ! ("  -> Hugging Face Validation Result: Dataset generated at {:#?}\n" , output_path) . as_bytes ()) . await ?']
expression_str = 'writer . write_all (format ! ("  -> Hugging Face Validation Result: Dataset generated at {:#?}\n" , output_path) . as_bytes ()) . await ?'
depth = 4
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."if let Item :: Use (_) = item { has_use_statements = true ; } else { new_items . push (item . clone ()) ; }"]
expression_str = "if let Item :: Use (_) = item { has_use_statements = true ; } else { new_items . push (item . clone ()) ; }"
depth = 3
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'toml :: to_string_pretty (& symbol_map . map) . context ("Failed to serialize symbol map to TOML ")']
expression_str = 'toml :: to_string_pretty (& symbol_map . map) . context ("Failed to serialize symbol map to TOML ")'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."let Type :: Path (type_path) = & field . ty"]
expression_str = "let Type :: Path (type_path) = & field . ty"
depth = 4
used_types = []
other_types_count = 0
node_type = "Let"

[expressions."if let Type :: Path (type_path) = & * * ty { if let Some (segment) = type_path . path . segments . last () { return segment . ident . to_string () ; } }"]
expression_str = "if let Type :: Path (type_path) = & * * ty { if let Some (segment) = type_path . path . segments . last () { return segment . ident . to_string () ; } }"
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions."fs :: create_dir (& src_dir) ?"]
expression_str = "fs :: create_dir (& src_dir) ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'code . push_str ("\n")']
expression_str = 'code . push_str ("\n")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."entry . duration_micros"]
expression_str = "entry . duration_micros"
depth = 4
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'fs :: read_to_string (& cached_file_path) . await . with_context (| | format ! ("Failed to read cached expanded code for {}" , file_path . display ())) ?']
expression_str = 'fs :: read_to_string (& cached_file_path) . await . with_context (| | format ! ("Failed to read cached expanded code for {}" , file_path . display ())) ?'
depth = 3
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.temp_crate_dir]
expression_str = "temp_crate_dir"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'_project_root . join (r"generated/string_constants")']
expression_str = '_project_root . join (r"generated/string_constants")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'stderr . write_all (format ! ("Pipeline failed: {:?}\n" , e) . as_bytes ()) . await ?']
expression_str = 'stderr . write_all (format ! ("Pipeline failed: {:?}\n" , e) . as_bytes ()) . await ?'
depth = 3
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."rustc_info . version"]
expression_str = "rustc_info . version"
depth = 4
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'"pub static AST_STATISTICS: Lazy<AstStatistics> = Lazy::new(|| {\n"']
expression_str = '"pub static AST_STATISTICS: Lazy<AstStatistics> = Lazy::new(|| {\n"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."std :: env :: current_dir () ?"]
expression_str = "std :: env :: current_dir () ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."{ new_items . push (item . clone ()) ; }"]
expression_str = "{ new_items . push (item . clone ()) ; }"
depth = 4
used_types = []
other_types_count = 0
node_type = "Block"

[expressions.collector]
expression_str = "collector"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."self . enum_lattices"]
expression_str = "self . enum_lattices"
depth = 4
used_types = []
other_types_count = 0
node_type = "Field"

[expressions."prelude_generator :: public_tests :: test_modify_crate_root_main_rs ()"]
expression_str = "prelude_generator :: public_tests :: test_modify_crate_root_main_rs ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'"        rust_version_counts,\n"']
expression_str = '"        rust_version_counts,\n"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."entry . start_time"]
expression_str = "entry . start_time"
depth = 4
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'| attr | { if attr . path () . is_ident ("derive") { if let syn :: Meta :: List (meta_list) = & attr . meta { meta_list . tokens . to_string () . contains ("Parser") } else { false } } else { false } }']
expression_str = '| attr | { if attr . path () . is_ident ("derive") { if let syn :: Meta :: List (meta_list) = & attr . meta { meta_list . tokens . to_string () . contains ("Parser") } else { false } } else { false } }'
depth = 4
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions.'MetadataCommand :: new () . current_dir (workspace_path) . exec () . context ("Failed to run cargo metadata")']
expression_str = 'MetadataCommand :: new () . current_dir (workspace_path) . exec () . context ("Failed to run cargo metadata")'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."type_path . path . segments"]
expression_str = "type_path . path . segments"
depth = 5
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'format ! ("- Total files processed: {}\n" , total_files)']
expression_str = 'format ! ("- Total files processed: {}\n" , total_files)'
depth = 4
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions."match & expr_lit . lit { syn :: Lit :: Int (_) | syn :: Lit :: Float (_) => all_numerical_constants . push (constant . clone ()) , syn :: Lit :: Str (_) => all_string_constants . push (constant . clone ()) , _ => { { } } , }"]
expression_str = "match & expr_lit . lit { syn :: Lit :: Int (_) | syn :: Lit :: Float (_) => all_numerical_constants . push (constant . clone ()) , syn :: Lit :: Str (_) => all_string_constants . push (constant . clone ()) , _ => { { } } , }"
depth = 4
used_types = []
other_types_count = 0
node_type = "Match"

[expressions.'setup_test_file (& dir , "src/lib.rs" , "fn main() {}\n")']
expression_str = 'setup_test_file (& dir , "src/lib.rs" , "fn main() {}\n")'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'" Calculate and report the layer of each type in the project."']
expression_str = '" Calculate and report the layer of each type in the project."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'" Extract and organize string constants into a hierarchical directory structure."']
expression_str = '" Extract and organize string constants into a hierarchical directory structure."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'writer . write_all (format ! ("---\n--- Stage 2: Extracting Use Statements ---\n") . as_bytes ()) . await']
expression_str = 'writer . write_all (format ! ("---\n--- Stage 2: Extracting Use Statements ---\n") . as_bytes ()) . await'
depth = 3
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.'writer . write_all (format ! ("---\n--- Validating Generated Code ---\n") . as_bytes ())']
expression_str = 'writer . write_all (format ! ("---\n--- Validating Generated Code ---\n") . as_bytes ())'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.const_name]
expression_str = "const_name"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."std :: env :: set_current_dir (& dir)"]
expression_str = "std :: env :: set_current_dir (& dir)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'if ! parent . components () . any (| c | c . as_os_str () == "target") { unique_crate_paths . insert (parent . to_path_buf ()) ; }']
expression_str = 'if ! parent . components () . any (| c | c . as_os_str () == "target") { unique_crate_paths . insert (parent . to_path_buf ()) ; }'
depth = 4
used_types = []
other_types_count = 0
node_type = "If"

[expressions."WalkDir :: new (output_dir) . into_iter () . filter_map (| e | e . ok ())"]
expression_str = "WalkDir :: new (output_dir) . into_iter () . filter_map (| e | e . ok ())"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."walkdir :: WalkDir :: new (& project_root) . into_iter ()"]
expression_str = "walkdir :: WalkDir :: new (& project_root) . into_iter ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."structure . fields"]
expression_str = "structure . fields"
depth = 4
used_types = []
other_types_count = 0
node_type = "Field"

[expressions."error_collection . write_to_file (& errors_json_path) . await"]
expression_str = "error_collection . write_to_file (& errors_json_path) . await"
depth = 4
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."BTreeSet :: new ()"]
expression_str = "BTreeSet :: new ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'"Yield" . to_string ()']
expression_str = '"Yield" . to_string ()'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."fs :: read_to_string (& lib_rs_path) ?"]
expression_str = "fs :: read_to_string (& lib_rs_path) ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'report_content . push_str (& format ! ("- {}\n" , test_name))']
expression_str = 'report_content . push_str (& format ! ("- {}\n" , test_name))'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."output_file_path . parent () . unwrap ()"]
expression_str = "output_file_path . parent () . unwrap ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."& path"]
expression_str = "& path"
depth = 5
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'match extract_declarations_from_single_file (file_path , & rustc_info , & current_crate_name , verbose ,) . await { Ok ((declarations , errors , _file_metadata , _public_symbols)) => { let file_content = fs :: read_to_string (& file_path) . context (format ! ("Failed to read file: {:?}" , file_path)) ? ; match syn :: parse_file (& file_content) { Ok (file) => parsed_files . push ((file_path . clone () , file)) , Err (e) => { eprintln ! ("Warning: Could not re-parse file for Pass 2 {}: {}" , file_path . display () , e) ; } } for decl in declarations { match dependency_validator . validate (& decl) { Ok (_) => all_declarations . push (decl) , Err (e) => { eprintln ! ("Validation Error for declaration {:?}: {:?}" , decl . get_identifier () , e) ; } } } error_collection . errors . extend (errors) ; } , Err (e) => { eprintln ! ("Error extracting declarations from file {:?}: {}" , file_path , e) ; } }']
expression_str = 'match extract_declarations_from_single_file (file_path , & rustc_info , & current_crate_name , verbose ,) . await { Ok ((declarations , errors , _file_metadata , _public_symbols)) => { let file_content = fs :: read_to_string (& file_path) . context (format ! ("Failed to read file: {:?}" , file_path)) ? ; match syn :: parse_file (& file_content) { Ok (file) => parsed_files . push ((file_path . clone () , file)) , Err (e) => { eprintln ! ("Warning: Could not re-parse file for Pass 2 {}: {}" , file_path . display () , e) ; } } for decl in declarations { match dependency_validator . validate (& decl) { Ok (_) => all_declarations . push (decl) , Err (e) => { eprintln ! ("Validation Error for declaration {:?}: {:?}" , decl . get_identifier () , e) ; } } } error_collection . errors . extend (errors) ; } , Err (e) => { eprintln ! ("Error extracting declarations from file {:?}: {}" , file_path , e) ; } }'
depth = 3
used_types = []
other_types_count = 0
node_type = "Match"

[expressions.'format ! ("---\n--- METRICS_START ---\n{}\n--- METRICS_END ---\n" , json_metrics) . as_bytes ()']
expression_str = 'format ! ("---\n--- METRICS_START ---\n{}\n--- METRICS_END ---\n" , json_metrics) . as_bytes ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."fs :: write"]
expression_str = "fs :: write"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."std :: env :: current_dir ()"]
expression_str = "std :: env :: current_dir ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'add_std_lib_symbol (& mut symbols , "Path" , "type" , Some ("std::path"))']
expression_str = 'add_std_lib_symbol (& mut symbols , "Path" , "type" , Some ("std::path"))'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'writer . write_all (format ! ("---\n--- Stage 3: Classifying Use Statements ---\n") . as_bytes ()) . await ?']
expression_str = 'writer . write_all (format ! ("---\n--- Stage 3: Classifying Use Statements ---\n") . as_bytes ()) . await ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."TypeUsageVisitor :: new"]
expression_str = "TypeUsageVisitor :: new"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'{ let mut excluded_crates : HashSet < String > = args . exclude_crates . clone () . into_iter () . collect () ; excluded_crates . insert ("prelude-generator" . to_string ()) ; excluded_crates . insert ("rust-decl-splitter" . to_string ()) ; excluded_crates . insert ("dependency-analyzer" . to_string ()) ; excluded_crates . insert ("prelude-collector" . to_string ()) ; println ! ("Excluded crates: {:?}" , excluded_crates) ; println ! ("\nPrelude generation complete.") ; println ! ("  -> Contents of all_file_processing_results: {:?}" , all_file_processing_results) ; if let Some (results_file_path) = & args . results_file { let json_content = serde_json :: to_string_pretty (& all_file_processing_results) . context ("Failed to serialize results to JSON") ? ; println ! ("  -> Attempting to save processing results to: {}" , results_file_path . display ()) ; fs :: write (results_file_path , json_content) . context ("Failed to write results to file") ? ; println ! ("Processing results saved to {}." , results_file_path . display ()) ; } else { println ! ("No results file specified. Skipping saving processing results.") ; } }']
expression_str = '{ let mut excluded_crates : HashSet < String > = args . exclude_crates . clone () . into_iter () . collect () ; excluded_crates . insert ("prelude-generator" . to_string ()) ; excluded_crates . insert ("rust-decl-splitter" . to_string ()) ; excluded_crates . insert ("dependency-analyzer" . to_string ()) ; excluded_crates . insert ("prelude-collector" . to_string ()) ; println ! ("Excluded crates: {:?}" , excluded_crates) ; println ! ("\nPrelude generation complete.") ; println ! ("  -> Contents of all_file_processing_results: {:?}" , all_file_processing_results) ; if let Some (results_file_path) = & args . results_file { let json_content = serde_json :: to_string_pretty (& all_file_processing_results) . context ("Failed to serialize results to JSON") ? ; println ! ("  -> Attempting to save processing results to: {}" , results_file_path . display ()) ; fs :: write (results_file_path , json_content) . context ("Failed to write results to file") ? ; println ! ("Processing results saved to {}." , results_file_path . display ()) ; } else { println ! ("No results file specified. Skipping saving processing results.") ; } }'
depth = 3
used_types = ["HashSet"]
other_types_count = 1
node_type = "Block"

[expressions."let Some (ident) = & field . ident"]
expression_str = "let Some (ident) = & field . ident"
depth = 5
used_types = []
other_types_count = 0
node_type = "Let"

[expressions.'format ! ("    column_stats.insert(\"{}\".to_string(), ({}, {}, {}, {}));\n" , node_type , min , max , sum , count)']
expression_str = 'format ! ("    column_stats.insert(\"{}\".to_string(), ({}, {}, {}, {}));\n" , node_type , min , max , sum , count)'
depth = 5
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions.'format ! ("  -> AST Reconstruction completed successfully.\n") . as_bytes ()']
expression_str = 'format ! ("  -> AST Reconstruction completed successfully.\n") . as_bytes ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."segment . ident"]
expression_str = "segment . ident"
depth = 5
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'"src/main.rs"']
expression_str = '"src/main.rs"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."self . enum_lattice_info . add_co_occurrence (BTreeSet :: from ([segment . ident . to_string ()]))"]
expression_str = "self . enum_lattice_info . add_co_occurrence (BTreeSet :: from ([segment . ident . to_string ()]))"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'if ! ident_str . is_empty () && ! matches ! (ident_str . as_str () , "bool" | "u8" | "u16" | "u32" | "u64" | "u128" | "i8" | "i16" | "i32" | "i64" | "i128" | "f32" | "f64" | "char" | "str" | "usize" | "isize") { let resolved_dep = self . symbol_map . resolve_and_increment_usage (ident_str . clone () , "type" . to_string () , self . crate_name . clone () , self . module_path . clone () ,) ; if self . verbose > 0 { println ! ("Resolved Type Reference: id={}, type={}, crate={}, module={}, usage={}" , resolved_dep . id , resolved_dep . dependency_type , resolved_dep . crate_name , resolved_dep . module_path , resolved_dep . usage_count) ; } }']
expression_str = 'if ! ident_str . is_empty () && ! matches ! (ident_str . as_str () , "bool" | "u8" | "u16" | "u32" | "u64" | "u128" | "i8" | "i16" | "i32" | "i64" | "i128" | "f32" | "f64" | "char" | "str" | "usize" | "isize") { let resolved_dep = self . symbol_map . resolve_and_increment_usage (ident_str . clone () , "type" . to_string () , self . crate_name . clone () , self . module_path . clone () ,) ; if self . verbose > 0 { println ! ("Resolved Type Reference: id={}, type={}, crate={}, module={}, usage={}" , resolved_dep . id , resolved_dep . dependency_type , resolved_dep . crate_name , resolved_dep . module_path , resolved_dep . usage_count) ; } }'
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions."super :: report :: generate_report (& results) ?"]
expression_str = "super :: report :: generate_report (& results) ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."_args . generated_decls_output_dir"]
expression_str = "_args . generated_decls_output_dir"
depth = 4
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'report_content . push_str ("# Prelude Generation Summary Report\n\n")']
expression_str = 'report_content . push_str ("# Prelude Generation Summary Report\n\n")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."if let Some (entry) = metrics . get_mut (function_name) { entry . end_time = Some (Instant :: now ()) ; let duration = entry . end_time . unwrap () . duration_since (entry . start_time) ; entry . duration_micros = Some (duration . as_micros ()) ; }"]
expression_str = "if let Some (entry) = metrics . get_mut (function_name) { entry . end_time = Some (Instant :: now ()) ; let duration = entry . end_time . unwrap () . duration_since (entry . start_time) ; entry . duration_micros = Some (duration . as_micros ()) ; }"
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'code . push_str ("        // snippet_length_stats,\n")']
expression_str = 'code . push_str ("        // snippet_length_stats,\n")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."& result . status"]
expression_str = "& result . status"
depth = 5
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."_args . generated_decls_output_dir . clone ()"]
expression_str = "_args . generated_decls_output_dir . clone ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."let syn :: Expr :: Path (expr_path) = & * i . func"]
expression_str = "let syn :: Expr :: Path (expr_path) = & * i . func"
depth = 3
used_types = []
other_types_count = 0
node_type = "Let"

[expressions."enum_lattices . is_empty ()"]
expression_str = "enum_lattices . is_empty ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."visitor . impl_lattices"]
expression_str = "visitor . impl_lattices"
depth = 5
used_types = []
other_types_count = 0
node_type = "Field"

[expressions."args . split_expanded_project_root"]
expression_str = "args . split_expanded_project_root"
depth = 4
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'dir . path () . join ("src")']
expression_str = 'dir . path () . join ("src")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."info . used_types . contains (& target_type)"]
expression_str = "info . used_types . contains (& target_type)"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."expr_str . clone ()"]
expression_str = "expr_str . clone ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'code . push_str (& format ! ("    rust_version_counts.insert(\"{}\".to_string(), {});\n" , version , count) ,)']
expression_str = 'code . push_str (& format ! ("    rust_version_counts.insert(\"{}\".to_string(), {});\n" , version , count) ,)'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."if crate_root_path . exists () && ! force { println ! (\"  -> Skipping crate root modification for {} (file exists, use --force to overwrite).\" , crate_root_path . display ()) ; } else { println ! (\"  -> Adding 'pub mod prelude;' to: {}\" , crate_root_path . display ()) ; println ! (\"    -> Writing modified content to: {}\" , crate_root_path . display ()) ; fs :: write (& crate_root_path , new_content) ? ; }"]
expression_str = """if crate_root_path . exists () && ! force { println ! ("  -> Skipping crate root modification for {} (file exists, use --force to overwrite)." , crate_root_path . display ()) ; } else { println ! ("  -> Adding 'pub mod prelude;' to: {}" , crate_root_path . display ()) ; println ! ("    -> Writing modified content to: {}" , crate_root_path . display ()) ; fs :: write (& crate_root_path , new_content) ? ; }"""
depth = 5
used_types = []
other_types_count = 0
node_type = "If"

[expressions.i]
expression_str = "i"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'{ uses . insert ("use clap::{Parser, Args, Command};\n") ; }']
expression_str = '{ uses . insert ("use clap::{Parser, Args, Command};\n") ; }'
depth = 5
used_types = []
other_types_count = 0
node_type = "Block"

[expressions."writer . write_all (format ! (\"--- Stage 4: Hugging Face Validation ---\n\") . as_bytes ()) . await ?"]
expression_str = """
writer . write_all (format ! ("--- Stage 4: Hugging Face Validation ---
") . as_bytes ()) . await ?"""
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.parent]
expression_str = "parent"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'writer . write_all (format ! ("  -> Parsed file successfully.\n") . as_bytes ()) . await ?']
expression_str = 'writer . write_all (format ! ("  -> Parsed file successfully.\n") . as_bytes ()) . await ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'version_line . and_then (| line | line . split_whitespace () . nth (1)) . unwrap_or ("unknown") . to_string ()']
expression_str = 'version_line . and_then (| line | line . split_whitespace () . nth (1)) . unwrap_or ("unknown") . to_string ()'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'writer . write_all (format ! ("  -> Generated code written to {:?}\n" , output_file_path) . as_bytes () ,) . await']
expression_str = 'writer . write_all (format ! ("  -> Generated code written to {:?}\n" , output_file_path) . as_bytes () ,) . await'
depth = 3
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."is_complex_type (& const_name)"]
expression_str = "is_complex_type (& const_name)"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.original_file_path]
expression_str = "original_file_path"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."b . 1"]
expression_str = "b . 1"
depth = 5
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'"MethodCall" . to_string ()']
expression_str = '"MethodCall" . to_string ()'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'if path . is_file () && path . extension () . map_or (false , | ext | ext == "rs") { println ! ("    -> Processing file: {}" , path . display ()) ; let content = fs :: read_to_string (path) . await ? ; match syn :: parse_file (& content) { Ok (file) => { println ! ("       Successfully parsed file: {}" , path . display ()) ; for item in file . items { if let syn :: Item :: Const (constant) = item { let type_name = get_type_name (& constant . ty) ; let value_str = get_constant_value_string (& constant . expr) ; println ! ("         Found constant: {} (type: {}, value: {})" , constant . ident , type_name , value_str) ; if ! type_name . is_empty () && ! value_str . is_empty () { * constants_by_type_and_size . entry (type_name) . or_default () . entry (value_str) . or_insert (0) += 1 ; } } } } , Err (e) => { eprintln ! ("       Failed to parse file {}: {}" , path . display () , e) ; } } }']
expression_str = 'if path . is_file () && path . extension () . map_or (false , | ext | ext == "rs") { println ! ("    -> Processing file: {}" , path . display ()) ; let content = fs :: read_to_string (path) . await ? ; match syn :: parse_file (& content) { Ok (file) => { println ! ("       Successfully parsed file: {}" , path . display ()) ; for item in file . items { if let syn :: Item :: Const (constant) = item { let type_name = get_type_name (& constant . ty) ; let value_str = get_constant_value_string (& constant . expr) ; println ! ("         Found constant: {} (type: {}, value: {})" , constant . ident , type_name , value_str) ; if ! type_name . is_empty () && ! value_str . is_empty () { * constants_by_type_and_size . entry (type_name) . or_default () . entry (value_str) . or_insert (0) += 1 ; } } } } , Err (e) => { eprintln ! ("       Failed to parse file {}: {}" , path . display () , e) ; } } }'
depth = 3
used_types = []
other_types_count = 0
node_type = "If"

[expressions."constant . ident . to_string ()"]
expression_str = "constant . ident . to_string ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'std :: fs :: read_to_string (config_path) . with_context (| | format ! ("Failed to read config file: {}" , config_path . display ())) ?']
expression_str = 'std :: fs :: read_to_string (config_path) . with_context (| | format ! ("Failed to read config file: {}" , config_path . display ())) ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'writer . write_all (format ! ("---\n--- Stage 1: Parsing ---\n") . as_bytes ())']
expression_str = 'writer . write_all (format ! ("---\n--- Stage 1: Parsing ---\n") . as_bytes ())'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'crate1_path . join ("src/prelude.rs")']
expression_str = 'crate1_path . join ("src/prelude.rs")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'code . push_str ("        analyzer_version_counts,\n")']
expression_str = 'code . push_str ("        analyzer_version_counts,\n")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."self . add_dependency (i)"]
expression_str = "self . add_dependency (i)"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."String :: from_utf8_lossy (& output . stderr)"]
expression_str = "String :: from_utf8_lossy (& output . stderr)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'" Path to a file to save/load processing results."']
expression_str = '" Path to a file to save/load processing results."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'"Classifying use statements failed"']
expression_str = '"Classifying use statements failed"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'WalkDir :: new (project_root) . into_iter () . filter_map (| e | e . ok ()) . filter (| e | e . file_type () . is_file () && e . path () . extension () . map_or (false , | ext | ext == "rs"))']
expression_str = 'WalkDir :: new (project_root) . into_iter () . filter_map (| e | e . ok ()) . filter (| e | e . file_type () . is_file () && e . path () . extension () . map_or (false , | ext | ext == "rs"))'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."generate_prelude :: generate_prelude"]
expression_str = "generate_prelude :: generate_prelude"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'for (term , count) in sorted_terms . iter () . take (20) { println ! (r"  - {}: {}" , term , count) ; }']
expression_str = 'for (term , count) in sorted_terms . iter () . take (20) { println ! (r"  - {}: {}" , term , count) ; }'
depth = 2
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions."matched_variant_types . is_empty ()"]
expression_str = "matched_variant_types . is_empty ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'code . push_str ("    let mut snippet_length_stats = HashMap::new();\n")']
expression_str = 'code . push_str ("    let mut snippet_length_stats = HashMap::new();\n")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'format ! ("    processing_time_stats.insert(\"{}\".to_string(), ({}, {}, {}, {}));\n" , node_type , min , max , sum , count)']
expression_str = 'format ! ("    processing_time_stats.insert(\"{}\".to_string(), ({}, {}, {}, {}));\n" , node_type , min , max , sum , count)'
depth = 5
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions.'for use_statement in classified_uses { if use_statement . error . is_some () { let temp_dir = tempfile :: tempdir () ? ; let temp_file_path = temp_dir . path () . join ("main.rs") ; let content = format ! ("{}\nfn main() {{}}" , use_statement . statement) ; tokio :: fs :: write (& temp_file_path , content) . await ? ; let output = tokio :: process :: Command :: new ("rustc") . arg (& temp_file_path) . output () . await ? ; if output . status . success () { new_classified_uses . push (UseStatement { statement : use_statement . statement , error : None , git_details : None , nix_details : None , rust_details : None , cargo_details : None , syn_details : None , llvm_details : None , linux_details : None , }) ; } else { new_classified_uses . push (UseStatement { statement : use_statement . statement , error : Some (String :: from_utf8_lossy (& output . stderr) . to_string ()) , git_details : None , nix_details : None , rust_details : None , cargo_details : None , syn_details : None , llvm_details : None , linux_details : None , }) ; } } else { new_classified_uses . push (UseStatement { statement : use_statement . statement , error : use_statement . error , git_details : use_statement . git_details , nix_details : use_statement . nix_details , rust_details : use_statement . rust_details , cargo_details : use_statement . cargo_details , syn_details : use_statement . syn_details , llvm_details : use_statement . llvm_details , linux_details : use_statement . linux_details , }) ; } }']
expression_str = 'for use_statement in classified_uses { if use_statement . error . is_some () { let temp_dir = tempfile :: tempdir () ? ; let temp_file_path = temp_dir . path () . join ("main.rs") ; let content = format ! ("{}\nfn main() {{}}" , use_statement . statement) ; tokio :: fs :: write (& temp_file_path , content) . await ? ; let output = tokio :: process :: Command :: new ("rustc") . arg (& temp_file_path) . output () . await ? ; if output . status . success () { new_classified_uses . push (UseStatement { statement : use_statement . statement , error : None , git_details : None , nix_details : None , rust_details : None , cargo_details : None , syn_details : None , llvm_details : None , linux_details : None , }) ; } else { new_classified_uses . push (UseStatement { statement : use_statement . statement , error : Some (String :: from_utf8_lossy (& output . stderr) . to_string ()) , git_details : None , nix_details : None , rust_details : None , cargo_details : None , syn_details : None , llvm_details : None , linux_details : None , }) ; } } else { new_classified_uses . push (UseStatement { statement : use_statement . statement , error : use_statement . error , git_details : use_statement . git_details , nix_details : use_statement . nix_details , rust_details : use_statement . rust_details , cargo_details : use_statement . cargo_details , syn_details : use_statement . syn_details , llvm_details : use_statement . llvm_details , linux_details : use_statement . linux_details , }) ; } }'
depth = 4
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions."& ast . items"]
expression_str = "& ast . items"
depth = 3
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."& string_output_dir"]
expression_str = "& string_output_dir"
depth = 5
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.dry_run]
expression_str = "dry_run"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'if ! status . success () { return Err (anyhow :: anyhow ! ("hf-validator command failed with status: {}" , status)) ; }']
expression_str = 'if ! status . success () { return Err (anyhow :: anyhow ! ("hf-validator command failed with status: {}" , status)) ; }'
depth = 4
used_types = []
other_types_count = 0
node_type = "If"

[expressions."tokio :: io :: stderr ()"]
expression_str = "tokio :: io :: stderr ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."type_path . path . segments . last ()"]
expression_str = "type_path . path . segments . last ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'return Err (anyhow :: anyhow ! ("cargo metadata failed with status: {:?}" , output . status))']
expression_str = 'return Err (anyhow :: anyhow ! ("cargo metadata failed with status: {:?}" , output . status))'
depth = 3
used_types = []
other_types_count = 0
node_type = "Return"

[expressions."for segment in & i . segments { self . add_dependency (& segment . ident) ; }"]
expression_str = "for segment in & i . segments { self . add_dependency (& segment . ident) ; }"
depth = 2
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions."prelude_generator :: public_tests :: test_modify_file_force_overwrite ()"]
expression_str = "prelude_generator :: public_tests :: test_modify_file_force_overwrite ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'| | format ! ("Failed to write aggregated test report to {}" , output_path . display ())']
expression_str = '| | format ! ("Failed to write aggregated test report to {}" , output_path . display ())'
depth = 4
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions.generated_decl_strings]
expression_str = "generated_decl_strings"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'anyhow :: anyhow ! ("Constant processing completed with errors.")']
expression_str = 'anyhow :: anyhow ! ("Constant processing completed with errors.")'
depth = 5
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions.'writer . write_all (format ! ("---\n--- Stage 2: Extracting Use Statements ---\n") . as_bytes ()) . await ?']
expression_str = 'writer . write_all (format ! ("---\n--- Stage 2: Extracting Use Statements ---\n") . as_bytes ()) . await ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'writer . write_all (format ! ("      -> Using cached expanded code for: {}\n" , file_path . display ()) . as_bytes ()) . await ?']
expression_str = 'writer . write_all (format ! ("      -> Using cached expanded code for: {}\n" , file_path . display ()) . as_bytes ()) . await ?'
depth = 3
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'{ eprintln ! ("Error reading file {}: {:?}" , path . display () , e) ; continue ; }']
expression_str = '{ eprintln ! ("Error reading file {}: {:?}" , path . display () , e) ; continue ; }'
depth = 4
used_types = []
other_types_count = 0
node_type = "Block"

[expressions."args . exclude_crates . clone () . into_iter ()"]
expression_str = "args . exclude_crates . clone () . into_iter ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."gem_entry . crate_name . clone ()"]
expression_str = "gem_entry . crate_name . clone ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."PipelineFunctor :: map (& ast_reconstruction_functor , writer , validated_file . clone ())"]
expression_str = "PipelineFunctor :: map (& ast_reconstruction_functor , writer , validated_file . clone ())"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'" Generate a report on the prelude cache."']
expression_str = '" Generate a report on the prelude cache."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'if func . attrs . iter () . any (| attr | attr . path () . is_ident ("test")) { test_functions . push (TestInfo { name : func . sig . ident . to_string () , file_path : file_path . to_path_buf () , }) ; }']
expression_str = 'if func . attrs . iter () . any (| attr | attr . path () . is_ident ("test")) { test_functions . push (TestInfo { name : func . sig . ident . to_string () , file_path : file_path . to_path_buf () , }) ; }'
depth = 5
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'writer . write_all (format ! ("---\n--- METRICS_START ---\n{}\n--- METRICS_END ---\n" , json_metrics) . as_bytes ()) . await ?']
expression_str = 'writer . write_all (format ! ("---\n--- METRICS_START ---\n{}\n--- METRICS_END ---\n" , json_metrics) . as_bytes ()) . await ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'writer . write_all (format ! ("  -> Generated code validated successfully.\n") . as_bytes ()) . await']
expression_str = 'writer . write_all (format ! ("  -> Generated code validated successfully.\n") . as_bytes ()) . await'
depth = 3
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.'" Force overwriting of files even if they exist."']
expression_str = '" Force overwriting of files even if they exist."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'format ! ("Failed to write TOML report to {:?}" , toml_output_path)']
expression_str = 'format ! ("Failed to write TOML report to {:?}" , toml_output_path)'
depth = 5
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions.self]
expression_str = "self"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."decl . crate_name . clone ()"]
expression_str = "decl . crate_name . clone ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."self . symbol_map"]
expression_str = "self . symbol_map"
depth = 4
used_types = []
other_types_count = 0
node_type = "Field"

[expressions."self . current_field_accesses . clear ()"]
expression_str = "self . current_field_accesses . clear ()"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'tokio :: fs :: write (& output_path , code . as_bytes ()) . await . context (format ! ("Failed to write constant {:?} to {:?}" , const_name , output_path)) ?']
expression_str = 'tokio :: fs :: write (& output_path , code . as_bytes ()) . await . context (format ! ("Failed to write constant {:?} to {:?}" , const_name , output_path)) ?'
depth = 5
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'"Let"']
expression_str = '"Let"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."entry . duration_micros = Some (duration . as_micros ())"]
expression_str = "entry . duration_micros = Some (duration . as_micros ())"
depth = 3
used_types = []
other_types_count = 0
node_type = "Assign"

[expressions.'if let Some (ref cfg) = config { eprintln ! ("Parsed config: {:#?}" , cfg) ; }']
expression_str = 'if let Some (ref cfg) = config { eprintln ! ("Parsed config: {:#?}" , cfg) ; }'
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions."prelude_generator :: public_tests :: test_collect_all_test_cases ()"]
expression_str = "prelude_generator :: public_tests :: test_collect_all_test_cases ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'uses . insert ("use syn::visit::Visit;\n")']
expression_str = 'uses . insert ("use syn::visit::Visit;\n")'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."Ok ((declarations , symbol_map , errors , file_metadata , public_symbols))"]
expression_str = "Ok ((declarations , symbol_map , errors , file_metadata , public_symbols))"
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."uses . into_iter ()"]
expression_str = "uses . into_iter ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'code . push_str (& format ! ("    node_type_counts.insert(\"{}\".to_string(), {});\n" , node_type , count))']
expression_str = 'code . push_str (& format ! ("    node_type_counts.insert(\"{}\".to_string(), {});\n" , node_type , count))'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"constants"']
expression_str = '"constants"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.current_path]
expression_str = "current_path"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."for entry in walker { let file_path = entry . path () . to_path_buf () ; let current_crate_name = file_path . file_stem () . unwrap () . to_string_lossy () . to_string () ; let should_process_file = args . filter_names . as_ref () . map_or (true , | filter_names | { filter_names . iter () . any (| f | file_path . to_string_lossy () . contains (f)) }) ; if should_process_file { let (declarations , errors , _file_metadata , public_symbols) = split_expanded_lib :: extract_declarations_from_single_file (& file_path , & rustc_info_for_split_expanded_lib , & current_crate_name , args . verbose ,) . await ? ; all_declarations_aggregated . extend (declarations) ; all_collected_errors_aggregated . extend (errors) ; all_public_symbols_aggregated . extend (public_symbols) ; } }"]
expression_str = "for entry in walker { let file_path = entry . path () . to_path_buf () ; let current_crate_name = file_path . file_stem () . unwrap () . to_string_lossy () . to_string () ; let should_process_file = args . filter_names . as_ref () . map_or (true , | filter_names | { filter_names . iter () . any (| f | file_path . to_string_lossy () . contains (f)) }) ; if should_process_file { let (declarations , errors , _file_metadata , public_symbols) = split_expanded_lib :: extract_declarations_from_single_file (& file_path , & rustc_info_for_split_expanded_lib , & current_crate_name , args . verbose ,) . await ? ; all_declarations_aggregated . extend (declarations) ; all_collected_errors_aggregated . extend (errors) ; all_public_symbols_aggregated . extend (public_symbols) ; } }"
depth = 2
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions."visit :: visit_type"]
expression_str = "visit :: visit_type"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."for (_ , info) in all_expression_info { for used_type in & info . used_types { all_user_defined_types . insert (used_type . clone ()) ; } }"]
expression_str = "for (_ , info) in all_expression_info { for used_type in & info . used_types { all_user_defined_types . insert (used_type . clone ()) ; } }"
depth = 2
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions.'add_std_lib_symbol (& mut symbols , "println!" , "macro" , Some ("std::macro"))']
expression_str = 'add_std_lib_symbol (& mut symbols , "println!" , "macro" , Some ("std::macro"))'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'toml :: to_string_pretty (& mapping) . context ("Failed to serialize mapping to TOML") ?']
expression_str = 'toml :: to_string_pretty (& mapping) . context ("Failed to serialize mapping to TOML") ?'
depth = 4
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'"PreprocessFunctor::map"']
expression_str = '"PreprocessFunctor::map"'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'"f32"']
expression_str = '"f32"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."collect_all_test_cases (& crate_root)"]
expression_str = "collect_all_test_cases (& crate_root)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."let PathArguments :: AngleBracketed (angle_args) = & segment . arguments"]
expression_str = "let PathArguments :: AngleBracketed (angle_args) = & segment . arguments"
depth = 5
used_types = []
other_types_count = 0
node_type = "Let"

[expressions."& all_enum_lattices"]
expression_str = "& all_enum_lattices"
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'anyhow :: anyhow ! ("test_report_input_file is required when compile_tests is true")']
expression_str = 'anyhow :: anyhow ! ("test_report_input_file is required when compile_tests is true")'
depth = 5
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions."fs :: write (& script_path , script_content)"]
expression_str = "fs :: write (& script_path , script_content)"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."hf_validator_functor . map (writer , parsed_file . clone ())"]
expression_str = "hf_validator_functor . map (writer , parsed_file . clone ())"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'serde_json :: to_string_pretty (& all_public_symbols) . context ("Failed to serialize public symbols to JSON") ?']
expression_str = 'serde_json :: to_string_pretty (& all_public_symbols) . context ("Failed to serialize public symbols to JSON") ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.layered_decls]
expression_str = "layered_decls"
depth = 2
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."self . enum_lattices . entry (enum_name . clone ()) . or_insert_with (| | EnumLatticeInfo :: new (enum_name . clone ()))"]
expression_str = "self . enum_lattices . entry (enum_name . clone ()) . or_insert_with (| | EnumLatticeInfo :: new (enum_name . clone ()))"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."& ast_statistics"]
expression_str = "& ast_statistics"
depth = 3
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'crate_root . join ("src/another_mod.rs")']
expression_str = 'crate_root . join ("src/another_mod.rs")'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'serde_json :: to_string_pretty (& all_collected_errors) . context ("Failed to serialize errors to JSON") ?']
expression_str = 'serde_json :: to_string_pretty (& all_collected_errors) . context ("Failed to serialize errors to JSON") ?'
depth = 3
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'fs :: read_to_string (file_to_process) . await . context ("Failed to read file content") ?']
expression_str = 'fs :: read_to_string (file_to_process) . await . context ("Failed to read file content") ?'
depth = 3
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."for (expr_str , info) in visitor . expressions { all_expression_info . insert (expr_str , info) ; }"]
expression_str = "for (expr_str , info) in visitor . expressions { all_expression_info . insert (expr_str , info) ; }"
depth = 4
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions.'" Generate a summary report of the prelude generation process."']
expression_str = '" Generate a summary report of the prelude generation process."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'add_primitive_type (& mut symbols , "str")']
expression_str = 'add_primitive_type (& mut symbols , "str")'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."tokio :: io :: stderr"]
expression_str = "tokio :: io :: stderr"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'project_root . join ("results.json")']
expression_str = 'project_root . join ("results.json")'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'dir . path () . join ("aggregated_tests.rs")']
expression_str = 'dir . path () . join ("aggregated_tests.rs")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'hf_validator_functor . map (writer , parsed_file . clone ()) . await . context ("Hugging Face Validation failed")']
expression_str = 'hf_validator_functor . map (writer , parsed_file . clone ()) . await . context ("Hugging Face Validation failed")'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'! parent . components () . any (| c | c . as_os_str () == "target")']
expression_str = '! parent . components () . any (| c | c . as_os_str () == "target")'
depth = 5
used_types = []
other_types_count = 0
node_type = "Unary"

[expressions."i . segments . last () . map (| s | s . ident . to_string ())"]
expression_str = "i . segments . last () . map (| s | s . ident . to_string ())"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."for variant in & i . variants { self . add_ident_to_bag (& variant . ident) ; for field in & variant . fields { if let Some (ident) = & field . ident { self . add_ident_to_bag (ident) ; } } }"]
expression_str = "for variant in & i . variants { self . add_ident_to_bag (& variant . ident) ; for field in & variant . fields { if let Some (ident) = & field . ident { self . add_ident_to_bag (ident) ; } } }"
depth = 2
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions."& constant . expr . as_ref ()"]
expression_str = "& constant . expr . as_ref ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'"prelude-generator"']
expression_str = '"prelude-generator"'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'"Parsing failed"']
expression_str = '"Parsing failed"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."generate_report (& results) ?"]
expression_str = "generate_report (& results) ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'async move { measurement :: record_function_entry ("ParseFunctor::map") ; let RawFile (file_path_str , content) = input ; let file_path = PathBuf :: from (file_path_str . clone ()) ; let parsed_code = tokio :: task :: spawn_blocking (move | | -> anyhow :: Result < _ > { let ast = match syn :: parse_file (& content) { Ok (ast) => ast , Err (_) => { return Err (anyhow :: anyhow ! ("Failed to parse file and expand macros")) ; } } ; Ok (prettyplease :: unparse (& ast)) }) . await . context ("Blocking task for parsing failed") ? ? ; measurement :: record_function_exit ("ParseFunctor::map") ; Ok (ParsedFile (parsed_code , file_path)) }']
expression_str = 'async move { measurement :: record_function_entry ("ParseFunctor::map") ; let RawFile (file_path_str , content) = input ; let file_path = PathBuf :: from (file_path_str . clone ()) ; let parsed_code = tokio :: task :: spawn_blocking (move | | -> anyhow :: Result < _ > { let ast = match syn :: parse_file (& content) { Ok (ast) => ast , Err (_) => { return Err (anyhow :: anyhow ! ("Failed to parse file and expand macros")) ; } } ; Ok (prettyplease :: unparse (& ast)) }) . await . context ("Blocking task for parsing failed") ? ? ; measurement :: record_function_exit ("ParseFunctor::map") ; Ok (ParsedFile (parsed_code , file_path)) }'
depth = 3
used_types = [
    "Result",
    "_",
]
other_types_count = 2
node_type = "Async"

[expressions.'if mod_item . ident == "prelude" { has_prelude_mod = true ; break ; }']
expression_str = 'if mod_item . ident == "prelude" { has_prelude_mod = true ; break ; }'
depth = 4
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'"Failed to serialize test info to JSON"']
expression_str = '"Failed to serialize test info to JSON"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'format ! ("  -> Classified use statements:\n") . as_bytes ()']
expression_str = 'format ! ("  -> Classified use statements:\n") . as_bytes ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'writer . write_all (format ! ("        -> rustc status for {}: {}\n" , file_path . display () , output . status) . as_bytes ()) . await ?']
expression_str = 'writer . write_all (format ! ("        -> rustc status for {}: {}\n" , file_path . display () , output . status) . as_bytes ()) . await ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'let Some (ld_library_path_env) = std :: env :: var_os ("LD_LIBRARY_PATH")']
expression_str = 'let Some (ld_library_path_env) = std :: env :: var_os ("LD_LIBRARY_PATH")'
depth = 5
used_types = []
other_types_count = 0
node_type = "Let"

[expressions.e]
expression_str = "e"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'{ project_root . join ("generated/level0_decls") }']
expression_str = '{ project_root . join ("generated/level0_decls") }'
depth = 4
used_types = []
other_types_count = 0
node_type = "Block"

[expressions."e . file_type () . is_file ()"]
expression_str = "e . file_type () . is_file ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"Failed to serialize public symbols to JSON"']
expression_str = '"Failed to serialize public symbols to JSON"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."serde_json :: to_string_pretty (& all_collected_errors)"]
expression_str = "serde_json :: to_string_pretty (& all_collected_errors)"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."! struct_lattices . is_empty ()"]
expression_str = "! struct_lattices . is_empty ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "Unary"

[expressions."fs :: read_to_string (& args . results_file . unwrap ())"]
expression_str = "fs :: read_to_string (& args . results_file . unwrap ())"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'format ! ("--- Stage 2: Extracting Use Statements ---\n") . as_bytes ()']
expression_str = 'format ! ("--- Stage 2: Extracting Use Statements ---\n") . as_bytes ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'| | { let mut node_type_counts = HashMap :: new () ; node_type_counts . insert ("variable" . to_string () , 41) ; node_type_counts . insert ("import" . to_string () , 18) ; node_type_counts . insert ("function" . to_string () , 6) ; node_type_counts . insert ("other" . to_string () , 230) ; let mut line_stats = HashMap :: new () ; line_stats . insert ("other" . to_string () , (12 , 295 , 36092 , 230)) ; line_stats . insert ("import" . to_string () , (1 , 212 , 891 , 18)) ; line_stats . insert ("variable" . to_string () , (25 , 274 , 5772 , 41)) ; line_stats . insert ("function" . to_string () , (18 , 208 , 905 , 6)) ; let mut column_stats = HashMap :: new () ; column_stats . insert ("import" . to_string () , (1 , 1 , 18 , 18)) ; column_stats . insert ("variable" . to_string () , (1 , 1 , 41 , 41)) ; column_stats . insert ("function" . to_string () , (1 , 1 , 6 , 6)) ; column_stats . insert ("other" . to_string () , (1 , 1 , 230 , 230)) ; let mut processing_time_stats = HashMap :: new () ; processing_time_stats . insert ("other" . to_string () , (1 , 1 , 230 , 230)) ; processing_time_stats . insert ("import" . to_string () , (1 , 1 , 18 , 18)) ; processing_time_stats . insert ("variable" . to_string () , (1 , 1 , 41 , 41)) ; processing_time_stats . insert ("function" . to_string () , (1 , 1 , 6 , 6)) ; let mut rust_version_counts = HashMap :: new () ; rust_version_counts . insert ("1.86.0" . to_string () , 295) ; let mut analyzer_version_counts = HashMap :: new () ; analyzer_version_counts . insert ("0.3.2000" . to_string () , 295) ; let mut snippet_length_stats = HashMap :: new () ; snippet_length_stats . insert ("function" . to_string () , (39 , 83 , 434 , 6)) ; snippet_length_stats . insert ("other" . to_string () , (1 , 92 , 7273 , 230)) ; snippet_length_stats . insert ("import" . to_string () , (14 , 85 , 812 , 18)) ; snippet_length_stats . insert ("variable" . to_string () , (29 , 89 , 2362 , 41)) ; AstStatistics { node_type_counts , line_stats , column_stats , processing_time_stats , rust_version_counts , analyzer_version_counts , snippet_length_stats , } }']
expression_str = '| | { let mut node_type_counts = HashMap :: new () ; node_type_counts . insert ("variable" . to_string () , 41) ; node_type_counts . insert ("import" . to_string () , 18) ; node_type_counts . insert ("function" . to_string () , 6) ; node_type_counts . insert ("other" . to_string () , 230) ; let mut line_stats = HashMap :: new () ; line_stats . insert ("other" . to_string () , (12 , 295 , 36092 , 230)) ; line_stats . insert ("import" . to_string () , (1 , 212 , 891 , 18)) ; line_stats . insert ("variable" . to_string () , (25 , 274 , 5772 , 41)) ; line_stats . insert ("function" . to_string () , (18 , 208 , 905 , 6)) ; let mut column_stats = HashMap :: new () ; column_stats . insert ("import" . to_string () , (1 , 1 , 18 , 18)) ; column_stats . insert ("variable" . to_string () , (1 , 1 , 41 , 41)) ; column_stats . insert ("function" . to_string () , (1 , 1 , 6 , 6)) ; column_stats . insert ("other" . to_string () , (1 , 1 , 230 , 230)) ; let mut processing_time_stats = HashMap :: new () ; processing_time_stats . insert ("other" . to_string () , (1 , 1 , 230 , 230)) ; processing_time_stats . insert ("import" . to_string () , (1 , 1 , 18 , 18)) ; processing_time_stats . insert ("variable" . to_string () , (1 , 1 , 41 , 41)) ; processing_time_stats . insert ("function" . to_string () , (1 , 1 , 6 , 6)) ; let mut rust_version_counts = HashMap :: new () ; rust_version_counts . insert ("1.86.0" . to_string () , 295) ; let mut analyzer_version_counts = HashMap :: new () ; analyzer_version_counts . insert ("0.3.2000" . to_string () , 295) ; let mut snippet_length_stats = HashMap :: new () ; snippet_length_stats . insert ("function" . to_string () , (39 , 83 , 434 , 6)) ; snippet_length_stats . insert ("other" . to_string () , (1 , 92 , 7273 , 230)) ; snippet_length_stats . insert ("import" . to_string () , (14 , 85 , 812 , 18)) ; snippet_length_stats . insert ("variable" . to_string () , (29 , 89 , 2362 , 41)) ; AstStatistics { node_type_counts , line_stats , column_stats , processing_time_stats , rust_version_counts , analyzer_version_counts , snippet_length_stats , } }'
depth = 3
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions.'serde_json :: to_string_pretty (& test_functions) . context ("Failed to serialize test info to JSON") ?']
expression_str = 'serde_json :: to_string_pretty (& test_functions) . context ("Failed to serialize test info to JSON") ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."format ! (\"[package]\\nname = \\\"{{}}\\nversion = \\\"0.1.0\\\"\nedition = \\\"2021\\\"\n\" , crate_name)"]
expression_str = '''
format ! ("[package]\nname = \"{{}}\nversion = \"0.1.0\"
edition = \"2021\"
" , crate_name)'''
depth = 4
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions.'writer . write_all (format ! ("  -> Generated AST statistics code written to {:?}\n" , ast_statistics_file_path) . as_bytes () ,)']
expression_str = 'writer . write_all (format ! ("  -> Generated AST statistics code written to {:?}\n" , ast_statistics_file_path) . as_bytes () ,)'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'if let Err (e) = result { eprintln ! (r"Error processing constant {}: {:?}\n" , const_name , e) ; errors . push (e) ; }']
expression_str = 'if let Err (e) = result { eprintln ! (r"Error processing constant {}: {:?}\n" , const_name , e) ; errors . push (e) ; }'
depth = 3
used_types = []
other_types_count = 0
node_type = "If"

[expressions."config . as_ref ()"]
expression_str = "config . as_ref ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."handle_pipeline_result (result)"]
expression_str = "handle_pipeline_result (result)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'hf_validator_functor . map (writer , parsed_file . clone ()) . await . context ("Hugging Face Validation failed") ?']
expression_str = 'hf_validator_functor . map (writer , parsed_file . clone ()) . await . context ("Hugging Face Validation failed") ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."& i . segments"]
expression_str = "& i . segments"
depth = 3
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."sorted_crates . sort_by (| a , b | a . cmp (b))"]
expression_str = "sorted_crates . sort_by (| a , b | a . cmp (b))"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'for item in items { match item { Item :: Fn (func) => { if func . attrs . iter () . any (| attr | attr . path () . is_ident ("test")) { test_functions . push (TestInfo { name : func . sig . ident . to_string () , file_path : file_path . to_path_buf () , }) ; } } Item :: Mod (module) => { if let Some ((_ , module_items)) = module . content { test_functions . extend (extract_test_functions_from_items (module_items , file_path)) ; } } _ => { } } }']
expression_str = 'for item in items { match item { Item :: Fn (func) => { if func . attrs . iter () . any (| attr | attr . path () . is_ident ("test")) { test_functions . push (TestInfo { name : func . sig . ident . to_string () , file_path : file_path . to_path_buf () , }) ; } } Item :: Mod (module) => { if let Some ((_ , module_items)) = module . content { test_functions . extend (extract_test_functions_from_items (module_items , file_path)) ; } } _ => { } } }'
depth = 2
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions.'| e | e . file_type () . is_file () && e . file_name () == "Cargo.toml"']
expression_str = '| e | e . file_type () . is_file () && e . file_name () == "Cargo.toml"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions.'"src"']
expression_str = '"src"'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."prelude_generator :: public_tests :: test_modify_file_dry_run () ?"]
expression_str = "prelude_generator :: public_tests :: test_modify_file_dry_run () ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."_args . use_statements_output_dir"]
expression_str = "_args . use_statements_output_dir"
depth = 5
used_types = []
other_types_count = 0
node_type = "Field"

[expressions."file_path . file_stem () . unwrap () . to_string_lossy () . to_string ()"]
expression_str = "file_path . file_stem () . unwrap () . to_string_lossy () . to_string ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'{ report_content . push_str (& format ! ("- Status:  Failed (Error: {}\n\n" , error)) ; }']
expression_str = '{ report_content . push_str (& format ! ("- Status:  Failed (Error: {}\n\n" , error)) ; }'
depth = 5
used_types = []
other_types_count = 0
node_type = "Block"

[expressions.'" Generate a JSON report of all unique test cases found in the repository."']
expression_str = '" Generate a JSON report of all unique test cases found in the repository."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'match syn :: parse_file (& file_content) { Ok (file) => file , Err (e) => { eprintln ! ("Warning: Could not parse file {}: {}" , file_path . display () , e) ; continue ; } }']
expression_str = 'match syn :: parse_file (& file_content) { Ok (file) => file , Err (e) => { eprintln ! ("Warning: Could not parse file {}: {}" , file_path . display () , e) ; continue ; } }'
depth = 4
used_types = []
other_types_count = 0
node_type = "Match"

[expressions.all_structs_by_layer]
expression_str = "all_structs_by_layer"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."{ args . path . clone () }"]
expression_str = "{ args . path . clone () }"
depth = 3
used_types = []
other_types_count = 0
node_type = "Block"

[expressions."tokio :: fs :: read_dir (& output_path) . await"]
expression_str = "tokio :: fs :: read_dir (& output_path) . await"
depth = 5
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."let Item :: Use (_) = item"]
expression_str = "let Item :: Use (_) = item"
depth = 4
used_types = []
other_types_count = 0
node_type = "Let"

[expressions.'writer . write_all (format ! ("---\n--- METRICS_START ---\n{}\n--- METRICS_END ---\n" , json_metrics) . as_bytes ())']
expression_str = 'writer . write_all (format ! ("---\n--- METRICS_START ---\n{}\n--- METRICS_END ---\n" , json_metrics) . as_bytes ())'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'type_name == "PathBuf"']
expression_str = 'type_name == "PathBuf"'
depth = 5
used_types = []
other_types_count = 0
node_type = "Binary"

[expressions.'| attr | { if attr . path () . is_ident ("derive") { if let Meta :: List (meta_list) = & attr . meta { let tokens_str = meta_list . tokens . to_string () ; tokens_str . contains ("Parser") || tokens_str . contains ("Serialize") || tokens_str . contains ("Deserialize") } else { false } } else { false } }']
expression_str = '| attr | { if attr . path () . is_ident ("derive") { if let Meta :: List (meta_list) = & attr . meta { let tokens_str = meta_list . tokens . to_string () ; tokens_str . contains ("Parser") || tokens_str . contains ("Serialize") || tokens_str . contains ("Deserialize") } else { false } } else { false } }'
depth = 3
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions.'code . push_str ("        // processing_time_stats,\n")']
expression_str = 'code . push_str ("        // processing_time_stats,\n")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"--cache-report"']
expression_str = '"--cache-report"'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'" Stop after processing N statements"']
expression_str = '" Stop after processing N statements"'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'"MacroExpansionFailed" . to_string ()']
expression_str = '"MacroExpansionFailed" . to_string ()'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."SymbolMap { map : HashMap :: new () , }"]
expression_str = "SymbolMap { map : HashMap :: new () , }"
depth = 2
used_types = []
other_types_count = 0
node_type = "Struct"

[expressions.'"fn main() { println!(\"Hello, world!\"); }" . to_string ()']
expression_str = '"fn main() { println!(\"Hello, world!\"); }" . to_string ()'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'writer . write_all (format ! ("        -> PATH environment variable: {:?}\n" , std :: env :: var ("PATH")) . as_bytes ()) . await']
expression_str = 'writer . write_all (format ! ("        -> PATH environment variable: {:?}\n" , std :: env :: var ("PATH")) . as_bytes ()) . await'
depth = 3
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.'if args . report { if let Some (results_file_path) = & args . results_file { if results_file_path . exists () { let json_content = fs :: read_to_string (results_file_path) . context ("Failed to read results file") ? ; let results : Vec < FileProcessingResult > = serde_json :: from_str (& json_content) . context ("Failed to deserialize results from JSON") ? ; generate_report (& results) ? ; } else { eprintln ! ("Error: Results file not found at {}. Cannot generate report." , results_file_path . display ()) ; } } } else { let mut excluded_crates : HashSet < String > = args . exclude_crates . clone () . into_iter () . collect () ; excluded_crates . insert ("prelude-generator" . to_string ()) ; excluded_crates . insert ("rust-decl-splitter" . to_string ()) ; excluded_crates . insert ("dependency-analyzer" . to_string ()) ; excluded_crates . insert ("prelude-collector" . to_string ()) ; println ! ("Excluded crates: {:?}" , excluded_crates) ; println ! ("\nPrelude generation complete.") ; println ! ("  -> Contents of all_file_processing_results: {:?}" , all_file_processing_results) ; if let Some (results_file_path) = & args . results_file { let json_content = serde_json :: to_string_pretty (& all_file_processing_results) . context ("Failed to serialize results to JSON") ? ; println ! ("  -> Attempting to save processing results to: {}" , results_file_path . display ()) ; fs :: write (results_file_path , json_content) . context ("Failed to write results to file") ? ; println ! ("Processing results saved to {}." , results_file_path . display ()) ; } else { println ! ("No results file specified. Skipping saving processing results.") ; } }']
expression_str = 'if args . report { if let Some (results_file_path) = & args . results_file { if results_file_path . exists () { let json_content = fs :: read_to_string (results_file_path) . context ("Failed to read results file") ? ; let results : Vec < FileProcessingResult > = serde_json :: from_str (& json_content) . context ("Failed to deserialize results from JSON") ? ; generate_report (& results) ? ; } else { eprintln ! ("Error: Results file not found at {}. Cannot generate report." , results_file_path . display ()) ; } } } else { let mut excluded_crates : HashSet < String > = args . exclude_crates . clone () . into_iter () . collect () ; excluded_crates . insert ("prelude-generator" . to_string ()) ; excluded_crates . insert ("rust-decl-splitter" . to_string ()) ; excluded_crates . insert ("dependency-analyzer" . to_string ()) ; excluded_crates . insert ("prelude-collector" . to_string ()) ; println ! ("Excluded crates: {:?}" , excluded_crates) ; println ! ("\nPrelude generation complete.") ; println ! ("  -> Contents of all_file_processing_results: {:?}" , all_file_processing_results) ; if let Some (results_file_path) = & args . results_file { let json_content = serde_json :: to_string_pretty (& all_file_processing_results) . context ("Failed to serialize results to JSON") ? ; println ! ("  -> Attempting to save processing results to: {}" , results_file_path . display ()) ; fs :: write (results_file_path , json_content) . context ("Failed to write results to file") ? ; println ! ("Processing results saved to {}." , results_file_path . display ()) ; } else { println ! ("No results file specified. Skipping saving processing results.") ; } }'
depth = 2
used_types = [
    "FileProcessingResult",
    "HashSet",
    "Vec",
]
other_types_count = 3
node_type = "If"

[expressions."a . cmp (b)"]
expression_str = "a . cmp (b)"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'writer . write_all (format ! ("---\n--- Stage 3: Classifying Use Statements ---\n") . as_bytes ()) . await']
expression_str = 'writer . write_all (format ! ("---\n--- Stage 3: Classifying Use Statements ---\n") . as_bytes ()) . await'
depth = 3
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.'"Test_Verification_Report.md"']
expression_str = '"Test_Verification_Report.md"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'"        // analyzer_version_counts,\n"']
expression_str = '"        // analyzer_version_counts,\n"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'"enum" . to_string ()']
expression_str = '"enum" . to_string ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."vec ! [test_func1 , test_func2]"]
expression_str = "vec ! [test_func1 , test_func2]"
depth = 4
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions."PipelineFunctor :: map (& ast_reconstruction_functor , writer , validated_file . clone () ,) . await"]
expression_str = "PipelineFunctor :: map (& ast_reconstruction_functor , writer , validated_file . clone () ,) . await"
depth = 4
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."args . file . as_ref ()"]
expression_str = "args . file . as_ref ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'PathBuf :: from ("generated/ast_statistics.rs")']
expression_str = 'PathBuf :: from ("generated/ast_statistics.rs")'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'code . push_str (& format ! ("    analyzer_version_counts.insert(\"{}\".to_string(), {});\n" , version , count) ,)']
expression_str = 'code . push_str (& format ! ("    analyzer_version_counts.insert(\"{}\".to_string(), {});\n" , version , count) ,)'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'if cached_file_path . exists () { writer . write_all (format ! ("      -> Using cached expanded code for: {}\n" , file_path . display ()) . as_bytes ()) . await ? ; let expanded_code = fs :: read_to_string (& cached_file_path) . await . with_context (| | format ! ("Failed to read cached expanded code for {}" , file_path . display ())) ? ; return Ok ((syn :: parse_file (& expanded_code) . with_context (| | format ! ("Failed to parse cached expanded code for {}" , file_path . display ())) ? , None)) ; }']
expression_str = 'if cached_file_path . exists () { writer . write_all (format ! ("      -> Using cached expanded code for: {}\n" , file_path . display ()) . as_bytes ()) . await ? ; let expanded_code = fs :: read_to_string (& cached_file_path) . await . with_context (| | format ! ("Failed to read cached expanded code for {}" , file_path . display ())) ? ; return Ok ((syn :: parse_file (& expanded_code) . with_context (| | format ! ("Failed to parse cached expanded code for {}" , file_path . display ())) ? , None)) ; }'
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions.should_process_file]
expression_str = "should_process_file"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."current_file_size > 0"]
expression_str = "current_file_size > 0"
depth = 3
used_types = []
other_types_count = 0
node_type = "Binary"

[expressions."ExpressionInfo { expression_str : expr_str . clone () , depth : self . current_depth , used_types , other_types_count , node_type , }"]
expression_str = "ExpressionInfo { expression_str : expr_str . clone () , depth : self . current_depth , used_types , other_types_count , node_type , }"
depth = 3
used_types = []
other_types_count = 0
node_type = "Struct"

[expressions."* self . method_co_occurrences . entry (method_names) . or_insert (0) += 1"]
expression_str = "* self . method_co_occurrences . entry (method_names) . or_insert (0) += 1"
depth = 2
used_types = []
other_types_count = 0
node_type = "Binary"

[expressions.'& format ! ("Type Usage Report (Max Depth: {})" , max_expression_depth)']
expression_str = '& format ! ("Type Usage Report (Max Depth: {})" , max_expression_depth)'
depth = 3
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."current_layer_num > 8"]
expression_str = "current_layer_num > 8"
depth = 4
used_types = []
other_types_count = 0
node_type = "Binary"

[expressions."if let Some ((_ , module_items)) = module . content { test_functions . extend (extract_test_functions_from_items (module_items , file_path)) ; }"]
expression_str = "if let Some ((_ , module_items)) = module . content { test_functions . extend (extract_test_functions_from_items (module_items , file_path)) ; }"
depth = 5
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'" Extracts test functions from a single Rust file."']
expression_str = '" Extracts test functions from a single Rust file."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."for used_type in & info . used_types { all_user_defined_types . insert (used_type . clone ()) ; }"]
expression_str = "for used_type in & info . used_types { all_user_defined_types . insert (used_type . clone ()) ; }"
depth = 3
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions.'writer . write_all (format ! ("      -> Wrote expanded code to cache: {}\n" , cached_file_path . display ()) . as_bytes ()) . await ?']
expression_str = 'writer . write_all (format ! ("      -> Wrote expanded code to cache: {}\n" , cached_file_path . display ()) . as_bytes ()) . await ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."visit :: visit_item_impl (self , i)"]
expression_str = "visit :: visit_item_impl (self , i)"
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."Args :: parse"]
expression_str = "Args :: parse"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."tokio :: fs :: create_dir_all (output_file_path . parent () . unwrap ()) . await"]
expression_str = "tokio :: fs :: create_dir_all (output_file_path . parent () . unwrap ()) . await"
depth = 3
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.'toml :: to_string_pretty (& mapping) . context ("Failed to serialize mapping to TOML")']
expression_str = 'toml :: to_string_pretty (& mapping) . context ("Failed to serialize mapping to TOML")'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'format ! ("--- Stage 5: AST Reconstruction from Hugging Face Dataset ---\n") . as_bytes ()']
expression_str = 'format ! ("--- Stage 5: AST Reconstruction from Hugging Face Dataset ---\n") . as_bytes ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'report_content . push_str (& format ! ("Total unique test functions found: {}\n\n" , test_infos . len ()))']
expression_str = 'report_content . push_str (& format ! ("Total unique test functions found: {}\n\n" , test_infos . len ()))'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"## Detailed Results\n"']
expression_str = '"## Detailed Results\n"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."args . path"]
expression_str = "args . path"
depth = 5
used_types = []
other_types_count = 0
node_type = "Field"

[expressions."prettyplease :: unparse"]
expression_str = "prettyplease :: unparse"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."return Ok (())"]
expression_str = "return Ok (())"
depth = 3
used_types = []
other_types_count = 0
node_type = "Return"

[expressions.'"Closure"']
expression_str = '"Closure"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."modify_crate_root (& src_dir , false , false) ?"]
expression_str = "modify_crate_root (& src_dir , false , false) ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."quote ! (# use_item) . to_string ()"]
expression_str = "quote ! (# use_item) . to_string ()"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."i . segments . last ()"]
expression_str = "i . segments . last ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'fs :: create_dir_all (crate_root . join ("tests")) ?']
expression_str = 'fs :: create_dir_all (crate_root . join ("tests")) ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'"struct"']
expression_str = '"struct"'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'for entry in WalkDir :: new (project_root) . into_iter () . filter_map (| e | e . ok ()) . filter (| e | e . file_type () . is_file () && e . path () . extension () . map_or (false , | ext | ext == "rs")) . filter (| e | { if let Some (names) = filter_names { names . iter () . any (| name | e . file_name () . to_string_lossy () . contains (name)) } else { true } }) { let path = entry . path () ; let content = match std :: fs :: read_to_string (& path) { Ok (c) => c , Err (e) => { eprintln ! ("Error reading file {}: {:?}" , path . display () , e) ; continue ; } } ; let file = match syn :: parse_file (& content) { Ok (f) => f , Err (e) => { eprintln ! ("Warning: Could not parse file {}: {:?}" , path . display () , e) ; continue ; } } ; let mut collector = TypeCollector { type_map : & mut type_map , } ; collector . visit_file (& file) ; }']
expression_str = 'for entry in WalkDir :: new (project_root) . into_iter () . filter_map (| e | e . ok ()) . filter (| e | e . file_type () . is_file () && e . path () . extension () . map_or (false , | ext | ext == "rs")) . filter (| e | { if let Some (names) = filter_names { names . iter () . any (| name | e . file_name () . to_string_lossy () . contains (name)) } else { true } }) { let path = entry . path () ; let content = match std :: fs :: read_to_string (& path) { Ok (c) => c , Err (e) => { eprintln ! ("Error reading file {}: {:?}" , path . display () , e) ; continue ; } } ; let file = match syn :: parse_file (& content) { Ok (f) => f , Err (e) => { eprintln ! ("Warning: Could not parse file {}: {:?}" , path . display () , e) ; continue ; } } ; let mut collector = TypeCollector { type_map : & mut type_map , } ; collector . visit_file (& file) ; }'
depth = 2
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions.'if ! errors . is_empty () { eprintln ! (r"\n--- Errors Encountered during struct processing ---") ; for error in & errors { eprintln ! ("{:?}" , error) ; } eprintln ! (r"---------------------------------------------------") ; return Err (anyhow :: anyhow ! ("Struct processing completed with errors.")) ; } else { println ! (r"Declaration processing completed successfully.") ; return Ok (()) }']
expression_str = 'if ! errors . is_empty () { eprintln ! (r"\n--- Errors Encountered during struct processing ---") ; for error in & errors { eprintln ! ("{:?}" , error) ; } eprintln ! (r"---------------------------------------------------") ; return Err (anyhow :: anyhow ! ("Struct processing completed with errors.")) ; } else { println ! (r"Declaration processing completed successfully.") ; return Ok (()) }'
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions."& all_string_constants"]
expression_str = "& all_string_constants"
depth = 5
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'return Err (anyhow :: anyhow ! ("git config user.name failed: {}\nStderr: {}" , String :: from_utf8_lossy (& output . status . code () . unwrap_or (- 1) . to_string () . as_bytes ()) , String :: from_utf8_lossy (& output . stderr)))']
expression_str = 'return Err (anyhow :: anyhow ! ("git config user.name failed: {}\nStderr: {}" , String :: from_utf8_lossy (& output . status . code () . unwrap_or (- 1) . to_string () . as_bytes ()) , String :: from_utf8_lossy (& output . stderr)))'
depth = 5
used_types = []
other_types_count = 0
node_type = "Return"

[expressions.temp_crate_path]
expression_str = "temp_crate_path"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'| e | e . file_type () . is_file () && e . path () . extension () . map_or (false , | ext | ext == "rs")']
expression_str = '| e | e . file_type () . is_file () && e . path () . extension () . map_or (false , | ext | ext == "rs")'
depth = 3
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions.'writer . write_all (format ! ("--- Inspecting: {} ---\n" , self . label) . as_bytes ()) . await']
expression_str = 'writer . write_all (format ! ("--- Inspecting: {} ---\n" , self . label) . as_bytes ()) . await'
depth = 5
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."type_usage_analyzer :: analyze_type_usage (& args) . await ?"]
expression_str = "type_usage_analyzer :: analyze_type_usage (& args) . await ?"
depth = 4
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.map]
expression_str = "map"
depth = 2
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."syn :: visit :: visit_expr_call"]
expression_str = "syn :: visit :: visit_expr_call"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."serde_json :: to_string_pretty (& dummy_results)"]
expression_str = "serde_json :: to_string_pretty (& dummy_results)"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'writer . write_all (format ! ("--- Stage 1: Parsing ---\n") . as_bytes ()) . await']
expression_str = 'writer . write_all (format ! ("--- Stage 1: Parsing ---\n") . as_bytes ()) . await'
depth = 3
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.'script_content . push_str ("set -e\n\n")']
expression_str = 'script_content . push_str ("set -e\n\n")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'Command :: new ("rustc") . arg ("--version") . arg ("--verbose") . output () ?']
expression_str = 'Command :: new ("rustc") . arg ("--version") . arg ("--verbose") . output () ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'format ! ("Failed to write generated code to {:?}" , output_file_path)']
expression_str = 'format ! ("Failed to write generated code to {:?}" , output_file_path)'
depth = 4
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions.'toml :: to_string_pretty (& collected_data) . context ("Failed to serialize collected analysis data to TOML") ?']
expression_str = 'toml :: to_string_pretty (& collected_data) . context ("Failed to serialize collected analysis data to TOML") ?'
depth = 3
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."tests_by_crate . get (crate_path) . unwrap () . clone ()"]
expression_str = "tests_by_crate . get (crate_path) . unwrap () . clone ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."fs :: read_to_string (& main_rs_path)"]
expression_str = "fs :: read_to_string (& main_rs_path)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'" Recursively extracts test functions from a list of AST items."']
expression_str = '" Recursively extracts test functions from a list of AST items."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."_args . test_report_output_file . clone ()"]
expression_str = "_args . test_report_output_file . clone ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."write_numerical_constants_to_hierarchical_structure (& all_numerical_constants , & numerical_output_dir) . await ?"]
expression_str = "write_numerical_constants_to_hierarchical_structure (& all_numerical_constants , & numerical_output_dir) . await ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'toml :: to_string_pretty (& serializable_decls) . context ("Failed to serialize declarations to TOML ") ?']
expression_str = 'toml :: to_string_pretty (& serializable_decls) . context ("Failed to serialize declarations to TOML ") ?'
depth = 3
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.cache_dir]
expression_str = "cache_dir"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."InspectFunctor { label , _phantom : std :: marker :: PhantomData , }"]
expression_str = "InspectFunctor { label , _phantom : std :: marker :: PhantomData , }"
depth = 2
used_types = []
other_types_count = 0
node_type = "Struct"

[expressions.'setup_test_file (& dir , "test_file.rs" , "use std::collections::HashMap;\nuse crate::another_module;\n\nfn main() {}\n" ,)']
expression_str = 'setup_test_file (& dir , "test_file.rs" , "use std::collections::HashMap;\nuse crate::another_module;\n\nfn main() {}\n" ,)'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'writer . write_all (format ! ("  -> Generated code written to {:?}\n" , output_file_path) . as_bytes () ,) . await ?']
expression_str = 'writer . write_all (format ! ("  -> Generated code written to {:?}\n" , output_file_path) . as_bytes () ,) . await ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'async move { measurement :: record_function_entry ("PreprocessFunctor::map") ; let ClassifiedUseStatements (classified_uses , _) = input ; let mut new_classified_uses = Vec :: new () ; for use_statement in classified_uses { if use_statement . error . is_some () { let temp_dir = tempfile :: tempdir () ? ; let temp_file_path = temp_dir . path () . join ("main.rs") ; let content = format ! ("{}\nfn main() {{}}" , use_statement . statement) ; tokio :: fs :: write (& temp_file_path , content) . await ? ; let output = tokio :: process :: Command :: new ("rustc") . arg (& temp_file_path) . output () . await ? ; if output . status . success () { new_classified_uses . push (UseStatement { statement : use_statement . statement , error : None , git_details : None , nix_details : None , rust_details : None , cargo_details : None , syn_details : None , llvm_details : None , linux_details : None , }) ; } else { new_classified_uses . push (UseStatement { statement : use_statement . statement , error : Some (String :: from_utf8_lossy (& output . stderr) . to_string ()) , git_details : None , nix_details : None , rust_details : None , cargo_details : None , syn_details : None , llvm_details : None , linux_details : None , }) ; } } else { new_classified_uses . push (UseStatement { statement : use_statement . statement , error : use_statement . error , git_details : use_statement . git_details , nix_details : use_statement . nix_details , rust_details : use_statement . rust_details , cargo_details : use_statement . cargo_details , syn_details : use_statement . syn_details , llvm_details : use_statement . llvm_details , linux_details : use_statement . linux_details , }) ; } } let __result = Ok (ClassifiedUseStatements (new_classified_uses , HashMap :: new ())) ; measurement :: record_function_exit ("PreprocessFunctor::map") ; __result }']
expression_str = 'async move { measurement :: record_function_entry ("PreprocessFunctor::map") ; let ClassifiedUseStatements (classified_uses , _) = input ; let mut new_classified_uses = Vec :: new () ; for use_statement in classified_uses { if use_statement . error . is_some () { let temp_dir = tempfile :: tempdir () ? ; let temp_file_path = temp_dir . path () . join ("main.rs") ; let content = format ! ("{}\nfn main() {{}}" , use_statement . statement) ; tokio :: fs :: write (& temp_file_path , content) . await ? ; let output = tokio :: process :: Command :: new ("rustc") . arg (& temp_file_path) . output () . await ? ; if output . status . success () { new_classified_uses . push (UseStatement { statement : use_statement . statement , error : None , git_details : None , nix_details : None , rust_details : None , cargo_details : None , syn_details : None , llvm_details : None , linux_details : None , }) ; } else { new_classified_uses . push (UseStatement { statement : use_statement . statement , error : Some (String :: from_utf8_lossy (& output . stderr) . to_string ()) , git_details : None , nix_details : None , rust_details : None , cargo_details : None , syn_details : None , llvm_details : None , linux_details : None , }) ; } } else { new_classified_uses . push (UseStatement { statement : use_statement . statement , error : use_statement . error , git_details : use_statement . git_details , nix_details : use_statement . nix_details , rust_details : use_statement . rust_details , cargo_details : use_statement . cargo_details , syn_details : use_statement . syn_details , llvm_details : use_statement . llvm_details , linux_details : use_statement . linux_details , }) ; } } let __result = Ok (ClassifiedUseStatements (new_classified_uses , HashMap :: new ())) ; measurement :: record_function_exit ("PreprocessFunctor::map") ; __result }'
depth = 3
used_types = []
other_types_count = 0
node_type = "Async"

[expressions.'tokio :: fs :: write (& cached_file_path , & relevant_expanded_code) . await . with_context (| | format ! ("Failed to write expanded code to cache for {}" , file_path . display ()))']
expression_str = 'tokio :: fs :: write (& cached_file_path , & relevant_expanded_code) . await . with_context (| | format ! ("Failed to write expanded code to cache for {}" , file_path . display ()))'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."string_constants . iter ()"]
expression_str = "string_constants . iter ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'{ let mut full_path = base_path . join ("::") ; if ! full_path . is_empty () { full_path . push_str ("::") ; } full_path . push_str ("* ") ; flat_uses . push (UseStatement { statement : format ! ("use {};" , full_path) , error : None , git_details : None , nix_details : None , rust_details : None , cargo_details : None , syn_details : None , llvm_details : None , linux_details : None , }) ; }']
expression_str = '{ let mut full_path = base_path . join ("::") ; if ! full_path . is_empty () { full_path . push_str ("::") ; } full_path . push_str ("* ") ; flat_uses . push (UseStatement { statement : format ! ("use {};" , full_path) , error : None , git_details : None , nix_details : None , rust_details : None , cargo_details : None , syn_details : None , llvm_details : None , linux_details : None , }) ; }'
depth = 3
used_types = []
other_types_count = 0
node_type = "Block"

[expressions.'stderr . write_all (format ! ("Pipeline failed: {:?}\n" , e) . as_bytes ()) . await']
expression_str = 'stderr . write_all (format ! ("Pipeline failed: {:?}\n" , e) . as_bytes ()) . await'
depth = 4
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."sorted_uses . sort_unstable ()"]
expression_str = "sorted_uses . sort_unstable ()"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."dir . path ()"]
expression_str = "dir . path ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."self . map"]
expression_str = "self . map"
depth = 4
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'{ uses . insert ("use std::collections::HashMap;\n") ; }']
expression_str = '{ uses . insert ("use std::collections::HashMap;\n") ; }'
depth = 5
used_types = []
other_types_count = 0
node_type = "Block"

[expressions."if let syn :: Expr :: Lit (expr_lit) = & constant . expr . as_ref () { match & expr_lit . lit { syn :: Lit :: Int (_) | syn :: Lit :: Float (_) => all_numerical_constants . push (constant . clone ()) , syn :: Lit :: Str (_) => all_string_constants . push (constant . clone ()) , _ => { { } } , } }"]
expression_str = "if let syn :: Expr :: Lit (expr_lit) = & constant . expr . as_ref () { match & expr_lit . lit { syn :: Lit :: Int (_) | syn :: Lit :: Float (_) => all_numerical_constants . push (constant . clone ()) , syn :: Lit :: Str (_) => all_string_constants . push (constant . clone ()) , _ => { { } } , } }"
depth = 3
used_types = []
other_types_count = 0
node_type = "If"

[expressions."for structure in layer0_structs { let struct_name = structure . ident . to_string () ; let layer = 0 ; let structs_output_dir = generated_decls_output_dir . join (format ! (\"layer_{}\" , layer)) . join (\"struct\") ; println ! (\"Attempting to create directory: {}\" , structs_output_dir . display ()) ; tokio :: fs :: create_dir_all (& structs_output_dir) . await . context (format ! (\"Failed to create output directory {:?}, for struct {}\" , structs_output_dir , struct_name)) ? ; let file_name = format ! (\"{}.rs\" , struct_name) ; let output_path = structs_output_dir . join (& file_name) ; println ! (\"Attempting to write file: {}\" , output_path . display ()) ; let content = quote :: quote ! { # structure } . to_string () ; let code = match struct_name . as_str () { \"DeclsVisitor\" => { format ! (\"use syn::{{visit::Visit, ItemConst, ItemFn, ItemStruct, ItemEnum, ItemStatic, Item}};\n{}\" , content) } , \"TypeCollector\" => { format ! (\"use std::collections::HashMap;\nuse crate::type_extractor::TypeInfo;\n{}\" , content) } , _ => content , } ; let result = async { tokio :: fs :: write (& output_path , code . as_bytes ()) . await . context (format ! (\"Failed to write struct {:?} to {:?}\" , struct_name , output_path)) ? ; println ! (\"  -> Wrote struct {:?} to {:?}\" , struct_name , output_path) ; utils :: format_rust_code (& output_path) . await . context (format ! (\"Struct {:?} formatting failed for {:?}\" , struct_name , output_path)) ? ; println ! (\"  -> Struct {:?} formatted successfully.\\n\" , struct_name) ; utils :: validate_rust_code (& output_path) . await . context (format ! (\"Struct {:?} validation failed for {:?}\" , struct_name , output_path)) ? ; println ! (r\"  -> Struct {:?} validated successfully.\\n\" , struct_name) ; Ok (()) } . await ; if let Err (e) = result { eprintln ! (r\"Error processing struct {}: {:?}\\n\" , struct_name , e) ; errors . push (e) ; } }"]
expression_str = '''
for structure in layer0_structs { let struct_name = structure . ident . to_string () ; let layer = 0 ; let structs_output_dir = generated_decls_output_dir . join (format ! ("layer_{}" , layer)) . join ("struct") ; println ! ("Attempting to create directory: {}" , structs_output_dir . display ()) ; tokio :: fs :: create_dir_all (& structs_output_dir) . await . context (format ! ("Failed to create output directory {:?}, for struct {}" , structs_output_dir , struct_name)) ? ; let file_name = format ! ("{}.rs" , struct_name) ; let output_path = structs_output_dir . join (& file_name) ; println ! ("Attempting to write file: {}" , output_path . display ()) ; let content = quote :: quote ! { # structure } . to_string () ; let code = match struct_name . as_str () { "DeclsVisitor" => { format ! ("use syn::{{visit::Visit, ItemConst, ItemFn, ItemStruct, ItemEnum, ItemStatic, Item}};
{}" , content) } , "TypeCollector" => { format ! ("use std::collections::HashMap;
use crate::type_extractor::TypeInfo;
{}" , content) } , _ => content , } ; let result = async { tokio :: fs :: write (& output_path , code . as_bytes ()) . await . context (format ! ("Failed to write struct {:?} to {:?}" , struct_name , output_path)) ? ; println ! ("  -> Wrote struct {:?} to {:?}" , struct_name , output_path) ; utils :: format_rust_code (& output_path) . await . context (format ! ("Struct {:?} formatting failed for {:?}" , struct_name , output_path)) ? ; println ! ("  -> Struct {:?} formatted successfully.\n" , struct_name) ; utils :: validate_rust_code (& output_path) . await . context (format ! ("Struct {:?} validation failed for {:?}" , struct_name , output_path)) ? ; println ! (r"  -> Struct {:?} validated successfully.\n" , struct_name) ; Ok (()) } . await ; if let Err (e) = result { eprintln ! (r"Error processing struct {}: {:?}\n" , struct_name , e) ; errors . push (e) ; } }'''
depth = 3
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions."& []"]
expression_str = "& []"
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."metrics . entry (function_name . to_string ()) . or_insert_with (FunctionMetrics :: new)"]
expression_str = "metrics . entry (function_name . to_string ()) . or_insert_with (FunctionMetrics :: new)"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."self . type_map . entry (struct_name . clone ())"]
expression_str = "self . type_map . entry (struct_name . clone ())"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'match syn :: parse_file (& content) { Ok (file) => { println ! ("       Successfully parsed file: {}" , path . display ()) ; for item in file . items { if let syn :: Item :: Const (constant) = item { let type_name = get_type_name (& constant . ty) ; let value_str = get_constant_value_string (& constant . expr) ; println ! ("         Found constant: {} (type: {}, value: {})" , constant . ident , type_name , value_str) ; if ! type_name . is_empty () && ! value_str . is_empty () { * constants_by_type_and_size . entry (type_name) . or_default () . entry (value_str) . or_insert (0) += 1 ; } } } } , Err (e) => { eprintln ! ("       Failed to parse file {}: {}" , path . display () , e) ; } }']
expression_str = 'match syn :: parse_file (& content) { Ok (file) => { println ! ("       Successfully parsed file: {}" , path . display ()) ; for item in file . items { if let syn :: Item :: Const (constant) = item { let type_name = get_type_name (& constant . ty) ; let value_str = get_constant_value_string (& constant . expr) ; println ! ("         Found constant: {} (type: {}, value: {})" , constant . ident , type_name , value_str) ; if ! type_name . is_empty () && ! value_str . is_empty () { * constants_by_type_and_size . entry (type_name) . or_default () . entry (value_str) . or_insert (0) += 1 ; } } } } , Err (e) => { eprintln ! ("       Failed to parse file {}: {}" , path . display () , e) ; } }'
depth = 4
used_types = []
other_types_count = 0
node_type = "Match"

[expressions.'fs :: create_dir_all (& crate_path . join ("src")) . unwrap ()']
expression_str = 'fs :: create_dir_all (& crate_path . join ("src")) . unwrap ()'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."syn :: visit :: visit_type (self , i)"]
expression_str = "syn :: visit :: visit_type (self , i)"
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."get_rustc_info ()"]
expression_str = "get_rustc_info ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'add_primitive_type (& mut symbols , "i64")']
expression_str = 'add_primitive_type (& mut symbols , "i64")'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'crate_root . join ("tests")']
expression_str = 'crate_root . join ("tests")'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."args . split_expanded_files . clone ()"]
expression_str = "args . split_expanded_files . clone ()"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'for (node_type , (min , max , sum , count)) in & stats . column_stats { code . push_str (& format ! ("    column_stats.insert(\"{}\".to_string(), ({}, {}, {}, {}));\n" , node_type , min , max , sum , count) ,) ; }']
expression_str = 'for (node_type , (min , max , sum , count)) in & stats . column_stats { code . push_str (& format ! ("    column_stats.insert(\"{}\".to_string(), ({}, {}, {}, {}));\n" , node_type , min , max , sum , count) ,) ; }'
depth = 2
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions."visit :: visit_item_static"]
expression_str = "visit :: visit_item_static"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."variant . fields"]
expression_str = "variant . fields"
depth = 5
used_types = []
other_types_count = 0
node_type = "Field"

[expressions."| r | matches ! (r . status , FileProcessingStatus :: Skipped { .. })"]
expression_str = "| r | matches ! (r . status , FileProcessingStatus :: Skipped { .. })"
depth = 4
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions."let Some (struct_lattice_info) = self . struct_lattices . get_mut (& impl_for_type_name)"]
expression_str = "let Some (struct_lattice_info) = self . struct_lattices . get_mut (& impl_for_type_name)"
depth = 4
used_types = []
other_types_count = 0
node_type = "Let"

[expressions."file_path_str . to_string ()"]
expression_str = "file_path_str . to_string ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'{ let default_config_path = project_root . join ("config.toml") ; if default_config_path . exists () { Some (crate :: config_parser :: read_config (& default_config_path , & project_root) ?) } else { None } }']
expression_str = '{ let default_config_path = project_root . join ("config.toml") ; if default_config_path . exists () { Some (crate :: config_parser :: read_config (& default_config_path , & project_root) ?) } else { None } }'
depth = 3
used_types = []
other_types_count = 0
node_type = "Block"

[expressions.numerical_constants]
expression_str = "numerical_constants"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."extract_test_cases_from_file (file_path)"]
expression_str = "extract_test_cases_from_file (file_path)"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'for test_name in sorted_test_names { report_content . push_str (& format ! ("- {}\n" , test_name)) ; }']
expression_str = 'for test_name in sorted_test_names { report_content . push_str (& format ! ("- {}\n" , test_name)) ; }'
depth = 3
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions."if is_complex_type (& ident_str) { return true ; }"]
expression_str = "if is_complex_type (& ident_str) { return true ; }"
depth = 5
used_types = []
other_types_count = 0
node_type = "If"

[expressions."()"]
expression_str = "()"
depth = 5
used_types = []
other_types_count = 0
node_type = "Tuple"

[expressions.'report_content . push_str ("The script will navigate to each identified Rust crate and run `cargo test` within it.\n\n")']
expression_str = 'report_content . push_str ("The script will navigate to each identified Rust crate and run `cargo test` within it.\n\n")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."fs :: read_to_string (path)"]
expression_str = "fs :: read_to_string (path)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."struct_name . clone ()"]
expression_str = "struct_name . clone ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."visit :: visit_path"]
expression_str = "visit :: visit_path"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."let Item :: Mod (mod_item) = item"]
expression_str = "let Item :: Mod (mod_item) = item"
depth = 4
used_types = []
other_types_count = 0
node_type = "Let"

[expressions."RE_SPLIT_IDENT . split (ident_str) . filter (| s | ! s . is_empty ()) . map (| s | s . to_lowercase ()) . collect ()"]
expression_str = "RE_SPLIT_IDENT . split (ident_str) . filter (| s | ! s . is_empty ()) . map (| s | s . to_lowercase ()) . collect ()"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."string_constants . push (constant)"]
expression_str = "string_constants . push (constant)"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'report_content . push_str ("## How to Run Tests\n")']
expression_str = 'report_content . push_str ("## How to Run Tests\n")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.cache_key]
expression_str = "cache_key"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'return "// No constant declarations found in this module.\n" . to_string ()']
expression_str = 'return "// No constant declarations found in this module.\n" . to_string ()'
depth = 3
used_types = []
other_types_count = 0
node_type = "Return"

[expressions.'{ println ! ("No results file specified. Skipping saving processing results.") ; }']
expression_str = '{ println ! ("No results file specified. Skipping saving processing results.") ; }'
depth = 5
used_types = []
other_types_count = 0
node_type = "Block"

[expressions."decl . referenced_types . iter () . any (| dep | { ! current_layer_idents . contains (dep) && ! layered_decls . values () . flatten () . any (| d | d . get_identifier () == * dep) })"]
expression_str = "decl . referenced_types . iter () . any (| dep | { ! current_layer_idents . contains (dep) && ! layered_decls . values () . flatten () . any (| d | d . get_identifier () == * dep) })"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'" Directory to output the generated declaration files for split-expanded-bin."']
expression_str = '" Directory to output the generated declaration files for split-expanded-bin."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'format ! ("Failed to create output directory {:?}" , constants_output_dir)']
expression_str = 'format ! ("Failed to create output directory {:?}" , constants_output_dir)'
depth = 4
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions.'add_std_lib_symbol (& mut symbols , "io" , "module" , Some ("std"))']
expression_str = 'add_std_lib_symbol (& mut symbols , "io" , "module" , Some ("std"))'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.string_constants]
expression_str = "string_constants"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."args . generated_decls_output_dir . clone ()"]
expression_str = "args . generated_decls_output_dir . clone ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."& files_to_process"]
expression_str = "& files_to_process"
depth = 3
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'if let Some (config_file_path) = & args . config_file_path { Some (crate :: config_parser :: read_config (config_file_path , & project_root) ?) } else { let default_config_path = project_root . join ("config.toml") ; if default_config_path . exists () { Some (crate :: config_parser :: read_config (& default_config_path , & project_root) ?) } else { None } }']
expression_str = 'if let Some (config_file_path) = & args . config_file_path { Some (crate :: config_parser :: read_config (config_file_path , & project_root) ?) } else { let default_config_path = project_root . join ("config.toml") ; if default_config_path . exists () { Some (crate :: config_parser :: read_config (& default_config_path , & project_root) ?) } else { None } }'
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'parent . join ("Cargo.toml") . exists ()']
expression_str = 'parent . join ("Cargo.toml") . exists ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'project_root . join ("collected_errors.json ")']
expression_str = 'project_root . join ("collected_errors.json ")'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'symbols . insert (id . to_string () , ResolvedDependency { id : id . to_string () , dependency_type : "primitive_type" . to_string () , crate_name : "std" . to_string () , module_path : "std" . to_string () , usage_count : 0 , })']
expression_str = 'symbols . insert (id . to_string () , ResolvedDependency { id : id . to_string () , dependency_type : "primitive_type" . to_string () , crate_name : "std" . to_string () , module_path : "std" . to_string () , usage_count : 0 , })'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."crate :: config_parser :: read_config (config_file_path , & project_root) ?"]
expression_str = "crate :: config_parser :: read_config (config_file_path , & project_root) ?"
depth = 4
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'Ok ((syn :: parse_file ("") . unwrap () , Some (error_sample)))']
expression_str = 'Ok ((syn :: parse_file ("") . unwrap () , Some (error_sample)))'
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'if ! output . status . success () { return Err (anyhow :: anyhow ! ("git config user.name failed: {}\nStderr: {}" , String :: from_utf8_lossy (& output . status . code () . unwrap_or (- 1) . to_string () . as_bytes ()) , String :: from_utf8_lossy (& output . stderr))) ; }']
expression_str = 'if ! output . status . success () { return Err (anyhow :: anyhow ! ("git config user.name failed: {}\nStderr: {}" , String :: from_utf8_lossy (& output . status . code () . unwrap_or (- 1) . to_string () . as_bytes ()) , String :: from_utf8_lossy (& output . stderr))) ; }'
depth = 4
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'"test_file.rs"']
expression_str = '"test_file.rs"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."Some (relevant_expanded_code . to_string ())"]
expression_str = "Some (relevant_expanded_code . to_string ())"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'| | format ! ("Failed to write run_all_tests.sh to {}" , script_path . display ())']
expression_str = '| | format ! ("Failed to write run_all_tests.sh to {}" , script_path . display ())'
depth = 4
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions.'"\n\nImpl Lattice Information\n"']
expression_str = '"\n\nImpl Lattice Information\n"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'" Run the declaration splitter functionality."']
expression_str = '" Run the declaration splitter functionality."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'args . generated_decls_output_dir . clone () . ok_or_else (| | anyhow :: anyhow ! ("generated_decls_output_dir is required"))']
expression_str = 'args . generated_decls_output_dir . clone () . ok_or_else (| | anyhow :: anyhow ! ("generated_decls_output_dir is required"))'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'line_stats . insert ("variable" . to_string () , (25 , 274 , 5772 , 41))']
expression_str = 'line_stats . insert ("variable" . to_string () , (25 , 274 , 5772 , 41))'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."tokio :: fs :: create_dir_all (cached_file_path . parent () . unwrap ()) . await"]
expression_str = "tokio :: fs :: create_dir_all (cached_file_path . parent () . unwrap ()) . await"
depth = 4
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."file_path . is_file ()"]
expression_str = "file_path . is_file ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.generate_report]
expression_str = "generate_report"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'let Some (field_ident) = i . member . clone () . into_token_stream () . to_string () . strip_prefix (".") . map (| s | s . to_string ())']
expression_str = 'let Some (field_ident) = i . member . clone () . into_token_stream () . to_string () . strip_prefix (".") . map (| s | s . to_string ())'
depth = 3
used_types = []
other_types_count = 0
node_type = "Let"

[expressions.'format ! ("---\n--- Stage 3: Classifying Use Statements ---\n") . as_bytes ()']
expression_str = 'format ! ("---\n--- Stage 3: Classifying Use Statements ---\n") . as_bytes ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."! ident_str . is_empty ()"]
expression_str = "! ident_str . is_empty ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "Unary"

[expressions.'format ! ("{:#?}\n" , ast_statistics) . as_bytes ()']
expression_str = 'format ! ("{:#?}\n" , ast_statistics) . as_bytes ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."visitor . struct_lattices"]
expression_str = "visitor . struct_lattices"
depth = 5
used_types = []
other_types_count = 0
node_type = "Field"

[expressions."std :: env :: current_dir () ? . parent () . unwrap ()"]
expression_str = "std :: env :: current_dir () ? . parent () . unwrap ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'if prelude_path . exists () && ! force { println ! ("  -> Skipping prelude file generation for {} (file exists, use --force to overwrite)." , prelude_path . display ()) ; } else { println ! ("  -> Generating prelude file: {}" , prelude_path . display ()) ; println ! ("    -> Writing prelude content to: {}" , prelude_path . display ()) ; fs :: write (& prelude_path , prelude_content) ? ; }']
expression_str = 'if prelude_path . exists () && ! force { println ! ("  -> Skipping prelude file generation for {} (file exists, use --force to overwrite)." , prelude_path . display ()) ; } else { println ! ("  -> Generating prelude file: {}" , prelude_path . display ()) ; println ! ("    -> Writing prelude content to: {}" , prelude_path . display ()) ; fs :: write (& prelude_path , prelude_content) ? ; }'
depth = 4
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'file_path . extension () . map_or (false , | ext | ext == "rs")']
expression_str = 'file_path . extension () . map_or (false , | ext | ext == "rs")'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."content . to_string ()"]
expression_str = "content . to_string ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."measurement :: record_function_exit"]
expression_str = "measurement :: record_function_exit"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."command_handlers :: handle_run_decl_splitter (& args , & project_root , & rustc_info) . await"]
expression_str = "command_handlers :: handle_run_decl_splitter (& args , & project_root , & rustc_info) . await"
depth = 4
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.'"--exclude-crates"']
expression_str = '"--exclude-crates"'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'PathBuf :: from ("generated/hf_dataset_output/mapping.toml")']
expression_str = 'PathBuf :: from ("generated/hf_dataset_output/mapping.toml")'
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.bag_of_words_visitor]
expression_str = "bag_of_words_visitor"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'"Unsafe" . to_string ()']
expression_str = '"Unsafe" . to_string ()'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."* i . cond"]
expression_str = "* i . cond"
depth = 5
used_types = []
other_types_count = 0
node_type = "Unary"

[expressions.'hf_dataset_reader :: analyze_hf_dataset_asts (& dataset_output_path) . await . context ("Failed to analyze ASTs from Hugging Face dataset") ?']
expression_str = 'hf_dataset_reader :: analyze_hf_dataset_asts (& dataset_output_path) . await . context ("Failed to analyze ASTs from Hugging Face dataset") ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."syn :: visit :: visit_item_struct"]
expression_str = "syn :: visit :: visit_item_struct"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."tokio :: fs :: create_dir_all (output_file_path . parent () . unwrap ()) . await ?"]
expression_str = "tokio :: fs :: create_dir_all (output_file_path . parent () . unwrap ()) . await ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'excluded_crates . insert ("prelude-collector" . to_string ())']
expression_str = 'excluded_crates . insert ("prelude-collector" . to_string ())'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.lib_rs_path]
expression_str = "lib_rs_path"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'stdout . write_all (b"Pipeline completed successfully.\n") . await']
expression_str = 'stdout . write_all (b"Pipeline completed successfully.\n") . await'
depth = 5
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."all_expression_info . clone ()"]
expression_str = "all_expression_info . clone ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."if ! self . current_field_accesses . is_empty () { self . struct_lattice_info . add_co_occurrence (self . current_field_accesses . clone ()) ; }"]
expression_str = "if ! self . current_field_accesses . is_empty () { self . struct_lattice_info . add_co_occurrence (self . current_field_accesses . clone ()) ; }"
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions."EnumLatticeInfo { enum_name , variant_type_co_occurrences : HashMap :: new () , total_expressions_analyzed : 0 , }"]
expression_str = "EnumLatticeInfo { enum_name , variant_type_co_occurrences : HashMap :: new () , total_expressions_analyzed : 0 , }"
depth = 2
used_types = []
other_types_count = 0
node_type = "Struct"

[expressions."& mut symbols"]
expression_str = "& mut symbols"
depth = 3
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."modify_file (& file_path , true , false) ?"]
expression_str = "modify_file (& file_path , true , false) ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."EnumVariantCoOccurrenceVisitor { _enum_name : & enum_name , _current_variant_types : BTreeSet :: new () , enum_lattice_info , }"]
expression_str = "EnumVariantCoOccurrenceVisitor { _enum_name : & enum_name , _current_variant_types : BTreeSet :: new () , enum_lattice_info , }"
depth = 2
used_types = []
other_types_count = 0
node_type = "Struct"

[expressions."fs :: read_dir (& current_src)"]
expression_str = "fs :: read_dir (& current_src)"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'"Failed to copy Cargo.toml to temporary directory"']
expression_str = '"Failed to copy Cargo.toml to temporary directory"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'Some ("std::string")']
expression_str = 'Some ("std::string")'
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'e . path () . extension () . map_or (false , | ext | ext == "rs")']
expression_str = 'e . path () . extension () . map_or (false , | ext | ext == "rs")'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."self . type_map"]
expression_str = "self . type_map"
depth = 4
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'"use syn::{ItemConst, ItemStruct};\n"']
expression_str = '"use syn::{ItemConst, ItemStruct};\n"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."self . impl_lattice_info . add_co_occurrence (self . current_method_calls . clone ())"]
expression_str = "self . impl_lattice_info . add_co_occurrence (self . current_method_calls . clone ())"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'| | anyhow :: anyhow ! ("test_verification_output_dir is required when compile_tests is true")']
expression_str = '| | anyhow :: anyhow ! ("test_verification_output_dir is required when compile_tests is true")'
depth = 4
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions.'"Failed to copy source file to temporary lib.rs"']
expression_str = '"Failed to copy source file to temporary lib.rs"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."i . fields"]
expression_str = "i . fields"
depth = 4
used_types = []
other_types_count = 0
node_type = "Field"

[expressions."fs :: metadata (& script_path)"]
expression_str = "fs :: metadata (& script_path)"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'" Path to the hf-validator executable."']
expression_str = '" Path to the hf-validator executable."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."! error_collection . errors . is_empty ()"]
expression_str = "! error_collection . errors . is_empty ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "Unary"

[expressions."if ! has_prelude_mod { let mut new_ast = ast . clone () ; let prelude_mod : Item = syn :: parse_quote ! { pub mod prelude ; } ; new_ast . items . insert (0 , prelude_mod) ; let new_content = prettyplease :: unparse (& new_ast) ; if dry_run { println ! (\"[DRY RUN] Would add 'pub mod prelude;' to: {}\" , crate_root_path . display ()) ; } else { if crate_root_path . exists () && ! force { println ! (\"  -> Skipping crate root modification for {} (file exists, use --force to overwrite).\" , crate_root_path . display ()) ; } else { println ! (\"  -> Adding 'pub mod prelude;' to: {}\" , crate_root_path . display ()) ; println ! (\"    -> Writing modified content to: {}\" , crate_root_path . display ()) ; fs :: write (& crate_root_path , new_content) ? ; } } }"]
expression_str = """if ! has_prelude_mod { let mut new_ast = ast . clone () ; let prelude_mod : Item = syn :: parse_quote ! { pub mod prelude ; } ; new_ast . items . insert (0 , prelude_mod) ; let new_content = prettyplease :: unparse (& new_ast) ; if dry_run { println ! ("[DRY RUN] Would add 'pub mod prelude;' to: {}" , crate_root_path . display ()) ; } else { if crate_root_path . exists () && ! force { println ! ("  -> Skipping crate root modification for {} (file exists, use --force to overwrite)." , crate_root_path . display ()) ; } else { println ! ("  -> Adding 'pub mod prelude;' to: {}" , crate_root_path . display ()) ; println ! ("    -> Writing modified content to: {}" , crate_root_path . display ()) ; fs :: write (& crate_root_path , new_content) ? ; } } }"""
depth = 2
used_types = ["Item"]
other_types_count = 1
node_type = "If"

[expressions."& format ! (\"\\n### Analyzing expressions using type: '{}' ###\\n\" , target_type)"]
expression_str = '''& format ! ("\n### Analyzing expressions using type: '{}' ###\n" , target_type)'''
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."Instant :: now ()"]
expression_str = "Instant :: now ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'if ! output . status . success () { let stderr = String :: from_utf8_lossy (& output . stderr) ; anyhow :: bail ! ("Rustfmt failed for file {:?}:\n{}" , file_path , stderr) ; }']
expression_str = 'if ! output . status . success () { let stderr = String :: from_utf8_lossy (& output . stderr) ; anyhow :: bail ! ("Rustfmt failed for file {:?}:\n{}" , file_path , stderr) ; }'
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'measurement :: record_function_exit ("ParseFunctor::map")']
expression_str = 'measurement :: record_function_exit ("ParseFunctor::map")'
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."Ok (ValidatedFile (source_code , permanent_output_dir))"]
expression_str = "Ok (ValidatedFile (source_code , permanent_output_dir))"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'return Err (anyhow :: anyhow ! ("git init failed: {}" , String :: from_utf8_lossy (& output . stderr)))']
expression_str = 'return Err (anyhow :: anyhow ! ("git init failed: {}" , String :: from_utf8_lossy (& output . stderr)))'
depth = 5
used_types = []
other_types_count = 0
node_type = "Return"

[expressions."type_map . get (& const_name)"]
expression_str = "type_map . get (& const_name)"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"Async"']
expression_str = '"Async"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."& args . results_file . unwrap ()"]
expression_str = "& args . results_file . unwrap ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'writer . write_all (format ! ("--- METRICS_START ---\n{}\n--- METRICS_END ---\n" , json_metrics) . as_bytes () ,) . await']
expression_str = 'writer . write_all (format ! ("--- METRICS_START ---\n{}\n--- METRICS_END ---\n" , json_metrics) . as_bytes () ,) . await'
depth = 3
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."sorted_other_types_keys . sort_unstable ()"]
expression_str = "sorted_other_types_keys . sort_unstable ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."StructLatticeInfo { struct_name , field_co_occurrences : HashMap :: new () , total_expressions_analyzed : 0 , }"]
expression_str = "StructLatticeInfo { struct_name , field_co_occurrences : HashMap :: new () , total_expressions_analyzed : 0 , }"
depth = 2
used_types = []
other_types_count = 0
node_type = "Struct"

[expressions."fs :: read_to_string (file_to_process) . await"]
expression_str = "fs :: read_to_string (file_to_process) . await"
depth = 5
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.'| c | { c . bins . paths . get ("hf_validator") . map (| p | p . to_path_buf ()) }']
expression_str = '| c | { c . bins . paths . get ("hf_validator") . map (| p | p . to_path_buf ()) }'
depth = 3
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions."visit :: visit_item_struct"]
expression_str = "visit :: visit_item_struct"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."& args . filter_names"]
expression_str = "& args . filter_names"
depth = 5
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."fs :: read_to_string (& main_rs_path) ?"]
expression_str = "fs :: read_to_string (& main_rs_path) ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."read_input_file (& args) . await"]
expression_str = "read_input_file (& args) . await"
depth = 3
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.expr_str]
expression_str = "expr_str"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'if dry_run { println ! ("[DRY RUN] Would generate prelude file: {}\n---\n{}---" , prelude_path . display () , prelude_content) ; } else { if prelude_path . exists () && ! force { println ! ("  -> Skipping prelude file generation for {} (file exists, use --force to overwrite)." , prelude_path . display ()) ; } else { println ! ("  -> Generating prelude file: {}" , prelude_path . display ()) ; println ! ("    -> Writing prelude content to: {}" , prelude_path . display ()) ; fs :: write (& prelude_path , prelude_content) ? ; } }']
expression_str = 'if dry_run { println ! ("[DRY RUN] Would generate prelude file: {}\n---\n{}---" , prelude_path . display () , prelude_content) ; } else { if prelude_path . exists () && ! force { println ! ("  -> Skipping prelude file generation for {} (file exists, use --force to overwrite)." , prelude_path . display ()) ; } else { println ! ("  -> Generating prelude file: {}" , prelude_path . display ()) ; println ! ("    -> Writing prelude content to: {}" , prelude_path . display ()) ; fs :: write (& prelude_path , prelude_content) ? ; } }'
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions."prelude_generator :: public_tests :: test_generate_prelude_creates_file"]
expression_str = "prelude_generator :: public_tests :: test_generate_prelude_creates_file"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."let syn :: Expr :: Lit (expr_lit) = & * constant . expr"]
expression_str = "let syn :: Expr :: Lit (expr_lit) = & * constant . expr"
depth = 4
used_types = []
other_types_count = 0
node_type = "Let"

[expressions.'"lib.rs"']
expression_str = '"lib.rs"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."self . struct_lattice_info"]
expression_str = "self . struct_lattice_info"
depth = 4
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'"    let mut analyzer_version_counts = HashMap::new();\n"']
expression_str = '"    let mut analyzer_version_counts = HashMap::new();\n"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'& PathBuf :: from ("gems.toml")']
expression_str = '& PathBuf :: from ("gems.toml")'
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."prelude_generator :: public_tests :: test_modify_file_no_force_no_overwrite () ?"]
expression_str = "prelude_generator :: public_tests :: test_modify_file_no_force_no_overwrite () ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'fs :: write (output_path , json_content) . with_context (| | format ! ("Failed to write aggregated test report to {}" , output_path . display ())) ?']
expression_str = 'fs :: write (output_path , json_content) . with_context (| | format ! ("Failed to write aggregated test report to {}" , output_path . display ())) ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."& path . tree"]
expression_str = "& path . tree"
depth = 5
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'"Closure" . to_string ()']
expression_str = '"Closure" . to_string ()'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'report_content . push_str ("## Summary\n")']
expression_str = 'report_content . push_str ("## Summary\n")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.results_file_content]
expression_str = "results_file_content"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'writer . write_all (format ! ("--- Stage 5: AST Reconstruction from Hugging Face Dataset ---\n") . as_bytes () ,)']
expression_str = 'writer . write_all (format ! ("--- Stage 5: AST Reconstruction from Hugging Face Dataset ---\n") . as_bytes () ,)'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."if should_process_file { let (declarations , errors , _file_metadata , public_symbols) = split_expanded_lib :: extract_declarations_from_single_file (& file_path , & rustc_info_for_split_expanded_lib , & current_crate_name , args . verbose ,) . await ? ; all_declarations_aggregated . extend (declarations) ; all_collected_errors_aggregated . extend (errors) ; all_public_symbols_aggregated . extend (public_symbols) ; }"]
expression_str = "if should_process_file { let (declarations , errors , _file_metadata , public_symbols) = split_expanded_lib :: extract_declarations_from_single_file (& file_path , & rustc_info_for_split_expanded_lib , & current_crate_name , args . verbose ,) . await ? ; all_declarations_aggregated . extend (declarations) ; all_collected_errors_aggregated . extend (errors) ; all_public_symbols_aggregated . extend (public_symbols) ; }"
depth = 3
used_types = []
other_types_count = 0
node_type = "If"

[expressions.generate_aggregated_test_file]
expression_str = "generate_aggregated_test_file"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."sorted_types . sort_by (| a , b | b . 1 . count . cmp (& a . 1 . count))"]
expression_str = "sorted_types . sort_by (| a , b | b . 1 . count . cmp (& a . 1 . count))"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.ast]
expression_str = "ast"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'"u64"']
expression_str = '"u64"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'args . generated_decls_output_dir . clone () . unwrap_or_else (| | PathBuf :: from ("./generated_declarations"))']
expression_str = 'args . generated_decls_output_dir . clone () . unwrap_or_else (| | PathBuf :: from ("./generated_declarations"))'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."fs :: remove_dir_all (& project_root)"]
expression_str = "fs :: remove_dir_all (& project_root)"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."sorted_node_types . sort_unstable ()"]
expression_str = "sorted_node_types . sort_unstable ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."fs :: read_to_string (& output_path) ?"]
expression_str = "fs :: read_to_string (& output_path) ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."generate_prelude (& src_dir , new_prelude_content , false , true)"]
expression_str = "generate_prelude (& src_dir , new_prelude_content , false , true)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."all_enum_lattices . clone ()"]
expression_str = "all_enum_lattices . clone ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."& output . stderr"]
expression_str = "& output . stderr"
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."toml :: from_str (& content)"]
expression_str = "toml :: from_str (& content)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."loop { if remaining_decls . is_empty () { break ; } let mut current_layer_decls = Vec :: new () ; let mut next_remaining_decls = Vec :: new () ; let mut current_layer_idents = std :: collections :: HashSet :: new () ; for decl in remaining_decls . into_iter () { let has_unresolved_deps = decl . referenced_types . iter () . any (| dep | { ! current_layer_idents . contains (dep) && ! layered_decls . values () . flatten () . any (| d | d . get_identifier () == * dep) }) ; if ! has_unresolved_deps { current_layer_idents . insert (decl . get_identifier ()) ; current_layer_decls . push (decl) ; } else { next_remaining_decls . push (decl) ; } } if current_layer_decls . is_empty () { break ; } layered_decls . insert (current_layer_num , current_layer_decls) ; remaining_decls = next_remaining_decls ; current_layer_num += 1 ; if current_layer_num > 8 { break ; } }"]
expression_str = "loop { if remaining_decls . is_empty () { break ; } let mut current_layer_decls = Vec :: new () ; let mut next_remaining_decls = Vec :: new () ; let mut current_layer_idents = std :: collections :: HashSet :: new () ; for decl in remaining_decls . into_iter () { let has_unresolved_deps = decl . referenced_types . iter () . any (| dep | { ! current_layer_idents . contains (dep) && ! layered_decls . values () . flatten () . any (| d | d . get_identifier () == * dep) }) ; if ! has_unresolved_deps { current_layer_idents . insert (decl . get_identifier ()) ; current_layer_decls . push (decl) ; } else { next_remaining_decls . push (decl) ; } } if current_layer_decls . is_empty () { break ; } layered_decls . insert (current_layer_num , current_layer_decls) ; remaining_decls = next_remaining_decls ; current_layer_num += 1 ; if current_layer_num > 8 { break ; } }"
depth = 2
used_types = []
other_types_count = 0
node_type = "Loop"

[expressions."visit :: visit_expr_field (self , i)"]
expression_str = "visit :: visit_expr_field (self , i)"
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'Command :: new ("cargo") . arg ("metadata") . arg ("--no-deps") . arg ("--format-version=1") . current_dir (workspace_path) . output () ?']
expression_str = 'Command :: new ("cargo") . arg ("metadata") . arg ("--no-deps") . arg ("--format-version=1") . current_dir (workspace_path) . output () ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'"Lit"']
expression_str = '"Lit"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."& config_content"]
expression_str = "& config_content"
depth = 5
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'" Timeout in seconds for each processing step"']
expression_str = '" Timeout in seconds for each processing step"'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'output_dir . join ("errors.json")']
expression_str = 'output_dir . join ("errors.json")'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."! has_unresolved_deps"]
expression_str = "! has_unresolved_deps"
depth = 5
used_types = []
other_types_count = 0
node_type = "Unary"

[expressions.'"BagOfWordsVisitor"']
expression_str = '"BagOfWordsVisitor"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'"This report summarizes the processing of Rust files during prelude generation.\n\n"']
expression_str = '"This report summarizes the processing of Rust files during prelude generation.\n\n"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'for constant in constants { let _const_name = constant . ident . to_string () ; let const_code = quote ! { # constant } . to_string () ; let line = format ! ("{}\n" , const_code) ; if current_file_size + line . len () > MAX_FILE_SIZE && current_file_size > 0 { let file_path = output_dir . join (format ! ("numerical_constants_{}.rs" , file_idx)) ; tokio :: fs :: create_dir_all (file_path . parent () . unwrap ()) . await ? ; tokio :: fs :: write (& file_path , current_file_content . as_bytes ()) . await ? ; println ! ("    -> Wrote numerical constants to {:?}\n" , file_path) ; current_file_content . clear () ; current_file_size = 0 ; file_idx += 1 ; } current_file_content . push_str (& line) ; current_file_size += line . len () ; }']
expression_str = 'for constant in constants { let _const_name = constant . ident . to_string () ; let const_code = quote ! { # constant } . to_string () ; let line = format ! ("{}\n" , const_code) ; if current_file_size + line . len () > MAX_FILE_SIZE && current_file_size > 0 { let file_path = output_dir . join (format ! ("numerical_constants_{}.rs" , file_idx)) ; tokio :: fs :: create_dir_all (file_path . parent () . unwrap ()) . await ? ; tokio :: fs :: write (& file_path , current_file_content . as_bytes ()) . await ? ; println ! ("    -> Wrote numerical constants to {:?}\n" , file_path) ; current_file_content . clear () ; current_file_size = 0 ; file_idx += 1 ; } current_file_content . push_str (& line) ; current_file_size += line . len () ; }'
depth = 2
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions."prelude_generator :: public_tests :: test_modify_crate_root_dry_run ()"]
expression_str = "prelude_generator :: public_tests :: test_modify_crate_root_dry_run ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'for (version , count) in & stats . analyzer_version_counts { code . push_str (& format ! ("    analyzer_version_counts.insert(\"{}\".to_string(), {});\n" , version , count) ,) ; }']
expression_str = 'for (version , count) in & stats . analyzer_version_counts { code . push_str (& format ! ("    analyzer_version_counts.insert(\"{}\".to_string(), {});\n" , version , count) ,) ; }'
depth = 2
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions.'code . push_str (& format ! ("    processing_time_stats.insert(\"{}\".to_string(), ({}, {}, {}, {}));\n" , node_type , min , max , sum , count) ,)']
expression_str = 'code . push_str (& format ! ("    processing_time_stats.insert(\"{}\".to_string(), ({}, {}, {}, {}));\n" , node_type , min , max , sum , count) ,)'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"Unknown"']
expression_str = '"Unknown"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'"Return"']
expression_str = '"Return"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.ParseFunctor]
expression_str = "ParseFunctor"
depth = 2
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."function_name . to_string ()"]
expression_str = "function_name . to_string ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'add_std_lib_symbol (& mut symbols , "fmt" , "module" , Some ("std"))']
expression_str = 'add_std_lib_symbol (& mut symbols , "fmt" , "module" , Some ("std"))'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'if ! output . status . success () { let error_message = format ! ("rustc macro expansion failed: {}\nStdout: {}\nStderr: {}" , String :: from_utf8_lossy (& output . stderr) , String :: from_utf8_lossy (& output . stdout) , String :: from_utf8_lossy (& output . stderr)) ; writer . write_all (format ! ("        -> {}\n" , error_message) . as_bytes ()) . await . context ("Failed to write rustc error to writer") ? ; let error_sample = ErrorSample { file_path : file_path . to_path_buf () , rustc_version : rustc_info . version . clone () , rustc_host : rustc_info . host . clone () , error_message : error_message . clone () , error_type : "MacroExpansionFailed" . to_string () , code_snippet : Some (content . to_string ()) , timestamp : Utc :: now () , context : None , } ; return Ok ((syn :: parse_file ("") . unwrap () , Some (error_sample))) ; }']
expression_str = 'if ! output . status . success () { let error_message = format ! ("rustc macro expansion failed: {}\nStdout: {}\nStderr: {}" , String :: from_utf8_lossy (& output . stderr) , String :: from_utf8_lossy (& output . stdout) , String :: from_utf8_lossy (& output . stderr)) ; writer . write_all (format ! ("        -> {}\n" , error_message) . as_bytes ()) . await . context ("Failed to write rustc error to writer") ? ; let error_sample = ErrorSample { file_path : file_path . to_path_buf () , rustc_version : rustc_info . version . clone () , rustc_host : rustc_info . host . clone () , error_message : error_message . clone () , error_type : "MacroExpansionFailed" . to_string () , code_snippet : Some (content . to_string ()) , timestamp : Utc :: now () , context : None , } ; return Ok ((syn :: parse_file ("") . unwrap () , Some (error_sample))) ; }'
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'"Loop" . to_string ()']
expression_str = '"Loop" . to_string ()'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."vec ! [src . as_ref () . to_path_buf ()]"]
expression_str = "vec ! [src . as_ref () . to_path_buf ()]"
depth = 2
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions.'if structure . ident . to_string () == "BagOfWordsVisitor" { uses . insert ("use std::collections::HashMap;\n") ; uses . insert ("use syn::visit::Visit;\n") ; }']
expression_str = 'if structure . ident . to_string () == "BagOfWordsVisitor" { uses . insert ("use std::collections::HashMap;\n") ; uses . insert ("use syn::visit::Visit;\n") ; }'
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'add_std_lib_symbol (& mut symbols , "std" , "module" , None)']
expression_str = 'add_std_lib_symbol (& mut symbols , "std" , "module" , None)'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."type_path . path . segments . last () . map (| segment | segment . ident . to_string ())"]
expression_str = "type_path . path . segments . last () . map (| segment | segment . ident . to_string ())"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"builtin" . to_string ()']
expression_str = '"builtin" . to_string ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."& stats . analyzer_version_counts"]
expression_str = "& stats . analyzer_version_counts"
depth = 3
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'args . output_type_usage_report . as_ref () . context ("Output path for type usage report must be specified") ?']
expression_str = 'args . output_type_usage_report . as_ref () . context ("Output path for type usage report must be specified") ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'format ! ("Type Usage Report (Max Depth: {})" , max_expression_depth)']
expression_str = 'format ! ("Type Usage Report (Max Depth: {})" , max_expression_depth)'
depth = 4
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions."current_file_content . clear ()"]
expression_str = "current_file_content . clear ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'format ! ("Total unique test functions found: {}\n\n" , test_infos . len ())']
expression_str = 'format ! ("Total unique test functions found: {}\n\n" , test_infos . len ())'
depth = 4
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions."original_file_path . hash (& mut hasher)"]
expression_str = "original_file_path . hash (& mut hasher)"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."entry . usage_count += 1"]
expression_str = "entry . usage_count += 1"
depth = 2
used_types = []
other_types_count = 0
node_type = "Binary"

[expressions."args . clone ()"]
expression_str = "args . clone ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."Vec :: new"]
expression_str = "Vec :: new"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."GemConfig { gem : Vec :: new () , }"]
expression_str = "GemConfig { gem : Vec :: new () , }"
depth = 2
used_types = []
other_types_count = 0
node_type = "Struct"

[expressions.'c . bins . paths . get ("hf_validator") . map (| p | p . to_path_buf ())']
expression_str = 'c . bins . paths . get ("hf_validator") . map (| p | p . to_path_buf ())'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'report_content . push_str ("This report summarizes the tests found and provides a script to run them.\n\n")']
expression_str = 'report_content . push_str ("This report summarizes the tests found and provides a script to run them.\n\n")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'fs :: read_to_string (file_to_process) . await . context ("Failed to read file content")']
expression_str = 'fs :: read_to_string (file_to_process) . await . context ("Failed to read file content")'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."version_line . and_then (| line | line . split_whitespace () . nth (1))"]
expression_str = "version_line . and_then (| line | line . split_whitespace () . nth (1))"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'measurement :: record_function_entry ("AstReconstructionFunctor::map")']
expression_str = 'measurement :: record_function_entry ("AstReconstructionFunctor::map")'
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."super :: report :: generate_report"]
expression_str = "super :: report :: generate_report"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."project_root . exists ()"]
expression_str = "project_root . exists ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."& dummy_content"]
expression_str = "& dummy_content"
depth = 5
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'"static" . to_string ()']
expression_str = '"static" . to_string ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'crate_path . join ("src/lib.rs")']
expression_str = 'crate_path . join ("src/lib.rs")'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."cache_dir . exists ()"]
expression_str = "cache_dir . exists ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'if ! output . status . success () { return Err (anyhow :: anyhow ! ("git init failed: {}" , String :: from_utf8_lossy (& output . stderr))) ; }']
expression_str = 'if ! output . status . success () { return Err (anyhow :: anyhow ! ("git init failed: {}" , String :: from_utf8_lossy (& output . stderr))) ; }'
depth = 4
used_types = []
other_types_count = 0
node_type = "If"

[expressions."let syn :: PathArguments :: AngleBracketed (angle_args) = & segment . arguments"]
expression_str = "let syn :: PathArguments :: AngleBracketed (angle_args) = & segment . arguments"
depth = 5
used_types = []
other_types_count = 0
node_type = "Let"

[expressions.'for entry in walkdir :: WalkDir :: new (& project_root) . into_iter () . filter_map (| e | e . ok ()) . filter (| e | e . file_type () . is_file () && e . path () . extension () . map_or (false , | ext | ext == r"rs")) { let path = entry . path () ; if let Ok (content) = std :: fs :: read_to_string (& path) { if let Ok (file) = syn :: parse_file (& content) { bag_of_words_visitor . visit_file (& file) ; files_processed_for_bow += 1 ; } else { eprintln ! (r"Warning: Could not parse file for bag of words analysis: {}" , path . display ()) ; } } else { eprintln ! (r"Warning: Could not read file for bag of words analysis: {}" , path . display ()) ; } }']
expression_str = 'for entry in walkdir :: WalkDir :: new (& project_root) . into_iter () . filter_map (| e | e . ok ()) . filter (| e | e . file_type () . is_file () && e . path () . extension () . map_or (false , | ext | ext == r"rs")) { let path = entry . path () ; if let Ok (content) = std :: fs :: read_to_string (& path) { if let Ok (file) = syn :: parse_file (& content) { bag_of_words_visitor . visit_file (& file) ; files_processed_for_bow += 1 ; } else { eprintln ! (r"Warning: Could not parse file for bag of words analysis: {}" , path . display ()) ; } } else { eprintln ! (r"Warning: Could not read file for bag of words analysis: {}" , path . display ()) ; } }'
depth = 2
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions."consts_output_dir . join (& file_name)"]
expression_str = "consts_output_dir . join (& file_name)"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'" Modifies a source file to remove its `use` statements and add `use crate::prelude::*;`."']
expression_str = '" Modifies a source file to remove its `use` statements and add `use crate::prelude::*;`."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'"Failed to serialize symbol map to TOML "']
expression_str = '"Failed to serialize symbol map to TOML "'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'report_content . push_str (& format ! ("- Skipped: {}\n" , skipped_files))']
expression_str = 'report_content . push_str (& format ! ("- Skipped: {}\n" , skipped_files))'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'Command :: new ("rustfmt") . arg (file_path) . arg ("--edition=2021") . arg ("--emit=files") . output ()']
expression_str = 'Command :: new ("rustfmt") . arg (file_path) . arg ("--edition=2021") . arg ("--emit=files") . output ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."self . variant_type_co_occurrences . entry (variant_types) . or_insert (0)"]
expression_str = "self . variant_type_co_occurrences . entry (variant_types) . or_insert (0)"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."fs :: write (crate_root . join (\"src/another_mod.rs\") , r#\"\n            #[test]\n            fn another_mod_test() { }\n        \"# ,)"]
expression_str = """
fs :: write (crate_root . join ("src/another_mod.rs") , r#"
            #[test]
            fn another_mod_test() { }
        "# ,)"""
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'format ! ("\n--- AST Node Type Report ---\n") . as_bytes ()']
expression_str = 'format ! ("\n--- AST Node Type Report ---\n") . as_bytes ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."short_id . clone ()"]
expression_str = "short_id . clone ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"use std::collections::HashMap;\nuse crate::another_module;\n\nfn main() {}\n"']
expression_str = '"use std::collections::HashMap;\nuse crate::another_module;\n\nfn main() {}\n"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."sorted_terms . iter () . take (20)"]
expression_str = "sorted_terms . iter () . take (20)"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."WalkDir :: new (repo_root) . into_iter () . filter_map (| e | e . ok ())"]
expression_str = "WalkDir :: new (repo_root) . into_iter () . filter_map (| e | e . ok ())"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."file_path . to_string_lossy ()"]
expression_str = "file_path . to_string_lossy ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'add_primitive_type (& mut symbols , "usize")']
expression_str = 'add_primitive_type (& mut symbols , "usize")'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'"Path"']
expression_str = '"Path"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."prelude_generator :: public_tests :: test_generate_prelude_force_overwrite ()"]
expression_str = "prelude_generator :: public_tests :: test_generate_prelude_force_overwrite ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."cached_file_path . exists ()"]
expression_str = "cached_file_path . exists ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"    AstStatistics {\n"']
expression_str = '"    AstStatistics {\n"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."let Some (impl_for_type_name) = impl_for_type"]
expression_str = "let Some (impl_for_type_name) = impl_for_type"
depth = 3
used_types = []
other_types_count = 0
node_type = "Let"

[expressions."* i . self_ty"]
expression_str = "* i . self_ty"
depth = 5
used_types = []
other_types_count = 0
node_type = "Unary"

[expressions.'column_stats . insert ("other" . to_string () , (1 , 1 , 230 , 230))']
expression_str = 'column_stats . insert ("other" . to_string () , (1 , 1 , 230 , 230))'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.perms]
expression_str = "perms"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."serde_json :: to_string_pretty (& all_public_symbols_aggregated)"]
expression_str = "serde_json :: to_string_pretty (& all_public_symbols_aggregated)"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'writer . write_all (format ! ("---\n--- Stage 2: Extracting Use Statements ---\n") . as_bytes ())']
expression_str = 'writer . write_all (format ! ("---\n--- Stage 2: Extracting Use Statements ---\n") . as_bytes ())'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.all_declarations]
expression_str = "all_declarations"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."self . process_expression (i)"]
expression_str = "self . process_expression (i)"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'for decl in declarations { match dependency_validator . validate (& decl) { Ok (_) => all_declarations . push (decl) , Err (e) => { eprintln ! ("Validation Error for declaration {:?}: {:?}" , decl . get_identifier () , e) ; } } }']
expression_str = 'for decl in declarations { match dependency_validator . validate (& decl) { Ok (_) => all_declarations . push (decl) , Err (e) => { eprintln ! ("Validation Error for declaration {:?}: {:?}" , decl . get_identifier () , e) ; } } }'
depth = 5
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions.impl_lattices]
expression_str = "impl_lattices"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'if args . path == PathBuf :: from (".") { std :: env :: current_dir () ? . parent () . unwrap () . to_path_buf () } else { PathBuf :: from (& args . path) }']
expression_str = 'if args . path == PathBuf :: from (".") { std :: env :: current_dir () ? . parent () . unwrap () . to_path_buf () } else { PathBuf :: from (& args . path) }'
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'r"generated/string_constants"']
expression_str = 'r"generated/string_constants"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.new_items]
expression_str = "new_items"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'"## Tests by Crate\n"']
expression_str = '"## Tests by Crate\n"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'"eprintln!"']
expression_str = '"eprintln!"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."& enum_name"]
expression_str = "& enum_name"
depth = 3
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."{ None }"]
expression_str = "{ None }"
depth = 5
used_types = []
other_types_count = 0
node_type = "Block"

[expressions.'| | { Regex :: new (r"[^a-zA-Z0-9_]+") . unwrap () }']
expression_str = '| | { Regex :: new (r"[^a-zA-Z0-9_]+") . unwrap () }'
depth = 3
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions.'"Infer" . to_string ()']
expression_str = '"Infer" . to_string ()'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'match item { Item :: Fn (func) => { if func . attrs . iter () . any (| attr | attr . path () . is_ident ("test")) { test_functions . push (TestInfo { name : func . sig . ident . to_string () , file_path : file_path . to_path_buf () , }) ; } } Item :: Mod (module) => { if let Some ((_ , module_items)) = module . content { test_functions . extend (extract_test_functions_from_items (module_items , file_path)) ; } } _ => { } }']
expression_str = 'match item { Item :: Fn (func) => { if func . attrs . iter () . any (| attr | attr . path () . is_ident ("test")) { test_functions . push (TestInfo { name : func . sig . ident . to_string () , file_path : file_path . to_path_buf () , }) ; } } Item :: Mod (module) => { if let Some ((_ , module_items)) = module . content { test_functions . extend (extract_test_functions_from_items (module_items , file_path)) ; } } _ => { } }'
depth = 3
used_types = []
other_types_count = 0
node_type = "Match"

[expressions.'& format ! ("- Total files processed: {}\n" , total_files)']
expression_str = '& format ! ("- Total files processed: {}\n" , total_files)'
depth = 3
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'| | anyhow :: anyhow ! ("ast_analysis_path is required when analyze_ast is true")']
expression_str = '| | anyhow :: anyhow ! ("ast_analysis_path is required when analyze_ast is true")'
depth = 4
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions.'" Path to the output TOML file for the bag of words report. Only used if `analyze_bag_of_words` is true."']
expression_str = '" Path to the output TOML file for the bag of words report. Only used if `analyze_bag_of_words` is true."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."tokio :: fs :: create_dir_all (output_file_path . parent () . unwrap ())"]
expression_str = "tokio :: fs :: create_dir_all (output_file_path . parent () . unwrap ())"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'tokio :: process :: Command :: new (hf_validator_executable . to_str () . unwrap ()) . current_dir (& self . args . path) . envs (std :: env :: vars_os ()) . arg ("analyze-rust-to-ir") . arg (hf_validator_project_dir . as_os_str ()) . arg (output_path . as_os_str ()) . status () . await . context ("Failed to execute hf-validator command")']
expression_str = 'tokio :: process :: Command :: new (hf_validator_executable . to_str () . unwrap ()) . current_dir (& self . args . path) . envs (std :: env :: vars_os ()) . arg ("analyze-rust-to-ir") . arg (hf_validator_project_dir . as_os_str ()) . arg (output_path . as_os_str ()) . status () . await . context ("Failed to execute hf-validator command")'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'writer . write_all (format ! ("        -> Writing expanded code to cache for: {}\n" , file_path . display ()) . as_bytes ())']
expression_str = 'writer . write_all (format ! ("        -> Writing expanded code to cache for: {}\n" , file_path . display ()) . as_bytes ())'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'& format ! ("### {}\n" , result . path . display ())']
expression_str = '& format ! ("### {}\n" , result . path . display ())'
depth = 5
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."& errors"]
expression_str = "& errors"
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."type_extractor :: extract_bag_of_types (project_root , & args . filter_names) . await"]
expression_str = "type_extractor :: extract_bag_of_types (project_root , & args . filter_names) . await"
depth = 3
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."i . to_token_stream () . to_string ()"]
expression_str = "i . to_token_stream () . to_string ()"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'tokio :: process :: Command :: new ("git") . arg ("commit") . arg ("--allow-empty") . arg ("-m") . arg ("Initial empty commit") . current_dir (& hf_validator_project_dir) . output () . await . context ("Failed to make initial empty git commit") ?']
expression_str = 'tokio :: process :: Command :: new ("git") . arg ("commit") . arg ("--allow-empty") . arg ("-m") . arg ("Initial empty commit") . current_dir (& hf_validator_project_dir) . output () . await . context ("Failed to make initial empty git commit") ?'
depth = 4
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'args . max_expression_depth . context ("Max expression depth must be specified for type usage analysis") ?']
expression_str = 'args . max_expression_depth . context ("Max expression depth must be specified for type usage analysis") ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'& format ! ("Total unique test functions found: {}\n\n" , test_infos . len ())']
expression_str = '& format ! ("Total unique test functions found: {}\n\n" , test_infos . len ())'
depth = 3
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."results . iter () . filter (| r | matches ! (r . status , FileProcessingStatus :: Skipped { .. })) . count ()"]
expression_str = "results . iter () . filter (| r | matches ! (r . status , FileProcessingStatus :: Skipped { .. })) . count ()"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."Self :: get_expr_node_type"]
expression_str = "Self :: get_expr_node_type"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."prelude_generator :: public_tests :: test_modify_crate_root_dry_run () ?"]
expression_str = "prelude_generator :: public_tests :: test_modify_crate_root_dry_run () ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.struct_name]
expression_str = "struct_name"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."prelude_generator :: public_tests :: test_modify_file_no_force_no_overwrite"]
expression_str = "prelude_generator :: public_tests :: test_modify_file_no_force_no_overwrite"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'"--results-file"']
expression_str = '"--results-file"'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'{ if prelude_path . exists () && ! force { println ! ("  -> Skipping prelude file generation for {} (file exists, use --force to overwrite)." , prelude_path . display ()) ; } else { println ! ("  -> Generating prelude file: {}" , prelude_path . display ()) ; println ! ("    -> Writing prelude content to: {}" , prelude_path . display ()) ; fs :: write (& prelude_path , prelude_content) ? ; } }']
expression_str = '{ if prelude_path . exists () && ! force { println ! ("  -> Skipping prelude file generation for {} (file exists, use --force to overwrite)." , prelude_path . display ()) ; } else { println ! ("  -> Generating prelude file: {}" , prelude_path . display ()) ; println ! ("    -> Writing prelude content to: {}" , prelude_path . display ()) ; fs :: write (& prelude_path , prelude_content) ? ; } }'
depth = 3
used_types = []
other_types_count = 0
node_type = "Block"

[expressions.'"cargo test\n"']
expression_str = '"cargo test\n"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'PipelineFunctor :: map (& ast_reconstruction_functor , writer , validated_file . clone () ,) . await . context ("AST Reconstruction failed") ?']
expression_str = 'PipelineFunctor :: map (& ast_reconstruction_functor , writer , validated_file . clone () ,) . await . context ("AST Reconstruction failed") ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."self . struct_lattices"]
expression_str = "self . struct_lattices"
depth = 4
used_types = []
other_types_count = 0
node_type = "Field"

[expressions."serde_json :: from_str (& results_file_content)"]
expression_str = "serde_json :: from_str (& results_file_content)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."let Some (layer0_structs) = all_structs_by_layer . get (& 0)"]
expression_str = "let Some (layer0_structs) = all_structs_by_layer . get (& 0)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Let"

[expressions.'tokio :: process :: Command :: new ("git") . arg ("config") . arg ("user.email") . arg ("test@example.com") . current_dir (& hf_validator_project_dir) . output () . await . context ("Failed to configure git user email")']
expression_str = 'tokio :: process :: Command :: new ("git") . arg ("config") . arg ("user.email") . arg ("test@example.com") . current_dir (& hf_validator_project_dir) . output () . await . context ("Failed to configure git user email")'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."generate_ast_statistics_code (& ast_statistics)"]
expression_str = "generate_ast_statistics_code (& ast_statistics)"
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'writer . write_all (format ! ("  -> Classified use statements:\n") . as_bytes ())']
expression_str = 'writer . write_all (format ! ("  -> Classified use statements:\n") . as_bytes ())'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'serde_json :: to_string_pretty (& all_collected_errors_aggregated) . context ("Failed to serialize errors to JSON")']
expression_str = 'serde_json :: to_string_pretty (& all_collected_errors_aggregated) . context ("Failed to serialize errors to JSON")'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"crate1,crate2"']
expression_str = '"crate1,crate2"'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.enum_lattices]
expression_str = "enum_lattices"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'writer . write_all (format ! ("  -> Hugging Face Validation Result: {:#?}\n" , validated_file) . as_bytes () ,) . await ?']
expression_str = 'writer . write_all (format ! ("  -> Hugging Face Validation Result: {:#?}\n" , validated_file) . as_bytes () ,) . await ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."rustc_info . host . clone ()"]
expression_str = "rustc_info . host . clone ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."structure . ident"]
expression_str = "structure . ident"
depth = 5
used_types = []
other_types_count = 0
node_type = "Field"

[expressions."generate_prelude :: generate_prelude (& src_dir , prelude_content , false , false) ?"]
expression_str = "generate_prelude :: generate_prelude (& src_dir , prelude_content , false , false) ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.label]
expression_str = "label"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."generate_prelude :: generate_prelude (& src_dir , new_prelude_content , false , false) ?"]
expression_str = "generate_prelude :: generate_prelude (& src_dir , new_prelude_content , false , false) ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'| | format ! ("Failed to create output directory {}" , output_dir . display ())']
expression_str = '| | format ! ("Failed to create output directory {}" , output_dir . display ())'
depth = 4
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions."fs :: create_dir_all (& cache_dir)"]
expression_str = "fs :: create_dir_all (& cache_dir)"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'writer . write_all (format ! ("      -> Using cached expanded code for: {}\n" , file_path . display ()) . as_bytes ())']
expression_str = 'writer . write_all (format ! ("      -> Using cached expanded code for: {}\n" , file_path . display ()) . as_bytes ())'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'temp_crate_path . join ("Cargo.toml")']
expression_str = 'temp_crate_path . join ("Cargo.toml")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.matched_variant_types]
expression_str = "matched_variant_types"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'Box :: pin (async move { measurement :: record_function_entry ("ExtractUsesFunctor::map") ; let ParsedFile (source_code , _) = input ; let use_statements = tokio :: task :: spawn_blocking (move | | -> anyhow :: Result < _ > { let ast = syn :: parse_file (& source_code) . context ("Failed to parse source code for use statement extraction") ? ; let mut use_statements = Vec :: new () ; for item in ast . items { if let syn :: Item :: Use (use_item) = item { use_statements . push (code_generator :: use_item_to_string (& use_item)) ; } } Ok (UseStatements (use_statements)) }) . await . context ("Blocking task for extracting use statements failed") ? ? ; measurement :: record_function_exit ("ExtractUsesFunctor::map") ; Ok (use_statements) })']
expression_str = 'Box :: pin (async move { measurement :: record_function_entry ("ExtractUsesFunctor::map") ; let ParsedFile (source_code , _) = input ; let use_statements = tokio :: task :: spawn_blocking (move | | -> anyhow :: Result < _ > { let ast = syn :: parse_file (& source_code) . context ("Failed to parse source code for use statement extraction") ? ; let mut use_statements = Vec :: new () ; for item in ast . items { if let syn :: Item :: Use (use_item) = item { use_statements . push (code_generator :: use_item_to_string (& use_item)) ; } } Ok (UseStatements (use_statements)) }) . await . context ("Blocking task for extracting use statements failed") ? ? ; measurement :: record_function_exit ("ExtractUsesFunctor::map") ; Ok (use_statements) })'
depth = 2
used_types = [
    "_",
    "Result",
]
other_types_count = 2
node_type = "Call"

[expressions."output_path . as_path ()"]
expression_str = "output_path . as_path ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'async move { measurement :: record_function_entry ("ClassifyUsesFunctor::map") ; let UseStatements (use_statements) = input ; let mut classified_uses = Vec :: new () ; for use_statement in use_statements { let mut current_use_statement = UseStatement { statement : use_statement . clone () , error : None , git_details : None , nix_details : None , rust_details : None , cargo_details : None , syn_details : None , llvm_details : None , linux_details : None , } ; if use_statement . contains ("git") { current_use_statement . git_details = Some (pipeline_traits :: GitDetails :: Info (pipeline_traits :: GitInfo { repo_url : "inferred_from_use" . to_string () , branch : "inferred_from_use" . to_string () , commit_hash : "inferred_from_use" . to_string () , })) ; } if use_statement . contains ("nix") { current_use_statement . nix_details = Some (pipeline_traits :: NixDetails :: Info (pipeline_traits :: NixInfo { flake_path : "inferred_from_use" . to_string () , output_type : "inferred_from_use" . to_string () , })) ; } if use_statement . contains ("rust") || use_statement . contains ("std") || use_statement . contains ("core") { current_use_statement . rust_details = Some (pipeline_traits :: RustDetails :: Info (pipeline_traits :: RustDetailsInfo { version : "inferred_from_use" . to_string () , crate_name : "inferred_from_use" . to_string () , item_path : "inferred_from_use" . to_string () , })) ; } if use_statement . contains ("cargo") { current_use_statement . cargo_details = Some (pipeline_traits :: CargoDetails :: Info (pipeline_traits :: CargoInfo { package_name : "inferred_from_use" . to_string () , version : "inferred_from_use" . to_string () , })) ; } if use_statement . contains ("syn") { current_use_statement . syn_details = Some (pipeline_traits :: SynDetails :: Info (pipeline_traits :: SynInfo { parsed_type : "ItemUse" . to_string () , version : "inferred_from_use" . to_string () , })) ; } if use_statement . contains ("llvm") { current_use_statement . llvm_details = Some (pipeline_traits :: LlvmDetails :: Info (pipeline_traits :: LlvmInfo { ir_version : "inferred_from_use" . to_string () , target_triple : "inferred_from_use" . to_string () , })) ; } if use_statement . contains ("linux") { current_use_statement . linux_details = Some (pipeline_traits :: LinuxDetails :: Info (pipeline_traits :: LinuxInfo { kernel_version : "inferred_from_use" . to_string () , architecture : "inferred_from_use" . to_string () , })) ; } match syn :: parse_str :: < syn :: ItemUse > (& use_statement) { Ok (_) => { } , Err (e) => { current_use_statement . error = Some (e . to_string ()) ; } , } classified_uses . push (current_use_statement) ; } let __result = Ok (ClassifiedUseStatements (classified_uses , HashMap :: new ())) ; measurement :: record_function_exit ("ClassifyUsesFunctor::map") ; __result }']
expression_str = 'async move { measurement :: record_function_entry ("ClassifyUsesFunctor::map") ; let UseStatements (use_statements) = input ; let mut classified_uses = Vec :: new () ; for use_statement in use_statements { let mut current_use_statement = UseStatement { statement : use_statement . clone () , error : None , git_details : None , nix_details : None , rust_details : None , cargo_details : None , syn_details : None , llvm_details : None , linux_details : None , } ; if use_statement . contains ("git") { current_use_statement . git_details = Some (pipeline_traits :: GitDetails :: Info (pipeline_traits :: GitInfo { repo_url : "inferred_from_use" . to_string () , branch : "inferred_from_use" . to_string () , commit_hash : "inferred_from_use" . to_string () , })) ; } if use_statement . contains ("nix") { current_use_statement . nix_details = Some (pipeline_traits :: NixDetails :: Info (pipeline_traits :: NixInfo { flake_path : "inferred_from_use" . to_string () , output_type : "inferred_from_use" . to_string () , })) ; } if use_statement . contains ("rust") || use_statement . contains ("std") || use_statement . contains ("core") { current_use_statement . rust_details = Some (pipeline_traits :: RustDetails :: Info (pipeline_traits :: RustDetailsInfo { version : "inferred_from_use" . to_string () , crate_name : "inferred_from_use" . to_string () , item_path : "inferred_from_use" . to_string () , })) ; } if use_statement . contains ("cargo") { current_use_statement . cargo_details = Some (pipeline_traits :: CargoDetails :: Info (pipeline_traits :: CargoInfo { package_name : "inferred_from_use" . to_string () , version : "inferred_from_use" . to_string () , })) ; } if use_statement . contains ("syn") { current_use_statement . syn_details = Some (pipeline_traits :: SynDetails :: Info (pipeline_traits :: SynInfo { parsed_type : "ItemUse" . to_string () , version : "inferred_from_use" . to_string () , })) ; } if use_statement . contains ("llvm") { current_use_statement . llvm_details = Some (pipeline_traits :: LlvmDetails :: Info (pipeline_traits :: LlvmInfo { ir_version : "inferred_from_use" . to_string () , target_triple : "inferred_from_use" . to_string () , })) ; } if use_statement . contains ("linux") { current_use_statement . linux_details = Some (pipeline_traits :: LinuxDetails :: Info (pipeline_traits :: LinuxInfo { kernel_version : "inferred_from_use" . to_string () , architecture : "inferred_from_use" . to_string () , })) ; } match syn :: parse_str :: < syn :: ItemUse > (& use_statement) { Ok (_) => { } , Err (e) => { current_use_statement . error = Some (e . to_string ()) ; } , } classified_uses . push (current_use_statement) ; } let __result = Ok (ClassifiedUseStatements (classified_uses , HashMap :: new ())) ; measurement :: record_function_exit ("ClassifyUsesFunctor::map") ; __result }'
depth = 3
used_types = ["ItemUse"]
other_types_count = 1
node_type = "Async"

[expressions."prelude_generator :: public_tests :: test_modify_crate_root_main_rs () ?"]
expression_str = "prelude_generator :: public_tests :: test_modify_crate_root_main_rs () ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'Command :: new ("cargo") . arg ("metadata") . arg ("--no-deps") . arg ("--format-version=1")']
expression_str = 'Command :: new ("cargo") . arg ("metadata") . arg ("--no-deps") . arg ("--format-version=1")'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."for (impl_for_type , lattice_info) in impl_lattices { report_content . push_str (& format ! (\"\\n### Impl for Type: '{}' (Expressions Analyzed: {}) ###\\n\" , impl_for_type , lattice_info . total_expressions_analyzed)) ; if lattice_info . method_co_occurrences . is_empty () { report_content . push_str (\"  No method co-occurrence data collected.\\n\") ; } else { let mut sorted_co_occurrences : Vec < (& BTreeSet < String > , & usize) > = lattice_info . method_co_occurrences . iter () . collect () ; sorted_co_occurrences . sort_by_key (| & (_ , count) | count) ; for (method_names , count) in sorted_co_occurrences { report_content . push_str (& format ! (\"  - Co-occurring methods: {:?} (Count: {})\\n\" , method_names , count)) ; } } }"]
expression_str = '''for (impl_for_type , lattice_info) in impl_lattices { report_content . push_str (& format ! ("\n### Impl for Type: '{}' (Expressions Analyzed: {}) ###\n" , impl_for_type , lattice_info . total_expressions_analyzed)) ; if lattice_info . method_co_occurrences . is_empty () { report_content . push_str ("  No method co-occurrence data collected.\n") ; } else { let mut sorted_co_occurrences : Vec < (& BTreeSet < String > , & usize) > = lattice_info . method_co_occurrences . iter () . collect () ; sorted_co_occurrences . sort_by_key (| & (_ , count) | count) ; for (method_names , count) in sorted_co_occurrences { report_content . push_str (& format ! ("  - Co-occurring methods: {:?} (Count: {})\n" , method_names , count)) ; } } }'''
depth = 3
used_types = [
    "(& BTreeSet < String > , & usize)",
    "& BTreeSet < String >",
    "Vec",
    "BTreeSet",
    "& usize",
]
other_types_count = 5
node_type = "ForLoop"

[expressions.'tokio :: fs :: create_dir_all (& constants_output_dir) . await . context (format ! ("Failed to create output directory {:?}" , constants_output_dir)) ?']
expression_str = 'tokio :: fs :: create_dir_all (& constants_output_dir) . await . context (format ! ("Failed to create output directory {:?}" , constants_output_dir)) ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'" Collects all unique test functions from the repository."']
expression_str = '" Collects all unique test functions from the repository."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."file_idx += 1"]
expression_str = "file_idx += 1"
depth = 4
used_types = []
other_types_count = 0
node_type = "Binary"

[expressions.'_args . generated_decls_output_dir . clone () . unwrap_or_else (| | { project_root . join ("generated/level0_decls") })']
expression_str = '_args . generated_decls_output_dir . clone () . unwrap_or_else (| | { project_root . join ("generated/level0_decls") })'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."prelude_generator :: public_tests :: test_modify_file_no_use_statements () ?"]
expression_str = "prelude_generator :: public_tests :: test_modify_file_no_use_statements () ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."& stats . rust_version_counts"]
expression_str = "& stats . rust_version_counts"
depth = 3
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.id]
expression_str = "id"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'PathBuf :: from (format ! ("generated/hf_dataset_output/{}" , short_id))']
expression_str = 'PathBuf :: from (format ! ("generated/hf_dataset_output/{}" , short_id))'
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'anyhow :: anyhow ! ("ast_analysis_path is required when analyze_ast is true")']
expression_str = 'anyhow :: anyhow ! ("ast_analysis_path is required when analyze_ast is true")'
depth = 5
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions."stats . analyzer_version_counts"]
expression_str = "stats . analyzer_version_counts"
depth = 4
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'"Hugging Face Validation failed"']
expression_str = '"Hugging Face Validation failed"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.generate_prelude]
expression_str = "generate_prelude"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'async { let tokens = quote ! { # constant } ; let mut code = tokens . to_string () ; let required_uses = use_statements :: get_required_uses_for_item_const (& constant) ; code = format ! ("{}{}" , required_uses , code) ; tokio :: fs :: write (& output_path , code . as_bytes ()) . await . context (format ! ("Failed to write constant {:?} to {:?}" , const_name , output_path)) ? ; println ! ("  -> Wrote constant {:?} to {:?}" , const_name , output_path) ; utils :: format_rust_code (& output_path) . await . context (format ! ("Constant {:?} formatting failed for {:?}" , const_name , output_path)) ? ; println ! ("  -> Constant {:?} formatted successfully.\n" , const_name) ; utils :: validate_rust_code (& output_path) . await . context (format ! ("Constant {:?} validation failed for {:?}" , const_name , output_path)) ? ; println ! (r"  -> Constant {:?} validated successfully.\n" , const_name) ; Ok (()) }']
expression_str = 'async { let tokens = quote ! { # constant } ; let mut code = tokens . to_string () ; let required_uses = use_statements :: get_required_uses_for_item_const (& constant) ; code = format ! ("{}{}" , required_uses , code) ; tokio :: fs :: write (& output_path , code . as_bytes ()) . await . context (format ! ("Failed to write constant {:?} to {:?}" , const_name , output_path)) ? ; println ! ("  -> Wrote constant {:?} to {:?}" , const_name , output_path) ; utils :: format_rust_code (& output_path) . await . context (format ! ("Constant {:?} formatting failed for {:?}" , const_name , output_path)) ? ; println ! ("  -> Constant {:?} formatted successfully.\n" , const_name) ; utils :: validate_rust_code (& output_path) . await . context (format ! ("Constant {:?} validation failed for {:?}" , const_name , output_path)) ? ; println ! (r"  -> Constant {:?} validated successfully.\n" , const_name) ; Ok (()) }'
depth = 4
used_types = []
other_types_count = 0
node_type = "Async"

[expressions."sorted_types . iter ()"]
expression_str = "sorted_types . iter ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'| line | line . starts_with ("rustc ")']
expression_str = '| line | line . starts_with ("rustc ")'
depth = 3
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions."& i . path . segments"]
expression_str = "& i . path . segments"
depth = 3
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'if let Err (ref e) = result { let mut stderr = tokio :: io :: stderr () ; stderr . write_all (format ! ("Pipeline failed: {:?}\n" , e) . as_bytes ()) . await ? ; } else { let mut stdout = tokio :: io :: stdout () ; stdout . write_all (b"Pipeline completed successfully.\n") . await ? ; }']
expression_str = 'if let Err (ref e) = result { let mut stderr = tokio :: io :: stderr () ; stderr . write_all (format ! ("Pipeline failed: {:?}\n" , e) . as_bytes ()) . await ? ; } else { let mut stdout = tokio :: io :: stdout () ; stdout . write_all (b"Pipeline completed successfully.\n") . await ? ; }'
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions."& main_rs_path"]
expression_str = "& main_rs_path"
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."PipelineFunctor :: map (& ast_reconstruction_functor , writer , validated_file . clone ()) . await"]
expression_str = "PipelineFunctor :: map (& ast_reconstruction_functor , writer , validated_file . clone ()) . await"
depth = 4
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.'file . read_to_string (& mut contents) . await . context ("Failed to read mapping.toml") ?']
expression_str = 'file . read_to_string (& mut contents) . await . context ("Failed to read mapping.toml") ?'
depth = 5
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."self . current_field_accesses"]
expression_str = "self . current_field_accesses"
depth = 5
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'"\n\n"']
expression_str = '"\n\n"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'setup_test_file (& dir , "src/lib.rs" , "pub mod prelude;\nfn main() {}\n")']
expression_str = 'setup_test_file (& dir , "src/lib.rs" , "pub mod prelude;\nfn main() {}\n")'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."crate_root . to_string_lossy () . as_bytes ()"]
expression_str = "crate_root . to_string_lossy () . as_bytes ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'tokio :: process :: Command :: new ("cargo") . arg ("rustc") . arg ("--manifest-path") . arg (& temp_cargo_toml_path) . arg ("--lib") . arg ("--") . arg ("-Zunpretty=expanded") . output () . await']
expression_str = 'tokio :: process :: Command :: new ("cargo") . arg ("rustc") . arg ("--manifest-path") . arg (& temp_cargo_toml_path) . arg ("--lib") . arg ("--") . arg ("-Zunpretty=expanded") . output () . await'
depth = 3
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.ident_str]
expression_str = "ident_str"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'Ok ((syn :: parse_file (& expanded_code) . with_context (| | format ! ("Failed to parse cached expanded code for {}" , file_path . display ())) ? , None))']
expression_str = 'Ok ((syn :: parse_file (& expanded_code) . with_context (| | format ! ("Failed to parse cached expanded code for {}" , file_path . display ())) ? , None))'
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'Some ("std::macro")']
expression_str = 'Some ("std::macro")'
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'"run_all_tests.sh"']
expression_str = '"run_all_tests.sh"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'"host: "']
expression_str = '"host: "'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."visit :: visit_expr_method_call"]
expression_str = "visit :: visit_expr_method_call"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'fs :: create_dir_all (crate_root . join ("tests"))']
expression_str = 'fs :: create_dir_all (crate_root . join ("tests"))'
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.RawFile]
expression_str = "RawFile"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'project_root . join ("generated/level0_decls")']
expression_str = 'project_root . join ("generated/level0_decls")'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."all_public_symbols . extend (public_symbols)"]
expression_str = "all_public_symbols . extend (public_symbols)"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"Return" . to_string ()']
expression_str = '"Return" . to_string ()'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."fs :: write (crate_root . join (\"tests/integration_test.rs\") , r#\"\n            #[test]\n            fn integration_test() { }\n        \"# ,)"]
expression_str = """
fs :: write (crate_root . join ("tests/integration_test.rs") , r#"
            #[test]
            fn integration_test() { }
        "# ,)"""
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'Err (anyhow :: anyhow ! ("Struct processing completed with errors."))']
expression_str = 'Err (anyhow :: anyhow ! ("Struct processing completed with errors."))'
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."Args { dry_run : false , path : project_root . clone () , exclude_crates : vec ! [] , report : true , results_file : results_json_path . clone () , cache_report : false , timeout : None , force : false , }"]
expression_str = "Args { dry_run : false , path : project_root . clone () , exclude_crates : vec ! [] , report : true , results_file : results_json_path . clone () , cache_report : false , timeout : None , force : false , }"
depth = 2
used_types = []
other_types_count = 0
node_type = "Struct"

[expressions."prelude_generator :: public_tests :: test_generate_test_runner_crate"]
expression_str = "prelude_generator :: public_tests :: test_generate_test_runner_crate"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'file . write_all (toml_string . as_bytes ()) . await . context ("Failed to write mapping.toml")']
expression_str = 'file . write_all (toml_string . as_bytes ()) . await . context ("Failed to write mapping.toml")'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'tokio :: process :: Command :: new ("git") . arg ("init") . current_dir (& hf_validator_project_dir) . output () . await . context ("Failed to initialize git repository") ?']
expression_str = 'tokio :: process :: Command :: new ("git") . arg ("init") . current_dir (& hf_validator_project_dir) . output () . await . context ("Failed to initialize git repository") ?'
depth = 4
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.file_metadata]
expression_str = "file_metadata"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'report_content . push_str (& format ! ("### {}\n" , result . path . display ()))']
expression_str = 'report_content . push_str (& format ! ("### {}\n" , result . path . display ()))'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'format ! ("layer_{}" , layer)']
expression_str = 'format ! ("layer_{}" , layer)'
depth = 5
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions.'fs :: create_dir_all (crate_root . join ("src")) ?']
expression_str = 'fs :: create_dir_all (crate_root . join ("src")) ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."! full_path . is_empty ()"]
expression_str = "! full_path . is_empty ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "Unary"

[expressions."decl . get_identifier ()"]
expression_str = "decl . get_identifier ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."{ if crate_root_path . exists () && ! force { println ! (\"  -> Skipping crate root modification for {} (file exists, use --force to overwrite).\" , crate_root_path . display ()) ; } else { println ! (\"  -> Adding 'pub mod prelude;' to: {}\" , crate_root_path . display ()) ; println ! (\"    -> Writing modified content to: {}\" , crate_root_path . display ()) ; fs :: write (& crate_root_path , new_content) ? ; } }"]
expression_str = """{ if crate_root_path . exists () && ! force { println ! ("  -> Skipping crate root modification for {} (file exists, use --force to overwrite)." , crate_root_path . display ()) ; } else { println ! ("  -> Adding 'pub mod prelude;' to: {}" , crate_root_path . display ()) ; println ! ("    -> Writing modified content to: {}" , crate_root_path . display ()) ; fs :: write (& crate_root_path , new_content) ? ; } }"""
depth = 4
used_types = []
other_types_count = 0
node_type = "Block"

[expressions.'if use_statement . contains ("cargo") { current_use_statement . cargo_details = Some (pipeline_traits :: CargoDetails :: Info (pipeline_traits :: CargoInfo { package_name : "inferred_from_use" . to_string () , version : "inferred_from_use" . to_string () , })) ; }']
expression_str = 'if use_statement . contains ("cargo") { current_use_statement . cargo_details = Some (pipeline_traits :: CargoDetails :: Info (pipeline_traits :: CargoInfo { package_name : "inferred_from_use" . to_string () , version : "inferred_from_use" . to_string () , })) ; }'
depth = 5
used_types = []
other_types_count = 0
node_type = "If"

[expressions."& mut stdout"]
expression_str = "& mut stdout"
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."bag_of_words_visitor . bag_of_words"]
expression_str = "bag_of_words_visitor . bag_of_words"
depth = 4
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'add_std_lib_symbol (& mut symbols , "assert_eq!" , "macro" , Some ("std::macro"))']
expression_str = 'add_std_lib_symbol (& mut symbols , "assert_eq!" , "macro" , Some ("std::macro"))'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."dir . path () . join (file_name)"]
expression_str = "dir . path () . join (file_name)"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"ForLoop"']
expression_str = '"ForLoop"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."generate_report (& [])"]
expression_str = "generate_report (& [])"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."modify_crate_root (& src_dir , false , false)"]
expression_str = "modify_crate_root (& src_dir , false , false)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."crate :: utils :: validate_rust_code (& output_file_path)"]
expression_str = "crate :: utils :: validate_rust_code (& output_file_path)"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'writer . write_all (format ! ("        -> Parsing expanded code for: {}\n" , file_path . display ()) . as_bytes ()) . await ?']
expression_str = 'writer . write_all (format ! ("        -> Parsing expanded code for: {}\n" , file_path . display ()) . as_bytes ()) . await ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."prelude_generator :: public_tests :: test_generate_report_with_results"]
expression_str = "prelude_generator :: public_tests :: test_generate_report_with_results"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."fs :: create_dir_all"]
expression_str = "fs :: create_dir_all"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'column_stats . insert ("function" . to_string () , (1 , 1 , 6 , 6))']
expression_str = 'column_stats . insert ("function" . to_string () , (1 , 1 , 6 , 6))'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.uses]
expression_str = "uses"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.script_path]
expression_str = "script_path"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."_args . test_report_input_file . clone ()"]
expression_str = "_args . test_report_input_file . clone ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."prelude_generator :: public_tests :: test_generate_test_report_json ()"]
expression_str = "prelude_generator :: public_tests :: test_generate_test_report_json ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."fs :: read_to_string (& report_path) ?"]
expression_str = "fs :: read_to_string (& report_path) ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."prelude_generator :: public_tests :: test_extract_test_cases_from_file () ?"]
expression_str = "prelude_generator :: public_tests :: test_extract_test_cases_from_file () ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."prelude_generator :: public_tests :: test_modify_file_adds_prelude_and_removes_uses () ?"]
expression_str = "prelude_generator :: public_tests :: test_modify_file_adds_prelude_and_removes_uses () ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."! primitive_types . contains (& type_str . as_str ())"]
expression_str = "! primitive_types . contains (& type_str . as_str ())"
depth = 3
used_types = []
other_types_count = 0
node_type = "Unary"

[expressions."tokio :: fs :: create_dir_all (& permanent_output_dir) . await"]
expression_str = "tokio :: fs :: create_dir_all (& permanent_output_dir) . await"
depth = 5
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."tokio :: fs :: create_dir_all (& string_output_dir)"]
expression_str = "tokio :: fs :: create_dir_all (& string_output_dir)"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'writer . write_all (format ! ("\n--- AST Node Type Report ---\n") . as_bytes ()) . await']
expression_str = 'writer . write_all (format ! ("\n--- AST Node Type Report ---\n") . as_bytes ()) . await'
depth = 3
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."prelude_generator :: public_tests :: test_extract_test_cases_from_file"]
expression_str = "prelude_generator :: public_tests :: test_extract_test_cases_from_file"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."prelude_generator :: public_tests :: test_modify_crate_root_adds_mod_prelude () ?"]
expression_str = "prelude_generator :: public_tests :: test_modify_crate_root_adds_mod_prelude () ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."classified_uses . push (current_use_statement)"]
expression_str = "classified_uses . push (current_use_statement)"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"Binary" . to_string ()']
expression_str = '"Binary" . to_string ()'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."generate_report (& all_expression_info , max_expression_depth , output_path , & all_struct_lattices , & all_enum_lattices , & all_impl_lattices)"]
expression_str = "generate_report (& all_expression_info , max_expression_depth , output_path , & all_struct_lattices , & all_enum_lattices , & all_impl_lattices)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'if structure . attrs . iter () . any (| attr | { if attr . path () . is_ident ("derive") { if let syn :: Meta :: List (meta_list) = & attr . meta { meta_list . tokens . to_string () . contains ("Serialize") || meta_list . tokens . to_string () . contains ("Deserialize") } else { false } } else { false } }) { uses . insert ("use serde::{Serialize, Deserialize};\n") ; }']
expression_str = 'if structure . attrs . iter () . any (| attr | { if attr . path () . is_ident ("derive") { if let syn :: Meta :: List (meta_list) = & attr . meta { meta_list . tokens . to_string () . contains ("Serialize") || meta_list . tokens . to_string () . contains ("Deserialize") } else { false } } else { false } }) { uses . insert ("use serde::{Serialize, Deserialize};\n") ; }'
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'writer . write_all (format ! ("  -> Generated code validated successfully.\n") . as_bytes ()) . await ?']
expression_str = 'writer . write_all (format ! ("  -> Generated code validated successfully.\n") . as_bytes ()) . await ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."base_path . push (path . ident . to_string ())"]
expression_str = "base_path . push (path . ident . to_string ())"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"Level0DeclsVisitor"']
expression_str = '"Level0DeclsVisitor"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."tempdir ()"]
expression_str = "tempdir ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."Utc :: now ()"]
expression_str = "Utc :: now ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."let syn :: Expr :: Lit (expr_lit) = & * * expr"]
expression_str = "let syn :: Expr :: Lit (expr_lit) = & * * expr"
depth = 3
used_types = []
other_types_count = 0
node_type = "Let"

[expressions.'if let Some (output_path) = _output_symbol_map { let toml_string = toml :: to_string_pretty (& symbol_map . map) . context ("Failed to serialize symbol map to TOML ") ? ; fs :: write (& output_path , toml_string) . context (format ! ("Failed to write symbol map to file: {:?}" , output_path)) ? ; println ! ("Successfully wrote symbol map to {:?}" , output_path) ; }']
expression_str = 'if let Some (output_path) = _output_symbol_map { let toml_string = toml :: to_string_pretty (& symbol_map . map) . context ("Failed to serialize symbol map to TOML ") ? ; fs :: write (& output_path , toml_string) . context (format ! ("Failed to write symbol map to file: {:?}" , output_path)) ? ; println ! ("Successfully wrote symbol map to {:?}" , output_path) ; }'
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'| line | line . starts_with ("host: ")']
expression_str = '| line | line . starts_with ("host: ")'
depth = 3
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions."visit :: visit_expr_if (self , i)"]
expression_str = "visit :: visit_expr_if (self , i)"
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."self . current_depth += 1"]
expression_str = "self . current_depth += 1"
depth = 2
used_types = []
other_types_count = 0
node_type = "Binary"

[expressions."let Some (segment) = expr_path . path . segments . last ()"]
expression_str = "let Some (segment) = expr_path . path . segments . last ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "Let"

[expressions."visit :: visit_item_const"]
expression_str = "visit :: visit_item_const"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'format ! ("Failed to write generated AST statistics code to {:?}" , ast_statistics_file_path)']
expression_str = 'format ! ("Failed to write generated AST statistics code to {:?}" , ast_statistics_file_path)'
depth = 4
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions.'output_dir . join ("run_all_tests.sh")']
expression_str = 'output_dir . join ("run_all_tests.sh")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."prelude_generator :: public_tests :: test_generate_report_empty_results () ?"]
expression_str = "prelude_generator :: public_tests :: test_generate_report_empty_results () ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."if entry_path . is_dir () { fs :: create_dir_all (& destination_path) . await ? ; stack . push (entry_path) ; } else { fs :: copy (& entry_path , & destination_path) . await ? ; }"]
expression_str = "if entry_path . is_dir () { fs :: create_dir_all (& destination_path) . await ? ; stack . push (entry_path) ; } else { fs :: copy (& entry_path , & destination_path) . await ? ; }"
depth = 4
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'tokio :: task :: spawn_blocking (move | | -> anyhow :: Result < _ > { let ast = syn :: parse_file (& source_code) . context ("Failed to parse source code for use statement extraction") ? ; let mut use_statements = Vec :: new () ; for item in ast . items { if let syn :: Item :: Use (use_item) = item { use_statements . push (code_generator :: use_item_to_string (& use_item)) ; } } Ok (UseStatements (use_statements)) }) . await . context ("Blocking task for extracting use statements failed") ?']
expression_str = 'tokio :: task :: spawn_blocking (move | | -> anyhow :: Result < _ > { let ast = syn :: parse_file (& source_code) . context ("Failed to parse source code for use statement extraction") ? ; let mut use_statements = Vec :: new () ; for item in ast . items { if let syn :: Item :: Use (use_item) = item { use_statements . push (code_generator :: use_item_to_string (& use_item)) ; } } Ok (UseStatements (use_statements)) }) . await . context ("Blocking task for extracting use statements failed") ?'
depth = 5
used_types = [
    "_",
    "Result",
]
other_types_count = 2
node_type = "Unknown"

[expressions.'writer . write_all (format ! ("  -> Hugging Face Validation Result: {:#?}\n" , validated_file) . as_bytes () ,)']
expression_str = 'writer . write_all (format ! ("  -> Hugging Face Validation Result: {:#?}\n" , validated_file) . as_bytes () ,)'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."fs :: write (& prelude_path , original_content) ?"]
expression_str = "fs :: write (& prelude_path , original_content) ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'"// Test prelude content"']
expression_str = '"// Test prelude content"'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."fs :: create_dir (& temp_src_dir)"]
expression_str = "fs :: create_dir (& temp_src_dir)"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."all_declarations . into_iter ()"]
expression_str = "all_declarations . into_iter ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."String :: new ()"]
expression_str = "String :: new ()"
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'output_dir . join ("Test_Verification_Report.md")']
expression_str = 'output_dir . join ("Test_Verification_Report.md")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."file_path . file_stem () . unwrap () . to_string_lossy ()"]
expression_str = "file_path . file_stem () . unwrap () . to_string_lossy ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.tokenize_ident_to_subwords]
expression_str = "tokenize_ident_to_subwords"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'setup_test_file (& dir , "test_file.rs" , "fn main() {}\n")']
expression_str = 'setup_test_file (& dir , "test_file.rs" , "fn main() {}\n")'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."Into :: into"]
expression_str = "Into :: into"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."results . iter ()"]
expression_str = "results . iter ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."collector . dependencies"]
expression_str = "collector . dependencies"
depth = 3
used_types = []
other_types_count = 0
node_type = "Field"

[expressions."for identifier in & gem_entry . identifiers { map . insert (identifier . clone () , gem_entry . name . clone ()) ; }"]
expression_str = "for identifier in & gem_entry . identifiers { map . insert (identifier . clone () , gem_entry . name . clone ()) ; }"
depth = 3
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions.file_content]
expression_str = "file_content"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."* * expr"]
expression_str = "* * expr"
depth = 5
used_types = []
other_types_count = 0
node_type = "Unary"

[expressions.'line . starts_with ("host: ")']
expression_str = 'line . starts_with ("host: ")'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'walkdir :: WalkDir :: new (project_root) . into_iter () . filter_map (| e | e . ok ()) . filter (| e | e . file_type () . is_file () && e . path () . extension () . map_or (false , | ext | ext == "rs"))']
expression_str = 'walkdir :: WalkDir :: new (project_root) . into_iter () . filter_map (| e | e . ok ()) . filter (| e | e . file_type () . is_file () && e . path () . extension () . map_or (false , | ext | ext == "rs"))'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."for field in & i . fields { if let Some (ident) = & field . ident { self . add_ident_to_bag (ident) ; } }"]
expression_str = "for field in & i . fields { if let Some (ident) = & field . ident { self . add_ident_to_bag (ident) ; } }"
depth = 2
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions."bins_config . paths"]
expression_str = "bins_config . paths"
depth = 5
used_types = []
other_types_count = 0
node_type = "Field"

[expressions."prelude_generator :: public_tests :: test_generate_prelude_force_overwrite () ?"]
expression_str = "prelude_generator :: public_tests :: test_generate_prelude_force_overwrite () ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'writer . write_all (format ! ("  -> Generated code written to {:?}\n" , output_file_path) . as_bytes ()) . await ?']
expression_str = 'writer . write_all (format ! ("  -> Generated code written to {:?}\n" , output_file_path) . as_bytes ()) . await ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'fs :: write (& script_path , script_content) . with_context (| | format ! ("Failed to write run_all_tests.sh to {}" , script_path . display ()))']
expression_str = 'fs :: write (& script_path , script_content) . with_context (| | format ! ("Failed to write run_all_tests.sh to {}" , script_path . display ()))'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."* * ty"]
expression_str = "* * ty"
depth = 5
used_types = []
other_types_count = 0
node_type = "Unary"

[expressions.'" Run the use statement processing pipeline"']
expression_str = '" Run the use statement processing pipeline"'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."& all_public_symbols"]
expression_str = "& all_public_symbols"
depth = 5
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'"type" . to_string ()']
expression_str = '"type" . to_string ()'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'add_std_lib_symbol (& mut symbols , "eprintln!" , "macro" , Some ("std::macro"))']
expression_str = 'add_std_lib_symbol (& mut symbols , "eprintln!" , "macro" , Some ("std::macro"))'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."for arm in & i . arms { if let syn :: Pat :: TupleStruct (pat_tuple_struct) = & arm . pat { if let Some (segment) = pat_tuple_struct . path . segments . last () { matched_variant_types . insert (segment . ident . to_string ()) ; } } else if let syn :: Pat :: Path (pat_path) = & arm . pat { if let Some (segment) = pat_path . path . segments . last () { matched_variant_types . insert (segment . ident . to_string ()) ; } } }"]
expression_str = "for arm in & i . arms { if let syn :: Pat :: TupleStruct (pat_tuple_struct) = & arm . pat { if let Some (segment) = pat_tuple_struct . path . segments . last () { matched_variant_types . insert (segment . ident . to_string ()) ; } } else if let syn :: Pat :: Path (pat_path) = & arm . pat { if let Some (segment) = pat_path . path . segments . last () { matched_variant_types . insert (segment . ident . to_string ()) ; } } }"
depth = 2
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions.enum_name]
expression_str = "enum_name"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.file_name]
expression_str = "file_name"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."if self . current_depth <= self . max_depth { let expr_str = expr . to_token_stream () . to_string () ; let used_types = self . extract_types_from_expr (expr) ; let other_types_count = used_types . len () ; let node_type = Self :: get_expr_node_type (expr) ; let info = ExpressionInfo { expression_str : expr_str . clone () , depth : self . current_depth , used_types , other_types_count , node_type , } ; self . expressions . insert (expr_str , info) ; }"]
expression_str = "if self . current_depth <= self . max_depth { let expr_str = expr . to_token_stream () . to_string () ; let used_types = self . extract_types_from_expr (expr) ; let other_types_count = used_types . len () ; let node_type = Self :: get_expr_node_type (expr) ; let info = ExpressionInfo { expression_str : expr_str . clone () , depth : self . current_depth , used_types , other_types_count , node_type , } ; self . expressions . insert (expr_str , info) ; }"
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'format ! ("Failed to create output directory {:?}" , numerical_output_dir)']
expression_str = 'format ! ("Failed to create output directory {:?}" , numerical_output_dir)'
depth = 4
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions."_args . test_verification_output_dir"]
expression_str = "_args . test_verification_output_dir"
depth = 5
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'"// No constant declarations found in this module.\n"']
expression_str = '"// No constant declarations found in this module.\n"'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'"Output path for type usage report must be specified"']
expression_str = '"Output path for type usage report must be specified"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."syn :: parse_file (& relevant_expanded_code)"]
expression_str = "syn :: parse_file (& relevant_expanded_code)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'if ! output . status . success () { return Err (anyhow :: anyhow ! ("git commit --allow-empty failed: {}\nStderr: {}" , String :: from_utf8_lossy (& output . status . code () . unwrap_or (- 1) . to_string () . as_bytes ()) , String :: from_utf8_lossy (& output . stderr))) ; }']
expression_str = 'if ! output . status . success () { return Err (anyhow :: anyhow ! ("git commit --allow-empty failed: {}\nStderr: {}" , String :: from_utf8_lossy (& output . status . code () . unwrap_or (- 1) . to_string () . as_bytes ()) , String :: from_utf8_lossy (& output . stderr))) ; }'
depth = 4
used_types = []
other_types_count = 0
node_type = "If"

[expressions."temp_output_dir . path () . to_path_buf ()"]
expression_str = "temp_output_dir . path () . to_path_buf ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."walkdir :: WalkDir :: new (project_root) . into_iter ()"]
expression_str = "walkdir :: WalkDir :: new (project_root) . into_iter ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."& results_file_content"]
expression_str = "& results_file_content"
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."for field in & variant . fields { if let Some (ident) = & field . ident { self . add_ident_to_bag (ident) ; } }"]
expression_str = "for field in & variant . fields { if let Some (ident) = & field . ident { self . add_ident_to_bag (ident) ; } }"
depth = 3
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions.'writer . write_all (format ! ("  -> Parsed file successfully.\n") . as_bytes ()) . await']
expression_str = 'writer . write_all (format ! ("  -> Parsed file successfully.\n") . as_bytes ()) . await'
depth = 3
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."errors . is_empty ()"]
expression_str = "errors . is_empty ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."report_content . push_str (& format ! (\"\\n### Analyzing expressions using type: '{}' ###\\n\" , target_type))"]
expression_str = '''report_content . push_str (& format ! ("\n### Analyzing expressions using type: '{}' ###\n" , target_type))'''
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."if let syn :: PathArguments :: AngleBracketed (angle_args) = & segment . arguments { for arg in angle_args . args . iter () { if let syn :: GenericArgument :: Type (syn :: Type :: Path (inner_type_path)) = arg { add_uses_from_type_path (inner_type_path , uses) ; } } }"]
expression_str = "if let syn :: PathArguments :: AngleBracketed (angle_args) = & segment . arguments { for arg in angle_args . args . iter () { if let syn :: GenericArgument :: Type (syn :: Type :: Path (inner_type_path)) = arg { add_uses_from_type_path (inner_type_path , uses) ; } } }"
depth = 4
used_types = []
other_types_count = 0
node_type = "If"

[expressions."prelude_generator :: public_tests :: test_generate_test_runner_crate ()"]
expression_str = "prelude_generator :: public_tests :: test_generate_test_runner_crate ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'"std::result"']
expression_str = '"std::result"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."* self . variant_type_co_occurrences . entry (variant_types) . or_insert (0)"]
expression_str = "* self . variant_type_co_occurrences . entry (variant_types) . or_insert (0)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Unary"

[expressions."fs :: write (toml_output_path , toml_content)"]
expression_str = "fs :: write (toml_output_path , toml_content)"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."fs :: create_dir_all (output_dir)"]
expression_str = "fs :: create_dir_all (output_dir)"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.current_layer_decls]
expression_str = "current_layer_decls"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."self . total_expressions_analyzed += 1"]
expression_str = "self . total_expressions_analyzed += 1"
depth = 2
used_types = []
other_types_count = 0
node_type = "Binary"

[expressions.'writer . write_all (format ! ("        -> rustc stdout for {}: {}\n" , file_path . display () , String :: from_utf8_lossy (& output . stdout)) . as_bytes ())']
expression_str = 'writer . write_all (format ! ("        -> rustc stdout for {}: {}\n" , file_path . display () , String :: from_utf8_lossy (& output . stdout)) . as_bytes ())'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."Args :: parse ()"]
expression_str = "Args :: parse ()"
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."& args"]
expression_str = "& args"
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.crate_path]
expression_str = "crate_path"
depth = 2
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."visit :: visit_expr_method_call (self , i)"]
expression_str = "visit :: visit_expr_method_call (self , i)"
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'fs :: write (& prelude_path , "// Original content") ?']
expression_str = 'fs :: write (& prelude_path , "// Original content") ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."& crate_root"]
expression_str = "& crate_root"
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.path]
expression_str = "path"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'format ! ("generated/hf_dataset_output/{}" , short_id)']
expression_str = 'format ! ("generated/hf_dataset_output/{}" , short_id)'
depth = 5
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions.ty]
expression_str = "ty"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'for result in results { report_content . push_str (& format ! ("### {}\n" , result . path . display ())) ; match & result . status { FileProcessingStatus :: Success => { report_content . push_str ("- Status:  Successfully Processed\n\n") ; } FileProcessingStatus :: Skipped { reason } => { report_content . push_str (& format ! ("- Status:  Skipped (Reason: {}\n\n" , reason)) ; } FileProcessingStatus :: Failed { error } => { report_content . push_str (& format ! ("- Status:  Failed (Error: {}\n\n" , error)) ; } } }']
expression_str = 'for result in results { report_content . push_str (& format ! ("### {}\n" , result . path . display ())) ; match & result . status { FileProcessingStatus :: Success => { report_content . push_str ("- Status:  Successfully Processed\n\n") ; } FileProcessingStatus :: Skipped { reason } => { report_content . push_str (& format ! ("- Status:  Skipped (Reason: {}\n\n" , reason)) ; } FileProcessingStatus :: Failed { error } => { report_content . push_str (& format ! ("- Status:  Failed (Error: {}\n\n" , error)) ; } } }'
depth = 3
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions."{ { } }"]
expression_str = "{ { } }"
depth = 5
used_types = []
other_types_count = 0
node_type = "Block"

[expressions."for _dep in & declaration . referenced_types { }"]
expression_str = "for _dep in & declaration . referenced_types { }"
depth = 2
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions."& gem_config . gem"]
expression_str = "& gem_config . gem"
depth = 3
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."pipeline :: run_category_pipeline"]
expression_str = "pipeline :: run_category_pipeline"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."i . to_token_stream ()"]
expression_str = "i . to_token_stream ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"Struct"']
expression_str = '"Struct"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."const_name . clone ()"]
expression_str = "const_name . clone ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."structs . iter () . map (| s | { let tokens = quote ! { # s } ; tokens . to_string () }) . collect ()"]
expression_str = "structs . iter () . map (| s | { let tokens = quote ! { # s } ; tokens . to_string () }) . collect ()"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."is_complex_type (& type_name)"]
expression_str = "is_complex_type (& type_name)"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."visit :: visit_item_impl"]
expression_str = "visit :: visit_item_impl"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."let syn :: Expr :: Let (expr_let) = & * i . cond"]
expression_str = "let syn :: Expr :: Let (expr_let) = & * i . cond"
depth = 3
used_types = []
other_types_count = 0
node_type = "Let"

[expressions."prelude_generator :: public_tests :: test_generate_report_with_results ()"]
expression_str = "prelude_generator :: public_tests :: test_generate_report_with_results ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."TypeUsageVisitor :: new (max_expression_depth)"]
expression_str = "TypeUsageVisitor :: new (max_expression_depth)"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."if let Type :: Path (type_path) = & * i . self_ty { type_path . path . segments . last () . map (| segment | segment . ident . to_string ()) } else { None }"]
expression_str = "if let Type :: Path (type_path) = & * i . self_ty { type_path . path . segments . last () . map (| segment | segment . ident . to_string ()) } else { None }"
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions."remaining_decls . is_empty ()"]
expression_str = "remaining_decls . is_empty ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."self . type_map . entry (struct_name . clone ()) . or_insert_with (| | TypeInfo { count : 0 , layer : Some (0) })"]
expression_str = "self . type_map . entry (struct_name . clone ()) . or_insert_with (| | TypeInfo { count : 0 , layer : Some (0) })"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."self . field_co_occurrences . entry (field_types) . or_insert (0)"]
expression_str = "self . field_co_occurrences . entry (field_types) . or_insert (0)"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."parse_arguments_and_config () ?"]
expression_str = "parse_arguments_and_config () ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.handle_pipeline_result]
expression_str = "handle_pipeline_result"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'format ! ("Failed to read config file: {}" , config_path . display ())']
expression_str = 'format ! ("Failed to read config file: {}" , config_path . display ())'
depth = 5
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions.'"module" . to_string ()']
expression_str = '"module" . to_string ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."for (_ , path) in bins_config . paths . iter_mut () { if ! path . is_absolute () { * path = project_root . join (& path) ; } }"]
expression_str = "for (_ , path) in bins_config . paths . iter_mut () { if ! path . is_absolute () { * path = project_root . join (& path) ; } }"
depth = 3
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions."BagOfWordsVisitor { bag_of_words : HashMap :: new () , }"]
expression_str = "BagOfWordsVisitor { bag_of_words : HashMap :: new () , }"
depth = 2
used_types = []
other_types_count = 0
node_type = "Struct"

[expressions."generate_prelude :: generate_prelude (& src_dir , prelude_content , true , false) ?"]
expression_str = "generate_prelude :: generate_prelude (& src_dir , prelude_content , true , false) ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."tokio :: fs :: write (& file_path , current_file_content . as_bytes ()) . await"]
expression_str = "tokio :: fs :: write (& file_path , current_file_content . as_bytes ()) . await"
depth = 4
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.has_prelude_mod]
expression_str = "has_prelude_mod"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."if ! path . is_absolute () { * path = project_root . join (& path) ; }"]
expression_str = "if ! path . is_absolute () { * path = project_root . join (& path) ; }"
depth = 4
used_types = []
other_types_count = 0
node_type = "If"

[expressions."segment . ident . to_string ()"]
expression_str = "segment . ident . to_string ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."WalkDir :: new (& repo_root) . into_iter () . filter_map (| e | e . ok ())"]
expression_str = "WalkDir :: new (& repo_root) . into_iter () . filter_map (| e | e . ok ())"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."ImplLatticeInfo { impl_for_type , method_co_occurrences : HashMap :: new () , total_expressions_analyzed : 0 , }"]
expression_str = "ImplLatticeInfo { impl_for_type , method_co_occurrences : HashMap :: new () , total_expressions_analyzed : 0 , }"
depth = 2
used_types = []
other_types_count = 0
node_type = "Struct"

[expressions."let Some (bins_config) = & mut config . bins"]
expression_str = "let Some (bins_config) = & mut config . bins"
depth = 3
used_types = []
other_types_count = 0
node_type = "Let"

[expressions."fs :: write (crate_path . join (\"Cargo.toml\") , format ! (\"[package]\\nname = \\\"{{}}\\nversion = \\\"0.1.0\\\"\nedition = \\\"2021\\\"\n\" , crate_name)) . unwrap ()"]
expression_str = '''
fs :: write (crate_path . join ("Cargo.toml") , format ! ("[package]\nname = \"{{}}\nversion = \"0.1.0\"
edition = \"2021\"
" , crate_name)) . unwrap ()'''
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'{ eprintln ! ("Warning: Could not parse file {}: {}" , file_path . display () , e) ; continue ; }']
expression_str = '{ eprintln ! ("Warning: Could not parse file {}: {}" , file_path . display () , e) ; continue ; }'
depth = 5
used_types = []
other_types_count = 0
node_type = "Block"

[expressions.'"Loop"']
expression_str = '"Loop"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'" Rustc version (e.g., \"1.89.0\") for split-expanded-bin."']
expression_str = '" Rustc version (e.g., \"1.89.0\") for split-expanded-bin."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'"prelude.rs"']
expression_str = '"prelude.rs"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'writer . write_all (format ! ("  -> Executing hf-validator: {:#?}\n" , hf_validator_executable) . as_bytes ()) . await']
expression_str = 'writer . write_all (format ! ("  -> Executing hf-validator: {:#?}\n" , hf_validator_executable) . as_bytes ()) . await'
depth = 5
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.'Lazy :: new (| | { let mut node_type_counts = HashMap :: new () ; node_type_counts . insert ("variable" . to_string () , 41) ; node_type_counts . insert ("import" . to_string () , 18) ; node_type_counts . insert ("function" . to_string () , 6) ; node_type_counts . insert ("other" . to_string () , 230) ; let mut line_stats = HashMap :: new () ; line_stats . insert ("other" . to_string () , (12 , 295 , 36092 , 230)) ; line_stats . insert ("import" . to_string () , (1 , 212 , 891 , 18)) ; line_stats . insert ("variable" . to_string () , (25 , 274 , 5772 , 41)) ; line_stats . insert ("function" . to_string () , (18 , 208 , 905 , 6)) ; let mut column_stats = HashMap :: new () ; column_stats . insert ("import" . to_string () , (1 , 1 , 18 , 18)) ; column_stats . insert ("variable" . to_string () , (1 , 1 , 41 , 41)) ; column_stats . insert ("function" . to_string () , (1 , 1 , 6 , 6)) ; column_stats . insert ("other" . to_string () , (1 , 1 , 230 , 230)) ; let mut processing_time_stats = HashMap :: new () ; processing_time_stats . insert ("other" . to_string () , (1 , 1 , 230 , 230)) ; processing_time_stats . insert ("import" . to_string () , (1 , 1 , 18 , 18)) ; processing_time_stats . insert ("variable" . to_string () , (1 , 1 , 41 , 41)) ; processing_time_stats . insert ("function" . to_string () , (1 , 1 , 6 , 6)) ; let mut rust_version_counts = HashMap :: new () ; rust_version_counts . insert ("1.86.0" . to_string () , 295) ; let mut analyzer_version_counts = HashMap :: new () ; analyzer_version_counts . insert ("0.3.2000" . to_string () , 295) ; let mut snippet_length_stats = HashMap :: new () ; snippet_length_stats . insert ("function" . to_string () , (39 , 83 , 434 , 6)) ; snippet_length_stats . insert ("other" . to_string () , (1 , 92 , 7273 , 230)) ; snippet_length_stats . insert ("import" . to_string () , (14 , 85 , 812 , 18)) ; snippet_length_stats . insert ("variable" . to_string () , (29 , 89 , 2362 , 41)) ; AstStatistics { node_type_counts , line_stats , column_stats , processing_time_stats , rust_version_counts , analyzer_version_counts , snippet_length_stats , } })']
expression_str = 'Lazy :: new (| | { let mut node_type_counts = HashMap :: new () ; node_type_counts . insert ("variable" . to_string () , 41) ; node_type_counts . insert ("import" . to_string () , 18) ; node_type_counts . insert ("function" . to_string () , 6) ; node_type_counts . insert ("other" . to_string () , 230) ; let mut line_stats = HashMap :: new () ; line_stats . insert ("other" . to_string () , (12 , 295 , 36092 , 230)) ; line_stats . insert ("import" . to_string () , (1 , 212 , 891 , 18)) ; line_stats . insert ("variable" . to_string () , (25 , 274 , 5772 , 41)) ; line_stats . insert ("function" . to_string () , (18 , 208 , 905 , 6)) ; let mut column_stats = HashMap :: new () ; column_stats . insert ("import" . to_string () , (1 , 1 , 18 , 18)) ; column_stats . insert ("variable" . to_string () , (1 , 1 , 41 , 41)) ; column_stats . insert ("function" . to_string () , (1 , 1 , 6 , 6)) ; column_stats . insert ("other" . to_string () , (1 , 1 , 230 , 230)) ; let mut processing_time_stats = HashMap :: new () ; processing_time_stats . insert ("other" . to_string () , (1 , 1 , 230 , 230)) ; processing_time_stats . insert ("import" . to_string () , (1 , 1 , 18 , 18)) ; processing_time_stats . insert ("variable" . to_string () , (1 , 1 , 41 , 41)) ; processing_time_stats . insert ("function" . to_string () , (1 , 1 , 6 , 6)) ; let mut rust_version_counts = HashMap :: new () ; rust_version_counts . insert ("1.86.0" . to_string () , 295) ; let mut analyzer_version_counts = HashMap :: new () ; analyzer_version_counts . insert ("0.3.2000" . to_string () , 295) ; let mut snippet_length_stats = HashMap :: new () ; snippet_length_stats . insert ("function" . to_string () , (39 , 83 , 434 , 6)) ; snippet_length_stats . insert ("other" . to_string () , (1 , 92 , 7273 , 230)) ; snippet_length_stats . insert ("import" . to_string () , (14 , 85 , 812 , 18)) ; snippet_length_stats . insert ("variable" . to_string () , (29 , 89 , 2362 , 41)) ; AstStatistics { node_type_counts , line_stats , column_stats , processing_time_stats , rust_version_counts , analyzer_version_counts , snippet_length_stats , } })'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."match ty { Type :: Path (type_path) => { for segment in type_path . path . segments . iter () { let ident_str = segment . ident . to_string () ; if is_complex_type (& ident_str) { return true ; } if let PathArguments :: AngleBracketed (angle_args) = & segment . arguments { for arg in angle_args . args . iter () { if let GenericArgument :: Type (inner_ty) = arg { if contains_complex_type_in_type (inner_ty) { return true ; } } } } } false } , _ => false , }"]
expression_str = "match ty { Type :: Path (type_path) => { for segment in type_path . path . segments . iter () { let ident_str = segment . ident . to_string () ; if is_complex_type (& ident_str) { return true ; } if let PathArguments :: AngleBracketed (angle_args) = & segment . arguments { for arg in angle_args . args . iter () { if let GenericArgument :: Type (inner_ty) = arg { if contains_complex_type_in_type (inner_ty) { return true ; } } } } } false } , _ => false , }"
depth = 2
used_types = []
other_types_count = 0
node_type = "Match"

[expressions."modify_crate_root (& src_dir , true , false) ?"]
expression_str = "modify_crate_root (& src_dir , true , false) ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."ReferenceVisitor { symbol_map , declarations , crate_name , module_path , verbose , }"]
expression_str = "ReferenceVisitor { symbol_map , declarations , crate_name , module_path , verbose , }"
depth = 2
used_types = []
other_types_count = 0
node_type = "Struct"

[expressions.'path . is_file () && path . extension () . map_or (false , | ext | ext == "rs")']
expression_str = 'path . is_file () && path . extension () . map_or (false , | ext | ext == "rs")'
depth = 4
used_types = []
other_types_count = 0
node_type = "Binary"

[expressions.'"--dry-run"']
expression_str = '"--dry-run"'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."self . method_co_occurrences . entry (method_names)"]
expression_str = "self . method_co_occurrences . entry (method_names)"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.extract_test_cases_from_file]
expression_str = "extract_test_cases_from_file"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."fs :: write (& file_path , r#\"\n            #[test]\n            fn my_test_1() { assert_eq!(1, 1); }\n\n            fn not_a_test() { }\n\n            #[cfg(test)]\n            mod my_tests {\n                #[test]\n                fn nested_test() { assert_eq!(2, 2); }\n            }\n\n            #[test]\n            async fn my_test_2() -> Result<()> { Ok(()) }\n        \"# ,)"]
expression_str = """
fs :: write (& file_path , r#"
            #[test]
            fn my_test_1() { assert_eq!(1, 1); }

            fn not_a_test() { }

            #[cfg(test)]
            mod my_tests {
                #[test]
                fn nested_test() { assert_eq!(2, 2); }
            }

            #[test]
            async fn my_test_2() -> Result<()> { Ok(()) }
        "# ,)"""
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."walkdir :: WalkDir :: new (project_root)"]
expression_str = "walkdir :: WalkDir :: new (project_root)"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'"results.json"']
expression_str = '"results.json"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."permanent_output_dir . join (entry_path . file_name () . unwrap ())"]
expression_str = "permanent_output_dir . join (entry_path . file_name () . unwrap ())"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."syn :: visit :: Visit :: visit_file"]
expression_str = "syn :: visit :: Visit :: visit_file"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."matches ! (r . status , FileProcessingStatus :: Success)"]
expression_str = "matches ! (r . status , FileProcessingStatus :: Success)"
depth = 5
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions.'for entry in WalkDir :: new (& args . path) { let entry = entry ? ; let file_path = entry . path () ; if file_path . is_file () && file_path . extension () . map_or (false , | ext | ext == "rs") { println ! ("Processing file for type usage analysis: {}" , file_path . display ()) ; let file_content = fs :: read_to_string (& file_path) . context (format ! ("Failed to read file: {:?}" , file_path)) ? ; let file = match syn :: parse_file (& file_content) { Ok (file) => file , Err (e) => { eprintln ! ("Warning: Could not parse file {}: {}" , file_path . display () , e) ; continue ; } } ; let mut visitor = TypeUsageVisitor :: new (max_expression_depth) ; visitor . visit_file (& file) ; for (expr_str , info) in visitor . expressions { all_expression_info . insert (expr_str , info) ; } all_struct_lattices . extend (visitor . struct_lattices) ; all_enum_lattices . extend (visitor . enum_lattices) ; all_impl_lattices . extend (visitor . impl_lattices) ; } }']
expression_str = 'for entry in WalkDir :: new (& args . path) { let entry = entry ? ; let file_path = entry . path () ; if file_path . is_file () && file_path . extension () . map_or (false , | ext | ext == "rs") { println ! ("Processing file for type usage analysis: {}" , file_path . display ()) ; let file_content = fs :: read_to_string (& file_path) . context (format ! ("Failed to read file: {:?}" , file_path)) ? ; let file = match syn :: parse_file (& file_content) { Ok (file) => file , Err (e) => { eprintln ! ("Warning: Could not parse file {}: {}" , file_path . display () , e) ; continue ; } } ; let mut visitor = TypeUsageVisitor :: new (max_expression_depth) ; visitor . visit_file (& file) ; for (expr_str , info) in visitor . expressions { all_expression_info . insert (expr_str , info) ; } all_struct_lattices . extend (visitor . struct_lattices) ; all_enum_lattices . extend (visitor . enum_lattices) ; all_impl_lattices . extend (visitor . impl_lattices) ; } }'
depth = 2
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions.'"Failed to create parent directories for cache file"']
expression_str = '"Failed to create parent directories for cache file"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."match & expr_lit . lit { syn :: Lit :: Int (_) | syn :: Lit :: Float (_) => numerical_constants . push (constant) , syn :: Lit :: Str (_) => string_constants . push (constant) , _ => { } }"]
expression_str = "match & expr_lit . lit { syn :: Lit :: Int (_) | syn :: Lit :: Float (_) => numerical_constants . push (constant) , syn :: Lit :: Str (_) => string_constants . push (constant) , _ => { } }"
depth = 4
used_types = []
other_types_count = 0
node_type = "Match"

[expressions."extract_uses_functor . map (writer , parsed_file . clone ())"]
expression_str = "extract_uses_functor . map (writer , parsed_file . clone ())"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'MetadataCommand :: new () . current_dir (workspace_path) . exec () . context ("Failed to run cargo metadata") ?']
expression_str = 'MetadataCommand :: new () . current_dir (workspace_path) . exec () . context ("Failed to run cargo metadata") ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'if let Some (results_file_path) = & args . results_file { if results_file_path . exists () { let json_content = fs :: read_to_string (results_file_path) . context ("Failed to read results file") ? ; let results : Vec < FileProcessingResult > = serde_json :: from_str (& json_content) . context ("Failed to deserialize results from JSON") ? ; generate_report (& results) ? ; } else { eprintln ! ("Error: Results file not found at {}. Cannot generate report." , results_file_path . display ()) ; } }']
expression_str = 'if let Some (results_file_path) = & args . results_file { if results_file_path . exists () { let json_content = fs :: read_to_string (results_file_path) . context ("Failed to read results file") ? ; let results : Vec < FileProcessingResult > = serde_json :: from_str (& json_content) . context ("Failed to deserialize results from JSON") ? ; generate_report (& results) ? ; } else { eprintln ! ("Error: Results file not found at {}. Cannot generate report." , results_file_path . display ()) ; } }'
depth = 3
used_types = [
    "FileProcessingResult",
    "Vec",
]
other_types_count = 2
node_type = "If"

[expressions."& i . ident"]
expression_str = "& i . ident"
depth = 3
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."prelude_generator :: use_extractor :: rustc_info :: get_rustc_info ()"]
expression_str = "prelude_generator :: use_extractor :: rustc_info :: get_rustc_info ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'ResolvedDependency { id : id . to_string () , dependency_type : "primitive_type" . to_string () , crate_name : "std" . to_string () , module_path : "std" . to_string () , usage_count : 0 , }']
expression_str = 'ResolvedDependency { id : id . to_string () , dependency_type : "primitive_type" . to_string () , crate_name : "std" . to_string () , module_path : "std" . to_string () , usage_count : 0 , }'
depth = 3
used_types = []
other_types_count = 0
node_type = "Struct"

[expressions.'"i32"']
expression_str = '"i32"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."i . ident"]
expression_str = "i . ident"
depth = 3
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'module_path . unwrap_or ("std") . to_string ()']
expression_str = 'module_path . unwrap_or ("std") . to_string ()'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."visit :: visit_type (self , i)"]
expression_str = "visit :: visit_type (self , i)"
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."self . enum_lattices . entry (enum_name . clone ())"]
expression_str = "self . enum_lattices . entry (enum_name . clone ())"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."entry . end_time = Some (Instant :: now ())"]
expression_str = "entry . end_time = Some (Instant :: now ())"
depth = 3
used_types = []
other_types_count = 0
node_type = "Assign"

[expressions.'File :: create (& mapping_file_path) . await . context ("Failed to create mapping.toml")']
expression_str = 'File :: create (& mapping_file_path) . await . context ("Failed to create mapping.toml")'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'format ! ("  -> Extracted {} use statements.\n" , use_statements . 0 . len ()) . as_bytes ()']
expression_str = 'format ! ("  -> Extracted {} use statements.\n" , use_statements . 0 . len ()) . as_bytes ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."| filter_names | { filter_names . iter () . any (| f | file_path . to_string_lossy () . contains (f)) }"]
expression_str = "| filter_names | { filter_names . iter () . any (| f | file_path . to_string_lossy () . contains (f)) }"
depth = 4
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions.'writer . write_all (format ! ("{:#?}\n" , classified_uses) . as_bytes ()) . await']
expression_str = 'writer . write_all (format ! ("{:#?}\n" , classified_uses) . as_bytes ()) . await'
depth = 3
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."& type_str . as_str ()"]
expression_str = "& type_str . as_str ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."let syn :: Pat :: Path (pat_path) = & * expr_let . pat"]
expression_str = "let syn :: Pat :: Path (pat_path) = & * expr_let . pat"
depth = 5
used_types = []
other_types_count = 0
node_type = "Let"

[expressions."\"================================================================\n\""]
expression_str = """
"================================================================
""""
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."FunctionMetrics :: new"]
expression_str = "FunctionMetrics :: new"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'writer . write_all (format ! ("{:#?}\n" , ast_statistics) . as_bytes ()) . await ?']
expression_str = 'writer . write_all (format ! ("{:#?}\n" , ast_statistics) . as_bytes ()) . await ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."use_statements :: get_required_uses_for_item_const (& constant)"]
expression_str = "use_statements :: get_required_uses_for_item_const (& constant)"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'column_stats . insert ("import" . to_string () , (1 , 1 , 18 , 18))']
expression_str = 'column_stats . insert ("import" . to_string () , (1 , 1 , 18 , 18))'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."modify_file (& file_path , false , false) ?"]
expression_str = "modify_file (& file_path , false , false) ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."current_file_size + line . len () > MAX_FILE_SIZE && current_file_size > 0"]
expression_str = "current_file_size + line . len () > MAX_FILE_SIZE && current_file_size > 0"
depth = 4
used_types = []
other_types_count = 0
node_type = "Binary"

[expressions.'measurement :: record_function_exit ("AstReconstructionFunctor::map")']
expression_str = 'measurement :: record_function_exit ("AstReconstructionFunctor::map")'
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."DefaultHasher :: new"]
expression_str = "DefaultHasher :: new"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'code . push_str ("        // column_stats,\n")']
expression_str = 'code . push_str ("        // column_stats,\n")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.enum_lattice_info]
expression_str = "enum_lattice_info"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'add_std_lib_symbol (& mut symbols , "collections" , "module" , Some ("std"))']
expression_str = 'add_std_lib_symbol (& mut symbols , "collections" , "module" , Some ("std"))'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'"union" . to_string ()']
expression_str = '"union" . to_string ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'format ! ("      -> Wrote expanded code to cache: {}\n" , cached_file_path . display ()) . as_bytes ()']
expression_str = 'format ! ("      -> Wrote expanded code to cache: {}\n" , cached_file_path . display ()) . as_bytes ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.main_rs]
expression_str = "main_rs"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."& args . results_file"]
expression_str = "& args . results_file"
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."{ return Ok (()) ; }"]
expression_str = "{ return Ok (()) ; }"
depth = 4
used_types = []
other_types_count = 0
node_type = "Block"

[expressions.declarations]
expression_str = "declarations"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."Box :: pin (async move { measurement :: record_function_entry (\"HuggingFaceValidatorFunctor::map\") ; let ParsedFile (source_code , original_file_path) = input ; use std :: hash :: { Hash , Hasher } ; use std :: collections :: hash_map :: DefaultHasher ; let mut hasher = DefaultHasher :: new () ; original_file_path . hash (& mut hasher) ; let short_id = format ! (\"{:x}\" , hasher . finish ()) ; writer . write_all (format ! (\"  -> Short ID for hf-validator project: {}\\n\" , short_id) . as_bytes ()) . await ? ; let hf_validator_project_dir = PathBuf :: from (format ! (\"generated/hf_validator_projects/{}\" , short_id)) ; tokio :: fs :: create_dir_all (& hf_validator_project_dir) . await ? ; let source_file_path = hf_validator_project_dir . join (\"main.rs\") ; tokio :: fs :: write (& source_file_path , source_code . as_bytes ()) . await . context (\"Failed to write source code to persistent file\") ? ; let cargo_toml_content = indoc ! { r#\"[package]\n                name = \"temp_hf_project\"\n                version = \"0.1.0\"\n                edition = \"2021\"\n\n                [[bin]]\n                name = \"temp_hf_project\"\n                path = \"main.rs\"\n\n                [dependencies]\n                anyhow = \"1.0\"\n                tokio = { version = \"1\", features = [\"full\"] }\n\n                [workspace]\n                \"# } ; tokio :: fs :: write (hf_validator_project_dir . join (\"Cargo.toml\") , cargo_toml_content) . await ? ; let output = tokio :: process :: Command :: new (\"git\") . arg (\"init\") . current_dir (& hf_validator_project_dir) . output () . await . context (\"Failed to initialize git repository\") ? ; if ! output . status . success () { return Err (anyhow :: anyhow ! (\"git init failed: {}\" , String :: from_utf8_lossy (& output . stderr))) ; } let output = tokio :: process :: Command :: new (\"git\") . arg (\"config\") . arg (\"user.email\") . arg (\"test@example.com\") . current_dir (& hf_validator_project_dir) . output () . await . context (\"Failed to configure git user email\") ? ; if ! output . status . success () { return Err (anyhow :: anyhow ! (\"git config user.email failed: {}\\nStderr: {}\" , String :: from_utf8_lossy (& output . status . code () . unwrap_or (- 1) . to_string () . as_bytes ()) , String :: from_utf8_lossy (& output . stderr))) ; } let output = tokio :: process :: Command :: new (\"git\") . arg (\"config\") . arg (\"user.name\") . arg (\"Test User\") . current_dir (& hf_validator_project_dir) . output () . await . context (\"Failed to configure git user name\") ? ; if ! output . status . success () { return Err (anyhow :: anyhow ! (\"git config user.name failed: {}\\nStderr: {}\" , String :: from_utf8_lossy (& output . status . code () . unwrap_or (- 1) . to_string () . as_bytes ()) , String :: from_utf8_lossy (& output . stderr))) ; } let output = tokio :: process :: Command :: new (\"git\") . arg (\"commit\") . arg (\"--allow-empty\") . arg (\"-m\") . arg (\"Initial empty commit\") . current_dir (& hf_validator_project_dir) . output () . await . context (\"Failed to make initial empty git commit\") ? ; if ! output . status . success () { return Err (anyhow :: anyhow ! (\"git commit --allow-empty failed: {}\\nStderr: {}\" , String :: from_utf8_lossy (& output . status . code () . unwrap_or (- 1) . to_string () . as_bytes ()) , String :: from_utf8_lossy (& output . stderr))) ; } let temp_output_dir = tempdir () . context (\"Failed to create temporary output directory\") ? ; let output_path = temp_output_dir . path () . to_path_buf () ; let hf_validator_executable = self . hf_validator_path . clone () . unwrap_or_else (| | { PathBuf :: from (& self . args . path) . join (\"target/release/hf-validator\") }) ; writer . write_all (format ! (\"  -> Executing hf-validator: {:#?}\\n\" , hf_validator_executable) . as_bytes ()) . await ? ; if let Some (path_env) = std :: env :: var_os (\"PATH\") { writer . write_all (format ! (\"  -> PATH: {:#?}\\n\" , path_env) . as_bytes ()) . await ? ; } if let Some (ld_library_path_env) = std :: env :: var_os (\"LD_LIBRARY_PATH\") { writer . write_all (format ! (\"  -> LD_LIBRARY_PATH: {:#?}\\n\" , ld_library_path_env) . as_bytes ()) . await ? ; } let status = tokio :: process :: Command :: new (hf_validator_executable . to_str () . unwrap ()) . current_dir (& self . args . path) . envs (std :: env :: vars_os ()) . arg (\"analyze-rust-to-ir\") . arg (hf_validator_project_dir . as_os_str ()) . arg (output_path . as_os_str ()) . status () . await . context (\"Failed to execute hf-validator command\") ? ; if ! status . success () { return Err (anyhow :: anyhow ! (\"hf-validator command failed with status: {}\" , status)) ; } writer . write_all (format ! (\"  -> Hugging Face Validation Result: Dataset generated at {:#?}\\n\" , output_path) . as_bytes ()) . await ? ; let permanent_output_dir = PathBuf :: from (format ! (\"generated/hf_dataset_output/{}\" , short_id)) ; tokio :: fs :: create_dir_all (& permanent_output_dir) . await ? ; use serde :: { Deserialize , Serialize } ; use std :: collections :: HashMap ; use tokio :: fs :: File ; use tokio :: io :: { AsyncReadExt , AsyncWriteExt } ; # [derive (Debug , Default , Deserialize , Serialize)] struct Mapping { # [serde (flatten)] files : HashMap < String , String > , } let mapping_file_path = PathBuf :: from (\"generated/hf_dataset_output/mapping.toml\") ; let mut mapping = if mapping_file_path . exists () { let mut file = File :: open (& mapping_file_path) . await . context (\"Failed to open mapping.toml\") ? ; let mut contents = String :: new () ; file . read_to_string (& mut contents) . await . context (\"Failed to read mapping.toml\") ? ; toml :: from_str (& contents) . context (\"Failed to parse mapping.toml\") ? } else { Mapping :: default () } ; mapping . files . insert (original_file_path . to_string_lossy () . to_string () , short_id . clone ()) ; let toml_string = toml :: to_string_pretty (& mapping) . context (\"Failed to serialize mapping to TOML\") ? ; let mut file = File :: create (& mapping_file_path) . await . context (\"Failed to create mapping.toml\") ? ; file . write_all (toml_string . as_bytes ()) . await . context (\"Failed to write mapping.toml\") ? ; let mut entries = tokio :: fs :: read_dir (& output_path) . await ? ; while let Some (entry) = entries . next_entry () . await ? { let entry_path = entry . path () ; let destination_path = permanent_output_dir . join (entry_path . file_name () . unwrap ()) ; if entry_path . is_dir () { copy_dir_all (& entry_path , & destination_path) . await ? ; } else { tokio :: fs :: copy (& entry_path , & destination_path) . await ? ; } } let __result = Ok (ValidatedFile (source_code , permanent_output_dir)) ; measurement :: record_function_exit (\"HuggingFaceValidatorFunctor::map\") ; __result })"]
expression_str = '''
Box :: pin (async move { measurement :: record_function_entry ("HuggingFaceValidatorFunctor::map") ; let ParsedFile (source_code , original_file_path) = input ; use std :: hash :: { Hash , Hasher } ; use std :: collections :: hash_map :: DefaultHasher ; let mut hasher = DefaultHasher :: new () ; original_file_path . hash (& mut hasher) ; let short_id = format ! ("{:x}" , hasher . finish ()) ; writer . write_all (format ! ("  -> Short ID for hf-validator project: {}\n" , short_id) . as_bytes ()) . await ? ; let hf_validator_project_dir = PathBuf :: from (format ! ("generated/hf_validator_projects/{}" , short_id)) ; tokio :: fs :: create_dir_all (& hf_validator_project_dir) . await ? ; let source_file_path = hf_validator_project_dir . join ("main.rs") ; tokio :: fs :: write (& source_file_path , source_code . as_bytes ()) . await . context ("Failed to write source code to persistent file") ? ; let cargo_toml_content = indoc ! { r#"[package]
                name = "temp_hf_project"
                version = "0.1.0"
                edition = "2021"

                [[bin]]
                name = "temp_hf_project"
                path = "main.rs"

                [dependencies]
                anyhow = "1.0"
                tokio = { version = "1", features = ["full"] }

                [workspace]
                "# } ; tokio :: fs :: write (hf_validator_project_dir . join ("Cargo.toml") , cargo_toml_content) . await ? ; let output = tokio :: process :: Command :: new ("git") . arg ("init") . current_dir (& hf_validator_project_dir) . output () . await . context ("Failed to initialize git repository") ? ; if ! output . status . success () { return Err (anyhow :: anyhow ! ("git init failed: {}" , String :: from_utf8_lossy (& output . stderr))) ; } let output = tokio :: process :: Command :: new ("git") . arg ("config") . arg ("user.email") . arg ("test@example.com") . current_dir (& hf_validator_project_dir) . output () . await . context ("Failed to configure git user email") ? ; if ! output . status . success () { return Err (anyhow :: anyhow ! ("git config user.email failed: {}\nStderr: {}" , String :: from_utf8_lossy (& output . status . code () . unwrap_or (- 1) . to_string () . as_bytes ()) , String :: from_utf8_lossy (& output . stderr))) ; } let output = tokio :: process :: Command :: new ("git") . arg ("config") . arg ("user.name") . arg ("Test User") . current_dir (& hf_validator_project_dir) . output () . await . context ("Failed to configure git user name") ? ; if ! output . status . success () { return Err (anyhow :: anyhow ! ("git config user.name failed: {}\nStderr: {}" , String :: from_utf8_lossy (& output . status . code () . unwrap_or (- 1) . to_string () . as_bytes ()) , String :: from_utf8_lossy (& output . stderr))) ; } let output = tokio :: process :: Command :: new ("git") . arg ("commit") . arg ("--allow-empty") . arg ("-m") . arg ("Initial empty commit") . current_dir (& hf_validator_project_dir) . output () . await . context ("Failed to make initial empty git commit") ? ; if ! output . status . success () { return Err (anyhow :: anyhow ! ("git commit --allow-empty failed: {}\nStderr: {}" , String :: from_utf8_lossy (& output . status . code () . unwrap_or (- 1) . to_string () . as_bytes ()) , String :: from_utf8_lossy (& output . stderr))) ; } let temp_output_dir = tempdir () . context ("Failed to create temporary output directory") ? ; let output_path = temp_output_dir . path () . to_path_buf () ; let hf_validator_executable = self . hf_validator_path . clone () . unwrap_or_else (| | { PathBuf :: from (& self . args . path) . join ("target/release/hf-validator") }) ; writer . write_all (format ! ("  -> Executing hf-validator: {:#?}\n" , hf_validator_executable) . as_bytes ()) . await ? ; if let Some (path_env) = std :: env :: var_os ("PATH") { writer . write_all (format ! ("  -> PATH: {:#?}\n" , path_env) . as_bytes ()) . await ? ; } if let Some (ld_library_path_env) = std :: env :: var_os ("LD_LIBRARY_PATH") { writer . write_all (format ! ("  -> LD_LIBRARY_PATH: {:#?}\n" , ld_library_path_env) . as_bytes ()) . await ? ; } let status = tokio :: process :: Command :: new (hf_validator_executable . to_str () . unwrap ()) . current_dir (& self . args . path) . envs (std :: env :: vars_os ()) . arg ("analyze-rust-to-ir") . arg (hf_validator_project_dir . as_os_str ()) . arg (output_path . as_os_str ()) . status () . await . context ("Failed to execute hf-validator command") ? ; if ! status . success () { return Err (anyhow :: anyhow ! ("hf-validator command failed with status: {}" , status)) ; } writer . write_all (format ! ("  -> Hugging Face Validation Result: Dataset generated at {:#?}\n" , output_path) . as_bytes ()) . await ? ; let permanent_output_dir = PathBuf :: from (format ! ("generated/hf_dataset_output/{}" , short_id)) ; tokio :: fs :: create_dir_all (& permanent_output_dir) . await ? ; use serde :: { Deserialize , Serialize } ; use std :: collections :: HashMap ; use tokio :: fs :: File ; use tokio :: io :: { AsyncReadExt , AsyncWriteExt } ; # [derive (Debug , Default , Deserialize , Serialize)] struct Mapping { # [serde (flatten)] files : HashMap < String , String > , } let mapping_file_path = PathBuf :: from ("generated/hf_dataset_output/mapping.toml") ; let mut mapping = if mapping_file_path . exists () { let mut file = File :: open (& mapping_file_path) . await . context ("Failed to open mapping.toml") ? ; let mut contents = String :: new () ; file . read_to_string (& mut contents) . await . context ("Failed to read mapping.toml") ? ; toml :: from_str (& contents) . context ("Failed to parse mapping.toml") ? } else { Mapping :: default () } ; mapping . files . insert (original_file_path . to_string_lossy () . to_string () , short_id . clone ()) ; let toml_string = toml :: to_string_pretty (& mapping) . context ("Failed to serialize mapping to TOML") ? ; let mut file = File :: create (& mapping_file_path) . await . context ("Failed to create mapping.toml") ? ; file . write_all (toml_string . as_bytes ()) . await . context ("Failed to write mapping.toml") ? ; let mut entries = tokio :: fs :: read_dir (& output_path) . await ? ; while let Some (entry) = entries . next_entry () . await ? { let entry_path = entry . path () ; let destination_path = permanent_output_dir . join (entry_path . file_name () . unwrap ()) ; if entry_path . is_dir () { copy_dir_all (& entry_path , & destination_path) . await ? ; } else { tokio :: fs :: copy (& entry_path , & destination_path) . await ? ; } } let __result = Ok (ValidatedFile (source_code , permanent_output_dir)) ; measurement :: record_function_exit ("HuggingFaceValidatorFunctor::map") ; __result })'''
depth = 2
used_types = ["HashMap"]
other_types_count = 1
node_type = "Call"

[expressions."self . add_dependency (& segment . ident)"]
expression_str = "self . add_dependency (& segment . ident)"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."grouped_by_node_type . keys () . cloned () . collect ()"]
expression_str = "grouped_by_node_type . keys () . cloned () . collect ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."if let Some (impl_for_type_name) = impl_for_type { let impl_lattice_info = self . impl_lattices . entry (impl_for_type_name . clone ()) . or_insert_with (| | ImplLatticeInfo :: new (impl_for_type_name . clone ())) ; let mut sub_visitor = ImplMethodCoOccurrenceVisitor { _impl_for_type : & impl_for_type_name , current_method_calls : BTreeSet :: new () , impl_lattice_info , } ; sub_visitor . visit_item_impl (i) ; if let Some (struct_lattice_info) = self . struct_lattices . get_mut (& impl_for_type_name) { let mut sub_visitor = StructFieldCoOccurrenceVisitor { _struct_name : & impl_for_type_name , current_field_accesses : BTreeSet :: new () , struct_lattice_info , } ; sub_visitor . visit_item_impl (i) ; } }"]
expression_str = "if let Some (impl_for_type_name) = impl_for_type { let impl_lattice_info = self . impl_lattices . entry (impl_for_type_name . clone ()) . or_insert_with (| | ImplLatticeInfo :: new (impl_for_type_name . clone ())) ; let mut sub_visitor = ImplMethodCoOccurrenceVisitor { _impl_for_type : & impl_for_type_name , current_method_calls : BTreeSet :: new () , impl_lattice_info , } ; sub_visitor . visit_item_impl (i) ; if let Some (struct_lattice_info) = self . struct_lattices . get_mut (& impl_for_type_name) { let mut sub_visitor = StructFieldCoOccurrenceVisitor { _struct_name : & impl_for_type_name , current_field_accesses : BTreeSet :: new () , struct_lattice_info , } ; sub_visitor . visit_item_impl (i) ; } }"
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions."args . generated_decls_output_dir"]
expression_str = "args . generated_decls_output_dir"
depth = 5
used_types = []
other_types_count = 0
node_type = "Field"

[expressions."tempfile :: tempdir ()"]
expression_str = "tempfile :: tempdir ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'"If" . to_string ()']
expression_str = '"If" . to_string ()'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."| c | { let tokens = quote ! { # c } ; tokens . to_string () }"]
expression_str = "| c | { let tokens = quote ! { # c } ; tokens . to_string () }"
depth = 4
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions."ValidatedFile (source_code , permanent_output_dir)"]
expression_str = "ValidatedFile (source_code , permanent_output_dir)"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."syn :: visit :: visit_type"]
expression_str = "syn :: visit :: visit_type"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."r#\"\n            #[test]\n            fn integration_test() { }\n        \"#"]
expression_str = """
r#"
            #[test]
            fn integration_test() { }
        "#"""
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'if let Some (file_name) = args . file . as_ref () { Path :: new (file_name) } else { return Err (anyhow :: anyhow ! ("No file specified to process. Use --file argument.") ,) ; }']
expression_str = 'if let Some (file_name) = args . file . as_ref () { Path :: new (file_name) } else { return Err (anyhow :: anyhow ! ("No file specified to process. Use --file argument.") ,) ; }'
depth = 3
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'code . push_str ("        line_stats,\n")']
expression_str = 'code . push_str ("        line_stats,\n")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'args . path == PathBuf :: from (".")']
expression_str = 'args . path == PathBuf :: from (".")'
depth = 3
used_types = []
other_types_count = 0
node_type = "Binary"

[expressions."fs :: read_to_string (& lib_rs_path)"]
expression_str = "fs :: read_to_string (& lib_rs_path)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."all_collected_errors . extend (errors)"]
expression_str = "all_collected_errors . extend (errors)"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"\n"']
expression_str = '"\n"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'match syn :: parse_file (& content) { Ok (f) => f , Err (e) => { eprintln ! ("Warning: Could not parse file {}: {:?}" , path . display () , e) ; continue ; } }']
expression_str = 'match syn :: parse_file (& content) { Ok (f) => f , Err (e) => { eprintln ! ("Warning: Could not parse file {}: {:?}" , path . display () , e) ; continue ; } }'
depth = 3
used_types = []
other_types_count = 0
node_type = "Match"

[expressions.'"Range"']
expression_str = '"Range"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'"Index" . to_string ()']
expression_str = '"Index" . to_string ()'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"Failed to analyze ASTs from Hugging Face dataset"']
expression_str = '"Failed to analyze ASTs from Hugging Face dataset"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.report_content]
expression_str = "report_content"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."std :: env :: current_dir () ? . parent ()"]
expression_str = "std :: env :: current_dir () ? . parent ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."fs :: write (& file_path , r#\"\n            #[test]\n            fn my_test_1() { assert_eq!(1, 1); }\n\n            fn not_a_test() { }\n\n            #[cfg(test)]\n            mod my_tests {\n                #[test]\n                fn nested_test() { assert_eq!(2, 2); }\n            }\n\n            #[test]\n            async fn my_test_2() -> Result<()> { Ok(()) }\n        \"# ,) ?"]
expression_str = """
fs :: write (& file_path , r#"
            #[test]
            fn my_test_1() { assert_eq!(1, 1); }

            fn not_a_test() { }

            #[cfg(test)]
            mod my_tests {
                #[test]
                fn nested_test() { assert_eq!(2, 2); }
            }

            #[test]
            async fn my_test_2() -> Result<()> { Ok(()) }
        "# ,) ?"""
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'project_root . join ("config.toml")']
expression_str = 'project_root . join ("config.toml")'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."match & expr_lit . lit { Lit :: Int (lit_int) => lit_int . base10_digits () . to_string () , Lit :: Float (lit_float) => lit_float . base10_digits () . to_string () , _ => String :: new () , }"]
expression_str = "match & expr_lit . lit { Lit :: Int (lit_int) => lit_int . base10_digits () . to_string () , Lit :: Float (lit_float) => lit_float . base10_digits () . to_string () , _ => String :: new () , }"
depth = 3
used_types = []
other_types_count = 0
node_type = "Match"

[expressions."if let Some (segment) = pat_path . path . segments . last () { matched_variant_types . insert (segment . ident . to_string ()) ; }"]
expression_str = "if let Some (segment) = pat_path . path . segments . last () { matched_variant_types . insert (segment . ident . to_string ()) ; }"
depth = 5
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'processing_time_stats . insert ("other" . to_string () , (1 , 1 , 230 , 230))']
expression_str = 'processing_time_stats . insert ("other" . to_string () , (1 , 1 , 230 , 230))'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."args . output_symbol_map"]
expression_str = "args . output_symbol_map"
depth = 3
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'stdout . lines () . find (| line | line . starts_with ("rustc "))']
expression_str = 'stdout . lines () . find (| line | line . starts_with ("rustc "))'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'format ! ("expanded_{}_{}_{}_{}_{}" , content_hash , rustc_info . version , rustc_info . host , "cargo_expand" , "2021")']
expression_str = 'format ! ("expanded_{}_{}_{}_{}_{}" , content_hash , rustc_info . version , rustc_info . host , "cargo_expand" , "2021")'
depth = 2
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions."let Some (parent) = cargo_toml_path . parent ()"]
expression_str = "let Some (parent) = cargo_toml_path . parent ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "Let"

[expressions."tests_by_crate . get (crate_path) . unwrap ()"]
expression_str = "tests_by_crate . get (crate_path) . unwrap ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'! ident_str . is_empty () && ! matches ! (ident_str . as_str () , "bool" | "u8" | "u16" | "u32" | "u64" | "u128" | "i8" | "i16" | "i32" | "i64" | "i128" | "f32" | "f64" | "char" | "str" | "usize" | "isize")']
expression_str = '! ident_str . is_empty () && ! matches ! (ident_str . as_str () , "bool" | "u8" | "u16" | "u32" | "u64" | "u128" | "i8" | "i16" | "i32" | "i64" | "i128" | "f32" | "f64" | "char" | "str" | "usize" | "isize")'
depth = 3
used_types = []
other_types_count = 0
node_type = "Binary"

[expressions."& original_dir"]
expression_str = "& original_dir"
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'tokio :: process :: Command :: new ("cargo") . arg ("rustc") . arg ("--manifest-path") . arg (& temp_cargo_toml_path) . arg ("--lib") . arg ("--") . arg ("-Zunpretty=expanded") . output ()']
expression_str = 'tokio :: process :: Command :: new ("cargo") . arg ("rustc") . arg ("--manifest-path") . arg (& temp_cargo_toml_path) . arg ("--lib") . arg ("--") . arg ("-Zunpretty=expanded") . output ()'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'tokio :: process :: Command :: new ("cargo") . arg ("rustc") . arg ("--manifest-path") . arg (& temp_cargo_toml_path) . arg ("--lib") . arg ("--") . arg ("-Zunpretty=expanded") . output () . await ?']
expression_str = 'tokio :: process :: Command :: new ("cargo") . arg ("rustc") . arg ("--manifest-path") . arg (& temp_cargo_toml_path) . arg ("--lib") . arg ("--") . arg ("-Zunpretty=expanded") . output () . await ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.contains_complex_fields]
expression_str = "contains_complex_fields"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.excluded_crates]
expression_str = "excluded_crates"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."parsed_file . 1 . clone ()"]
expression_str = "parsed_file . 1 . clone ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"// No struct declarations found in this module.\n"']
expression_str = '"// No struct declarations found in this module.\n"'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'{ eprintln ! (r"Warning: Could not read file for bag of words analysis: {}" , path . display ()) ; }']
expression_str = '{ eprintln ! (r"Warning: Could not read file for bag of words analysis: {}" , path . display ()) ; }'
depth = 4
used_types = []
other_types_count = 0
node_type = "Block"

[expressions."error_collection . errors . is_empty ()"]
expression_str = "error_collection . errors . is_empty ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'Box :: pin (async move { writer . write_all (format ! ("--- Inspecting: {} ---\n" , self . label) . as_bytes ()) . await ? ; writer . write_all (format ! ("{:#?}\n" , input) . as_bytes ()) . await ? ; Ok (input) })']
expression_str = 'Box :: pin (async move { writer . write_all (format ! ("--- Inspecting: {} ---\n" , self . label) . as_bytes ()) . await ? ; writer . write_all (format ! ("{:#?}\n" , input) . as_bytes ()) . await ? ; Ok (input) })'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."async move { measurement :: record_function_entry (\"HuggingFaceValidatorFunctor::map\") ; let ParsedFile (source_code , original_file_path) = input ; use std :: hash :: { Hash , Hasher } ; use std :: collections :: hash_map :: DefaultHasher ; let mut hasher = DefaultHasher :: new () ; original_file_path . hash (& mut hasher) ; let short_id = format ! (\"{:x}\" , hasher . finish ()) ; writer . write_all (format ! (\"  -> Short ID for hf-validator project: {}\\n\" , short_id) . as_bytes ()) . await ? ; let hf_validator_project_dir = PathBuf :: from (format ! (\"generated/hf_validator_projects/{}\" , short_id)) ; tokio :: fs :: create_dir_all (& hf_validator_project_dir) . await ? ; let source_file_path = hf_validator_project_dir . join (\"main.rs\") ; tokio :: fs :: write (& source_file_path , source_code . as_bytes ()) . await . context (\"Failed to write source code to persistent file\") ? ; let cargo_toml_content = indoc ! { r#\"[package]\n                name = \"temp_hf_project\"\n                version = \"0.1.0\"\n                edition = \"2021\"\n\n                [[bin]]\n                name = \"temp_hf_project\"\n                path = \"main.rs\"\n\n                [dependencies]\n                anyhow = \"1.0\"\n                tokio = { version = \"1\", features = [\"full\"] }\n\n                [workspace]\n                \"# } ; tokio :: fs :: write (hf_validator_project_dir . join (\"Cargo.toml\") , cargo_toml_content) . await ? ; let output = tokio :: process :: Command :: new (\"git\") . arg (\"init\") . current_dir (& hf_validator_project_dir) . output () . await . context (\"Failed to initialize git repository\") ? ; if ! output . status . success () { return Err (anyhow :: anyhow ! (\"git init failed: {}\" , String :: from_utf8_lossy (& output . stderr))) ; } let output = tokio :: process :: Command :: new (\"git\") . arg (\"config\") . arg (\"user.email\") . arg (\"test@example.com\") . current_dir (& hf_validator_project_dir) . output () . await . context (\"Failed to configure git user email\") ? ; if ! output . status . success () { return Err (anyhow :: anyhow ! (\"git config user.email failed: {}\\nStderr: {}\" , String :: from_utf8_lossy (& output . status . code () . unwrap_or (- 1) . to_string () . as_bytes ()) , String :: from_utf8_lossy (& output . stderr))) ; } let output = tokio :: process :: Command :: new (\"git\") . arg (\"config\") . arg (\"user.name\") . arg (\"Test User\") . current_dir (& hf_validator_project_dir) . output () . await . context (\"Failed to configure git user name\") ? ; if ! output . status . success () { return Err (anyhow :: anyhow ! (\"git config user.name failed: {}\\nStderr: {}\" , String :: from_utf8_lossy (& output . status . code () . unwrap_or (- 1) . to_string () . as_bytes ()) , String :: from_utf8_lossy (& output . stderr))) ; } let output = tokio :: process :: Command :: new (\"git\") . arg (\"commit\") . arg (\"--allow-empty\") . arg (\"-m\") . arg (\"Initial empty commit\") . current_dir (& hf_validator_project_dir) . output () . await . context (\"Failed to make initial empty git commit\") ? ; if ! output . status . success () { return Err (anyhow :: anyhow ! (\"git commit --allow-empty failed: {}\\nStderr: {}\" , String :: from_utf8_lossy (& output . status . code () . unwrap_or (- 1) . to_string () . as_bytes ()) , String :: from_utf8_lossy (& output . stderr))) ; } let temp_output_dir = tempdir () . context (\"Failed to create temporary output directory\") ? ; let output_path = temp_output_dir . path () . to_path_buf () ; let hf_validator_executable = self . hf_validator_path . clone () . unwrap_or_else (| | { PathBuf :: from (& self . args . path) . join (\"target/release/hf-validator\") }) ; writer . write_all (format ! (\"  -> Executing hf-validator: {:#?}\\n\" , hf_validator_executable) . as_bytes ()) . await ? ; if let Some (path_env) = std :: env :: var_os (\"PATH\") { writer . write_all (format ! (\"  -> PATH: {:#?}\\n\" , path_env) . as_bytes ()) . await ? ; } if let Some (ld_library_path_env) = std :: env :: var_os (\"LD_LIBRARY_PATH\") { writer . write_all (format ! (\"  -> LD_LIBRARY_PATH: {:#?}\\n\" , ld_library_path_env) . as_bytes ()) . await ? ; } let status = tokio :: process :: Command :: new (hf_validator_executable . to_str () . unwrap ()) . current_dir (& self . args . path) . envs (std :: env :: vars_os ()) . arg (\"analyze-rust-to-ir\") . arg (hf_validator_project_dir . as_os_str ()) . arg (output_path . as_os_str ()) . status () . await . context (\"Failed to execute hf-validator command\") ? ; if ! status . success () { return Err (anyhow :: anyhow ! (\"hf-validator command failed with status: {}\" , status)) ; } writer . write_all (format ! (\"  -> Hugging Face Validation Result: Dataset generated at {:#?}\\n\" , output_path) . as_bytes ()) . await ? ; let permanent_output_dir = PathBuf :: from (format ! (\"generated/hf_dataset_output/{}\" , short_id)) ; tokio :: fs :: create_dir_all (& permanent_output_dir) . await ? ; use serde :: { Deserialize , Serialize } ; use std :: collections :: HashMap ; use tokio :: fs :: File ; use tokio :: io :: { AsyncReadExt , AsyncWriteExt } ; # [derive (Debug , Default , Deserialize , Serialize)] struct Mapping { # [serde (flatten)] files : HashMap < String , String > , } let mapping_file_path = PathBuf :: from (\"generated/hf_dataset_output/mapping.toml\") ; let mut mapping = if mapping_file_path . exists () { let mut file = File :: open (& mapping_file_path) . await . context (\"Failed to open mapping.toml\") ? ; let mut contents = String :: new () ; file . read_to_string (& mut contents) . await . context (\"Failed to read mapping.toml\") ? ; toml :: from_str (& contents) . context (\"Failed to parse mapping.toml\") ? } else { Mapping :: default () } ; mapping . files . insert (original_file_path . to_string_lossy () . to_string () , short_id . clone ()) ; let toml_string = toml :: to_string_pretty (& mapping) . context (\"Failed to serialize mapping to TOML\") ? ; let mut file = File :: create (& mapping_file_path) . await . context (\"Failed to create mapping.toml\") ? ; file . write_all (toml_string . as_bytes ()) . await . context (\"Failed to write mapping.toml\") ? ; let mut entries = tokio :: fs :: read_dir (& output_path) . await ? ; while let Some (entry) = entries . next_entry () . await ? { let entry_path = entry . path () ; let destination_path = permanent_output_dir . join (entry_path . file_name () . unwrap ()) ; if entry_path . is_dir () { copy_dir_all (& entry_path , & destination_path) . await ? ; } else { tokio :: fs :: copy (& entry_path , & destination_path) . await ? ; } } let __result = Ok (ValidatedFile (source_code , permanent_output_dir)) ; measurement :: record_function_exit (\"HuggingFaceValidatorFunctor::map\") ; __result }"]
expression_str = '''
async move { measurement :: record_function_entry ("HuggingFaceValidatorFunctor::map") ; let ParsedFile (source_code , original_file_path) = input ; use std :: hash :: { Hash , Hasher } ; use std :: collections :: hash_map :: DefaultHasher ; let mut hasher = DefaultHasher :: new () ; original_file_path . hash (& mut hasher) ; let short_id = format ! ("{:x}" , hasher . finish ()) ; writer . write_all (format ! ("  -> Short ID for hf-validator project: {}\n" , short_id) . as_bytes ()) . await ? ; let hf_validator_project_dir = PathBuf :: from (format ! ("generated/hf_validator_projects/{}" , short_id)) ; tokio :: fs :: create_dir_all (& hf_validator_project_dir) . await ? ; let source_file_path = hf_validator_project_dir . join ("main.rs") ; tokio :: fs :: write (& source_file_path , source_code . as_bytes ()) . await . context ("Failed to write source code to persistent file") ? ; let cargo_toml_content = indoc ! { r#"[package]
                name = "temp_hf_project"
                version = "0.1.0"
                edition = "2021"

                [[bin]]
                name = "temp_hf_project"
                path = "main.rs"

                [dependencies]
                anyhow = "1.0"
                tokio = { version = "1", features = ["full"] }

                [workspace]
                "# } ; tokio :: fs :: write (hf_validator_project_dir . join ("Cargo.toml") , cargo_toml_content) . await ? ; let output = tokio :: process :: Command :: new ("git") . arg ("init") . current_dir (& hf_validator_project_dir) . output () . await . context ("Failed to initialize git repository") ? ; if ! output . status . success () { return Err (anyhow :: anyhow ! ("git init failed: {}" , String :: from_utf8_lossy (& output . stderr))) ; } let output = tokio :: process :: Command :: new ("git") . arg ("config") . arg ("user.email") . arg ("test@example.com") . current_dir (& hf_validator_project_dir) . output () . await . context ("Failed to configure git user email") ? ; if ! output . status . success () { return Err (anyhow :: anyhow ! ("git config user.email failed: {}\nStderr: {}" , String :: from_utf8_lossy (& output . status . code () . unwrap_or (- 1) . to_string () . as_bytes ()) , String :: from_utf8_lossy (& output . stderr))) ; } let output = tokio :: process :: Command :: new ("git") . arg ("config") . arg ("user.name") . arg ("Test User") . current_dir (& hf_validator_project_dir) . output () . await . context ("Failed to configure git user name") ? ; if ! output . status . success () { return Err (anyhow :: anyhow ! ("git config user.name failed: {}\nStderr: {}" , String :: from_utf8_lossy (& output . status . code () . unwrap_or (- 1) . to_string () . as_bytes ()) , String :: from_utf8_lossy (& output . stderr))) ; } let output = tokio :: process :: Command :: new ("git") . arg ("commit") . arg ("--allow-empty") . arg ("-m") . arg ("Initial empty commit") . current_dir (& hf_validator_project_dir) . output () . await . context ("Failed to make initial empty git commit") ? ; if ! output . status . success () { return Err (anyhow :: anyhow ! ("git commit --allow-empty failed: {}\nStderr: {}" , String :: from_utf8_lossy (& output . status . code () . unwrap_or (- 1) . to_string () . as_bytes ()) , String :: from_utf8_lossy (& output . stderr))) ; } let temp_output_dir = tempdir () . context ("Failed to create temporary output directory") ? ; let output_path = temp_output_dir . path () . to_path_buf () ; let hf_validator_executable = self . hf_validator_path . clone () . unwrap_or_else (| | { PathBuf :: from (& self . args . path) . join ("target/release/hf-validator") }) ; writer . write_all (format ! ("  -> Executing hf-validator: {:#?}\n" , hf_validator_executable) . as_bytes ()) . await ? ; if let Some (path_env) = std :: env :: var_os ("PATH") { writer . write_all (format ! ("  -> PATH: {:#?}\n" , path_env) . as_bytes ()) . await ? ; } if let Some (ld_library_path_env) = std :: env :: var_os ("LD_LIBRARY_PATH") { writer . write_all (format ! ("  -> LD_LIBRARY_PATH: {:#?}\n" , ld_library_path_env) . as_bytes ()) . await ? ; } let status = tokio :: process :: Command :: new (hf_validator_executable . to_str () . unwrap ()) . current_dir (& self . args . path) . envs (std :: env :: vars_os ()) . arg ("analyze-rust-to-ir") . arg (hf_validator_project_dir . as_os_str ()) . arg (output_path . as_os_str ()) . status () . await . context ("Failed to execute hf-validator command") ? ; if ! status . success () { return Err (anyhow :: anyhow ! ("hf-validator command failed with status: {}" , status)) ; } writer . write_all (format ! ("  -> Hugging Face Validation Result: Dataset generated at {:#?}\n" , output_path) . as_bytes ()) . await ? ; let permanent_output_dir = PathBuf :: from (format ! ("generated/hf_dataset_output/{}" , short_id)) ; tokio :: fs :: create_dir_all (& permanent_output_dir) . await ? ; use serde :: { Deserialize , Serialize } ; use std :: collections :: HashMap ; use tokio :: fs :: File ; use tokio :: io :: { AsyncReadExt , AsyncWriteExt } ; # [derive (Debug , Default , Deserialize , Serialize)] struct Mapping { # [serde (flatten)] files : HashMap < String , String > , } let mapping_file_path = PathBuf :: from ("generated/hf_dataset_output/mapping.toml") ; let mut mapping = if mapping_file_path . exists () { let mut file = File :: open (& mapping_file_path) . await . context ("Failed to open mapping.toml") ? ; let mut contents = String :: new () ; file . read_to_string (& mut contents) . await . context ("Failed to read mapping.toml") ? ; toml :: from_str (& contents) . context ("Failed to parse mapping.toml") ? } else { Mapping :: default () } ; mapping . files . insert (original_file_path . to_string_lossy () . to_string () , short_id . clone ()) ; let toml_string = toml :: to_string_pretty (& mapping) . context ("Failed to serialize mapping to TOML") ? ; let mut file = File :: create (& mapping_file_path) . await . context ("Failed to create mapping.toml") ? ; file . write_all (toml_string . as_bytes ()) . await . context ("Failed to write mapping.toml") ? ; let mut entries = tokio :: fs :: read_dir (& output_path) . await ? ; while let Some (entry) = entries . next_entry () . await ? { let entry_path = entry . path () ; let destination_path = permanent_output_dir . join (entry_path . file_name () . unwrap ()) ; if entry_path . is_dir () { copy_dir_all (& entry_path , & destination_path) . await ? ; } else { tokio :: fs :: copy (& entry_path , & destination_path) . await ? ; } } let __result = Ok (ValidatedFile (source_code , permanent_output_dir)) ; measurement :: record_function_exit ("HuggingFaceValidatorFunctor::map") ; __result }'''
depth = 3
used_types = ["HashMap"]
other_types_count = 1
node_type = "Async"

[expressions.'fs :: write (toml_output_path , toml_content) . context (format ! ("Failed to write TOML report to {:?}" , toml_output_path))']
expression_str = 'fs :: write (toml_output_path , toml_content) . context (format ! ("Failed to write TOML report to {:?}" , toml_output_path))'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'writer . write_all (format ! ("  -> Generated code written to {:?}\n" , output_file_path) . as_bytes ()) . await']
expression_str = 'writer . write_all (format ! ("  -> Generated code written to {:?}\n" , output_file_path) . as_bytes ()) . await'
depth = 3
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."files_to_process . is_empty ()"]
expression_str = "files_to_process . is_empty ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'Some ("std::collections")']
expression_str = 'Some ("std::collections")'
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."self . current_method_calls . clear ()"]
expression_str = "self . current_method_calls . clear ()"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'config . as_ref () . and_then (| c | { c . bins . paths . get ("hf_validator") . map (| p | p . to_path_buf ()) })']
expression_str = 'config . as_ref () . and_then (| c | { c . bins . paths . get ("hf_validator") . map (| p | p . to_path_buf ()) })'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."String :: from_utf8_lossy (& output . stdout)"]
expression_str = "String :: from_utf8_lossy (& output . stdout)"
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'Some (project_root . join ("results.json"))']
expression_str = 'Some (project_root . join ("results.json"))'
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'"prelude-collector" . to_string ()']
expression_str = '"prelude-collector" . to_string ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'path . extension () . map_or (false , | ext | ext == "rs")']
expression_str = 'path . extension () . map_or (false , | ext | ext == "rs")'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'if file_path . is_file () && file_path . extension () . map_or (false , | ext | ext == "rs") { println ! ("Processing file for type usage analysis: {}" , file_path . display ()) ; let file_content = fs :: read_to_string (& file_path) . context (format ! ("Failed to read file: {:?}" , file_path)) ? ; let file = match syn :: parse_file (& file_content) { Ok (file) => file , Err (e) => { eprintln ! ("Warning: Could not parse file {}: {}" , file_path . display () , e) ; continue ; } } ; let mut visitor = TypeUsageVisitor :: new (max_expression_depth) ; visitor . visit_file (& file) ; for (expr_str , info) in visitor . expressions { all_expression_info . insert (expr_str , info) ; } all_struct_lattices . extend (visitor . struct_lattices) ; all_enum_lattices . extend (visitor . enum_lattices) ; all_impl_lattices . extend (visitor . impl_lattices) ; }']
expression_str = 'if file_path . is_file () && file_path . extension () . map_or (false , | ext | ext == "rs") { println ! ("Processing file for type usage analysis: {}" , file_path . display ()) ; let file_content = fs :: read_to_string (& file_path) . context (format ! ("Failed to read file: {:?}" , file_path)) ? ; let file = match syn :: parse_file (& file_content) { Ok (file) => file , Err (e) => { eprintln ! ("Warning: Could not parse file {}: {}" , file_path . display () , e) ; continue ; } } ; let mut visitor = TypeUsageVisitor :: new (max_expression_depth) ; visitor . visit_file (& file) ; for (expr_str , info) in visitor . expressions { all_expression_info . insert (expr_str , info) ; } all_struct_lattices . extend (visitor . struct_lattices) ; all_enum_lattices . extend (visitor . enum_lattices) ; all_impl_lattices . extend (visitor . impl_lattices) ; }'
depth = 3
used_types = []
other_types_count = 0
node_type = "If"

[expressions."{ fs :: copy (& entry_path , & destination_path) . await ? ; }"]
expression_str = "{ fs :: copy (& entry_path , & destination_path) . await ? ; }"
depth = 5
used_types = []
other_types_count = 0
node_type = "Block"

[expressions.'| attr | { if attr . path () . is_ident ("derive") { if let syn :: Meta :: List (meta_list) = & attr . meta { meta_list . tokens . to_string () . contains ("Serialize") || meta_list . tokens . to_string () . contains ("Deserialize") } else { false } } else { false } }']
expression_str = '| attr | { if attr . path () . is_ident ("derive") { if let syn :: Meta :: List (meta_list) = & attr . meta { meta_list . tokens . to_string () . contains ("Serialize") || meta_list . tokens . to_string () . contains ("Deserialize") } else { false } } else { false } }'
depth = 4
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions.'"        processing_time_stats,\n"']
expression_str = '"        processing_time_stats,\n"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'{ uses . insert ("use serde::{Serialize, Deserialize};\n") ; }']
expression_str = '{ uses . insert ("use serde::{Serialize, Deserialize};\n") ; }'
depth = 5
used_types = []
other_types_count = 0
node_type = "Block"

[expressions.rustc_version]
expression_str = "rustc_version"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."args . split_expanded_output_global_toml"]
expression_str = "args . split_expanded_output_global_toml"
depth = 3
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'"type_alias" . to_string ()']
expression_str = '"type_alias" . to_string ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"Result"']
expression_str = '"Result"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."collector . visit_item (item)"]
expression_str = "collector . visit_item (item)"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"String"']
expression_str = '"String"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'format ! ("rustc macro expansion failed: {}\nStdout: {}\nStderr: {}" , String :: from_utf8_lossy (& output . stderr) , String :: from_utf8_lossy (& output . stdout) , String :: from_utf8_lossy (& output . stderr))']
expression_str = 'format ! ("rustc macro expansion failed: {}\nStdout: {}\nStderr: {}" , String :: from_utf8_lossy (& output . stderr) , String :: from_utf8_lossy (& output . stdout) , String :: from_utf8_lossy (& output . stderr))'
depth = 3
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions."! matched_variant_types . is_empty ()"]
expression_str = "! matched_variant_types . is_empty ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "Unary"

[expressions.'writer . write_all (format ! ("--- End AST Node Type Report ---\n") . as_bytes ()) . await ?']
expression_str = 'writer . write_all (format ! ("--- End AST Node Type Report ---\n") . as_bytes ()) . await ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'"."']
expression_str = '"."'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'"fmt"']
expression_str = '"fmt"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'uses . insert ("use clap::{Parser, Args, Command};\n")']
expression_str = 'uses . insert ("use clap::{Parser, Args, Command};\n")'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."if current_layer_decls . is_empty () { break ; }"]
expression_str = "if current_layer_decls . is_empty () { break ; }"
depth = 3
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'code . push_str ("});\n")']
expression_str = 'code . push_str ("});\n")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."WalkDir :: new (project_root) . into_iter () . filter_map (| e | e . ok ())"]
expression_str = "WalkDir :: new (project_root) . into_iter () . filter_map (| e | e . ok ())"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."fs :: write (crate_root . join (\"src/lib.rs\") , r#\"\n            #[test]\n            fn lib_test() { }\n            #[cfg(test)]\n            mod lib_tests {\n                #[test]\n                fn nested_lib_test() { }\n            }\n        \"# ,) ?"]
expression_str = """
fs :: write (crate_root . join ("src/lib.rs") , r#"
            #[test]
            fn lib_test() { }
            #[cfg(test)]
            mod lib_tests {
                #[test]
                fn nested_lib_test() { }
            }
        "# ,) ?"""
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'& ["prelude-generator"]']
expression_str = '& ["prelude-generator"]'
depth = 3
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."measurement :: get_collected_metrics ()"]
expression_str = "measurement :: get_collected_metrics ()"
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."flatten_use_tree (base_path , & path . tree , flat_uses)"]
expression_str = "flatten_use_tree (base_path , & path . tree , flat_uses)"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'async move { measurement :: record_function_entry ("AstReconstructionFunctor::map") ; let ValidatedFile (source_code , dataset_path) = input ; writer . write_all (format ! ("--- Stage 5: AST Reconstruction from Hugging Face Dataset (Mock) ---\n") . as_bytes ()) . await ? ; writer . write_all (format ! ("  -> Dataset path: {:#?}\n" , dataset_path) . as_bytes ()) . await ? ; writer . write_all (format ! ("  -> Returning original source code as mock reconstruction.\n") . as_bytes ()) . await ? ; let __result = Ok (source_code) ; measurement :: record_function_exit ("AstReconstructionFunctor::map") ; __result }']
expression_str = 'async move { measurement :: record_function_entry ("AstReconstructionFunctor::map") ; let ValidatedFile (source_code , dataset_path) = input ; writer . write_all (format ! ("--- Stage 5: AST Reconstruction from Hugging Face Dataset (Mock) ---\n") . as_bytes ()) . await ? ; writer . write_all (format ! ("  -> Dataset path: {:#?}\n" , dataset_path) . as_bytes ()) . await ? ; writer . write_all (format ! ("  -> Returning original source code as mock reconstruction.\n") . as_bytes ()) . await ? ; let __result = Ok (source_code) ; measurement :: record_function_exit ("AstReconstructionFunctor::map") ; __result }'
depth = 3
used_types = []
other_types_count = 0
node_type = "Async"

[expressions."fs :: copy (& original_cargo_toml_path , & temp_cargo_toml_path)"]
expression_str = "fs :: copy (& original_cargo_toml_path , & temp_cargo_toml_path)"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'fs :: create_dir (& temp_src_dir) . await . context ("Failed to create temporary src directory")']
expression_str = 'fs :: create_dir (& temp_src_dir) . await . context ("Failed to create temporary src directory")'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'" Path to output all collected analysis data (expressions, lattices) to a TOML file."']
expression_str = '" Path to output all collected analysis data (expressions, lattices) to a TOML file."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."& numerical_output_dir"]
expression_str = "& numerical_output_dir"
depth = 5
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."self . type_map . entry (type_name . clone ())"]
expression_str = "self . type_map . entry (type_name . clone ())"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'utils :: format_rust_code (& output_path) . await . context (format ! ("Constant {:?} formatting failed for {:?}" , const_name , output_path)) ?']
expression_str = 'utils :: format_rust_code (& output_path) . await . context (format ! ("Constant {:?} formatting failed for {:?}" , const_name , output_path)) ?'
depth = 5
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."tokio :: fs :: create_dir_all (& numerical_output_dir) . await"]
expression_str = "tokio :: fs :: create_dir_all (& numerical_output_dir) . await"
depth = 4
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.structs]
expression_str = "structs"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'Command :: new ("cargo") . arg ("metadata") . arg ("--no-deps") . arg ("--format-version=1") . current_dir (workspace_path) . output ()']
expression_str = 'Command :: new ("cargo") . arg ("metadata") . arg ("--no-deps") . arg ("--format-version=1") . current_dir (workspace_path) . output ()'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'_args . test_verification_output_dir . clone () . ok_or_else (| | anyhow :: anyhow ! ("test_verification_output_dir is required when compile_tests is true"))']
expression_str = '_args . test_verification_output_dir . clone () . ok_or_else (| | anyhow :: anyhow ! ("test_verification_output_dir is required when compile_tests is true"))'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."constants_by_type_and_size . is_empty ()"]
expression_str = "constants_by_type_and_size . is_empty ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."id . clone ()"]
expression_str = "id . clone ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'add_std_lib_symbol (& mut symbols , "Option" , "enum" , Some ("std::option"))']
expression_str = 'add_std_lib_symbol (& mut symbols , "Option" , "enum" , Some ("std::option"))'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'async { tokio :: fs :: write (& output_path , code . as_bytes ()) . await . context (format ! ("Failed to write struct {:?} to {:?}" , struct_name , output_path)) ? ; println ! ("  -> Wrote struct {:?} to {:?}" , struct_name , output_path) ; utils :: format_rust_code (& output_path) . await . context (format ! ("Struct {:?} formatting failed for {:?}" , struct_name , output_path)) ? ; println ! ("  -> Struct {:?} formatted successfully.\n" , struct_name) ; utils :: validate_rust_code (& output_path) . await . context (format ! ("Struct {:?} validation failed for {:?}" , struct_name , output_path)) ? ; println ! (r"  -> Struct {:?} validated successfully.\n" , struct_name) ; Ok (()) }']
expression_str = 'async { tokio :: fs :: write (& output_path , code . as_bytes ()) . await . context (format ! ("Failed to write struct {:?} to {:?}" , struct_name , output_path)) ? ; println ! ("  -> Wrote struct {:?} to {:?}" , struct_name , output_path) ; utils :: format_rust_code (& output_path) . await . context (format ! ("Struct {:?} formatting failed for {:?}" , struct_name , output_path)) ? ; println ! ("  -> Struct {:?} formatted successfully.\n" , struct_name) ; utils :: validate_rust_code (& output_path) . await . context (format ! ("Struct {:?} validation failed for {:?}" , struct_name , output_path)) ? ; println ! (r"  -> Struct {:?} validated successfully.\n" , struct_name) ; Ok (()) }'
depth = 5
used_types = []
other_types_count = 0
node_type = "Async"

[expressions.'i . member . clone () . into_token_stream () . to_string () . strip_prefix (".")']
expression_str = 'i . member . clone () . into_token_stream () . to_string () . strip_prefix (".")'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'tokio :: process :: Command :: new ("git") . arg ("config") . arg ("user.email") . arg ("test@example.com") . current_dir (& hf_validator_project_dir) . output () . await . context ("Failed to configure git user email") ?']
expression_str = 'tokio :: process :: Command :: new ("git") . arg ("config") . arg ("user.email") . arg ("test@example.com") . current_dir (& hf_validator_project_dir) . output () . await . context ("Failed to configure git user email") ?'
depth = 4
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'" Path to the main configuration file (config.toml)."']
expression_str = '" Path to the main configuration file (config.toml)."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'" Verify the parsed configuration and exit."']
expression_str = '" Verify the parsed configuration and exit."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'{ println ! (r"Declaration processing completed successfully.") ; return Ok (()) }']
expression_str = '{ println ! (r"Declaration processing completed successfully.") ; return Ok (()) }'
depth = 3
used_types = []
other_types_count = 0
node_type = "Block"

[expressions.'["prelude-generator" , "--dry-run" , "--path" , "/tmp/my_project" , "--exclude-crates" , "crate1,crate2" , "--report" , "--results-file" , "custom_results.json" , "--cache-report" , "--timeout" , "60" , "--force" ,]']
expression_str = '["prelude-generator" , "--dry-run" , "--path" , "/tmp/my_project" , "--exclude-crates" , "crate1,crate2" , "--report" , "--results-file" , "custom_results.json" , "--cache-report" , "--timeout" , "60" , "--force" ,]'
depth = 4
used_types = []
other_types_count = 0
node_type = "Array"

[expressions.'["prelude-generator"]']
expression_str = '["prelude-generator"]'
depth = 4
used_types = []
other_types_count = 0
node_type = "Array"

[expressions."file_path . file_stem () . unwrap ()"]
expression_str = "file_path . file_stem () . unwrap ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'setup_test_file (& dir , "test_file.rs" , "use std::collections::HashMap;\nfn main() {}\n" ,)']
expression_str = 'setup_test_file (& dir , "test_file.rs" , "use std::collections::HashMap;\nfn main() {}\n" ,)'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."split_expanded_lib :: extract_declarations_from_single_file (& file_path , & rustc_info_for_split_expanded_lib , & crate_name , args . verbose ,) . await"]
expression_str = "split_expanded_lib :: extract_declarations_from_single_file (& file_path , & rustc_info_for_split_expanded_lib , & crate_name , args . verbose ,) . await"
depth = 5
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."visit :: visit_item"]
expression_str = "visit :: visit_item"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'& crate_path . join ("src")']
expression_str = '& crate_path . join ("src")'
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."fs :: read_to_string (& crate_root_path) ?"]
expression_str = "fs :: read_to_string (& crate_root_path) ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."* self . field_co_occurrences . entry (field_types) . or_insert (0) += 1"]
expression_str = "* self . field_co_occurrences . entry (field_types) . or_insert (0) += 1"
depth = 2
used_types = []
other_types_count = 0
node_type = "Binary"

[expressions.'"    let mut rust_version_counts = HashMap::new();\n"']
expression_str = '"    let mut rust_version_counts = HashMap::new();\n"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."prelude_generator :: public_tests :: test_modify_crate_root_force_overwrite ()"]
expression_str = "prelude_generator :: public_tests :: test_modify_crate_root_force_overwrite ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'writer . write_all (format ! ("--- Stage 5: AST Reconstruction from Hugging Face Dataset ---\n") . as_bytes () ,) . await']
expression_str = 'writer . write_all (format ! ("--- Stage 5: AST Reconstruction from Hugging Face Dataset ---\n") . as_bytes () ,) . await'
depth = 3
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.'writer . write_all (format ! ("  -> Generated AST statistics code written to {:?}\n" , ast_statistics_file_path) . as_bytes () ,) . await']
expression_str = 'writer . write_all (format ! ("  -> Generated AST statistics code written to {:?}\n" , ast_statistics_file_path) . as_bytes () ,) . await'
depth = 3
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."self . map . get (id) . cloned ()"]
expression_str = "self . map . get (id) . cloned ()"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'code . push_str ("        processing_time_stats,\n")']
expression_str = 'code . push_str ("        processing_time_stats,\n")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."serde_json :: to_string_pretty (& all_public_symbols)"]
expression_str = "serde_json :: to_string_pretty (& all_public_symbols)"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.other_types_count]
expression_str = "other_types_count"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'format ! ("Failed to parse expanded code for {}: {}" , file_path . display () , e)']
expression_str = 'format ! ("Failed to parse expanded code for {}: {}" , file_path . display () , e)'
depth = 4
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions."fs :: create_dir_all (& dst)"]
expression_str = "fs :: create_dir_all (& dst)"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'dir . path () . join ("prelude_generator_summary.md")']
expression_str = 'dir . path () . join ("prelude_generator_summary.md")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'format ! ("    snippet_length_stats.insert(\"{}\".to_string(), ({}, {}, {}, {}));\n" , node_type , min , max , sum , count)']
expression_str = 'format ! ("    snippet_length_stats.insert(\"{}\".to_string(), ({}, {}, {}, {}));\n" , node_type , min , max , sum , count)'
depth = 5
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions.'writer . write_all (format ! ("--- METRICS_START ---\n{}\n--- METRICS_END ---\n" , json_metrics) . as_bytes () ,) . await ?']
expression_str = 'writer . write_all (format ! ("--- METRICS_START ---\n{}\n--- METRICS_END ---\n" , json_metrics) . as_bytes () ,) . await ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."serde_json :: to_string_pretty (& test_functions)"]
expression_str = "serde_json :: to_string_pretty (& test_functions)"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'setup_test_file (& dir , "test_file.rs" , "use std::fmt;\nfn some_func() {}\n" ,)']
expression_str = 'setup_test_file (& dir , "test_file.rs" , "use std::fmt;\nfn some_func() {}\n" ,)'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."self . impl_lattices"]
expression_str = "self . impl_lattices"
depth = 5
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'if use_statement . contains ("llvm") { current_use_statement . llvm_details = Some (pipeline_traits :: LlvmDetails :: Info (pipeline_traits :: LlvmInfo { ir_version : "inferred_from_use" . to_string () , target_triple : "inferred_from_use" . to_string () , })) ; }']
expression_str = 'if use_statement . contains ("llvm") { current_use_statement . llvm_details = Some (pipeline_traits :: LlvmDetails :: Info (pipeline_traits :: LlvmInfo { ir_version : "inferred_from_use" . to_string () , target_triple : "inferred_from_use" . to_string () , })) ; }'
depth = 5
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'tokio :: fs :: write (& error_output_path , error_json_content) . await . context (format ! ("Failed to write errors to file: {:?}" , error_output_path))']
expression_str = 'tokio :: fs :: write (& error_output_path , error_json_content) . await . context (format ! ("Failed to write errors to file: {:?}" , error_output_path))'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'serde_json :: to_string_pretty (& all_public_symbols_aggregated) . context ("Failed to serialize public symbols to JSON")']
expression_str = 'serde_json :: to_string_pretty (& all_public_symbols_aggregated) . context ("Failed to serialize public symbols to JSON")'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"println!"']
expression_str = '"println!"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'writer . write_all (format ! ("  -> AST Reconstruction completed successfully.\n") . as_bytes ())']
expression_str = 'writer . write_all (format ! ("  -> AST Reconstruction completed successfully.\n") . as_bytes ())'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"src/another_mod.rs"']
expression_str = '"src/another_mod.rs"'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'stdout . write_all (b"Pipeline completed successfully.\n") . await ?']
expression_str = 'stdout . write_all (b"Pipeline completed successfully.\n") . await ?'
depth = 4
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'" Analyze type usage in expressions."']
expression_str = '" Analyze type usage in expressions."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'snippet_length_stats . insert ("variable" . to_string () , (29 , 89 , 2362 , 41))']
expression_str = 'snippet_length_stats . insert ("variable" . to_string () , (29 , 89 , 2362 , 41))'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."fs :: copy (& original_cargo_toml_path , & temp_cargo_toml_path) . await"]
expression_str = "fs :: copy (& original_cargo_toml_path , & temp_cargo_toml_path) . await"
depth = 4
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."AstStatistics { node_type_counts , line_stats , column_stats , processing_time_stats , rust_version_counts , analyzer_version_counts , snippet_length_stats , }"]
expression_str = "AstStatistics { node_type_counts , line_stats , column_stats , processing_time_stats , rust_version_counts , analyzer_version_counts , snippet_length_stats , }"
depth = 5
used_types = []
other_types_count = 0
node_type = "Struct"

[expressions."WalkDir :: new (output_dir)"]
expression_str = "WalkDir :: new (output_dir)"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'"Cast"']
expression_str = '"Cast"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."(content , file_to_process . to_string_lossy () . to_string ())"]
expression_str = "(content , file_to_process . to_string_lossy () . to_string ())"
depth = 4
used_types = []
other_types_count = 0
node_type = "Tuple"

[expressions."match syn :: parse_str :: < syn :: ItemUse > (& use_statement) { Ok (_) => { } , Err (e) => { current_use_statement . error = Some (e . to_string ()) ; } , }"]
expression_str = "match syn :: parse_str :: < syn :: ItemUse > (& use_statement) { Ok (_) => { } , Err (e) => { current_use_statement . error = Some (e . to_string ()) ; } , }"
depth = 5
used_types = ["ItemUse"]
other_types_count = 1
node_type = "Match"

[expressions."generate_prelude :: generate_prelude (& src_dir , new_prelude_content , false , false)"]
expression_str = "generate_prelude :: generate_prelude (& src_dir , new_prelude_content , false , false)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."& test_functions"]
expression_str = "& test_functions"
depth = 5
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."ClassifiedUseStatements (classified_uses , HashMap :: new ())"]
expression_str = "ClassifiedUseStatements (classified_uses , HashMap :: new ())"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."std :: collections :: HashSet :: new ()"]
expression_str = "std :: collections :: HashSet :: new ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."bag_of_words_visitor . bag_of_words . iter () . collect ()"]
expression_str = "bag_of_words_visitor . bag_of_words . iter () . collect ()"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'writer . write_all (format ! ("\n--- AST Node Type Report ---\n") . as_bytes ()) . await ?']
expression_str = 'writer . write_all (format ! ("\n--- AST Node Type Report ---\n") . as_bytes ()) . await ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.config_path]
expression_str = "config_path"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'fs :: write (& report_path , report_content) . with_context (| | format ! ("Failed to write Test_Verification_Report.md to {}" , report_path . display ()))']
expression_str = 'fs :: write (& report_path , report_content) . with_context (| | format ! ("Failed to write Test_Verification_Report.md to {}" , report_path . display ()))'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'writer . write_all (format ! ("---\n--- Stage 1: Parsing ---\n") . as_bytes ()) . await ?']
expression_str = 'writer . write_all (format ! ("---\n--- Stage 1: Parsing ---\n") . as_bytes ()) . await ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'tokio :: fs :: create_dir_all (& output_dir) . await . context ("Failed to create output directory") ?']
expression_str = 'tokio :: fs :: create_dir_all (& output_dir) . await . context ("Failed to create output directory") ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'tokio :: fs :: create_dir_all (& structs_output_dir) . await . context (format ! ("Failed to create output directory {:?}, for struct {}" , structs_output_dir , struct_name)) ?']
expression_str = 'tokio :: fs :: create_dir_all (& structs_output_dir) . await . context (format ! ("Failed to create output directory {:?}, for struct {}" , structs_output_dir , struct_name)) ?'
depth = 4
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'full_path . push_str ("::")']
expression_str = 'full_path . push_str ("::")'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.type_path]
expression_str = "type_path"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."collector . visit_file (& file)"]
expression_str = "collector . visit_file (& file)"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."results . iter () . filter (| r | matches ! (r . status , FileProcessingStatus :: Failed { .. }))"]
expression_str = "results . iter () . filter (| r | matches ! (r . status , FileProcessingStatus :: Failed { .. }))"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'tokio :: process :: Command :: new ("cargo") . arg ("rustc") . arg ("--manifest-path") . arg (& temp_cargo_toml_path) . arg ("--lib") . arg ("--") . arg ("-Zunpretty=expanded")']
expression_str = 'tokio :: process :: Command :: new ("cargo") . arg ("rustc") . arg ("--manifest-path") . arg (& temp_cargo_toml_path) . arg ("--lib") . arg ("--") . arg ("-Zunpretty=expanded")'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."std :: fs :: read_to_string (path)"]
expression_str = "std :: fs :: read_to_string (path)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."self . gem"]
expression_str = "self . gem"
depth = 4
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'symbol_map . add_declaration (identifier . clone () , "builtin" . to_string () , gem_entry . crate_name . clone () , gem_entry . crate_name . clone () ,)']
expression_str = 'symbol_map . add_declaration (identifier . clone () , "builtin" . to_string () , gem_entry . crate_name . clone () , gem_entry . crate_name . clone () ,)'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."all_user_defined_types . insert (used_type . clone ())"]
expression_str = "all_user_defined_types . insert (used_type . clone ())"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."Ok (input)"]
expression_str = "Ok (input)"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."let syn :: Expr :: Lit (expr_lit) = & constant . expr . as_ref ()"]
expression_str = "let syn :: Expr :: Lit (expr_lit) = & constant . expr . as_ref ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "Let"

[expressions."generate_aggregated_test_file (output_path . as_path () , vec ! [test_func1 , test_func2] ,) ?"]
expression_str = "generate_aggregated_test_file (output_path . as_path () , vec ! [test_func1 , test_func2] ,) ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."Ok ((content , file_to_process . to_string_lossy () . to_string ()))"]
expression_str = "Ok ((content , file_to_process . to_string_lossy () . to_string ()))"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.files_to_process]
expression_str = "files_to_process"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'src_dir . join ("lib.rs")']
expression_str = 'src_dir . join ("lib.rs")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."tokio :: fs :: write (& public_symbols_output_path , json_content)"]
expression_str = "tokio :: fs :: write (& public_symbols_output_path , json_content)"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."prelude_generator :: public_tests :: test_modify_file_force_overwrite"]
expression_str = "prelude_generator :: public_tests :: test_modify_file_force_overwrite"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'" Collect and process use statements"']
expression_str = '" Collect and process use statements"'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."mapping . files"]
expression_str = "mapping . files"
depth = 5
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.f]
expression_str = "f"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.setup_test_crate]
expression_str = "setup_test_crate"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'for entry in WalkDir :: new (& repo_root) . into_iter () . filter_map (| e | e . ok ()) . filter (| e | e . file_type () . is_file () && e . file_name () == "Cargo.toml") { let cargo_toml_path = entry . path () ; if let Some (parent) = cargo_toml_path . parent () { if ! parent . components () . any (| c | c . as_os_str () == "target") { unique_crate_paths . insert (parent . to_path_buf ()) ; } } }']
expression_str = 'for entry in WalkDir :: new (& repo_root) . into_iter () . filter_map (| e | e . ok ()) . filter (| e | e . file_type () . is_file () && e . file_name () == "Cargo.toml") { let cargo_toml_path = entry . path () ; if let Some (parent) = cargo_toml_path . parent () { if ! parent . components () . any (| c | c . as_os_str () == "target") { unique_crate_paths . insert (parent . to_path_buf ()) ; } } }'
depth = 2
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions."Ok (ParsedFile (parsed_code , file_path))"]
expression_str = "Ok (ParsedFile (parsed_code , file_path))"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'for (file_path , file) in parsed_files { println ! ("Processing file for references: {:?}" , file_path) ; let current_crate_name = project_root . file_name () . and_then (| s | s . to_str ()) . unwrap_or ("unknown_crate") . to_string () ; let current_module_path = file_path . strip_prefix (& project_root) . unwrap_or (& file_path) . with_extension ("") . to_str () . unwrap_or ("unknown_module") . to_string () . replace ("/" , "::") ; let mut visitor = ReferenceVisitor :: new (& mut symbol_map , & mut all_declarations , current_crate_name , current_module_path , args . verbose ,) ; syn :: visit :: Visit :: visit_file (& mut visitor , & file) ; }']
expression_str = 'for (file_path , file) in parsed_files { println ! ("Processing file for references: {:?}" , file_path) ; let current_crate_name = project_root . file_name () . and_then (| s | s . to_str ()) . unwrap_or ("unknown_crate") . to_string () ; let current_module_path = file_path . strip_prefix (& project_root) . unwrap_or (& file_path) . with_extension ("") . to_str () . unwrap_or ("unknown_module") . to_string () . replace ("/" , "::") ; let mut visitor = ReferenceVisitor :: new (& mut symbol_map , & mut all_declarations , current_crate_name , current_module_path , args . verbose ,) ; syn :: visit :: Visit :: visit_file (& mut visitor , & file) ; }'
depth = 2
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions.'format ! ("Failed to write aggregated test report to {}" , output_path . display ())']
expression_str = 'format ! ("Failed to write aggregated test report to {}" , output_path . display ())'
depth = 5
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions."i . method . to_string ()"]
expression_str = "i . method . to_string ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'writer . write_all (format ! ("--- Stage 5: AST Reconstruction from Hugging Face Dataset ---\n") . as_bytes () ,) . await ?']
expression_str = 'writer . write_all (format ! ("--- Stage 5: AST Reconstruction from Hugging Face Dataset ---\n") . as_bytes () ,) . await ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'"macro" . to_string ()']
expression_str = '"macro" . to_string ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'tokio :: fs :: create_dir_all (& output_dir) . await . context ("Failed to create output directory")']
expression_str = 'tokio :: fs :: create_dir_all (& output_dir) . await . context ("Failed to create output directory")'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."prelude_generator :: public_tests :: test_generate_prelude_force_overwrite"]
expression_str = "prelude_generator :: public_tests :: test_generate_prelude_force_overwrite"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'format ! ("---\n--- Stage 1: Parsing ---\n") . as_bytes ()']
expression_str = 'format ! ("---\n--- Stage 1: Parsing ---\n") . as_bytes ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'writer . write_all (format ! ("  -> Dataset path: {:#?}\n" , dataset_path) . as_bytes ()) . await']
expression_str = 'writer . write_all (format ! ("  -> Dataset path: {:#?}\n" , dataset_path) . as_bytes ()) . await'
depth = 5
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.'setup_test_file (& dir , "test_file.rs" , "use std::fmt;\nfn some_func() {}\n")']
expression_str = 'setup_test_file (& dir , "test_file.rs" , "use std::fmt;\nfn some_func() {}\n")'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'"Repeat" . to_string ()']
expression_str = '"Repeat" . to_string ()'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'tokio :: fs :: create_dir_all (cached_file_path . parent () . unwrap ()) . await . context ("Failed to create parent directories for cache file") ?']
expression_str = 'tokio :: fs :: create_dir_all (cached_file_path . parent () . unwrap ()) . await . context ("Failed to create parent directories for cache file") ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.project_root]
expression_str = "project_root"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'"Tuple"']
expression_str = '"Tuple"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."for other_types_count in sorted_other_types_keys { report_content . push_str (& format ! (\"  Expressions using '{}' with {} other type(s):\\n\" , target_type , other_types_count)) ; let grouped_by_depth = grouped_by_other_types . get (& other_types_count) . unwrap () ; let mut sorted_depth_keys : Vec < usize > = grouped_by_depth . keys () . cloned () . collect () ; sorted_depth_keys . sort_unstable () ; for depth in sorted_depth_keys { let mut expressions_at_depth = grouped_by_depth . get (& depth) . unwrap () . clone () ; expressions_at_depth . sort_by_key (| info | info . expression_str . clone ()) ; report_content . push_str (& format ! (\"    Depth {}: (Count: {})\n\" , depth , expressions_at_depth . len ())) ; for info in expressions_at_depth { report_content . push_str (& format ! (\"      - '{}' (Used Types: {:?})\\n\" , info . expression_str , info . used_types)) ; } } }"]
expression_str = '''
for other_types_count in sorted_other_types_keys { report_content . push_str (& format ! ("  Expressions using '{}' with {} other type(s):\n" , target_type , other_types_count)) ; let grouped_by_depth = grouped_by_other_types . get (& other_types_count) . unwrap () ; let mut sorted_depth_keys : Vec < usize > = grouped_by_depth . keys () . cloned () . collect () ; sorted_depth_keys . sort_unstable () ; for depth in sorted_depth_keys { let mut expressions_at_depth = grouped_by_depth . get (& depth) . unwrap () . clone () ; expressions_at_depth . sort_by_key (| info | info . expression_str . clone ()) ; report_content . push_str (& format ! ("    Depth {}: (Count: {})
" , depth , expressions_at_depth . len ())) ; for info in expressions_at_depth { report_content . push_str (& format ! ("      - '{}' (Used Types: {:?})\n" , info . expression_str , info . used_types)) ; } } }'''
depth = 4
used_types = ["Vec"]
other_types_count = 1
node_type = "ForLoop"

[expressions.'Box :: pin (async move { measurement :: record_function_entry ("ClassifyUsesFunctor::map") ; let UseStatements (use_statements) = input ; let mut classified_uses = Vec :: new () ; for use_statement in use_statements { let mut current_use_statement = UseStatement { statement : use_statement . clone () , error : None , git_details : None , nix_details : None , rust_details : None , cargo_details : None , syn_details : None , llvm_details : None , linux_details : None , } ; if use_statement . contains ("git") { current_use_statement . git_details = Some (pipeline_traits :: GitDetails :: Info (pipeline_traits :: GitInfo { repo_url : "inferred_from_use" . to_string () , branch : "inferred_from_use" . to_string () , commit_hash : "inferred_from_use" . to_string () , })) ; } if use_statement . contains ("nix") { current_use_statement . nix_details = Some (pipeline_traits :: NixDetails :: Info (pipeline_traits :: NixInfo { flake_path : "inferred_from_use" . to_string () , output_type : "inferred_from_use" . to_string () , })) ; } if use_statement . contains ("rust") || use_statement . contains ("std") || use_statement . contains ("core") { current_use_statement . rust_details = Some (pipeline_traits :: RustDetails :: Info (pipeline_traits :: RustDetailsInfo { version : "inferred_from_use" . to_string () , crate_name : "inferred_from_use" . to_string () , item_path : "inferred_from_use" . to_string () , })) ; } if use_statement . contains ("cargo") { current_use_statement . cargo_details = Some (pipeline_traits :: CargoDetails :: Info (pipeline_traits :: CargoInfo { package_name : "inferred_from_use" . to_string () , version : "inferred_from_use" . to_string () , })) ; } if use_statement . contains ("syn") { current_use_statement . syn_details = Some (pipeline_traits :: SynDetails :: Info (pipeline_traits :: SynInfo { parsed_type : "ItemUse" . to_string () , version : "inferred_from_use" . to_string () , })) ; } if use_statement . contains ("llvm") { current_use_statement . llvm_details = Some (pipeline_traits :: LlvmDetails :: Info (pipeline_traits :: LlvmInfo { ir_version : "inferred_from_use" . to_string () , target_triple : "inferred_from_use" . to_string () , })) ; } if use_statement . contains ("linux") { current_use_statement . linux_details = Some (pipeline_traits :: LinuxDetails :: Info (pipeline_traits :: LinuxInfo { kernel_version : "inferred_from_use" . to_string () , architecture : "inferred_from_use" . to_string () , })) ; } match syn :: parse_str :: < syn :: ItemUse > (& use_statement) { Ok (_) => { } , Err (e) => { current_use_statement . error = Some (e . to_string ()) ; } , } classified_uses . push (current_use_statement) ; } let __result = Ok (ClassifiedUseStatements (classified_uses , HashMap :: new ())) ; measurement :: record_function_exit ("ClassifyUsesFunctor::map") ; __result })']
expression_str = 'Box :: pin (async move { measurement :: record_function_entry ("ClassifyUsesFunctor::map") ; let UseStatements (use_statements) = input ; let mut classified_uses = Vec :: new () ; for use_statement in use_statements { let mut current_use_statement = UseStatement { statement : use_statement . clone () , error : None , git_details : None , nix_details : None , rust_details : None , cargo_details : None , syn_details : None , llvm_details : None , linux_details : None , } ; if use_statement . contains ("git") { current_use_statement . git_details = Some (pipeline_traits :: GitDetails :: Info (pipeline_traits :: GitInfo { repo_url : "inferred_from_use" . to_string () , branch : "inferred_from_use" . to_string () , commit_hash : "inferred_from_use" . to_string () , })) ; } if use_statement . contains ("nix") { current_use_statement . nix_details = Some (pipeline_traits :: NixDetails :: Info (pipeline_traits :: NixInfo { flake_path : "inferred_from_use" . to_string () , output_type : "inferred_from_use" . to_string () , })) ; } if use_statement . contains ("rust") || use_statement . contains ("std") || use_statement . contains ("core") { current_use_statement . rust_details = Some (pipeline_traits :: RustDetails :: Info (pipeline_traits :: RustDetailsInfo { version : "inferred_from_use" . to_string () , crate_name : "inferred_from_use" . to_string () , item_path : "inferred_from_use" . to_string () , })) ; } if use_statement . contains ("cargo") { current_use_statement . cargo_details = Some (pipeline_traits :: CargoDetails :: Info (pipeline_traits :: CargoInfo { package_name : "inferred_from_use" . to_string () , version : "inferred_from_use" . to_string () , })) ; } if use_statement . contains ("syn") { current_use_statement . syn_details = Some (pipeline_traits :: SynDetails :: Info (pipeline_traits :: SynInfo { parsed_type : "ItemUse" . to_string () , version : "inferred_from_use" . to_string () , })) ; } if use_statement . contains ("llvm") { current_use_statement . llvm_details = Some (pipeline_traits :: LlvmDetails :: Info (pipeline_traits :: LlvmInfo { ir_version : "inferred_from_use" . to_string () , target_triple : "inferred_from_use" . to_string () , })) ; } if use_statement . contains ("linux") { current_use_statement . linux_details = Some (pipeline_traits :: LinuxDetails :: Info (pipeline_traits :: LinuxInfo { kernel_version : "inferred_from_use" . to_string () , architecture : "inferred_from_use" . to_string () , })) ; } match syn :: parse_str :: < syn :: ItemUse > (& use_statement) { Ok (_) => { } , Err (e) => { current_use_statement . error = Some (e . to_string ()) ; } , } classified_uses . push (current_use_statement) ; } let __result = Ok (ClassifiedUseStatements (classified_uses , HashMap :: new ())) ; measurement :: record_function_exit ("ClassifyUsesFunctor::map") ; __result })'
depth = 2
used_types = ["ItemUse"]
other_types_count = 1
node_type = "Call"

[expressions.'for (node_type , (min , max , sum , count)) in & stats . processing_time_stats { code . push_str (& format ! ("    processing_time_stats.insert(\"{}\".to_string(), ({}, {}, {}, {}));\n" , node_type , min , max , sum , count) ,) ; }']
expression_str = 'for (node_type , (min , max , sum , count)) in & stats . processing_time_stats { code . push_str (& format ! ("    processing_time_stats.insert(\"{}\".to_string(), ({}, {}, {}, {}));\n" , node_type , min , max , sum , count) ,) ; }'
depth = 2
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions.'"--verbose"']
expression_str = '"--verbose"'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."file_path_str . clone ()"]
expression_str = "file_path_str . clone ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."has_prelude_mod = true"]
expression_str = "has_prelude_mod = true"
depth = 5
used_types = []
other_types_count = 0
node_type = "Assign"

[expressions."crate :: declaration_processing :: extract_all_declarations_from_file (file_path , & std :: path :: PathBuf :: new () , false , verbose , & rustc_info , crate_name ,)"]
expression_str = "crate :: declaration_processing :: extract_all_declarations_from_file (file_path , & std :: path :: PathBuf :: new () , false , verbose , & rustc_info , crate_name ,)"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."* self . bag_of_words . entry (subword) . or_insert (0) += 1"]
expression_str = "* self . bag_of_words . entry (subword) . or_insert (0) += 1"
depth = 3
used_types = []
other_types_count = 0
node_type = "Binary"

[expressions.'std :: fs :: read_to_string (config_path) . with_context (| | format ! ("Failed to read config file: {}" , config_path . display ()))']
expression_str = 'std :: fs :: read_to_string (config_path) . with_context (| | format ! ("Failed to read config file: {}" , config_path . display ()))'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.content]
expression_str = "content"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."for node_type in sorted_node_types { report_content . push_str (& format ! (\"\\n--- AST Node Type: {} ---\\n\" , node_type)) ; let grouped_by_other_types = grouped_by_node_type . get (& node_type) . unwrap () ; let mut sorted_other_types_keys : Vec < usize > = grouped_by_other_types . keys () . cloned () . collect () ; sorted_other_types_keys . sort_unstable () ; for other_types_count in sorted_other_types_keys { report_content . push_str (& format ! (\"  Expressions using '{}' with {} other type(s):\\n\" , target_type , other_types_count)) ; let grouped_by_depth = grouped_by_other_types . get (& other_types_count) . unwrap () ; let mut sorted_depth_keys : Vec < usize > = grouped_by_depth . keys () . cloned () . collect () ; sorted_depth_keys . sort_unstable () ; for depth in sorted_depth_keys { let mut expressions_at_depth = grouped_by_depth . get (& depth) . unwrap () . clone () ; expressions_at_depth . sort_by_key (| info | info . expression_str . clone ()) ; report_content . push_str (& format ! (\"    Depth {}: (Count: {})\n\" , depth , expressions_at_depth . len ())) ; for info in expressions_at_depth { report_content . push_str (& format ! (\"      - '{}' (Used Types: {:?})\\n\" , info . expression_str , info . used_types)) ; } } } }"]
expression_str = '''
for node_type in sorted_node_types { report_content . push_str (& format ! ("\n--- AST Node Type: {} ---\n" , node_type)) ; let grouped_by_other_types = grouped_by_node_type . get (& node_type) . unwrap () ; let mut sorted_other_types_keys : Vec < usize > = grouped_by_other_types . keys () . cloned () . collect () ; sorted_other_types_keys . sort_unstable () ; for other_types_count in sorted_other_types_keys { report_content . push_str (& format ! ("  Expressions using '{}' with {} other type(s):\n" , target_type , other_types_count)) ; let grouped_by_depth = grouped_by_other_types . get (& other_types_count) . unwrap () ; let mut sorted_depth_keys : Vec < usize > = grouped_by_depth . keys () . cloned () . collect () ; sorted_depth_keys . sort_unstable () ; for depth in sorted_depth_keys { let mut expressions_at_depth = grouped_by_depth . get (& depth) . unwrap () . clone () ; expressions_at_depth . sort_by_key (| info | info . expression_str . clone ()) ; report_content . push_str (& format ! ("    Depth {}: (Count: {})
" , depth , expressions_at_depth . len ())) ; for info in expressions_at_depth { report_content . push_str (& format ! ("      - '{}' (Used Types: {:?})\n" , info . expression_str , info . used_types)) ; } } } }'''
depth = 3
used_types = ["Vec"]
other_types_count = 1
node_type = "ForLoop"

[expressions."s . ident . to_string ()"]
expression_str = "s . ident . to_string ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"u16"']
expression_str = '"u16"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."prelude_generator :: public_tests :: test_generate_prelude_creates_file ()"]
expression_str = "prelude_generator :: public_tests :: test_generate_prelude_creates_file ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.hf_validator_path]
expression_str = "hf_validator_path"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."entry . clone ()"]
expression_str = "entry . clone ()"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."fs :: read_dir (& cache_dir) ? . count ()"]
expression_str = "fs :: read_dir (& cache_dir) ? . count ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"test_report.json"']
expression_str = '"test_report.json"'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."args . output_type_usage_report . as_ref ()"]
expression_str = "args . output_type_usage_report . as_ref ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."fs :: write (crate_root . join (\"src/lib.rs\") , r#\"\n            #[test]\n            fn lib_test() { }\n            #[cfg(test)]\n            mod lib_tests {\n                #[test]\n                fn nested_lib_test() { }\n            }\n        \"# ,)"]
expression_str = """
fs :: write (crate_root . join ("src/lib.rs") , r#"
            #[test]
            fn lib_test() { }
            #[cfg(test)]
            mod lib_tests {
                #[test]
                fn nested_lib_test() { }
            }
        "# ,)"""
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'match extract_test_cases_from_file (file_path) { Ok (functions) => { for func_info in functions { if seen_test_names . insert (func_info . name . clone ()) { all_test_functions . push (func_info) ; } } } Err (e) => { eprintln ! ("Warning: Could not extract tests from {}: {}" , file_path . display () , e) ; } }']
expression_str = 'match extract_test_cases_from_file (file_path) { Ok (functions) => { for func_info in functions { if seen_test_names . insert (func_info . name . clone ()) { all_test_functions . push (func_info) ; } } } Err (e) => { eprintln ! ("Warning: Could not extract tests from {}: {}" , file_path . display () , e) ; } }'
depth = 3
used_types = []
other_types_count = 0
node_type = "Match"

[expressions.METRICS]
expression_str = "METRICS"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."current_file_size += line . len ()"]
expression_str = "current_file_size += line . len ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "Binary"

[expressions.'fs :: copy (file_path , & temp_lib_rs_path) . await . context ("Failed to copy source file to temporary lib.rs") ?']
expression_str = 'fs :: copy (file_path , & temp_lib_rs_path) . await . context ("Failed to copy source file to temporary lib.rs") ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'"std" . to_string ()']
expression_str = '"std" . to_string ()'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."args . exclude_crates . clone () . into_iter () . collect ()"]
expression_str = "args . exclude_crates . clone () . into_iter () . collect ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions._output_global_toml]
expression_str = "_output_global_toml"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."visit :: visit_expr_match (self , i)"]
expression_str = "visit :: visit_expr_match (self , i)"
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."gem_config . gem"]
expression_str = "gem_config . gem"
depth = 4
used_types = []
other_types_count = 0
node_type = "Field"

[expressions."config_parser :: read_config (config_path , & project_root) ?"]
expression_str = "config_parser :: read_config (config_path , & project_root) ?"
depth = 4
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'excluded_crates . insert ("rust-decl-splitter" . to_string ())']
expression_str = 'excluded_crates . insert ("rust-decl-splitter" . to_string ())'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'code . push_str ("    let mut line_stats = HashMap::new();\n")']
expression_str = 'code . push_str ("    let mut line_stats = HashMap::new();\n")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"use std::fmt;\nfn some_func() {}\n"']
expression_str = '"use std::fmt;\nfn some_func() {}\n"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."prelude_generator :: public_tests :: test_modify_crate_root_no_force_no_overwrite ()"]
expression_str = "prelude_generator :: public_tests :: test_modify_crate_root_no_force_no_overwrite ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'WalkDir :: new (repo_root) . into_iter () . filter_map (| e | e . ok ()) . filter (| e | e . file_type () . is_file () && e . path () . extension () . map_or (false , | ext | ext == "rs"))']
expression_str = 'WalkDir :: new (repo_root) . into_iter () . filter_map (| e | e . ok ()) . filter (| e | e . file_type () . is_file () && e . path () . extension () . map_or (false , | ext | ext == "rs"))'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'writer . write_all (format ! ("  -> Extracted {} use statements.\n" , use_statements . 0 . len ()) . as_bytes () ,) . await ?']
expression_str = 'writer . write_all (format ! ("  -> Extracted {} use statements.\n" , use_statements . 0 . len ()) . as_bytes () ,) . await ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."& lib_rs_path"]
expression_str = "& lib_rs_path"
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."Ok (ClassifiedUseStatements (new_classified_uses , HashMap :: new ()))"]
expression_str = "Ok (ClassifiedUseStatements (new_classified_uses , HashMap :: new ()))"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'if generated_decl_strings . is_empty () { return "// No struct declarations found in this module.\n" . to_string () ; }']
expression_str = 'if generated_decl_strings . is_empty () { return "// No struct declarations found in this module.\n" . to_string () ; }'
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'tokio :: fs :: write (& public_symbols_output_path , json_content) . await . context (format ! ("Failed to write public symbols to file: {:?}" , public_symbols_output_path))']
expression_str = 'tokio :: fs :: write (& public_symbols_output_path , json_content) . await . context (format ! ("Failed to write public symbols to file: {:?}" , public_symbols_output_path))'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."if let Some (ident) = & field . ident { self . add_ident_to_bag (ident) ; }"]
expression_str = "if let Some (ident) = & field . ident { self . add_ident_to_bag (ident) ; }"
depth = 4
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'"Field"']
expression_str = '"Field"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'format ! ("echo \"Running tests in {}...\"\n" , crate_path . display ())']
expression_str = 'format ! ("echo \"Running tests in {}...\"\n" , crate_path . display ())'
depth = 5
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions."group . items . iter ()"]
expression_str = "group . items . iter ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."fs :: write (& results_json_path , serde_json :: to_string_pretty (& dummy_results) ?) ?"]
expression_str = "fs :: write (& results_json_path , serde_json :: to_string_pretty (& dummy_results) ?) ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.constants_by_type_and_size]
expression_str = "constants_by_type_and_size"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."prelude_generator :: public_tests :: test_generate_test_runner_crate () ?"]
expression_str = "prelude_generator :: public_tests :: test_generate_test_runner_crate () ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.generated_decls_output_dir]
expression_str = "generated_decls_output_dir"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."entry_path . strip_prefix (& current_src)"]
expression_str = "entry_path . strip_prefix (& current_src)"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'add_std_lib_symbol (& mut symbols , "String" , "type" , Some ("std::string"))']
expression_str = 'add_std_lib_symbol (& mut symbols , "String" , "type" , Some ("std::string"))'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'code . push_str ("    AstStatistics {\n")']
expression_str = 'code . push_str ("    AstStatistics {\n")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'tokio :: fs :: write (& source_file_path , source_code . as_bytes ()) . await . context ("Failed to write source code to persistent file")']
expression_str = 'tokio :: fs :: write (& source_file_path , source_code . as_bytes ()) . await . context ("Failed to write source code to persistent file")'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'anyhow :: anyhow ! ("Struct processing completed with errors.")']
expression_str = 'anyhow :: anyhow ! ("Struct processing completed with errors.")'
depth = 5
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions."& mut visitor"]
expression_str = "& mut visitor"
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'" Path to the JSON test report input file. Required if `compile_tests` is true."']
expression_str = '" Path to the JSON test report input file. Required if `compile_tests` is true."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'fs :: create_dir_all (& cache_dir) . context ("Failed to create prelude cache directory") ?']
expression_str = 'fs :: create_dir_all (& cache_dir) . context ("Failed to create prelude cache directory") ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'Args { dry_run : false , path : project_root . clone () , exclude_crates : vec ! [] , report : false , results_file : project_root . join ("results.json") , cache_report : false , timeout : None , force : true , }']
expression_str = 'Args { dry_run : false , path : project_root . clone () , exclude_crates : vec ! [] , report : false , results_file : project_root . join ("results.json") , cache_report : false , timeout : None , force : true , }'
depth = 2
used_types = []
other_types_count = 0
node_type = "Struct"

[expressions."dep_type . to_string ()"]
expression_str = "dep_type . to_string ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."& variant . fields"]
expression_str = "& variant . fields"
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."structure . fields . iter ()"]
expression_str = "structure . fields . iter ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.parsed_file]
expression_str = "parsed_file"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'" Comma-separated list of file/module names to filter by during processing."']
expression_str = '" Comma-separated list of file/module names to filter by during processing."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'" Extract unique use statements and generate test files for a use statement parser."']
expression_str = '" Extract unique use statements and generate test files for a use statement parser."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'"custom_results.json"']
expression_str = '"custom_results.json"'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."current_layer_num += 1"]
expression_str = "current_layer_num += 1"
depth = 3
used_types = []
other_types_count = 0
node_type = "Binary"

[expressions."args . filter_names . as_ref () . map_or (true , | filter_names | { filter_names . iter () . any (| f | file_path . to_string_lossy () . contains (f)) })"]
expression_str = "args . filter_names . as_ref () . map_or (true , | filter_names | { filter_names . iter () . any (| f | file_path . to_string_lossy () . contains (f)) })"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'self . symbol_map . resolve_and_increment_usage (ident_str . clone () , "type" . to_string () , self . crate_name . clone () , self . module_path . clone () ,)']
expression_str = 'self . symbol_map . resolve_and_increment_usage (ident_str . clone () , "type" . to_string () , self . crate_name . clone () , self . module_path . clone () ,)'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'fs :: create_dir_all (crate_root . join ("src"))']
expression_str = 'fs :: create_dir_all (crate_root . join ("src"))'
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."HashMap :: new ()"]
expression_str = "HashMap :: new ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."path . ident . to_string ()"]
expression_str = "path . ident . to_string ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'report_content . push_str (& format ! ("To run all tests, execute the generated script:\n\n```bash\n./{}\n```\n\n" , script_path . file_name () . unwrap () . to_str () . unwrap ()))']
expression_str = 'report_content . push_str (& format ! ("To run all tests, execute the generated script:\n\n```bash\n./{}\n```\n\n" , script_path . file_name () . unwrap () . to_str () . unwrap ()))'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."HashMap :: new"]
expression_str = "HashMap :: new"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."entry . end_time . unwrap () . duration_since (entry . start_time)"]
expression_str = "entry . end_time . unwrap () . duration_since (entry . start_time)"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."args . timeout"]
expression_str = "args . timeout"
depth = 3
used_types = []
other_types_count = 0
node_type = "Field"

[expressions."{ if let Some ((_ , module_items)) = module . content { test_functions . extend (extract_test_functions_from_items (module_items , file_path)) ; } }"]
expression_str = "{ if let Some ((_ , module_items)) = module . content { test_functions . extend (extract_test_functions_from_items (module_items , file_path)) ; } }"
depth = 4
used_types = []
other_types_count = 0
node_type = "Block"

[expressions."uses . into_iter () . collect ()"]
expression_str = "uses . into_iter () . collect ()"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'writer . write_all (format ! ("  -> AST Reconstruction completed successfully.\n") . as_bytes () ,) . await']
expression_str = 'writer . write_all (format ! ("  -> AST Reconstruction completed successfully.\n") . as_bytes () ,) . await'
depth = 3
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.'format ! ("--- Stage 3: Classifying Use Statements ---\n") . as_bytes ()']
expression_str = 'format ! ("--- Stage 3: Classifying Use Statements ---\n") . as_bytes ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'| | format ! ("Failed to read cached expanded code for {}" , file_path . display ())']
expression_str = '| | format ! ("Failed to read cached expanded code for {}" , file_path . display ())'
depth = 5
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions.'{ uses . insert ("use std::string::String;\n") ; }']
expression_str = '{ uses . insert ("use std::string::String;\n") ; }'
depth = 5
used_types = []
other_types_count = 0
node_type = "Block"

[expressions."type_map . get (& const_name) . and_then (| info | info . layer) . unwrap_or (0)"]
expression_str = "type_map . get (& const_name) . and_then (| info | info . layer) . unwrap_or (0)"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."i . path"]
expression_str = "i . path"
depth = 5
used_types = []
other_types_count = 0
node_type = "Field"

[expressions."entry . end_time . unwrap ()"]
expression_str = "entry . end_time . unwrap ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'crate_root . join ("tests/integration_test.rs")']
expression_str = 'crate_root . join ("tests/integration_test.rs")'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'| | PathBuf :: from ("generated_workspace")']
expression_str = '| | PathBuf :: from ("generated_workspace")'
depth = 3
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions.'code . push_str ("        snippet_length_stats,\n")']
expression_str = 'code . push_str ("        snippet_length_stats,\n")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'writer . write_all (format ! ("--- Stage 5: AST Reconstruction from Hugging Face Dataset (Mock) ---\n") . as_bytes ()) . await']
expression_str = 'writer . write_all (format ! ("--- Stage 5: AST Reconstruction from Hugging Face Dataset (Mock) ---\n") . as_bytes ()) . await'
depth = 5
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.json_content]
expression_str = "json_content"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."structs_output_dir . join (& file_name)"]
expression_str = "structs_output_dir . join (& file_name)"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."format ! (\"\\n### Analyzing expressions using type: '{}' ###\\n\" , target_type)"]
expression_str = '''format ! ("\n### Analyzing expressions using type: '{}' ###\n" , target_type)'''
depth = 5
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions."generate_prelude (& src_dir , prelude_content , true , false) ?"]
expression_str = "generate_prelude (& src_dir , prelude_content , true , false) ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."& new_ast"]
expression_str = "& new_ast"
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."! path . is_absolute ()"]
expression_str = "! path . is_absolute ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "Unary"

[expressions."i . sig . ident"]
expression_str = "i . sig . ident"
depth = 4
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.continue]
expression_str = "continue"
depth = 5
used_types = []
other_types_count = 0
node_type = "Continue"

[expressions."let Some (parent) = current_path . parent ()"]
expression_str = "let Some (parent) = current_path . parent ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "Let"

[expressions.'async move { measurement :: record_function_entry ("ExtractUsesFunctor::map") ; let ParsedFile (source_code , _) = input ; let use_statements = tokio :: task :: spawn_blocking (move | | -> anyhow :: Result < _ > { let ast = syn :: parse_file (& source_code) . context ("Failed to parse source code for use statement extraction") ? ; let mut use_statements = Vec :: new () ; for item in ast . items { if let syn :: Item :: Use (use_item) = item { use_statements . push (code_generator :: use_item_to_string (& use_item)) ; } } Ok (UseStatements (use_statements)) }) . await . context ("Blocking task for extracting use statements failed") ? ? ; measurement :: record_function_exit ("ExtractUsesFunctor::map") ; Ok (use_statements) }']
expression_str = 'async move { measurement :: record_function_entry ("ExtractUsesFunctor::map") ; let ParsedFile (source_code , _) = input ; let use_statements = tokio :: task :: spawn_blocking (move | | -> anyhow :: Result < _ > { let ast = syn :: parse_file (& source_code) . context ("Failed to parse source code for use statement extraction") ? ; let mut use_statements = Vec :: new () ; for item in ast . items { if let syn :: Item :: Use (use_item) = item { use_statements . push (code_generator :: use_item_to_string (& use_item)) ; } } Ok (UseStatements (use_statements)) }) . await . context ("Blocking task for extracting use statements failed") ? ? ; measurement :: record_function_exit ("ExtractUsesFunctor::map") ; Ok (use_statements) }'
depth = 3
used_types = [
    "_",
    "Result",
]
other_types_count = 2
node_type = "Async"

[expressions."args . split_expanded_files"]
expression_str = "args . split_expanded_files"
depth = 3
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'crate_root . join ("src")']
expression_str = 'crate_root . join ("src")'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."| info | info . layer"]
expression_str = "| info | info . layer"
depth = 5
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions."while let Some (entry) = entries . next_entry () . await ? { let entry_path = entry . path () ; let destination_path = permanent_output_dir . join (entry_path . file_name () . unwrap ()) ; if entry_path . is_dir () { copy_dir_all (& entry_path , & destination_path) . await ? ; } else { tokio :: fs :: copy (& entry_path , & destination_path) . await ? ; } }"]
expression_str = "while let Some (entry) = entries . next_entry () . await ? { let entry_path = entry . path () ; let destination_path = permanent_output_dir . join (entry_path . file_name () . unwrap ()) ; if entry_path . is_dir () { copy_dir_all (& entry_path , & destination_path) . await ? ; } else { tokio :: fs :: copy (& entry_path , & destination_path) . await ? ; } }"
depth = 4
used_types = []
other_types_count = 0
node_type = "While"

[expressions."constants . iter () . map (| c | { let tokens = quote ! { # c } ; tokens . to_string () }) . collect ()"]
expression_str = "constants . iter () . map (| c | { let tokens = quote ! { # c } ; tokens . to_string () }) . collect ()"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.all_test_functions]
expression_str = "all_test_functions"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."prelude_generator :: public_tests :: test_process_crates_report_only () ?"]
expression_str = "prelude_generator :: public_tests :: test_process_crates_report_only () ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."return segment . ident . to_string ()"]
expression_str = "return segment . ident . to_string ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "Return"

[expressions.read_input_file]
expression_str = "read_input_file"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'{ println ! ("Prelude cache directory not found at {}." , cache_dir . display ()) ; }']
expression_str = '{ println ! ("Prelude cache directory not found at {}." , cache_dir . display ()) ; }'
depth = 4
used_types = []
other_types_count = 0
node_type = "Block"

[expressions."tokio :: fs :: write (& output_file_path , reconstructed_code . as_bytes ())"]
expression_str = "tokio :: fs :: write (& output_file_path , reconstructed_code . as_bytes ())"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'"Verbatim"']
expression_str = '"Verbatim"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."std :: env :: set_current_dir (& original_dir)"]
expression_str = "std :: env :: set_current_dir (& original_dir)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.generate_ast_statistics_code]
expression_str = "generate_ast_statistics_code"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."self . current_depth <= self . max_depth"]
expression_str = "self . current_depth <= self . max_depth"
depth = 3
used_types = []
other_types_count = 0
node_type = "Binary"

[expressions."rustc_info . version . clone ()"]
expression_str = "rustc_info . version . clone ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'sorted_uses . join ("")']
expression_str = 'sorted_uses . join ("")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'Command :: new ("cargo") . arg ("metadata") . arg ("--no-deps") . arg ("--format-version=1") . current_dir (workspace_path)']
expression_str = 'Command :: new ("cargo") . arg ("metadata") . arg ("--no-deps") . arg ("--format-version=1") . current_dir (workspace_path)'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.dep_type]
expression_str = "dep_type"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."DefaultHasher :: new ()"]
expression_str = "DefaultHasher :: new ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'Some ("std::result")']
expression_str = 'Some ("std::result")'
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'if args . path == PathBuf :: from (".") { std :: env :: current_dir () ? . parent () . unwrap () . to_path_buf () } else { args . path . clone () }']
expression_str = 'if args . path == PathBuf :: from (".") { std :: env :: current_dir () ? . parent () . unwrap () . to_path_buf () } else { args . path . clone () }'
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'format ! ("{}{}" , header , joined_decls)']
expression_str = 'format ! ("{}{}" , header , joined_decls)'
depth = 2
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions."prelude_generator :: public_tests :: test_modify_file_no_use_statements ()"]
expression_str = "prelude_generator :: public_tests :: test_modify_file_no_use_statements ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'"Failed to execute rustc"']
expression_str = '"Failed to execute rustc"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."hf_validator_functor . map (writer , parsed_file . clone ()) . await"]
expression_str = "hf_validator_functor . map (writer , parsed_file . clone ()) . await"
depth = 4
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.'"        snippet_length_stats,\n"']
expression_str = '"        snippet_length_stats,\n"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."command_handlers :: handle_run_decl_splitter (& args , & project_root , & rustc_info) . await ?"]
expression_str = "command_handlers :: handle_run_decl_splitter (& args , & project_root , & rustc_info) . await ?"
depth = 3
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'crate :: utils :: validate_rust_code (& output_file_path) . await . context (format ! ("Generated code validation failed for {:?}" , output_file_path)) ?']
expression_str = 'crate :: utils :: validate_rust_code (& output_file_path) . await . context (format ! ("Generated code validation failed for {:?}" , output_file_path)) ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.Err]
expression_str = "Err"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'"Failed to serialize declarations to TOML "']
expression_str = '"Failed to serialize declarations to TOML "'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."& rustc_info"]
expression_str = "& rustc_info"
depth = 5
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."results . is_empty ()"]
expression_str = "results . is_empty ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."StructFieldCoOccurrenceVisitor { _struct_name : & impl_for_type_name , current_field_accesses : BTreeSet :: new () , struct_lattice_info , }"]
expression_str = "StructFieldCoOccurrenceVisitor { _struct_name : & impl_for_type_name , current_field_accesses : BTreeSet :: new () , struct_lattice_info , }"
depth = 4
used_types = []
other_types_count = 0
node_type = "Struct"

[expressions."self . current_depth -= 1"]
expression_str = "self . current_depth -= 1"
depth = 2
used_types = []
other_types_count = 0
node_type = "Binary"

[expressions."crate :: constant_storage :: string_constants :: write_string_constants_to_hierarchical_structure (& all_string_constants , & string_output_dir) . await"]
expression_str = "crate :: constant_storage :: string_constants :: write_string_constants_to_hierarchical_structure (& all_string_constants , & string_output_dir) . await"
depth = 3
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.'"src/prelude.rs"']
expression_str = '"src/prelude.rs"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."sorted_test_names . sort ()"]
expression_str = "sorted_test_names . sort ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."i . arms"]
expression_str = "i . arms"
depth = 4
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'fs :: write (output_path , & report_content) . context (format ! ("Failed to write type usage report to {:?}" , output_path)) ?']
expression_str = 'fs :: write (output_path , & report_content) . context (format ! ("Failed to write type usage report to {:?}" , output_path)) ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'" Path to output the leveled type usage report. Required if `analyze_type_usage` is true."']
expression_str = '" Path to output the leveled type usage report. Required if `analyze_type_usage` is true."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'toml :: to_string_pretty (& symbol_map . map) . context ("Failed to serialize symbol map to TOML ") ?']
expression_str = 'toml :: to_string_pretty (& symbol_map . map) . context ("Failed to serialize symbol map to TOML ") ?'
depth = 3
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."METRICS . lock () . unwrap ()"]
expression_str = "METRICS . lock () . unwrap ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'for (type_name , values) in & constants_by_type_and_size { println ! ("Type: {}" , type_name) ; let mut sorted_values : Vec < (& String , & usize) > = values . iter () . collect () ; sorted_values . sort_by (| a , b | a . 0 . cmp (b . 0)) ; for (value , count) in sorted_values { println ! ("  Value: {}, Count: {}" , value , count) ; } }']
expression_str = 'for (type_name , values) in & constants_by_type_and_size { println ! ("Type: {}" , type_name) ; let mut sorted_values : Vec < (& String , & usize) > = values . iter () . collect () ; sorted_values . sort_by (| a , b | a . 0 . cmp (b . 0)) ; for (value , count) in sorted_values { println ! ("  Value: {}, Count: {}" , value , count) ; } }'
depth = 4
used_types = [
    "(& String , & usize)",
    "& usize",
    "Vec",
    "& String",
]
other_types_count = 4
node_type = "ForLoop"

[expressions."& content"]
expression_str = "& content"
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'writer . write_all (format ! ("{:#?}\n" , ast_statistics) . as_bytes ()) . await']
expression_str = 'writer . write_all (format ! ("{:#?}\n" , ast_statistics) . as_bytes ()) . await'
depth = 3
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.prelude_use]
expression_str = "prelude_use"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."Ok (all_test_functions)"]
expression_str = "Ok (all_test_functions)"
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'Some ("std")']
expression_str = 'Some ("std")'
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."let Some (entry) = metrics . get_mut (function_name)"]
expression_str = "let Some (entry) = metrics . get_mut (function_name)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Let"

[expressions.'Command :: new ("rustfmt") . arg (file_path) . arg ("--edition=2021") . arg ("--emit=files") . output () . await . context ("Failed to execute rustfmt")']
expression_str = 'Command :: new ("rustfmt") . arg (file_path) . arg ("--edition=2021") . arg ("--emit=files") . output () . await . context ("Failed to execute rustfmt")'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'Some ("std::option")']
expression_str = 'Some ("std::option")'
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'format ! ("{}\n" , const_code)']
expression_str = 'format ! ("{}\n" , const_code)'
depth = 3
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions."visit :: visit_item_fn"]
expression_str = "visit :: visit_item_fn"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."prelude_generator :: public_tests :: test_process_crates_integration ()"]
expression_str = "prelude_generator :: public_tests :: test_process_crates_integration ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'for error in & errors { eprintln ! (r"{:{}}" , error) ; }']
expression_str = 'for error in & errors { eprintln ! (r"{:{}}" , error) ; }'
depth = 3
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions.sorted_test_names]
expression_str = "sorted_test_names"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."args . split_expanded_rustc_version"]
expression_str = "args . split_expanded_rustc_version"
depth = 4
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'"std::string"']
expression_str = '"std::string"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'Command :: new ("rustc") . arg ("--emit=metadata") . arg ("--crate-type=lib") . arg (file_path) . output () . await . context ("Failed to execute rustc")']
expression_str = 'Command :: new ("rustc") . arg ("--emit=metadata") . arg ("--crate-type=lib") . arg (file_path) . output () . await . context ("Failed to execute rustc")'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."tokio :: fs :: remove_dir_all (& output_dir) . await"]
expression_str = "tokio :: fs :: remove_dir_all (& output_dir) . await"
depth = 5
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."args . analyze_type_usage"]
expression_str = "args . analyze_type_usage"
depth = 4
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'fs :: create_dir_all (output_dir) . with_context (| | format ! ("Failed to create output directory {}" , output_dir . display ())) ?']
expression_str = 'fs :: create_dir_all (output_dir) . with_context (| | format ! ("Failed to create output directory {}" , output_dir . display ())) ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."& args . output_toml_report"]
expression_str = "& args . output_toml_report"
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."fs :: read_dir (& cache_dir) ?"]
expression_str = "fs :: read_dir (& cache_dir) ?"
depth = 5
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'tokio :: fs :: write (& output_file_path , reconstructed_code . as_bytes ()) . await . context (format ! ("Failed to write generated code to {:?}" , output_file_path))']
expression_str = 'tokio :: fs :: write (& output_file_path , reconstructed_code . as_bytes ()) . await . context (format ! ("Failed to write generated code to {:?}" , output_file_path))'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."if ! has_unresolved_deps { current_layer_idents . insert (decl . get_identifier ()) ; current_layer_decls . push (decl) ; } else { next_remaining_decls . push (decl) ; }"]
expression_str = "if ! has_unresolved_deps { current_layer_idents . insert (decl . get_identifier ()) ; current_layer_decls . push (decl) ; } else { next_remaining_decls . push (decl) ; }"
depth = 4
used_types = []
other_types_count = 0
node_type = "If"

[expressions."| s | s . ident . to_string ()"]
expression_str = "| s | s . ident . to_string ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions.'code . push_str ("        node_type_counts,\n")']
expression_str = 'code . push_str ("        node_type_counts,\n")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'" Path to the output file for the JSON test report. Only used if `generate_test_report` is true."']
expression_str = '" Path to the output file for the JSON test report. Only used if `generate_test_report` is true."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.all_public_symbols_aggregated]
expression_str = "all_public_symbols_aggregated"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.current_file_size]
expression_str = "current_file_size"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.args]
expression_str = "args"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."pipeline :: run_category_pipeline (& mut stdout , & dummy_content , & dummy_path , & args , & Some (config . clone ()) ,)"]
expression_str = "pipeline :: run_category_pipeline (& mut stdout , & dummy_content , & dummy_path , & args , & Some (config . clone ()) ,)"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'" Only used if `extract_global_level0_decls` is true."']
expression_str = '" Only used if `extract_global_level0_decls` is true."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'"f64"']
expression_str = '"f64"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.structs_output_dir]
expression_str = "structs_output_dir"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."self . struct_lattices . get_mut (& impl_for_type_name)"]
expression_str = "self . struct_lattices . get_mut (& impl_for_type_name)"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."generate_prelude (& src_dir , new_prelude_content , false , false)"]
expression_str = "generate_prelude (& src_dir , new_prelude_content , false , false)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."Some (0)"]
expression_str = "Some (0)"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."bins_config . paths . iter_mut ()"]
expression_str = "bins_config . paths . iter_mut ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"prelude-generator" . to_string ()']
expression_str = '"prelude-generator" . to_string ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."values . iter () . collect ()"]
expression_str = "values . iter () . collect ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."if remaining_decls . is_empty () { break ; }"]
expression_str = "if remaining_decls . is_empty () { break ; }"
depth = 3
used_types = []
other_types_count = 0
node_type = "If"

[expressions.all_collected_errors_aggregated]
expression_str = "all_collected_errors_aggregated"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."type_extractor :: extract_bag_of_types (project_root , & args . filter_names) . await ?"]
expression_str = "type_extractor :: extract_bag_of_types (project_root , & args . filter_names) . await ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'format ! ("Failed to write TOML to file: {:?}" , output_path)']
expression_str = 'format ! ("Failed to write TOML to file: {:?}" , output_path)'
depth = 5
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions.'format ! ("  -> Generated code validated successfully.\n") . as_bytes ()']
expression_str = 'format ! ("  -> Generated code validated successfully.\n") . as_bytes ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'if attr . path () . is_ident ("derive") { if let Meta :: List (meta_list) = & attr . meta { let tokens_str = meta_list . tokens . to_string () ; tokens_str . contains ("Parser") || tokens_str . contains ("Serialize") || tokens_str . contains ("Deserialize") } else { false } } else { false }']
expression_str = 'if attr . path () . is_ident ("derive") { if let Meta :: List (meta_list) = & attr . meta { let tokens_str = meta_list . tokens . to_string () ; tokens_str . contains ("Parser") || tokens_str . contains ("Serialize") || tokens_str . contains ("Deserialize") } else { false } } else { false }'
depth = 5
used_types = []
other_types_count = 0
node_type = "If"

[expressions."& * i . func"]
expression_str = "& * i . func"
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'project_root . file_name () . and_then (| s | s . to_str ()) . unwrap_or ("unknown_crate") . to_string ()']
expression_str = 'project_root . file_name () . and_then (| s | s . to_str ()) . unwrap_or ("unknown_crate") . to_string ()'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."i . segments"]
expression_str = "i . segments"
depth = 4
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'& format ! ("- Successfully processed: {}\n" , successful_files)']
expression_str = '& format ! ("- Successfully processed: {}\n" , successful_files)'
depth = 3
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'async { tokio :: fs :: write (& output_path , code . as_bytes ()) . await . context (format ! ("Failed to write struct {:?} to {:?}" , struct_name , output_path)) ? ; println ! ("  -> Wrote struct {:?} to {:?}" , struct_name , output_path) ; utils :: format_rust_code (& output_path) . await . context (format ! ("Struct {:?} formatting failed for {:?}" , struct_name , output_path)) ? ; println ! ("  -> Struct {:?} formatted successfully.\n" , struct_name) ; utils :: validate_rust_code (& output_path) . await . context (format ! ("Struct {:?} validation failed for {:?}" , struct_name , output_path)) ? ; println ! (r"  -> Struct {:?} validated successfully.\n" , struct_name) ; Ok (()) } . await']
expression_str = 'async { tokio :: fs :: write (& output_path , code . as_bytes ()) . await . context (format ! ("Failed to write struct {:?} to {:?}" , struct_name , output_path)) ? ; println ! ("  -> Wrote struct {:?} to {:?}" , struct_name , output_path) ; utils :: format_rust_code (& output_path) . await . context (format ! ("Struct {:?} formatting failed for {:?}" , struct_name , output_path)) ? ; println ! ("  -> Struct {:?} formatted successfully.\n" , struct_name) ; utils :: validate_rust_code (& output_path) . await . context (format ! ("Struct {:?} validation failed for {:?}" , struct_name , output_path)) ? ; println ! (r"  -> Struct {:?} validated successfully.\n" , struct_name) ; Ok (()) } . await'
depth = 4
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."self . map . get (id)"]
expression_str = "self . map . get (id)"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'if self . verbose > 0 { println ! ("Resolved Function Reference: id={}, type={}, crate={}, module={}, usage={}" , resolved_dep . id , resolved_dep . dependency_type , resolved_dep . crate_name , resolved_dep . module_path , resolved_dep . usage_count) ; }']
expression_str = 'if self . verbose > 0 { println ! ("Resolved Function Reference: id={}, type={}, crate={}, module={}, usage={}" , resolved_dep . id , resolved_dep . dependency_type , resolved_dep . crate_name , resolved_dep . module_path , resolved_dep . usage_count) ; }'
depth = 4
used_types = []
other_types_count = 0
node_type = "If"

[expressions."if default_config_path . exists () { Some (config_parser :: read_config (& default_config_path , & project_root) ?) } else { None }"]
expression_str = "if default_config_path . exists () { Some (config_parser :: read_config (& default_config_path , & project_root) ?) } else { None }"
depth = 4
used_types = []
other_types_count = 0
node_type = "If"

[expressions."contains_complex_attributes_for_const (i) || is_complex_type (& const_name)"]
expression_str = "contains_complex_attributes_for_const (i) || is_complex_type (& const_name)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Binary"

[expressions.'return Err (anyhow :: anyhow ! ("No file specified to process. Use --file argument.") ,)']
expression_str = 'return Err (anyhow :: anyhow ! ("No file specified to process. Use --file argument.") ,)'
depth = 5
used_types = []
other_types_count = 0
node_type = "Return"

[expressions.'" Timeout in seconds for the prelude generation process."']
expression_str = '" Timeout in seconds for the prelude generation process."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'PathBuf :: from (& args . path) . join (".prelude_cache")']
expression_str = 'PathBuf :: from (& args . path) . join (".prelude_cache")'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."quote ! { # constant }"]
expression_str = "quote ! { # constant }"
depth = 4
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions.'File :: open (& mapping_file_path) . await . context ("Failed to open mapping.toml") ?']
expression_str = 'File :: open (& mapping_file_path) . await . context ("Failed to open mapping.toml") ?'
depth = 5
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'tokio :: fs :: write (& output_path , content) . await . context (format ! ("Failed to write constant {:?} to {:?}" , const_name , output_path))']
expression_str = 'tokio :: fs :: write (& output_path , content) . await . context (format ! ("Failed to write constant {:?} to {:?}" , const_name , output_path))'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."tokio :: fs :: create_dir_all (file_path . parent () . unwrap ()) . await"]
expression_str = "tokio :: fs :: create_dir_all (file_path . parent () . unwrap ()) . await"
depth = 4
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."HashSet :: new ()"]
expression_str = "HashSet :: new ()"
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."tokio :: fs :: read_to_string (file_path)"]
expression_str = "tokio :: fs :: read_to_string (file_path)"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'| | format ! ("Failed to parse config file: {}" , config_path . display ())']
expression_str = '| | format ! ("Failed to parse config file: {}" , config_path . display ())'
depth = 4
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions.'if let Some (toml_output_path) = & args . output_toml_report { let collected_data = CollectedAnalysisData { expressions : all_expression_info . clone () , struct_lattices : all_struct_lattices . clone () , enum_lattices : all_enum_lattices . clone () , impl_lattices : all_impl_lattices . clone () , } ; let toml_content = toml :: to_string_pretty (& collected_data) . context ("Failed to serialize collected analysis data to TOML") ? ; fs :: write (toml_output_path , toml_content) . context (format ! ("Failed to write TOML report to {:?}" , toml_output_path)) ? ; println ! ("TOML report saved to {:?}" , toml_output_path) ; }']
expression_str = 'if let Some (toml_output_path) = & args . output_toml_report { let collected_data = CollectedAnalysisData { expressions : all_expression_info . clone () , struct_lattices : all_struct_lattices . clone () , enum_lattices : all_enum_lattices . clone () , impl_lattices : all_impl_lattices . clone () , } ; let toml_content = toml :: to_string_pretty (& collected_data) . context ("Failed to serialize collected analysis data to TOML") ? ; fs :: write (toml_output_path , toml_content) . context (format ! ("Failed to write TOML report to {:?}" , toml_output_path)) ? ; println ! ("TOML report saved to {:?}" , toml_output_path) ; }'
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions."prelude_generator :: use_extractor :: rustc_info :: get_rustc_info () ?"]
expression_str = "prelude_generator :: use_extractor :: rustc_info :: get_rustc_info () ?"
depth = 3
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'PipelineFunctor :: map (& ast_reconstruction_functor , writer , validated_file . clone ()) . await . context ("AST Reconstruction failed") ?']
expression_str = 'PipelineFunctor :: map (& ast_reconstruction_functor , writer , validated_file . clone ()) . await . context ("AST Reconstruction failed") ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.stats]
expression_str = "stats"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'& format ! ("- Skipped: {}\n" , skipped_files)']
expression_str = '& format ! ("- Skipped: {}\n" , skipped_files)'
depth = 3
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."& all_numerical_constants"]
expression_str = "& all_numerical_constants"
depth = 5
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."DependencyCollector :: new"]
expression_str = "DependencyCollector :: new"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.__result]
expression_str = "__result"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."fs :: create_dir_all (& destination_path) . await ?"]
expression_str = "fs :: create_dir_all (& destination_path) . await ?"
depth = 5
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."while let Some (current_src) = stack . pop () { let current_dst = dst . as_ref () . join (current_src . strip_prefix (src . as_ref ()) . unwrap ()) ; let mut entries = fs :: read_dir (& current_src) . await ? ; while let Some (entry) = entries . next_entry () . await ? { let entry_path = entry . path () ; let relative_path = entry_path . strip_prefix (& current_src) . unwrap () ; let destination_path = current_dst . join (relative_path) ; if entry_path . is_dir () { fs :: create_dir_all (& destination_path) . await ? ; stack . push (entry_path) ; } else { fs :: copy (& entry_path , & destination_path) . await ? ; } } }"]
expression_str = "while let Some (current_src) = stack . pop () { let current_dst = dst . as_ref () . join (current_src . strip_prefix (src . as_ref ()) . unwrap ()) ; let mut entries = fs :: read_dir (& current_src) . await ? ; while let Some (entry) = entries . next_entry () . await ? { let entry_path = entry . path () ; let relative_path = entry_path . strip_prefix (& current_src) . unwrap () ; let destination_path = current_dst . join (relative_path) ; if entry_path . is_dir () { fs :: create_dir_all (& destination_path) . await ? ; stack . push (entry_path) ; } else { fs :: copy (& entry_path , & destination_path) . await ? ; } } }"
depth = 2
used_types = []
other_types_count = 0
node_type = "While"

[expressions.'format ! ("- Skipped: {}\n" , skipped_files)']
expression_str = 'format ! ("- Skipped: {}\n" , skipped_files)'
depth = 4
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions."current_src . strip_prefix (src . as_ref ())"]
expression_str = "current_src . strip_prefix (src . as_ref ())"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."args . split_expanded_output_global_toml . clone ()"]
expression_str = "args . split_expanded_output_global_toml . clone ()"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."crate :: constant_storage :: numerical_constants :: write_numerical_constants_to_hierarchical_structure (& numerical_constants , & numerical_output_dir ,) . await"]
expression_str = "crate :: constant_storage :: numerical_constants :: write_numerical_constants_to_hierarchical_structure (& numerical_constants , & numerical_output_dir ,) . await"
depth = 3
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."fs :: File :: create (& file_path)"]
expression_str = "fs :: File :: create (& file_path)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.ClassifyUsesFunctor]
expression_str = "ClassifyUsesFunctor"
depth = 2
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'{ uses . insert ("use std::path::PathBuf;\n") ; }']
expression_str = '{ uses . insert ("use std::path::PathBuf;\n") ; }'
depth = 5
used_types = []
other_types_count = 0
node_type = "Block"

[expressions."collector . dependencies . len ()"]
expression_str = "collector . dependencies . len ()"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.remaining_decls]
expression_str = "remaining_decls"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."report_content . push_str (& format ! (\"  Expressions using '{}' with {} other type(s):\\n\" , target_type , other_types_count))"]
expression_str = '''report_content . push_str (& format ! ("  Expressions using '{}' with {} other type(s):\n" , target_type , other_types_count))'''
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."parsed_file . 1"]
expression_str = "parsed_file . 1"
depth = 4
used_types = []
other_types_count = 0
node_type = "Field"

[expressions."RE_SPLIT_IDENT . split (ident_str) . filter (| s | ! s . is_empty ())"]
expression_str = "RE_SPLIT_IDENT . split (ident_str) . filter (| s | ! s . is_empty ())"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'_args . test_report_output_file . clone () . unwrap_or_else (| | PathBuf :: from ("test_report.json"))']
expression_str = '_args . test_report_output_file . clone () . unwrap_or_else (| | PathBuf :: from ("test_report.json"))'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."numerical_constants . iter ()"]
expression_str = "numerical_constants . iter ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'if lattice_info . method_co_occurrences . is_empty () { report_content . push_str ("  No method co-occurrence data collected.\n") ; } else { let mut sorted_co_occurrences : Vec < (& BTreeSet < String > , & usize) > = lattice_info . method_co_occurrences . iter () . collect () ; sorted_co_occurrences . sort_by_key (| & (_ , count) | count) ; for (method_names , count) in sorted_co_occurrences { report_content . push_str (& format ! ("  - Co-occurring methods: {:?} (Count: {})\n" , method_names , count)) ; } }']
expression_str = 'if lattice_info . method_co_occurrences . is_empty () { report_content . push_str ("  No method co-occurrence data collected.\n") ; } else { let mut sorted_co_occurrences : Vec < (& BTreeSet < String > , & usize) > = lattice_info . method_co_occurrences . iter () . collect () ; sorted_co_occurrences . sort_by_key (| & (_ , count) | count) ; for (method_names , count) in sorted_co_occurrences { report_content . push_str (& format ! ("  - Co-occurring methods: {:?} (Count: {})\n" , method_names , count)) ; } }'
depth = 4
used_types = [
    "& usize",
    "& BTreeSet < String >",
    "(& BTreeSet < String > , & usize)",
    "Vec",
    "BTreeSet",
]
other_types_count = 5
node_type = "If"

[expressions."for item in & ast . items { if let Item :: Use (_) = item { has_use_statements = true ; } else { new_items . push (item . clone ()) ; } }"]
expression_str = "for item in & ast . items { if let Item :: Use (_) = item { has_use_statements = true ; } else { new_items . push (item . clone ()) ; } }"
depth = 2
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions."prelude_generator :: public_tests :: test_modify_crate_root_no_force_no_overwrite"]
expression_str = "prelude_generator :: public_tests :: test_modify_crate_root_no_force_no_overwrite"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.crate_name]
expression_str = "crate_name"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'format ! ("---\n--- Stage 2: Extracting Use Statements ---\n") . as_bytes ()']
expression_str = 'format ! ("---\n--- Stage 2: Extracting Use Statements ---\n") . as_bytes ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.output_dir]
expression_str = "output_dir"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'{ println ! ("No Level 0 structs found to process.") ; }']
expression_str = '{ println ! ("No Level 0 structs found to process.") ; }'
depth = 3
used_types = []
other_types_count = 0
node_type = "Block"

[expressions.Ok]
expression_str = "Ok"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'"dummy_results.json"']
expression_str = '"dummy_results.json"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."& config"]
expression_str = "& config"
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."writer . write_all (format ! (\"--- Stage 4: Hugging Face Validation ---\n\") . as_bytes ()) . await"]
expression_str = """
writer . write_all (format ! ("--- Stage 4: Hugging Face Validation ---
") . as_bytes ()) . await"""
depth = 3
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.'measurement :: record_function_entry ("PreprocessFunctor::map")']
expression_str = 'measurement :: record_function_entry ("PreprocessFunctor::map")'
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'tokio :: fs :: write (& public_symbols_output_path , json_content) . await . context (format ! ("Failed to write public symbols to file: {:?}" , public_symbols_output_path)) ?']
expression_str = 'tokio :: fs :: write (& public_symbols_output_path , json_content) . await . context (format ! ("Failed to write public symbols to file: {:?}" , public_symbols_output_path)) ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."& dst"]
expression_str = "& dst"
depth = 5
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'for decl in declarations { match & decl . item { split_expanded_lib :: DeclarationItem :: Const (s) => { if let Ok (item_const) = syn :: parse_str :: < syn :: ItemConst > (s) { if item_const . ident . to_string () . ends_with ("_NUM") { all_numerical_constants . push (item_const) ; } else { all_string_constants . push (item_const) ; } } } , _ => { } , } }']
expression_str = 'for decl in declarations { match & decl . item { split_expanded_lib :: DeclarationItem :: Const (s) => { if let Ok (item_const) = syn :: parse_str :: < syn :: ItemConst > (s) { if item_const . ident . to_string () . ends_with ("_NUM") { all_numerical_constants . push (item_const) ; } else { all_string_constants . push (item_const) ; } } } , _ => { } , } }'
depth = 4
used_types = ["ItemConst"]
other_types_count = 1
node_type = "ForLoop"

[expressions.'_args . test_report_input_file . clone () . ok_or_else (| | anyhow :: anyhow ! ("test_report_input_file is required when compile_tests is true"))']
expression_str = '_args . test_report_input_file . clone () . ok_or_else (| | anyhow :: anyhow ! ("test_report_input_file is required when compile_tests is true"))'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'fs :: remove_dir_all (& project_root) . context (format ! ("Failed to remove existing project root: {:?}" , project_root)) ?']
expression_str = 'fs :: remove_dir_all (& project_root) . context (format ! ("Failed to remove existing project root: {:?}" , project_root)) ?'
depth = 3
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.false]
expression_str = "false"
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'"Cast" . to_string ()']
expression_str = '"Cast" . to_string ()'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"Paren" . to_string ()']
expression_str = '"Paren" . to_string ()'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'classify_uses_functor . map (writer , use_statements) . await . context ("Classifying use statements failed")']
expression_str = 'classify_uses_functor . map (writer , use_statements) . await . context ("Classifying use statements failed")'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."decl . source_file . to_string_lossy ()"]
expression_str = "decl . source_file . to_string_lossy ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'if has_use_statements { let prelude_use : Item = syn :: parse_quote ! { use crate :: prelude ::*; } ; new_items . insert (0 , prelude_use) ; let mut new_ast = ast . clone () ; new_ast . items = new_items ; let new_content = prettyplease :: unparse (& new_ast) ; if dry_run { println ! ("[DRY RUN] Would modify file: {}\n---\n{}---" , path . display () , new_content) ; } else { if path . exists () && ! force { println ! ("  -> Skipping file modification for {} (file exists, use --force to overwrite)." , path . display ()) ; } else { println ! ("  -> Modifying file: {}" , path . display ()) ; println ! ("    -> Writing modified content to: {}" , path . display ()) ; fs :: write (path , new_content) ? ; } } }']
expression_str = 'if has_use_statements { let prelude_use : Item = syn :: parse_quote ! { use crate :: prelude ::*; } ; new_items . insert (0 , prelude_use) ; let mut new_ast = ast . clone () ; new_ast . items = new_items ; let new_content = prettyplease :: unparse (& new_ast) ; if dry_run { println ! ("[DRY RUN] Would modify file: {}\n---\n{}---" , path . display () , new_content) ; } else { if path . exists () && ! force { println ! ("  -> Skipping file modification for {} (file exists, use --force to overwrite)." , path . display ()) ; } else { println ! ("  -> Modifying file: {}" , path . display ()) ; println ! ("    -> Writing modified content to: {}" , path . display ()) ; fs :: write (path , new_content) ? ; } } }'
depth = 2
used_types = ["Item"]
other_types_count = 1
node_type = "If"

[expressions.'setup_test_crate (& project_root , "my-crate" , "use std::collections::HashMap;\nfn my_func() {}\n")']
expression_str = 'setup_test_crate (& project_root , "my-crate" , "use std::collections::HashMap;\nfn my_func() {}\n")'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'{ if func . attrs . iter () . any (| attr | attr . path () . is_ident ("test")) { test_functions . push (TestInfo { name : func . sig . ident . to_string () , file_path : file_path . to_path_buf () , }) ; } }']
expression_str = '{ if func . attrs . iter () . any (| attr | attr . path () . is_ident ("test")) { test_functions . push (TestInfo { name : func . sig . ident . to_string () , file_path : file_path . to_path_buf () , }) ; } }'
depth = 4
used_types = []
other_types_count = 0
node_type = "Block"

[expressions."visitor . visit_file (file)"]
expression_str = "visitor . visit_file (file)"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."for segment in type_path . path . segments . iter () { let ident_str = segment . ident . to_string () ; if is_complex_type (& ident_str) { return true ; } if let PathArguments :: AngleBracketed (angle_args) = & segment . arguments { for arg in angle_args . args . iter () { if let GenericArgument :: Type (inner_ty) = arg { if contains_complex_type_in_type (inner_ty) { return true ; } } } } }"]
expression_str = "for segment in type_path . path . segments . iter () { let ident_str = segment . ident . to_string () ; if is_complex_type (& ident_str) { return true ; } if let PathArguments :: AngleBracketed (angle_args) = & segment . arguments { for arg in angle_args . args . iter () { if let GenericArgument :: Type (inner_ty) = arg { if contains_complex_type_in_type (inner_ty) { return true ; } } } } }"
depth = 4
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions.'for segment in type_path . path . segments . iter () { let ident_str = segment . ident . to_string () ; match ident_str . as_str () { "HashMap" => { uses . insert ("use std::collections::HashMap;\n") ; } , "PathBuf" => { uses . insert ("use std::path::PathBuf;\n") ; } , "String" => { uses . insert ("use std::string::String;\n") ; } , "syn" => { uses . insert ("use syn::{ItemConst, ItemStruct};\n") ; uses . insert ("use syn::visit::Visit;\n") ; } , "clap" => { uses . insert ("use clap::{Parser, Args, Command};\n") ; } , "serde" => { uses . insert ("use serde::{Serialize, Deserialize};\n") ; } , _ => { } , } if let syn :: PathArguments :: AngleBracketed (angle_args) = & segment . arguments { for arg in angle_args . args . iter () { if let syn :: GenericArgument :: Type (syn :: Type :: Path (inner_type_path)) = arg { add_uses_from_type_path (inner_type_path , uses) ; } } } }']
expression_str = 'for segment in type_path . path . segments . iter () { let ident_str = segment . ident . to_string () ; match ident_str . as_str () { "HashMap" => { uses . insert ("use std::collections::HashMap;\n") ; } , "PathBuf" => { uses . insert ("use std::path::PathBuf;\n") ; } , "String" => { uses . insert ("use std::string::String;\n") ; } , "syn" => { uses . insert ("use syn::{ItemConst, ItemStruct};\n") ; uses . insert ("use syn::visit::Visit;\n") ; } , "clap" => { uses . insert ("use clap::{Parser, Args, Command};\n") ; } , "serde" => { uses . insert ("use serde::{Serialize, Deserialize};\n") ; } , _ => { } , } if let syn :: PathArguments :: AngleBracketed (angle_args) = & segment . arguments { for arg in angle_args . args . iter () { if let syn :: GenericArgument :: Type (syn :: Type :: Path (inner_type_path)) = arg { add_uses_from_type_path (inner_type_path , uses) ; } } } }'
depth = 3
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions.'if ! all_collected_errors_aggregated . is_empty () { let error_output_path = output_dir . join ("errors.json") ; let error_json_content = serde_json :: to_string_pretty (& all_collected_errors_aggregated) . context ("Failed to serialize errors to JSON") ? ; tokio :: fs :: write (& error_output_path , error_json_content) . await . context (format ! ("Failed to write errors to file: {:?}" , error_output_path)) ? ; eprintln ! ("{} errors collected during declaration extraction. See {:?}" , all_collected_errors_aggregated . len () , error_output_path) ; }']
expression_str = 'if ! all_collected_errors_aggregated . is_empty () { let error_output_path = output_dir . join ("errors.json") ; let error_json_content = serde_json :: to_string_pretty (& all_collected_errors_aggregated) . context ("Failed to serialize errors to JSON") ? ; tokio :: fs :: write (& error_output_path , error_json_content) . await . context (format ! ("Failed to write errors to file: {:?}" , error_output_path)) ? ; eprintln ! ("{} errors collected during declaration extraction. See {:?}" , all_collected_errors_aggregated . len () , error_output_path) ; }'
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions."fs :: write (crate_root . join (\"tests/integration_test.rs\") , r#\"\n            #[test]\n            fn integration_test() { }\n        \"# ,) ?"]
expression_str = """
fs :: write (crate_root . join ("tests/integration_test.rs") , r#"
            #[test]
            fn integration_test() { }
        "# ,) ?"""
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."toml :: from_str"]
expression_str = "toml :: from_str"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."let Some (current_src) = stack . pop ()"]
expression_str = "let Some (current_src) = stack . pop ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "Let"

[expressions."extract_test_cases_from_file (& file_path) ?"]
expression_str = "extract_test_cases_from_file (& file_path) ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."Some (duration . as_micros ())"]
expression_str = "Some (duration . as_micros ())"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."if ! self . current_method_calls . is_empty () { self . impl_lattice_info . add_co_occurrence (self . current_method_calls . clone ()) ; }"]
expression_str = "if ! self . current_method_calls . is_empty () { self . impl_lattice_info . add_co_occurrence (self . current_method_calls . clone ()) ; }"
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions.type_name]
expression_str = "type_name"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."ident_str . as_str ()"]
expression_str = "ident_str . as_str ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."tokio :: fs :: write (& output_file_path , reconstructed_code . as_bytes ()) . await"]
expression_str = "tokio :: fs :: write (& output_file_path , reconstructed_code . as_bytes ()) . await"
depth = 4
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."if let syn :: Expr :: Lit (expr_lit) = & * * expr { match & expr_lit . lit { Lit :: Int (lit_int) => lit_int . base10_digits () . to_string () , Lit :: Float (lit_float) => lit_float . base10_digits () . to_string () , _ => String :: new () , } } else { String :: new () }"]
expression_str = "if let syn :: Expr :: Lit (expr_lit) = & * * expr { match & expr_lit . lit { Lit :: Int (lit_int) => lit_int . base10_digits () . to_string () , Lit :: Float (lit_float) => lit_float . base10_digits () . to_string () , _ => String :: new () , } } else { String :: new () }"
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'{ let mut sorted_co_occurrences : Vec < (& BTreeSet < String > , & usize) > = lattice_info . field_co_occurrences . iter () . collect () ; sorted_co_occurrences . sort_by_key (| & (_ , count) | count) ; for (field_types , count) in sorted_co_occurrences { report_content . push_str (& format ! ("  - Co-occurring fields: {:?} (Count: {})\n" , field_types , count)) ; } }']
expression_str = '{ let mut sorted_co_occurrences : Vec < (& BTreeSet < String > , & usize) > = lattice_info . field_co_occurrences . iter () . collect () ; sorted_co_occurrences . sort_by_key (| & (_ , count) | count) ; for (field_types , count) in sorted_co_occurrences { report_content . push_str (& format ! ("  - Co-occurring fields: {:?} (Count: {})\n" , field_types , count)) ; } }'
depth = 5
used_types = [
    "Vec",
    "(& BTreeSet < String > , & usize)",
    "& usize",
    "BTreeSet",
    "& BTreeSet < String >",
]
other_types_count = 5
node_type = "Block"

[expressions.'"i16"']
expression_str = '"i16"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."self . add_ident_to_bag (& i . sig . ident)"]
expression_str = "self . add_ident_to_bag (& i . sig . ident)"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."write_numerical_constants_to_hierarchical_structure (& all_numerical_constants , & numerical_output_dir) . await"]
expression_str = "write_numerical_constants_to_hierarchical_structure (& all_numerical_constants , & numerical_output_dir) . await"
depth = 3
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."new_ast . items = new_items"]
expression_str = "new_ast . items = new_items"
depth = 3
used_types = []
other_types_count = 0
node_type = "Assign"

[expressions."sorted_depth_keys . sort_unstable ()"]
expression_str = "sorted_depth_keys . sort_unstable ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"The script will navigate to each identified Rust crate and run `cargo test` within it.\n\n"']
expression_str = '"The script will navigate to each identified Rust crate and run `cargo test` within it.\n\n"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'writer . write_all (format ! ("  -> Short ID for hf-validator project: {}\n" , short_id) . as_bytes ()) . await']
expression_str = 'writer . write_all (format ! ("  -> Short ID for hf-validator project: {}\n" , short_id) . as_bytes ()) . await'
depth = 5
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."constant . ident"]
expression_str = "constant . ident"
depth = 4
used_types = []
other_types_count = 0
node_type = "Field"

[expressions."let syn :: Type :: Path (type_path) = & field . ty"]
expression_str = "let syn :: Type :: Path (type_path) = & field . ty"
depth = 4
used_types = []
other_types_count = 0
node_type = "Let"

[expressions."if let Type :: Path (type_path) = & field . ty { for segment in type_path . path . segments . iter () { let ident_str = segment . ident . to_string () ; if is_complex_type (& ident_str) { return true ; } if let PathArguments :: AngleBracketed (angle_args) = & segment . arguments { for arg in angle_args . args . iter () { if let GenericArgument :: Type (inner_ty) = arg { if contains_complex_type_in_type (inner_ty) { return true ; } } } } } }"]
expression_str = "if let Type :: Path (type_path) = & field . ty { for segment in type_path . path . segments . iter () { let ident_str = segment . ident . to_string () ; if is_complex_type (& ident_str) { return true ; } if let PathArguments :: AngleBracketed (angle_args) = & segment . arguments { for arg in angle_args . args . iter () { if let GenericArgument :: Type (inner_ty) = arg { if contains_complex_type_in_type (inner_ty) { return true ; } } } } } }"
depth = 3
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'project_root . join ("generated/string_constants")']
expression_str = 'project_root . join ("generated/string_constants")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."type_map . get (& const_name) . and_then (| info | info . layer)"]
expression_str = "type_map . get (& const_name) . and_then (| info | info . layer)"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."& numerical_constants"]
expression_str = "& numerical_constants"
depth = 5
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'"trait_alias" . to_string ()']
expression_str = '"trait_alias" . to_string ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."std :: env :: set_current_dir"]
expression_str = "std :: env :: set_current_dir"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'"Failed to create output directory"']
expression_str = '"Failed to create output directory"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."type_map . iter ()"]
expression_str = "type_map . iter ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."crate :: constant_storage :: string_constants :: write_string_constants_to_hierarchical_structure (& all_string_constants , & string_output_dir)"]
expression_str = "crate :: constant_storage :: string_constants :: write_string_constants_to_hierarchical_structure (& all_string_constants , & string_output_dir)"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'fs :: remove_dir_all (& project_root) . context (format ! ("Failed to remove existing project root: {:?}" , project_root))']
expression_str = 'fs :: remove_dir_all (& project_root) . context (format ! ("Failed to remove existing project root: {:?}" , project_root))'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'if files_to_process . is_empty () { println ! ("No expanded files provided for processing.") ; return Ok (()) ; }']
expression_str = 'if files_to_process . is_empty () { println ! ("No expanded files provided for processing.") ; return Ok (()) ; }'
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'measurement :: record_function_exit ("HuggingFaceValidatorFunctor::map")']
expression_str = 'measurement :: record_function_exit ("HuggingFaceValidatorFunctor::map")'
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."| | EnumLatticeInfo :: new (enum_name . clone ())"]
expression_str = "| | EnumLatticeInfo :: new (enum_name . clone ())"
depth = 3
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions."& stats . column_stats"]
expression_str = "& stats . column_stats"
depth = 3
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'code . push_str ("    let mut column_stats = HashMap::new();\n")']
expression_str = 'code . push_str ("    let mut column_stats = HashMap::new();\n")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'snippet_length_stats . insert ("function" . to_string () , (39 , 83 , 434 , 6))']
expression_str = 'snippet_length_stats . insert ("function" . to_string () , (39 , 83 , 434 , 6))'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'" Comma-separated list of crate names to exclude from processing."']
expression_str = '" Comma-separated list of crate names to exclude from processing."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."self . current_method_calls . is_empty ()"]
expression_str = "self . current_method_calls . is_empty ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."| s | ! s . is_empty ()"]
expression_str = "| s | ! s . is_empty ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions."parsed_file . 0 . clone ()"]
expression_str = "parsed_file . 0 . clone ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."tokio :: fs :: read_dir (& output_path) . await ?"]
expression_str = "tokio :: fs :: read_dir (& output_path) . await ?"
depth = 4
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."Ok (source_code)"]
expression_str = "Ok (source_code)"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."results . iter () . filter (| r | matches ! (r . status , FileProcessingStatus :: Success)) . count ()"]
expression_str = "results . iter () . filter (| r | matches ! (r . status , FileProcessingStatus :: Success)) . count ()"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."type_map . iter () . collect ()"]
expression_str = "type_map . iter () . collect ()"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"str"']
expression_str = '"str"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'add_std_lib_symbol (& mut symbols , "fs" , "module" , Some ("std"))']
expression_str = 'add_std_lib_symbol (& mut symbols , "fs" , "module" , Some ("std"))'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'" Specify the stage of the pipeline to run"']
expression_str = '" Specify the stage of the pipeline to run"'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'"// This module contains extracted struct declarations.\n// It is automatically generated.\n\n"']
expression_str = '"// This module contains extracted struct declarations.\n// It is automatically generated.\n\n"'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."for decl in remaining_decls . into_iter () { let has_unresolved_deps = decl . referenced_types . iter () . any (| dep | { ! current_layer_idents . contains (dep) && ! layered_decls . values () . flatten () . any (| d | d . get_identifier () == * dep) }) ; if ! has_unresolved_deps { current_layer_idents . insert (decl . get_identifier ()) ; current_layer_decls . push (decl) ; } else { next_remaining_decls . push (decl) ; } }"]
expression_str = "for decl in remaining_decls . into_iter () { let has_unresolved_deps = decl . referenced_types . iter () . any (| dep | { ! current_layer_idents . contains (dep) && ! layered_decls . values () . flatten () . any (| d | d . get_identifier () == * dep) }) ; if ! has_unresolved_deps { current_layer_idents . insert (decl . get_identifier ()) ; current_layer_decls . push (decl) ; } else { next_remaining_decls . push (decl) ; } }"
depth = 3
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions."if current_layer_num > 8 { break ; }"]
expression_str = "if current_layer_num > 8 { break ; }"
depth = 3
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'"Unknown" . to_string ()']
expression_str = '"Unknown" . to_string ()'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."let Some (file_name) = args . file . as_ref ()"]
expression_str = "let Some (file_name) = args . file . as_ref ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "Let"

[expressions."gem_entry . name . clone ()"]
expression_str = "gem_entry . name . clone ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.current_crate_name]
expression_str = "current_crate_name"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."self . expressions . insert (expr_str , info)"]
expression_str = "self . expressions . insert (expr_str , info)"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'for (node_type , count) in & stats . node_type_counts { code . push_str (& format ! ("    node_type_counts.insert(\"{}\".to_string(), {});\n" , node_type , count) ,) ; }']
expression_str = 'for (node_type , count) in & stats . node_type_counts { code . push_str (& format ! ("    node_type_counts.insert(\"{}\".to_string(), {});\n" , node_type , count) ,) ; }'
depth = 2
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions.'if use_statement . contains ("git") { current_use_statement . git_details = Some (pipeline_traits :: GitDetails :: Info (pipeline_traits :: GitInfo { repo_url : "inferred_from_use" . to_string () , branch : "inferred_from_use" . to_string () , commit_hash : "inferred_from_use" . to_string () , })) ; }']
expression_str = 'if use_statement . contains ("git") { current_use_statement . git_details = Some (pipeline_traits :: GitDetails :: Info (pipeline_traits :: GitInfo { repo_url : "inferred_from_use" . to_string () , branch : "inferred_from_use" . to_string () , commit_hash : "inferred_from_use" . to_string () , })) ; }'
depth = 5
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'if let Some (segment) = expr_path . path . segments . last () { let resolved_dep = self . symbol_map . resolve_and_increment_usage (segment . ident . to_string () , "function" . to_string () , self . crate_name . clone () , self . module_path . clone () ,) ; if self . verbose > 0 { println ! ("Resolved Function Reference: id={}, type={}, crate={}, module={}, usage={}" , resolved_dep . id , resolved_dep . dependency_type , resolved_dep . crate_name , resolved_dep . module_path , resolved_dep . usage_count) ; } }']
expression_str = 'if let Some (segment) = expr_path . path . segments . last () { let resolved_dep = self . symbol_map . resolve_and_increment_usage (segment . ident . to_string () , "function" . to_string () , self . crate_name . clone () , self . module_path . clone () ,) ; if self . verbose > 0 { println ! ("Resolved Function Reference: id={}, type={}, crate={}, module={}, usage={}" , resolved_dep . id , resolved_dep . dependency_type , resolved_dep . crate_name , resolved_dep . module_path , resolved_dep . usage_count) ; } }'
depth = 3
used_types = []
other_types_count = 0
node_type = "If"

[expressions."& * i . cond"]
expression_str = "& * i . cond"
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'_args . use_statements_output_dir . clone () . ok_or_else (| | anyhow :: anyhow ! ("use_statements_output_dir is required when extract_use_statements is true"))']
expression_str = '_args . use_statements_output_dir . clone () . ok_or_else (| | anyhow :: anyhow ! ("use_statements_output_dir is required when extract_use_statements is true"))'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"Index"']
expression_str = '"Index"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'{ let error_message = format ! ("Failed to parse expanded code for {}: {}" , file_path . display () , e) ; writer . write_all (format ! ("        -> {}\n" , error_message) . as_bytes ()) . await . context ("Failed to write parsing error to writer") ? ; let error_sample = ErrorSample { file_path : file_path . to_path_buf () , rustc_version : rustc_info . version . clone () , rustc_host : rustc_info . host . clone () , error_message : error_message . clone () , error_type : "SynParsingFailed" . to_string () , code_snippet : Some (relevant_expanded_code . to_string ()) , timestamp : Utc :: now () , context : None , } ; Ok ((syn :: parse_file ("") . unwrap () , Some (error_sample))) }']
expression_str = '{ let error_message = format ! ("Failed to parse expanded code for {}: {}" , file_path . display () , e) ; writer . write_all (format ! ("        -> {}\n" , error_message) . as_bytes ()) . await . context ("Failed to write parsing error to writer") ? ; let error_sample = ErrorSample { file_path : file_path . to_path_buf () , rustc_version : rustc_info . version . clone () , rustc_host : rustc_info . host . clone () , error_message : error_message . clone () , error_type : "SynParsingFailed" . to_string () , code_snippet : Some (relevant_expanded_code . to_string ()) , timestamp : Utc :: now () , context : None , } ; Ok ((syn :: parse_file ("") . unwrap () , Some (error_sample))) }'
depth = 3
used_types = []
other_types_count = 0
node_type = "Block"

[expressions."modify_crate_root (& src_dir , true , false)"]
expression_str = "modify_crate_root (& src_dir , true , false)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."if lib_rs . exists () { lib_rs } else if main_rs . exists () { main_rs } else { return Ok (()) ; }"]
expression_str = "if lib_rs . exists () { lib_rs } else if main_rs . exists () { main_rs } else { return Ok (()) ; }"
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions."self . struct_lattices . entry (struct_name . clone ())"]
expression_str = "self . struct_lattices . entry (struct_name . clone ())"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."entry . count"]
expression_str = "entry . count"
depth = 3
used_types = []
other_types_count = 0
node_type = "Field"

[expressions."fs :: read_to_string (& args . results_file)"]
expression_str = "fs :: read_to_string (& args . results_file)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."r#\"\n            #[test]\n            fn lib_test() { }\n            #[cfg(test)]\n            mod lib_tests {\n                #[test]\n                fn nested_lib_test() { }\n            }\n        \"#"]
expression_str = """
r#"
            #[test]
            fn lib_test() { }
            #[cfg(test)]
            mod lib_tests {
                #[test]
                fn nested_lib_test() { }
            }
        "#"""
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."prelude_generator :: public_tests :: test_modify_crate_root_already_has_prelude"]
expression_str = "prelude_generator :: public_tests :: test_modify_crate_root_already_has_prelude"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."parse_arguments_and_config ()"]
expression_str = "parse_arguments_and_config ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."syn :: parse_quote ! { pub mod prelude ; }"]
expression_str = "syn :: parse_quote ! { pub mod prelude ; }"
depth = 3
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions."stdout . lines ()"]
expression_str = "stdout . lines ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."type_usage_analyzer :: analyze_type_usage (& args) . await"]
expression_str = "type_usage_analyzer :: analyze_type_usage (& args) . await"
depth = 5
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."syn :: visit :: visit_item_const (self , i)"]
expression_str = "syn :: visit :: visit_item_const (self , i)"
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."generate_report (& results)"]
expression_str = "generate_report (& results)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."all_numerical_constants . push (constant . clone ())"]
expression_str = "all_numerical_constants . push (constant . clone ())"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"## How to Run Tests\n"']
expression_str = '"## How to Run Tests\n"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'writer . write_all (format ! ("  -> Dataset path: {:#?}\n" , dataset_path) . as_bytes ()) . await ?']
expression_str = 'writer . write_all (format ! ("  -> Dataset path: {:#?}\n" , dataset_path) . as_bytes ()) . await ?'
depth = 4
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."output . status . success ()"]
expression_str = "output . status . success ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."matches ! (r . status , FileProcessingStatus :: Failed { .. })"]
expression_str = "matches ! (r . status , FileProcessingStatus :: Failed { .. })"
depth = 5
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions.'{ let mut sorted_co_occurrences : Vec < (& BTreeSet < String > , & usize) > = lattice_info . variant_type_co_occurrences . iter () . collect () ; sorted_co_occurrences . sort_by_key (| & (_ , count) | count) ; for (variant_types , count) in sorted_co_occurrences { report_content . push_str (& format ! ("  - Co-occurring variant types: {:?} (Count: {})\n" , variant_types , count)) ; } }']
expression_str = '{ let mut sorted_co_occurrences : Vec < (& BTreeSet < String > , & usize) > = lattice_info . variant_type_co_occurrences . iter () . collect () ; sorted_co_occurrences . sort_by_key (| & (_ , count) | count) ; for (variant_types , count) in sorted_co_occurrences { report_content . push_str (& format ! ("  - Co-occurring variant types: {:?} (Count: {})\n" , variant_types , count)) ; } }'
depth = 5
used_types = [
    "BTreeSet",
    "& usize",
    "Vec",
    "& BTreeSet < String >",
    "(& BTreeSet < String > , & usize)",
]
other_types_count = 5
node_type = "Block"

[expressions.'node_type_counts . insert ("import" . to_string () , 18)']
expression_str = 'node_type_counts . insert ("import" . to_string () , 18)'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'" Enable verbose output"']
expression_str = '" Enable verbose output"'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'anyhow :: anyhow ! ("generated_decls_output_dir is required")']
expression_str = 'anyhow :: anyhow ! ("generated_decls_output_dir is required")'
depth = 5
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions.'Args { dry_run : false , path : project_root . clone () , exclude_crates : vec ! [] , report : false , results_file : Some (project_root . join ("results.json")) , cache_report : false , timeout : None , force : true , .. Default :: default () }']
expression_str = 'Args { dry_run : false , path : project_root . clone () , exclude_crates : vec ! [] , report : false , results_file : Some (project_root . join ("results.json")) , cache_report : false , timeout : None , force : true , .. Default :: default () }'
depth = 2
used_types = []
other_types_count = 0
node_type = "Struct"

[expressions."decl . crate_name"]
expression_str = "decl . crate_name"
depth = 5
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'"generated/hf_dataset_output/mapping.toml"']
expression_str = '"generated/hf_dataset_output/mapping.toml"'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'_args . ast_analysis_path . clone () . ok_or_else (| | anyhow :: anyhow ! ("ast_analysis_path is required when analyze_ast is true"))']
expression_str = '_args . ast_analysis_path . clone () . ok_or_else (| | anyhow :: anyhow ! ("ast_analysis_path is required when analyze_ast is true"))'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."& format ! (\"\\n### Enum: '{}' (Expressions Analyzed: {}) ###\\n\" , enum_name , lattice_info . total_expressions_analyzed)"]
expression_str = '''& format ! ("\n### Enum: '{}' (Expressions Analyzed: {}) ###\n" , enum_name , lattice_info . total_expressions_analyzed)'''
depth = 5
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.'"unknown"']
expression_str = '"unknown"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."prelude_generator :: public_tests :: test_generate_report_empty_results"]
expression_str = "prelude_generator :: public_tests :: test_generate_report_empty_results"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."{ PathBuf :: from (& args . path) }"]
expression_str = "{ PathBuf :: from (& args . path) }"
depth = 3
used_types = []
other_types_count = 0
node_type = "Block"

[expressions.'" Path to output the global declarations TOML file for split-expanded-bin."']
expression_str = '" Path to output the global declarations TOML file for split-expanded-bin."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'{ if path . exists () && ! force { println ! ("  -> Skipping file modification for {} (file exists, use --force to overwrite)." , path . display ()) ; } else { println ! ("  -> Modifying file: {}" , path . display ()) ; println ! ("    -> Writing modified content to: {}" , path . display ()) ; fs :: write (path , new_content) ? ; } }']
expression_str = '{ if path . exists () && ! force { println ! ("  -> Skipping file modification for {} (file exists, use --force to overwrite)." , path . display ()) ; } else { println ! ("  -> Modifying file: {}" , path . display ()) ; println ! ("    -> Writing modified content to: {}" , path . display ()) ; fs :: write (path , new_content) ? ; } }'
depth = 4
used_types = []
other_types_count = 0
node_type = "Block"

[expressions."prelude_generator :: public_tests :: test_process_crates_report_only ()"]
expression_str = "prelude_generator :: public_tests :: test_process_crates_report_only ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."& segment . ident"]
expression_str = "& segment . ident"
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.version_line]
expression_str = "version_line"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'format ! ("generated/hf_validator_projects/{}" , short_id)']
expression_str = 'format ! ("generated/hf_validator_projects/{}" , short_id)'
depth = 5
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions.'if ! output . status . success () { anyhow :: bail ! ("rustc --version --verbose failed: {}" , String :: from_utf8_lossy (& output . stderr)) ; }']
expression_str = 'if ! output . status . success () { anyhow :: bail ! ("rustc --version --verbose failed: {}" , String :: from_utf8_lossy (& output . stderr)) ; }'
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'{ eprintln ! ("Warning: Could not parse file {}: {:?}" , path . display () , e) ; continue ; }']
expression_str = '{ eprintln ! ("Warning: Could not parse file {}: {:?}" , path . display () , e) ; continue ; }'
depth = 4
used_types = []
other_types_count = 0
node_type = "Block"

[expressions."error_collection . write_to_file (& errors_json_path)"]
expression_str = "error_collection . write_to_file (& errors_json_path)"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"Group"']
expression_str = '"Group"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.types]
expression_str = "types"
depth = 2
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'if let Ok (file) = syn :: parse_file (& content) { bag_of_words_visitor . visit_file (& file) ; files_processed_for_bow += 1 ; } else { eprintln ! (r"Warning: Could not parse file for bag of words analysis: {}" , path . display ()) ; }']
expression_str = 'if let Ok (file) = syn :: parse_file (& content) { bag_of_words_visitor . visit_file (& file) ; files_processed_for_bow += 1 ; } else { eprintln ! (r"Warning: Could not parse file for bag of words analysis: {}" , path . display ()) ; }'
depth = 4
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'"Block"']
expression_str = '"Block"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."PipelineFunctor :: map (& ast_reconstruction_functor , writer , validated_file . clone () ,)"]
expression_str = "PipelineFunctor :: map (& ast_reconstruction_functor , writer , validated_file . clone () ,)"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'"Failed to read file content"']
expression_str = '"Failed to read file content"'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."entry . call_count"]
expression_str = "entry . call_count"
depth = 3
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'"// No constant declarations found in this module.\n" . to_string ()']
expression_str = '"// No constant declarations found in this module.\n" . to_string ()'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'line_stats . insert ("function" . to_string () , (18 , 208 , 905 , 6))']
expression_str = 'line_stats . insert ("function" . to_string () , (18 , 208 , 905 , 6))'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."Args { dry_run : false , path : project_root . clone () , exclude_crates : vec ! [] , report : true , results_file : Some (results_json_path . clone ()) , cache_report : false , timeout : None , force : false , .. Default :: default () }"]
expression_str = "Args { dry_run : false , path : project_root . clone () , exclude_crates : vec ! [] , report : true , results_file : Some (results_json_path . clone ()) , cache_report : false , timeout : None , force : false , .. Default :: default () }"
depth = 2
used_types = []
other_types_count = 0
node_type = "Struct"

[expressions.'"macro"']
expression_str = '"macro"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'writer . write_all (format ! ("  -> Extracted {} use statements.\n" , use_statements . 0 . len ()) . as_bytes ())']
expression_str = 'writer . write_all (format ! ("  -> Extracted {} use statements.\n" , use_statements . 0 . len ()) . as_bytes ())'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."stats . node_type_counts"]
expression_str = "stats . node_type_counts"
depth = 4
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'serde_json :: to_string_pretty (& all_public_symbols) . context ("Failed to serialize public symbols to JSON")']
expression_str = 'serde_json :: to_string_pretty (& all_public_symbols) . context ("Failed to serialize public symbols to JSON")'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."let syn :: Pat :: TupleStruct (pat_tuple_struct) = & * expr_let . pat"]
expression_str = "let syn :: Pat :: TupleStruct (pat_tuple_struct) = & * expr_let . pat"
depth = 4
used_types = []
other_types_count = 0
node_type = "Let"

[expressions.'writer . write_all (format ! ("--- Stage 5: AST Reconstruction from Hugging Face Dataset (Mock) ---\n") . as_bytes ()) . await ?']
expression_str = 'writer . write_all (format ! ("--- Stage 5: AST Reconstruction from Hugging Face Dataset (Mock) ---\n") . as_bytes ()) . await ?'
depth = 4
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'if args . cache_report { let cache_dir = PathBuf :: from (& args . path) . join (".prelude_cache") ; if cache_dir . exists () { let count = fs :: read_dir (& cache_dir) ? . count () ; println ! ("Prelude cache at {} contains {} items." , cache_dir . display () , count) ; } else { println ! ("Prelude cache directory not found at {}." , cache_dir . display ()) ; } return Ok (()) ; }']
expression_str = 'if args . cache_report { let cache_dir = PathBuf :: from (& args . path) . join (".prelude_cache") ; if cache_dir . exists () { let count = fs :: read_dir (& cache_dir) ? . count () ; println ! ("Prelude cache at {} contains {} items." , cache_dir . display () , count) ; } else { println ! ("Prelude cache directory not found at {}." , cache_dir . display ()) ; } return Ok (()) ; }'
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions."syn :: parse_quote ! { # [test] async fn generated_test_2 () -> Result < () > { Ok (()) } }"]
expression_str = "syn :: parse_quote ! { # [test] async fn generated_test_2 () -> Result < () > { Ok (()) } }"
depth = 2
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions."prelude_generator :: public_tests :: test_modify_crate_root_main_rs"]
expression_str = "prelude_generator :: public_tests :: test_modify_crate_root_main_rs"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'"vec!"']
expression_str = '"vec!"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'writer . write_all (format ! ("  -> Generated code validated successfully.\n") . as_bytes ())']
expression_str = 'writer . write_all (format ! ("  -> Generated code validated successfully.\n") . as_bytes ())'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'" Analyze the AST of Rust files in a given path."']
expression_str = '" Analyze the AST of Rust files in a given path."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."current_file_size = 0"]
expression_str = "current_file_size = 0"
depth = 4
used_types = []
other_types_count = 0
node_type = "Assign"

[expressions.'Command :: new ("rustfmt") . arg (file_path) . arg ("--edition=2021") . arg ("--emit=files") . output () . await']
expression_str = 'Command :: new ("rustfmt") . arg (file_path) . arg ("--edition=2021") . arg ("--emit=files") . output () . await'
depth = 4
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."{ format ! (\"use syn::{{visit::Visit, ItemConst, ItemFn, ItemStruct, ItemEnum, ItemStatic, Item}};\n{}\" , content) }"]
expression_str = """
{ format ! ("use syn::{{visit::Visit, ItemConst, ItemFn, ItemStruct, ItemEnum, ItemStatic, Item}};
{}" , content) }"""
depth = 5
used_types = []
other_types_count = 0
node_type = "Block"

[expressions.write_numerical_constants_to_hierarchical_structure]
expression_str = "write_numerical_constants_to_hierarchical_structure"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."self . impl_lattices . entry (impl_for_type_name . clone ()) . or_insert_with (| | ImplLatticeInfo :: new (impl_for_type_name . clone ()))"]
expression_str = "self . impl_lattices . entry (impl_for_type_name . clone ()) . or_insert_with (| | ImplLatticeInfo :: new (impl_for_type_name . clone ()))"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."duration . as_micros ()"]
expression_str = "duration . as_micros ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."quote :: quote ! { # structure } . to_string ()"]
expression_str = "quote :: quote ! { # structure } . to_string ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'writer . write_all (format ! ("  -> Extracted {} use statements.\n" , use_statements . 0 . len ()) . as_bytes ()) . await']
expression_str = 'writer . write_all (format ! ("  -> Extracted {} use statements.\n" , use_statements . 0 . len ()) . as_bytes ()) . await'
depth = 3
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.'for entry in WalkDir :: new (repo_root) . into_iter () . filter_map (| e | e . ok ()) . filter (| e | e . file_type () . is_file () && e . path () . extension () . map_or (false , | ext | ext == "rs")) { let file_path = entry . path () ; println ! ("  -> Processing file for tests: {}" , file_path . display ()) ; match extract_test_cases_from_file (file_path) { Ok (functions) => { for func_info in functions { if seen_test_names . insert (func_info . name . clone ()) { all_test_functions . push (func_info) ; } } } Err (e) => { eprintln ! ("Warning: Could not extract tests from {}: {}" , file_path . display () , e) ; } } }']
expression_str = 'for entry in WalkDir :: new (repo_root) . into_iter () . filter_map (| e | e . ok ()) . filter (| e | e . file_type () . is_file () && e . path () . extension () . map_or (false , | ext | ext == "rs")) { let file_path = entry . path () ; println ! ("  -> Processing file for tests: {}" , file_path . display ()) ; match extract_test_cases_from_file (file_path) { Ok (functions) => { for func_info in functions { if seen_test_names . insert (func_info . name . clone ()) { all_test_functions . push (func_info) ; } } } Err (e) => { eprintln ! ("Warning: Could not extract tests from {}: {}" , file_path . display () , e) ; } } }'
depth = 2
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions."contains_complex_fields (i)"]
expression_str = "contains_complex_fields (i)"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'"" . to_string ()']
expression_str = '"" . to_string ()'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."! self . current_field_accesses . is_empty ()"]
expression_str = "! self . current_field_accesses . is_empty ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "Unary"

[expressions.'"Break"']
expression_str = '"Break"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."prelude_generator :: public_tests :: test_generate_prelude_no_force_no_overwrite () ?"]
expression_str = "prelude_generator :: public_tests :: test_generate_prelude_no_force_no_overwrite () ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."| f | f . sig . ident . to_string ()"]
expression_str = "| f | f . sig . ident . to_string ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions."tokio :: fs :: create_dir_all (& string_output_dir) . await"]
expression_str = "tokio :: fs :: create_dir_all (& string_output_dir) . await"
depth = 4
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.'"--path"']
expression_str = '"--path"'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'"config.toml"']
expression_str = '"config.toml"'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'"errors.json"']
expression_str = '"errors.json"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.host_line]
expression_str = "host_line"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'async move { writer . write_all (format ! ("--- Inspecting: {} ---\n" , self . label) . as_bytes ()) . await ? ; writer . write_all (format ! ("{:#?}\n" , input) . as_bytes ()) . await ? ; Ok (input) }']
expression_str = 'async move { writer . write_all (format ! ("--- Inspecting: {} ---\n" , self . label) . as_bytes ()) . await ? ; writer . write_all (format ! ("{:#?}\n" , input) . as_bytes ()) . await ? ; Ok (input) }'
depth = 3
used_types = []
other_types_count = 0
node_type = "Async"

[expressions.'PathBuf :: from ("test_report.json")']
expression_str = 'PathBuf :: from ("test_report.json")'
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'add_std_lib_symbol (& mut symbols , "HashMap" , "type" , Some ("std::collections"))']
expression_str = 'add_std_lib_symbol (& mut symbols , "HashMap" , "type" , Some ("std::collections"))'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'format ! ("    rust_version_counts.insert(\"{}\".to_string(), {});\n" , version , count)']
expression_str = 'format ! ("    rust_version_counts.insert(\"{}\".to_string(), {});\n" , version , count)'
depth = 5
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions.'mod_item . ident == "prelude"']
expression_str = 'mod_item . ident == "prelude"'
depth = 5
used_types = []
other_types_count = 0
node_type = "Binary"

[expressions."generated_decl_strings . is_empty ()"]
expression_str = "generated_decl_strings . is_empty ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."all_string_constants . push (constant . clone ())"]
expression_str = "all_string_constants . push (constant . clone ())"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"ParseFunctor::map"']
expression_str = '"ParseFunctor::map"'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'report_content . push_str ("\n\nStruct Lattice Information\n")']
expression_str = 'report_content . push_str ("\n\nStruct Lattice Information\n")'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."ParsedFile (parsed_code , file_path)"]
expression_str = "ParsedFile (parsed_code , file_path)"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'if ! output . status . success () { return Err (anyhow :: anyhow ! ("git config user.email failed: {}\nStderr: {}" , String :: from_utf8_lossy (& output . status . code () . unwrap_or (- 1) . to_string () . as_bytes ()) , String :: from_utf8_lossy (& output . stderr))) ; }']
expression_str = 'if ! output . status . success () { return Err (anyhow :: anyhow ! ("git config user.email failed: {}\nStderr: {}" , String :: from_utf8_lossy (& output . status . code () . unwrap_or (- 1) . to_string () . as_bytes ()) , String :: from_utf8_lossy (& output . stderr))) ; }'
depth = 4
used_types = []
other_types_count = 0
node_type = "If"

[expressions."host_line . and_then (| line | line . split_whitespace () . nth (1))"]
expression_str = "host_line . and_then (| line | line . split_whitespace () . nth (1))"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."self . type_map . entry (const_name . clone ()) . or_insert_with (| | TypeInfo { count : 0 , layer : Some (0) })"]
expression_str = "self . type_map . entry (const_name . clone ()) . or_insert_with (| | TypeInfo { count : 0 , layer : Some (0) })"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."enum_name . clone ()"]
expression_str = "enum_name . clone ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."tokenize_ident_to_subwords (& ident . to_string ())"]
expression_str = "tokenize_ident_to_subwords (& ident . to_string ())"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."StructLatticeInfo :: new"]
expression_str = "StructLatticeInfo :: new"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."while let Some (entry) = entries . next_entry () . await ? { let entry_path = entry . path () ; let relative_path = entry_path . strip_prefix (& current_src) . unwrap () ; let destination_path = current_dst . join (relative_path) ; if entry_path . is_dir () { fs :: create_dir_all (& destination_path) . await ? ; stack . push (entry_path) ; } else { fs :: copy (& entry_path , & destination_path) . await ? ; } }"]
expression_str = "while let Some (entry) = entries . next_entry () . await ? { let entry_path = entry . path () ; let relative_path = entry_path . strip_prefix (& current_src) . unwrap () ; let destination_path = current_dst . join (relative_path) ; if entry_path . is_dir () { fs :: create_dir_all (& destination_path) . await ? ; stack . push (entry_path) ; } else { fs :: copy (& entry_path , & destination_path) . await ? ; } }"
depth = 3
used_types = []
other_types_count = 0
node_type = "While"

[expressions."prelude_generator :: public_tests :: test_modify_crate_root_adds_mod_prelude"]
expression_str = "prelude_generator :: public_tests :: test_modify_crate_root_adds_mod_prelude"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."& variant . ident"]
expression_str = "& variant . ident"
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions.consts_output_dir]
expression_str = "consts_output_dir"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."tokens . to_string ()"]
expression_str = "tokens . to_string ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."tokio :: fs :: create_dir_all (& constants_output_dir) . await"]
expression_str = "tokio :: fs :: create_dir_all (& constants_output_dir) . await"
depth = 4
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.'for entry in WalkDir :: new (output_dir) . into_iter () . filter_map (| e | e . ok ()) { let path = entry . path () ; if path . is_file () && path . extension () . map_or (false , | ext | ext == "rs") { println ! ("    -> Processing file: {}" , path . display ()) ; let content = fs :: read_to_string (path) . await ? ; match syn :: parse_file (& content) { Ok (file) => { println ! ("       Successfully parsed file: {}" , path . display ()) ; for item in file . items { if let syn :: Item :: Const (constant) = item { let type_name = get_type_name (& constant . ty) ; let value_str = get_constant_value_string (& constant . expr) ; println ! ("         Found constant: {} (type: {}, value: {})" , constant . ident , type_name , value_str) ; if ! type_name . is_empty () && ! value_str . is_empty () { * constants_by_type_and_size . entry (type_name) . or_default () . entry (value_str) . or_insert (0) += 1 ; } } } } , Err (e) => { eprintln ! ("       Failed to parse file {}: {}" , path . display () , e) ; } } } }']
expression_str = 'for entry in WalkDir :: new (output_dir) . into_iter () . filter_map (| e | e . ok ()) { let path = entry . path () ; if path . is_file () && path . extension () . map_or (false , | ext | ext == "rs") { println ! ("    -> Processing file: {}" , path . display ()) ; let content = fs :: read_to_string (path) . await ? ; match syn :: parse_file (& content) { Ok (file) => { println ! ("       Successfully parsed file: {}" , path . display ()) ; for item in file . items { if let syn :: Item :: Const (constant) = item { let type_name = get_type_name (& constant . ty) ; let value_str = get_constant_value_string (& constant . expr) ; println ! ("         Found constant: {} (type: {}, value: {})" , constant . ident , type_name , value_str) ; if ! type_name . is_empty () && ! value_str . is_empty () { * constants_by_type_and_size . entry (type_name) . or_default () . entry (value_str) . or_insert (0) += 1 ; } } } } , Err (e) => { eprintln ! ("       Failed to parse file {}: {}" , path . display () , e) ; } } } }'
depth = 2
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions.'file_path . strip_prefix (& project_root) . unwrap_or (& file_path) . with_extension ("") . to_str () . unwrap_or ("unknown_module") . to_string () . replace ("/" , "::")']
expression_str = 'file_path . strip_prefix (& project_root) . unwrap_or (& file_path) . with_extension ("") . to_str () . unwrap_or ("unknown_module") . to_string () . replace ("/" , "::")'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'"popd\n\n"']
expression_str = '"popd\n\n"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'{ let mut full_path = base_path . join ("::") ; if ! full_path . is_empty () { full_path . push_str ("::") ; } flat_uses . push (UseStatement { statement : format ! ("use {} as {};" , full_path , rename . rename . to_string ()) , error : None , git_details : None , nix_details : None , rust_details : None , cargo_details : None , syn_details : None , llvm_details : None , linux_details : None , }) ; }']
expression_str = '{ let mut full_path = base_path . join ("::") ; if ! full_path . is_empty () { full_path . push_str ("::") ; } flat_uses . push (UseStatement { statement : format ! ("use {} as {};" , full_path , rename . rename . to_string ()) , error : None , git_details : None , nix_details : None , rust_details : None , cargo_details : None , syn_details : None , llvm_details : None , linux_details : None , }) ; }'
depth = 3
used_types = []
other_types_count = 0
node_type = "Block"

[expressions."args . verbose"]
expression_str = "args . verbose"
depth = 4
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'"char"']
expression_str = '"char"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'format ! ("--- METRICS_START ---\n{}\n--- METRICS_END ---\n" , json_metrics) . as_bytes ()']
expression_str = 'format ! ("--- METRICS_START ---\n{}\n--- METRICS_END ---\n" , json_metrics) . as_bytes ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."if ! primitive_types . contains (& type_str . as_str ()) { match i { Type :: Path (type_path) => { if let Some (segment) = type_path . path . segments . last () { self . types . insert (segment . ident . to_string ()) ; } } , _ => { self . types . insert (type_str) ; } } }"]
expression_str = "if ! primitive_types . contains (& type_str . as_str ()) { match i { Type :: Path (type_path) => { if let Some (segment) = type_path . path . segments . last () { self . types . insert (segment . ident . to_string ()) ; } } , _ => { self . types . insert (type_str) ; } } }"
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'writer . write_all (format ! ("        -> Parsing expanded code for: {}\n" , file_path . display ()) . as_bytes ())']
expression_str = 'writer . write_all (format ! ("        -> Parsing expanded code for: {}\n" , file_path . display ()) . as_bytes ())'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."prelude_path . exists () && ! force"]
expression_str = "prelude_path . exists () && ! force"
depth = 5
used_types = []
other_types_count = 0
node_type = "Binary"

[expressions."visit :: visit_item (self , i)"]
expression_str = "visit :: visit_item (self , i)"
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'"rust-decl-splitter" . to_string ()']
expression_str = '"rust-decl-splitter" . to_string ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."self . types . insert (type_str)"]
expression_str = "self . types . insert (type_str)"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."prelude_generator :: public_tests :: test_args_default_values"]
expression_str = "prelude_generator :: public_tests :: test_args_default_values"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'tokio :: process :: Command :: new (hf_validator_executable . to_str () . unwrap ()) . current_dir (& self . args . path) . envs (std :: env :: vars_os ()) . arg ("analyze-rust-to-ir") . arg (hf_validator_project_dir . as_os_str ()) . arg (output_path . as_os_str ()) . status () . await . context ("Failed to execute hf-validator command") ?']
expression_str = 'tokio :: process :: Command :: new (hf_validator_executable . to_str () . unwrap ()) . current_dir (& self . args . path) . envs (std :: env :: vars_os ()) . arg ("analyze-rust-to-ir") . arg (hf_validator_project_dir . as_os_str ()) . arg (output_path . as_os_str ()) . status () . await . context ("Failed to execute hf-validator command") ?'
depth = 4
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."run_category_pipeline (& mut stdout , & content , & file_path_str , & args , & config ,)"]
expression_str = "run_category_pipeline (& mut stdout , & content , & file_path_str , & args , & config ,)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."let Some (output_path) = _output_global_toml"]
expression_str = "let Some (output_path) = _output_global_toml"
depth = 3
used_types = []
other_types_count = 0
node_type = "Let"

[expressions.'" Generate a test verification script and report from a JSON test report."']
expression_str = '" Generate a test verification script and report from a JSON test report."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."GemConfig :: load_from_file"]
expression_str = "GemConfig :: load_from_file"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."output_dir . exists ()"]
expression_str = "output_dir . exists ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."Some (config_parser :: read_config (config_path , & project_root) ?)"]
expression_str = "Some (config_parser :: read_config (config_path , & project_root) ?)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'fs :: write ("prelude_generator_summary.md" , report_content) ?']
expression_str = 'fs :: write ("prelude_generator_summary.md" , report_content) ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'self . symbol_map . resolve_and_increment_usage (segment . ident . to_string () , "function" . to_string () , self . crate_name . clone () , self . module_path . clone () ,)']
expression_str = 'self . symbol_map . resolve_and_increment_usage (segment . ident . to_string () , "function" . to_string () , self . crate_name . clone () , self . module_path . clone () ,)'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."sorted_crate_paths . sort_by (| a , b | a . cmp (b))"]
expression_str = "sorted_crate_paths . sort_by (| a , b | a . cmp (b))"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'| | format ! ("Failed to read file: {}" , file_path . display ())']
expression_str = '| | format ! ("Failed to read file: {}" , file_path . display ())'
depth = 4
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions.'tokio :: task :: spawn_blocking (move | | -> anyhow :: Result < _ > { let ast = syn :: parse_file (& source_code) . context ("Failed to parse source code for use statement extraction") ? ; let mut use_statements = Vec :: new () ; for item in ast . items { if let syn :: Item :: Use (use_item) = item { use_statements . push (code_generator :: use_item_to_string (& use_item)) ; } } Ok (UseStatements (use_statements)) }) . await . context ("Blocking task for extracting use statements failed") ? ?']
expression_str = 'tokio :: task :: spawn_blocking (move | | -> anyhow :: Result < _ > { let ast = syn :: parse_file (& source_code) . context ("Failed to parse source code for use statement extraction") ? ; let mut use_statements = Vec :: new () ; for item in ast . items { if let syn :: Item :: Use (use_item) = item { use_statements . push (code_generator :: use_item_to_string (& use_item)) ; } } Ok (UseStatements (use_statements)) }) . await . context ("Blocking task for extracting use statements failed") ? ?'
depth = 4
used_types = [
    "_",
    "Result",
]
other_types_count = 2
node_type = "Unknown"

[expressions.'{ eprintln ! ("Error extracting declarations from file {:?}: {}" , file_path , e) ; }']
expression_str = '{ eprintln ! ("Error extracting declarations from file {:?}: {}" , file_path , e) ; }'
depth = 4
used_types = []
other_types_count = 0
node_type = "Block"

[expressions."{ self . types . insert (type_str) ; }"]
expression_str = "{ self . types . insert (type_str) ; }"
depth = 4
used_types = []
other_types_count = 0
node_type = "Block"

[expressions.'"Reference" . to_string ()']
expression_str = '"Reference" . to_string ()'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."hf_dataset_reader :: analyze_hf_dataset_asts (& dataset_output_path)"]
expression_str = "hf_dataset_reader :: analyze_hf_dataset_asts (& dataset_output_path)"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'{ uses . insert ("use syn::{ItemConst, ItemStruct};\n") ; uses . insert ("use syn::visit::Visit;\n") ; }']
expression_str = '{ uses . insert ("use syn::{ItemConst, ItemStruct};\n") ; uses . insert ("use syn::visit::Visit;\n") ; }'
depth = 5
used_types = []
other_types_count = 0
node_type = "Block"

[expressions._args]
expression_str = "_args"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'measurement :: record_function_entry ("ExtractUsesFunctor::map")']
expression_str = 'measurement :: record_function_entry ("ExtractUsesFunctor::map")'
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."prelude_generator :: public_tests :: test_generate_prelude_no_force_no_overwrite ()"]
expression_str = "prelude_generator :: public_tests :: test_generate_prelude_no_force_no_overwrite ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."fs :: read_to_string (& file_path)"]
expression_str = "fs :: read_to_string (& file_path)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."if let syn :: Pat :: Path (pat_path) = & arm . pat { if let Some (segment) = pat_path . path . segments . last () { matched_variant_types . insert (segment . ident . to_string ()) ; } }"]
expression_str = "if let syn :: Pat :: Path (pat_path) = & arm . pat { if let Some (segment) = pat_path . path . segments . last () { matched_variant_types . insert (segment . ident . to_string ()) ; } }"
depth = 4
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'"\n\nEnum Lattice Information\n"']
expression_str = '"\n\nEnum Lattice Information\n"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."serde_json :: to_string_pretty (& dummy_results) ?"]
expression_str = "serde_json :: to_string_pretty (& dummy_results) ?"
depth = 4
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."crate :: config_parser :: read_config (config_file_path , & project_root)"]
expression_str = "crate :: config_parser :: read_config (config_file_path , & project_root)"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."for field in structure . fields . iter () { if let syn :: Type :: Path (type_path) = & field . ty { add_uses_from_type_path (type_path , & mut uses) ; } }"]
expression_str = "for field in structure . fields . iter () { if let syn :: Type :: Path (type_path) = & field . ty { add_uses_from_type_path (type_path , & mut uses) ; } }"
depth = 2
used_types = []
other_types_count = 0
node_type = "ForLoop"

[expressions.'syn :: parse_file (& content) . with_context (| | format ! ("Failed to parse Rust file: {}" , file_path . display ()))']
expression_str = 'syn :: parse_file (& content) . with_context (| | format ! ("Failed to parse Rust file: {}" , file_path . display ()))'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'script_content . push_str (& format ! ("pushd \"{}\"\n" , crate_path . display ()))']
expression_str = 'script_content . push_str (& format ! ("pushd \"{}\"\n" , crate_path . display ()))'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."decl . referenced_types . iter ()"]
expression_str = "decl . referenced_types . iter ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."self . struct_lattices . entry (struct_name . clone ()) . or_insert_with (| | StructLatticeInfo :: new (struct_name))"]
expression_str = "self . struct_lattices . entry (struct_name . clone ()) . or_insert_with (| | StructLatticeInfo :: new (struct_name))"
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'format ! ("Failed to read file content for hashing: {}" , file_path . display ())']
expression_str = 'format ! ("Failed to read file content for hashing: {}" , file_path . display ())'
depth = 5
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions.'writer . write_all (format ! ("        -> rustc stdout for {}: {}\n" , file_path . display () , String :: from_utf8_lossy (& output . stdout)) . as_bytes ()) . await ?']
expression_str = 'writer . write_all (format ! ("        -> rustc stdout for {}: {}\n" , file_path . display () , String :: from_utf8_lossy (& output . stdout)) . as_bytes ()) . await ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'host_line . and_then (| line | line . split_whitespace () . nth (1)) . unwrap_or ("unknown") . to_string ()']
expression_str = 'host_line . and_then (| line | line . split_whitespace () . nth (1)) . unwrap_or ("unknown") . to_string ()'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."ast . items"]
expression_str = "ast . items"
depth = 4
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.item]
expression_str = "item"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'flat_uses . push (UseStatement { statement : format ! ("use {};" , full_path) , error : None , git_details : None , nix_details : None , rust_details : None , cargo_details : None , syn_details : None , llvm_details : None , linux_details : None , })']
expression_str = 'flat_uses . push (UseStatement { statement : format ! ("use {};" , full_path) , error : None , git_details : None , nix_details : None , rust_details : None , cargo_details : None , syn_details : None , llvm_details : None , linux_details : None , })'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."ReferenceVisitor :: new"]
expression_str = "ReferenceVisitor :: new"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."std :: fs :: read_to_string (& path)"]
expression_str = "std :: fs :: read_to_string (& path)"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'script_content . push_str ("cargo test\n")']
expression_str = 'script_content . push_str ("cargo test\n")'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."_args . use_statements_output_dir . clone ()"]
expression_str = "_args . use_statements_output_dir . clone ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."args . results_file . unwrap ()"]
expression_str = "args . results_file . unwrap ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'if structure . ident . to_string () == "Level0DeclsVisitor" { uses . insert ("use syn::{ItemConst, ItemStruct};\n") ; uses . insert ("use syn::visit::Visit;\n") ; }']
expression_str = 'if structure . ident . to_string () == "Level0DeclsVisitor" { uses . insert ("use syn::{ItemConst, ItemStruct};\n") ; uses . insert ("use syn::visit::Visit;\n") ; }'
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions."crate :: constant_storage :: string_constants :: write_string_constants_to_hierarchical_structure"]
expression_str = "crate :: constant_storage :: string_constants :: write_string_constants_to_hierarchical_structure"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'"u128"']
expression_str = '"u128"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'tokio :: task :: spawn_blocking (move | | -> anyhow :: Result < _ > { let ast = match syn :: parse_file (& content) { Ok (ast) => ast , Err (_) => { return Err (anyhow :: anyhow ! ("Failed to parse file and expand macros")) ; } } ; Ok (prettyplease :: unparse (& ast)) }) . await . context ("Blocking task for parsing failed") ? ?']
expression_str = 'tokio :: task :: spawn_blocking (move | | -> anyhow :: Result < _ > { let ast = match syn :: parse_file (& content) { Ok (ast) => ast , Err (_) => { return Err (anyhow :: anyhow ! ("Failed to parse file and expand macros")) ; } } ; Ok (prettyplease :: unparse (& ast)) }) . await . context ("Blocking task for parsing failed") ? ?'
depth = 4
used_types = [
    "Result",
    "_",
]
other_types_count = 2
node_type = "Unknown"

[expressions.'"HuggingFaceValidatorFunctor::map"']
expression_str = '"HuggingFaceValidatorFunctor::map"'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."! results . is_empty ()"]
expression_str = "! results . is_empty ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "Unary"

[expressions.'_args . ast_analysis_path . clone () . ok_or_else (| | anyhow :: anyhow ! ("ast_analysis_path is required when analyze_ast is true")) ?']
expression_str = '_args . ast_analysis_path . clone () . ok_or_else (| | anyhow :: anyhow ! ("ast_analysis_path is required when analyze_ast is true")) ?'
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."tokio :: fs :: create_dir_all"]
expression_str = "tokio :: fs :: create_dir_all"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.rustc_host]
expression_str = "rustc_host"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'format ! ("Failed to write public symbols to file: {:?}" , public_symbols_output_path)']
expression_str = 'format ! ("Failed to write public symbols to file: {:?}" , public_symbols_output_path)'
depth = 4
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions."| a , b | b . 1 . count . cmp (& a . 1 . count)"]
expression_str = "| a , b | b . 1 . count . cmp (& a . 1 . count)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions.expr]
expression_str = "expr"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."self . current_field_accesses . insert (field_ident)"]
expression_str = "self . current_field_accesses . insert (field_ident)"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."grouped_by_other_types . get (& other_types_count) . unwrap ()"]
expression_str = "grouped_by_other_types . get (& other_types_count) . unwrap ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'fs :: write (output_path , & report_content) . context (format ! ("Failed to write type usage report to {:?}" , output_path))']
expression_str = 'fs :: write (output_path , & report_content) . context (format ! ("Failed to write type usage report to {:?}" , output_path))'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."generate_prelude (& src_dir , prelude_content , false , false)"]
expression_str = "generate_prelude (& src_dir , prelude_content , false , false)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."constants_output_dir . join (& file_name)"]
expression_str = "constants_output_dir . join (& file_name)"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."prelude_generator :: public_tests :: test_extract_test_cases_from_file ()"]
expression_str = "prelude_generator :: public_tests :: test_extract_test_cases_from_file ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.all_impl_lattices]
expression_str = "all_impl_lattices"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."extract_declarations_from_single_file (file_path , rustc_info , crate_name , verbose ,) . await"]
expression_str = "extract_declarations_from_single_file (file_path , rustc_info , crate_name , verbose ,) . await"
depth = 3
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.'"HashMap"']
expression_str = '"HashMap"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."std :: collections :: HashSet :: new"]
expression_str = "std :: collections :: HashSet :: new"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."quote ! { # constant } . to_string ()"]
expression_str = "quote ! { # constant } . to_string ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions._output_symbol_map]
expression_str = "_output_symbol_map"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'"Call"']
expression_str = '"Call"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.'format ! ("Failed to parse config file: {}" , config_path . display ())']
expression_str = 'format ! ("Failed to parse config file: {}" , config_path . display ())'
depth = 5
used_types = []
other_types_count = 0
node_type = "Macro"

[expressions."generate_prelude :: generate_prelude (& src_dir , new_prelude_content , false , true) ?"]
expression_str = "generate_prelude :: generate_prelude (& src_dir , new_prelude_content , false , true) ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'" Modifies the crate root (`lib.rs` or `main.rs`) to ensure it contains `pub mod prelude;`."']
expression_str = '" Modifies the crate root (`lib.rs` or `main.rs`) to ensure it contains `pub mod prelude;`."'
depth = 2
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."generate_prelude :: generate_prelude (& src_dir , prelude_content , false , false)"]
expression_str = "generate_prelude :: generate_prelude (& src_dir , prelude_content , false , false)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'"Lit" . to_string ()']
expression_str = '"Lit" . to_string ()'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."Utc :: now"]
expression_str = "Utc :: now"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'"Struct" . to_string ()']
expression_str = '"Struct" . to_string ()'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."| e | { if let Some (names) = filter_names { names . iter () . any (| name | e . file_name () . to_string_lossy () . contains (name)) } else { true } }"]
expression_str = "| e | { if let Some (names) = filter_names { names . iter () . any (| name | e . file_name () . to_string_lossy () . contains (name)) } else { true } }"
depth = 4
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions."info . file_path . as_path ()"]
expression_str = "info . file_path . as_path ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."if contains_complex_attributes (i) || contains_complex_fields (i) { entry . layer = Some (1) ; }"]
expression_str = "if contains_complex_attributes (i) || contains_complex_fields (i) { entry . layer = Some (1) ; }"
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'fs :: write (& output_path , toml_string) . context (format ! ("Failed to write symbol map to file: {:?}" , output_path))']
expression_str = 'fs :: write (& output_path , toml_string) . context (format ! ("Failed to write symbol map to file: {:?}" , output_path))'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."* path = project_root . join (& path)"]
expression_str = "* path = project_root . join (& path)"
depth = 5
used_types = []
other_types_count = 0
node_type = "Assign"

[expressions.'writer . write_all (format ! ("--- End AST Node Type Report ---\n") . as_bytes ())']
expression_str = 'writer . write_all (format ! ("--- End AST Node Type Report ---\n") . as_bytes ())'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."std :: env :: current_dir () ? . parent () . unwrap () . to_path_buf ()"]
expression_str = "std :: env :: current_dir () ? . parent () . unwrap () . to_path_buf ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'& format ! ("    column_stats.insert(\"{}\".to_string(), ({}, {}, {}, {}));\n" , node_type , min , max , sum , count)']
expression_str = '& format ! ("    column_stats.insert(\"{}\".to_string(), ({}, {}, {}, {}));\n" , node_type , min , max , sum , count)'
depth = 4
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."entries . next_entry () . await ?"]
expression_str = "entries . next_entry () . await ?"
depth = 5
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions.'"        // line_stats,\n"']
expression_str = '"        // line_stats,\n"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."current_src . strip_prefix (src . as_ref ()) . unwrap ()"]
expression_str = "current_src . strip_prefix (src . as_ref ()) . unwrap ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."args . cache_report"]
expression_str = "args . cache_report"
depth = 3
used_types = []
other_types_count = 0
node_type = "Field"

[expressions.'"main.rs"']
expression_str = '"main.rs"'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."match struct_name . as_str () { \"DeclsVisitor\" => { format ! (\"use syn::{{visit::Visit, ItemConst, ItemFn, ItemStruct, ItemEnum, ItemStatic, Item}};\n{}\" , content) } , \"TypeCollector\" => { format ! (\"use std::collections::HashMap;\nuse crate::type_extractor::TypeInfo;\n{}\" , content) } , _ => content , }"]
expression_str = """
match struct_name . as_str () { "DeclsVisitor" => { format ! ("use syn::{{visit::Visit, ItemConst, ItemFn, ItemStruct, ItemEnum, ItemStatic, Item}};
{}" , content) } , "TypeCollector" => { format ! ("use std::collections::HashMap;
use crate::type_extractor::TypeInfo;
{}" , content) } , _ => content , }"""
depth = 4
used_types = []
other_types_count = 0
node_type = "Match"

[expressions.'"--force"']
expression_str = '"--force"'
depth = 5
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."RustcInfo { version : rustc_version , host : rustc_host }"]
expression_str = "RustcInfo { version : rustc_version , host : rustc_host }"
depth = 2
used_types = []
other_types_count = 0
node_type = "Struct"

[expressions.c]
expression_str = "c"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'"SynParsingFailed" . to_string ()']
expression_str = '"SynParsingFailed" . to_string ()'
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."output . stderr"]
expression_str = "output . stderr"
depth = 5
used_types = []
other_types_count = 0
node_type = "Field"

[expressions."super :: report :: generate_report (& results)"]
expression_str = "super :: report :: generate_report (& results)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'"    let mut snippet_length_stats = HashMap::new();\n"']
expression_str = '"    let mut snippet_length_stats = HashMap::new();\n"'
depth = 3
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."self . add_ident_to_bag (& variant . ident)"]
expression_str = "self . add_ident_to_bag (& variant . ident)"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."syn :: visit :: visit_item_fn (self , i)"]
expression_str = "syn :: visit :: visit_item_fn (self , i)"
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."& i . arms"]
expression_str = "& i . arms"
depth = 3
used_types = []
other_types_count = 0
node_type = "Reference"

[expressions."if let Some (segment) = pat_tuple_struct . path . segments . last () { self . enum_lattice_info . add_co_occurrence (BTreeSet :: from ([segment . ident . to_string ()])) ; }"]
expression_str = "if let Some (segment) = pat_tuple_struct . path . segments . last () { self . enum_lattice_info . add_co_occurrence (BTreeSet :: from ([segment . ident . to_string ()])) ; }"
depth = 4
used_types = []
other_types_count = 0
node_type = "If"

[expressions."fs :: create_dir_all (& dst) . await ?"]
expression_str = "fs :: create_dir_all (& dst) . await ?"
depth = 2
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."tokio :: fs :: create_dir_all (& numerical_output_dir)"]
expression_str = "tokio :: fs :: create_dir_all (& numerical_output_dir)"
depth = 5
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."fs :: set_permissions"]
expression_str = "fs :: set_permissions"
depth = 4
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."results . iter () . filter (| r | matches ! (r . status , FileProcessingStatus :: Success))"]
expression_str = "results . iter () . filter (| r | matches ! (r . status , FileProcessingStatus :: Success))"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'if let Some (path_env) = std :: env :: var_os ("PATH") { writer . write_all (format ! ("  -> PATH: {:#?}\n" , path_env) . as_bytes ()) . await ? ; }']
expression_str = 'if let Some (path_env) = std :: env :: var_os ("PATH") { writer . write_all (format ! ("  -> PATH: {:#?}\n" , path_env) . as_bytes ()) . await ? ; }'
depth = 4
used_types = []
other_types_count = 0
node_type = "If"

[expressions.'workspace_path . join (".prelude_cache")']
expression_str = 'workspace_path . join (".prelude_cache")'
depth = 2
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."crate_root . to_string_lossy ()"]
expression_str = "crate_root . to_string_lossy ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.visitor]
expression_str = "visitor"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."s . to_lowercase ()"]
expression_str = "s . to_lowercase ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions.'line . starts_with ("rustc ")']
expression_str = 'line . starts_with ("rustc ")'
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."crate :: utils :: validate_rust_code (& output_file_path) . await"]
expression_str = "crate :: utils :: validate_rust_code (& output_file_path) . await"
depth = 4
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.main_rs_path]
expression_str = "main_rs_path"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'if ! results . is_empty () { report_content . push_str ("## Detailed Results\n") ; for result in results { report_content . push_str (& format ! ("### {}\n" , result . path . display ())) ; match & result . status { FileProcessingStatus :: Success => { report_content . push_str ("- Status:  Successfully Processed\n\n") ; } FileProcessingStatus :: Skipped { reason } => { report_content . push_str (& format ! ("- Status:  Skipped (Reason: {}\n\n" , reason)) ; } FileProcessingStatus :: Failed { error } => { report_content . push_str (& format ! ("- Status:  Failed (Error: {}\n\n" , error)) ; } } } }']
expression_str = 'if ! results . is_empty () { report_content . push_str ("## Detailed Results\n") ; for result in results { report_content . push_str (& format ! ("### {}\n" , result . path . display ())) ; match & result . status { FileProcessingStatus :: Success => { report_content . push_str ("- Status:  Successfully Processed\n\n") ; } FileProcessingStatus :: Skipped { reason } => { report_content . push_str (& format ! ("- Status:  Skipped (Reason: {}\n\n" , reason)) ; } FileProcessingStatus :: Failed { error } => { report_content . push_str (& format ! ("- Status:  Failed (Error: {}\n\n" , error)) ; } } } }'
depth = 2
used_types = []
other_types_count = 0
node_type = "If"

[expressions."fs :: create_dir_all (& project_root)"]
expression_str = "fs :: create_dir_all (& project_root)"
depth = 4
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."syn :: visit :: visit_expr_call (self , i)"]
expression_str = "syn :: visit :: visit_expr_call (self , i)"
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.a]
expression_str = "a"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'"Yield"']
expression_str = '"Yield"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions."Self :: get_expr_node_type (expr)"]
expression_str = "Self :: get_expr_node_type (expr)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'add_primitive_type (& mut symbols , "i128")']
expression_str = 'add_primitive_type (& mut symbols , "i128")'
depth = 2
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."Sha256 :: new"]
expression_str = "Sha256 :: new"
depth = 3
used_types = []
other_types_count = 0
node_type = "Path"

[expressions.'"Await" . to_string ()']
expression_str = '"Await" . to_string ()'
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."| dep | { ! current_layer_idents . contains (dep) && ! layered_decls . values () . flatten () . any (| d | d . get_identifier () == * dep) }"]
expression_str = "| dep | { ! current_layer_idents . contains (dep) && ! layered_decls . values () . flatten () . any (| d | d . get_identifier () == * dep) }"
depth = 5
used_types = []
other_types_count = 0
node_type = "Closure"

[expressions."prelude_generator :: public_tests :: test_modify_file_no_force_no_overwrite ()"]
expression_str = "prelude_generator :: public_tests :: test_modify_file_no_force_no_overwrite ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions."fs :: copy (file_path , & temp_lib_rs_path) . await"]
expression_str = "fs :: copy (file_path , & temp_lib_rs_path) . await"
depth = 4
used_types = []
other_types_count = 0
node_type = "Await"

[expressions.'"If"']
expression_str = '"If"'
depth = 4
used_types = []
other_types_count = 0
node_type = "Lit"

[expressions.file_path]
expression_str = "file_path"
depth = 5
used_types = []
other_types_count = 0
node_type = "Path"

[expressions."ImplMethodCoOccurrenceVisitor { _impl_for_type : & impl_for_type_name , current_method_calls : BTreeSet :: new () , impl_lattice_info , }"]
expression_str = "ImplMethodCoOccurrenceVisitor { _impl_for_type : & impl_for_type_name , current_method_calls : BTreeSet :: new () , impl_lattice_info , }"
depth = 3
used_types = []
other_types_count = 0
node_type = "Struct"

[expressions.'fs :: read_to_string (results_file_path) . context ("Failed to read results file") ?']
expression_str = 'fs :: read_to_string (results_file_path) . context ("Failed to read results file") ?'
depth = 5
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."grouped_by_node_type . get (& node_type)"]
expression_str = "grouped_by_node_type . get (& node_type)"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."report_content . push_str (& format ! (\"\\n### Impl for Type: '{}' (Expressions Analyzed: {}) ###\\n\" , impl_for_type , lattice_info . total_expressions_analyzed))"]
expression_str = '''report_content . push_str (& format ! ("\n### Impl for Type: '{}' (Expressions Analyzed: {}) ###\n" , impl_for_type , lattice_info . total_expressions_analyzed))'''
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."entry ?"]
expression_str = "entry ?"
depth = 3
used_types = []
other_types_count = 0
node_type = "Unknown"

[expressions."results_json_path . clone ()"]
expression_str = "results_json_path . clone ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."prelude_generator :: public_tests :: test_generate_prelude_dry_run ()"]
expression_str = "prelude_generator :: public_tests :: test_generate_prelude_dry_run ()"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[expressions.'writer . write_all (format ! ("--- End AST Node Type Report ---\n") . as_bytes ()) . await']
expression_str = 'writer . write_all (format ! ("--- End AST Node Type Report ---\n") . as_bytes ()) . await'
depth = 3
used_types = []
other_types_count = 0
node_type = "Await"

[expressions."file_to_process . to_string_lossy () . to_string ()"]
expression_str = "file_to_process . to_string_lossy () . to_string ()"
depth = 5
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."impl_lattices . is_empty ()"]
expression_str = "impl_lattices . is_empty ()"
depth = 4
used_types = []
other_types_count = 0
node_type = "MethodCall"

[expressions."if ! impl_lattices . is_empty () { report_content . push_str (\"\\n\\nImpl Lattice Information\\n\") ; report_content . push_str (\"================================================================\n\") ; for (impl_for_type , lattice_info) in impl_lattices { report_content . push_str (& format ! (\"\\n### Impl for Type: '{}' (Expressions Analyzed: {}) ###\\n\" , impl_for_type , lattice_info . total_expressions_analyzed)) ; if lattice_info . method_co_occurrences . is_empty () { report_content . push_str (\"  No method co-occurrence data collected.\\n\") ; } else { let mut sorted_co_occurrences : Vec < (& BTreeSet < String > , & usize) > = lattice_info . method_co_occurrences . iter () . collect () ; sorted_co_occurrences . sort_by_key (| & (_ , count) | count) ; for (method_names , count) in sorted_co_occurrences { report_content . push_str (& format ! (\"  - Co-occurring methods: {:?} (Count: {})\\n\" , method_names , count)) ; } } } }"]
expression_str = '''
if ! impl_lattices . is_empty () { report_content . push_str ("\n\nImpl Lattice Information\n") ; report_content . push_str ("================================================================
") ; for (impl_for_type , lattice_info) in impl_lattices { report_content . push_str (& format ! ("\n### Impl for Type: '{}' (Expressions Analyzed: {}) ###\n" , impl_for_type , lattice_info . total_expressions_analyzed)) ; if lattice_info . method_co_occurrences . is_empty () { report_content . push_str ("  No method co-occurrence data collected.\n") ; } else { let mut sorted_co_occurrences : Vec < (& BTreeSet < String > , & usize) > = lattice_info . method_co_occurrences . iter () . collect () ; sorted_co_occurrences . sort_by_key (| & (_ , count) | count) ; for (method_names , count) in sorted_co_occurrences { report_content . push_str (& format ! ("  - Co-occurring methods: {:?} (Count: {})\n" , method_names , count)) ; } } } }'''
depth = 2
used_types = [
    "(& BTreeSet < String > , & usize)",
    "& usize",
    "& BTreeSet < String >",
    "BTreeSet",
    "Vec",
]
other_types_count = 5
node_type = "If"

[expressions."fs :: read_to_string (& report_path)"]
expression_str = "fs :: read_to_string (& report_path)"
depth = 3
used_types = []
other_types_count = 0
node_type = "Call"

[struct_lattices.CollectedAnalysisData]
struct_name = "CollectedAnalysisData"
total_expressions_analyzed = 0

[struct_lattices.CollectedAnalysisData.field_co_occurrences]

[struct_lattices.RustConfig]
struct_name = "RustConfig"
total_expressions_analyzed = 0

[struct_lattices.RustConfig.field_co_occurrences]

[struct_lattices.CollectedPreludeInfo]
struct_name = "CollectedPreludeInfo"
total_expressions_analyzed = 0

[struct_lattices.CollectedPreludeInfo.field_co_occurrences]

[struct_lattices.DistConfig]
struct_name = "DistConfig"
total_expressions_analyzed = 0

[struct_lattices.DistConfig.field_co_occurrences]

[struct_lattices.BagOfWordsVisitor]
struct_name = "BagOfWordsVisitor"
total_expressions_analyzed = 0

[struct_lattices.BagOfWordsVisitor.field_co_occurrences]

[struct_lattices.RustcInfo]
struct_name = "RustcInfo"
total_expressions_analyzed = 0

[struct_lattices.RustcInfo.field_co_occurrences]

[struct_lattices.PreprocessFunctor]
struct_name = "PreprocessFunctor"
total_expressions_analyzed = 0

[struct_lattices.PreprocessFunctor.field_co_occurrences]

[struct_lattices.TypeUsageVisitor]
struct_name = "TypeUsageVisitor"
total_expressions_analyzed = 0

[struct_lattices.TypeUsageVisitor.field_co_occurrences]

[struct_lattices.TypeCollector]
struct_name = "TypeCollector"
total_expressions_analyzed = 0

[struct_lattices.TypeCollector.field_co_occurrences]

[struct_lattices.EnvConfig]
struct_name = "EnvConfig"
total_expressions_analyzed = 0

[struct_lattices.EnvConfig.field_co_occurrences]

[struct_lattices.EnumVariantCoOccurrenceVisitor]
struct_name = "EnumVariantCoOccurrenceVisitor"
total_expressions_analyzed = 0

[struct_lattices.EnumVariantCoOccurrenceVisitor.field_co_occurrences]

[struct_lattices.ExpressionInfo]
struct_name = "ExpressionInfo"
total_expressions_analyzed = 0

[struct_lattices.ExpressionInfo.field_co_occurrences]

[struct_lattices.TypeInfo]
struct_name = "TypeInfo"
total_expressions_analyzed = 0

[struct_lattices.TypeInfo.field_co_occurrences]

[struct_lattices.StructLatticeInfo]
struct_name = "StructLatticeInfo"
total_expressions_analyzed = 0

[struct_lattices.StructLatticeInfo.field_co_occurrences]

[struct_lattices.ExtractUsesFunctor]
struct_name = "ExtractUsesFunctor"
total_expressions_analyzed = 0

[struct_lattices.ExtractUsesFunctor.field_co_occurrences]

[struct_lattices.BinsConfig]
struct_name = "BinsConfig"
total_expressions_analyzed = 0

[struct_lattices.BinsConfig.field_co_occurrences]

[struct_lattices.ModuleExportsConfig]
struct_name = "ModuleExportsConfig"
total_expressions_analyzed = 0

[struct_lattices.ModuleExportsConfig.field_co_occurrences]

[struct_lattices.AstReconstructionFunctor]
struct_name = "AstReconstructionFunctor"
total_expressions_analyzed = 0

[struct_lattices.AstReconstructionFunctor.field_co_occurrences]

[struct_lattices.Mapping]
struct_name = "Mapping"
total_expressions_analyzed = 0

[struct_lattices.Mapping.field_co_occurrences]

[struct_lattices.Config]
struct_name = "Config"
total_expressions_analyzed = 0

[struct_lattices.Config.field_co_occurrences]

[struct_lattices.NixConfig]
struct_name = "NixConfig"
total_expressions_analyzed = 0

[struct_lattices.NixConfig.field_co_occurrences]

[struct_lattices.HuggingFaceValidatorFunctor]
struct_name = "HuggingFaceValidatorFunctor"
total_expressions_analyzed = 0

[struct_lattices.HuggingFaceValidatorFunctor.field_co_occurrences]

[struct_lattices.SymbolMap]
struct_name = "SymbolMap"
total_expressions_analyzed = 0

[struct_lattices.SymbolMap.field_co_occurrences]

[struct_lattices.StructFieldCoOccurrenceVisitor]
struct_name = "StructFieldCoOccurrenceVisitor"
total_expressions_analyzed = 0

[struct_lattices.StructFieldCoOccurrenceVisitor.field_co_occurrences]

[struct_lattices.ReferenceVisitor]
struct_name = "ReferenceVisitor"
total_expressions_analyzed = 0

[struct_lattices.ReferenceVisitor.field_co_occurrences]

[struct_lattices.Args]
struct_name = "Args"
total_expressions_analyzed = 0

[struct_lattices.Args.field_co_occurrences]

[struct_lattices.GemEntry]
struct_name = "GemEntry"
total_expressions_analyzed = 0

[struct_lattices.GemEntry.field_co_occurrences]

[struct_lattices.DependencyCollector]
struct_name = "DependencyCollector"
total_expressions_analyzed = 0

[struct_lattices.DependencyCollector.field_co_occurrences]

[struct_lattices.DependencyValidator]
struct_name = "DependencyValidator"
total_expressions_analyzed = 0

[struct_lattices.DependencyValidator.field_co_occurrences]

[struct_lattices.ClassifyUsesFunctor]
struct_name = "ClassifyUsesFunctor"
total_expressions_analyzed = 0

[struct_lattices.ClassifyUsesFunctor.field_co_occurrences]

[struct_lattices.LlvmConfig]
struct_name = "LlvmConfig"
total_expressions_analyzed = 0

[struct_lattices.LlvmConfig.field_co_occurrences]

[struct_lattices.CollectedProjectInfo]
struct_name = "CollectedProjectInfo"
total_expressions_analyzed = 0

[struct_lattices.CollectedProjectInfo.field_co_occurrences]

[struct_lattices.InstallConfig]
struct_name = "InstallConfig"
total_expressions_analyzed = 0

[struct_lattices.InstallConfig.field_co_occurrences]

[struct_lattices.ImplMethodCoOccurrenceVisitor]
struct_name = "ImplMethodCoOccurrenceVisitor"
total_expressions_analyzed = 0

[struct_lattices.ImplMethodCoOccurrenceVisitor.field_co_occurrences]

[struct_lattices.BuildConfig]
struct_name = "BuildConfig"
total_expressions_analyzed = 0

[struct_lattices.BuildConfig.field_co_occurrences]

[struct_lattices.ParseFunctor]
struct_name = "ParseFunctor"
total_expressions_analyzed = 0

[struct_lattices.ParseFunctor.field_co_occurrences]

[struct_lattices.EnumLatticeInfo]
struct_name = "EnumLatticeInfo"
total_expressions_analyzed = 0

[struct_lattices.EnumLatticeInfo.field_co_occurrences]

[struct_lattices.InspectFunctor]
struct_name = "InspectFunctor"
total_expressions_analyzed = 0

[struct_lattices.InspectFunctor.field_co_occurrences]

[struct_lattices.TestInfo]
struct_name = "TestInfo"
total_expressions_analyzed = 0

[struct_lattices.TestInfo.field_co_occurrences]

[struct_lattices.FunctionMetrics]
struct_name = "FunctionMetrics"
total_expressions_analyzed = 0

[struct_lattices.FunctionMetrics.field_co_occurrences]

[struct_lattices.FileProcessingResult]
struct_name = "FileProcessingResult"
total_expressions_analyzed = 0

[struct_lattices.FileProcessingResult.field_co_occurrences]

[struct_lattices.ImplLatticeInfo]
struct_name = "ImplLatticeInfo"
total_expressions_analyzed = 0

[struct_lattices.ImplLatticeInfo.field_co_occurrences]

[struct_lattices.GemConfig]
struct_name = "GemConfig"
total_expressions_analyzed = 0

[struct_lattices.GemConfig.field_co_occurrences]

[struct_lattices.ChangeIdConfig]
struct_name = "ChangeIdConfig"
total_expressions_analyzed = 0

[struct_lattices.ChangeIdConfig.field_co_occurrences]

[enum_lattices.ValidationError]
enum_name = "ValidationError"
total_expressions_analyzed = 0

[enum_lattices.ValidationError.variant_type_co_occurrences]

[enum_lattices.FileProcessingStatus]
enum_name = "FileProcessingStatus"
total_expressions_analyzed = 0

[enum_lattices.FileProcessingStatus.variant_type_co_occurrences]

[impl_lattices.AstReconstructionFunctor]
impl_for_type = "AstReconstructionFunctor"
total_expressions_analyzed = 0

[impl_lattices.AstReconstructionFunctor.method_co_occurrences]

[impl_lattices.InspectFunctor]
impl_for_type = "InspectFunctor"
total_expressions_analyzed = 0

[impl_lattices.InspectFunctor.method_co_occurrences]

[impl_lattices.StructFieldCoOccurrenceVisitor]
impl_for_type = "StructFieldCoOccurrenceVisitor"
total_expressions_analyzed = 0

[impl_lattices.StructFieldCoOccurrenceVisitor.method_co_occurrences]

[impl_lattices.StructLatticeInfo]
impl_for_type = "StructLatticeInfo"
total_expressions_analyzed = 0

[impl_lattices.StructLatticeInfo.method_co_occurrences]

[impl_lattices.ExtractUsesFunctor]
impl_for_type = "ExtractUsesFunctor"
total_expressions_analyzed = 0

[impl_lattices.ExtractUsesFunctor.method_co_occurrences]

[impl_lattices.ReferenceVisitor]
impl_for_type = "ReferenceVisitor"
total_expressions_analyzed = 0

[impl_lattices.ReferenceVisitor.method_co_occurrences]

[impl_lattices.ClassifyUsesFunctor]
impl_for_type = "ClassifyUsesFunctor"
total_expressions_analyzed = 0

[impl_lattices.ClassifyUsesFunctor.method_co_occurrences]

[impl_lattices.EnumLatticeInfo]
impl_for_type = "EnumLatticeInfo"
total_expressions_analyzed = 0

[impl_lattices.EnumLatticeInfo.method_co_occurrences]

[impl_lattices.DependencyValidator]
impl_for_type = "DependencyValidator"
total_expressions_analyzed = 0

[impl_lattices.DependencyValidator.method_co_occurrences]

[impl_lattices.ParseFunctor]
impl_for_type = "ParseFunctor"
total_expressions_analyzed = 0

[impl_lattices.ParseFunctor.method_co_occurrences]

[impl_lattices.PreprocessFunctor]
impl_for_type = "PreprocessFunctor"
total_expressions_analyzed = 0

[impl_lattices.PreprocessFunctor.method_co_occurrences]

[impl_lattices.BagOfWordsVisitor]
impl_for_type = "BagOfWordsVisitor"
total_expressions_analyzed = 0

[impl_lattices.BagOfWordsVisitor.method_co_occurrences]

[impl_lattices.TypeCollector]
impl_for_type = "TypeCollector"
total_expressions_analyzed = 0

[impl_lattices.TypeCollector.method_co_occurrences]

[impl_lattices.ImplMethodCoOccurrenceVisitor]
impl_for_type = "ImplMethodCoOccurrenceVisitor"
total_expressions_analyzed = 0

[impl_lattices.ImplMethodCoOccurrenceVisitor.method_co_occurrences]

[impl_lattices.TypeUsageVisitor]
impl_for_type = "TypeUsageVisitor"
total_expressions_analyzed = 0

[impl_lattices.TypeUsageVisitor.method_co_occurrences]

[impl_lattices.SymbolMap]
impl_for_type = "SymbolMap"
total_expressions_analyzed = 0

[impl_lattices.SymbolMap.method_co_occurrences]

[impl_lattices.GemConfig]
impl_for_type = "GemConfig"
total_expressions_analyzed = 0

[impl_lattices.GemConfig.method_co_occurrences]

[impl_lattices.EnumVariantCoOccurrenceVisitor]
impl_for_type = "EnumVariantCoOccurrenceVisitor"
total_expressions_analyzed = 0

[impl_lattices.EnumVariantCoOccurrenceVisitor.method_co_occurrences]

[impl_lattices.ImplLatticeInfo]
impl_for_type = "ImplLatticeInfo"
total_expressions_analyzed = 0

[impl_lattices.ImplLatticeInfo.method_co_occurrences]

[impl_lattices.HuggingFaceValidatorFunctor]
impl_for_type = "HuggingFaceValidatorFunctor"
total_expressions_analyzed = 0

[impl_lattices.HuggingFaceValidatorFunctor.method_co_occurrences]

[impl_lattices.DependencyCollector]
impl_for_type = "DependencyCollector"
total_expressions_analyzed = 0

[impl_lattices.DependencyCollector.method_co_occurrences]

[impl_lattices.FunctionMetrics]
impl_for_type = "FunctionMetrics"
total_expressions_analyzed = 0

[impl_lattices.FunctionMetrics.method_co_occurrences]
